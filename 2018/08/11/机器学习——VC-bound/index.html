<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>机器学习——VC bound | 無聊時的自娛自樂</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="上次的Hoeffding不等式那篇，证明了一个hypothesis集合是有限集合，那么学习是可行的。">
<meta name="keywords" content="machine learning,mathematics">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习——VC bound">
<meta property="og:url" content="http://wlsdzyzl.com/2018/08/11/机器学习——VC-bound/index.html">
<meta property="og:site_name" content="無聊時的自娛自樂">
<meta property="og:description" content="上次的Hoeffding不等式那篇，证明了一个hypothesis集合是有限集合，那么学习是可行的。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/SEKLYM%60EURGS%40%5D4F%247%5B347X.png">
<meta property="og:image" content="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/XU%5DTY%7DQ%24SSE4X%40B%24_A1ZORN.png">
<meta property="og:image" content="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/M%29P32DW%29EE9%7BWB%246A08T8%29X.png">
<meta property="og:updated_time" content="2018-08-14T14:23:34.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习——VC bound">
<meta name="twitter:description" content="上次的Hoeffding不等式那篇，证明了一个hypothesis集合是有限集合，那么学习是可行的。">
<meta name="twitter:image" content="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/SEKLYM%60EURGS%40%5D4F%247%5B347X.png">
  
    <link rel="alternate" href="/atom.xml" title="無聊時的自娛自樂" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">無聊時的自娛自樂</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://wlsdzyzl.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-机器学习——VC-bound" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/11/机器学习——VC-bound/" class="article-date">
  <time datetime="2018-08-11T10:13:11.000Z" itemprop="datePublished">2018-08-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习——VC bound
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>上次的Hoeffding不等式那篇，证明了一个hypothesis集合是有限集合，那么学习是可行的。<br><a id="more"></a><br>如果定义$E_{in}$是资料上的错误率，$E_{out}$是整体的错误率，我们证明的结果，如果N足够大，那么很大概率上，$E_{in} \approx E_{out}$.我们只需要在有限的集合利用里学习算法选出一个$E_{in}$最低的，就可以实现学习，因为很大概率上它对整体分类后的错误率也是与$E_{in}$差不太多的。</p>
<p>先思考一个问题，H的大小影响的了什么？学习需要做的有两个：1. 保证$E_{in} \approx E_{out}$ 2.找到一个h使得$E_{in}很小$。<br>如果H集合过大，那么我们不容易保证第一个条件，但是如果集合过小，我们不一定能找到一个h使得它甚至在测试数据上有很好的表现。</p>
<p>上次博客留下来了一个问题：如果这个$H$集合是无限集合呢？例如之前实现的PLA算法。那我们怎么保证在无限的集合上，学习是可行的呢？</p>
<p>首先，我们来观察上次得到的hoeffding不等式：$P_{baddata} \leq 2te^{-2\epsilon ^2N}.如果其中t-&gt;$\lnfty$，那么这个不等式实际上是没有意义的，因为右边的值将会远大于1，但是说一个概率小于等于1那是废话。</p>
<p>仔细想想，那是因为我们的union bound太宽松了。它们实际上会有很多重叠的部分，比如对于某个hypothesis是bad data，对于另一个它可能也是。这就要求我们将这个union bound继续压缩。</p>
<p>利用2D的perceptron learning algorithm来举例，如果N = 1，也就是我们只有一个样本，那么它要么是正要么是负，虽然平面上有无数条线，但是似乎只有这么两个效果，也就是只有这么两类线，在这两类线上，它们的$E_{in}$是一致的。</p>
<p>同样的道理，如果平面上有两个点，我们利用平面上的直线最多也就只能分成4种情况,我们将每一种情况称为一个dichotomy。</p>
<p>当N为3的时候，在纸上我们可以画出，平面上可以有8种dichotomy，但是也会有意外，例如如果3个点拍成一条直线，那么“× ○ ×”的情况，我们似乎无法用一条直线分开了。</p>
<p>当N为4的时候，即使4个点是每一个点都是凸四边形的顶点，我们依然无法将所有的情况都表示出来，如下面这种情况：</p>
<p>× ○</p>
<p>○ ×</p>
<p>实际上，当N为4的时候，我们可以分出来的dichotomy共有14种。而所有的情况有$2^4=16$种，很明显可以看出dichotomy的数量是少于$2^N$。</p>
<p>我们将某个大小为N的dataset所有情况都可以用这个H做出来(dichotomy的数量为$2^N$)，成为被H shatter。</p>
<p>当N&gt;4的时候，这个dichotomy又有多少？现在我们很难找到2d perceptron其中这个规律。幸运的是最后我们也不需要关注它具体是多少。</p>
<p>在这里我们考虑几种不同的简单的H，来更加熟悉这个概念：</p>
<ol>
<li>Positive Ray</li>
</ol>
<p>样本为1维的点，这个hypothesis set是在直线上所有的非样本点，选取一个点，该点坐标之前的为positive，之后的为negative。容易看出来，当样本个数为N时候，最多可以有N+1个dichotomy（N个点将该轴分为N+1个部分，每个部分的点是一类）。</p>
<ol start="2">
<li>Positive Intervals</li>
</ol>
<p>样本依然是1维的点，这个hypothesis set是选取一个范围，范围内的为positive，范围之外的为negative。当样本个数为N的时候，最多可以有$\frac {(N+1)N} {2}+1$个dichotomy（N个点将该轴分为N+1个部分，从N+1个部分中任两个取一个点即可，但是这样还缺一种，就是全是positive的情况，我们依然可以做到将这个情况，只需要将两次的点选在同一个部分即可）。</p>
<ol start="3">
<li>Convex Sets</li>
</ol>
<p>样本是二维的点，并且是凸N边形的顶点。选取一个凸多边形的范围，使得多边形内部为positive，外部为negative。可以看到任何时候这个dataset都可以被H shatter，所以它的dichotomy个数是$2^N$.</p>
<p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/SEKLYM%60EURGS%40%5D4F%247%5B347X.png" alt="1"></p>
<ol start="4">
<li>1D perceptron（positive/negative ray）</li>
</ol>
<p>与1类似，除了最端点的两个部分，其他的分割之后都有个与之对立的dichotomy，而端点的部分得到的是全p或者全n，所有是$2(N+1-2)+2 = 2N$.</p>
<p>而这个2N，N+1等等，我们乘其为成长函数。假设我们希望用$m_H$来代替乘进去的那个集合的大小，用$m_H(N)$来表示成长函数，例如：对于positive ray来说，$m_H(N) = N+1$。</p>
<h2 id="Break-Point"><a href="#Break-Point" class="headerlink" title="Break Point"></a>Break Point</h2><p>我们引入一个新的定义，叫做Break Point，它表示第一个所有情况下都不能被shatter的样本个数。我们将break point简写为k，举个例子，positive ray的k = 2，因为$2+1!=2^2$，同样的道理，positive intervals的k = 3，1D perceptron的k = 3，convex sets的k不存在。</p>
<p>如果用2D perceptron为例，他的k = 4，但是我们很难得到它的成长函数。我们希望它的成长函数可以是一个多项式，这样随着N的增加，$E_{in}$与$E_{out}$还是会很大可能相差不多的。</p>
<p>找不到成长函数，另一个希望是可以找到成长函数的上限。比如，在k = 4的情况下，N个样本最多能产生几个dichotomy？我们将这个简写为B(N,k).<br>k = 4，意味着任意3个样本都不能被shatter。我们试图去填写下面这样的一个表格：</p>
<table>
<thead>
<tr>
<th>B(N,k)</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">…</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">…</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">3</td>
<td style="text-align:center">4</td>
<td style="text-align:center">4</td>
<td style="text-align:center">4</td>
<td style="text-align:center">…</td>
<td>4</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center">7</td>
<td style="text-align:center">8</td>
<td style="text-align:center">8</td>
<td style="text-align:center">…</td>
<td>8</td>
</tr>
<tr>
<td>4</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">15</td>
<td style="text-align:center">16</td>
<td style="text-align:center">…</td>
<td>16</td>
</tr>
<tr>
<td>5</td>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">31</td>
<td style="text-align:center">…</td>
<td>32</td>
</tr>
</tbody>
</table>
<p>表格中的已经填写的部分我们很容易就知道了，如果N &lt; k，那么可以shatter，答案就是$2^N$，如果N = k，那么恰好不能shatter，所以最多就是$2^N-1$,接下来我们尝试一个简单的,N = 3,k = 2的情况。我们一个个列举所看到的情况，很容易发现最多最多，可以写出4个dichotomy，任意两个都没有被shatter,如下：</p>
<p>o o o</p>
<p>o o x</p>
<p>o x x</p>
<p>x o o </p>
<p>我们再添加任何一种，都会导致有两个样本被shatter。</p>
<p>将 4 填入表中后，我们发现了一个有趣的规律，在已经填好的数据里，任何一个$B(N,k) = B(N-1,k)+B(N-1,k-1)$，不知道这是否是个巧合？</p>
<p>利用程序$^{见p.s1.}$将B(4,3)的情况跑出来，发现B(4,3)=11:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">11</span><br><span class="line">[0, 0, 0, 0]</span><br><span class="line">[1, 0, 0, 0]</span><br><span class="line">[0, 1, 0, 0]</span><br><span class="line">[1, 1, 0, 0]</span><br><span class="line">[0, 0, 1, 0]</span><br><span class="line">[1, 0, 1, 0]</span><br><span class="line">[0, 1, 1, 0]</span><br><span class="line">[0, 0, 0, 1]</span><br><span class="line">[1, 0, 0, 1]</span><br><span class="line">[0, 1, 0, 1]</span><br><span class="line">[0, 0, 1, 1]</span><br></pre></td></tr></table></figure></p>
<p>我们将0标为negative，1标为positive，经过整理可以得到下面的样子：</p>
<p>2α</p>
<p>$$<br>\begin{Bmatrix}<br>X &amp; X &amp; X &amp; X \<br>X &amp; X &amp; X &amp; O \<br>X &amp; X &amp; O &amp; X \<br>X &amp; X &amp; O &amp; O \<br>X &amp; O &amp; X &amp; X \<br>X &amp; O &amp; X &amp; O \<br>O &amp; X &amp; X &amp; X \<br>O &amp; X &amp; X &amp; O<br>\end{Bmatrix}<br>$$</p>
<p>β</p>
<p>$$<br>\begin{Bmatrix}<br>O &amp; O &amp; X &amp; X \<br>O &amp; X &amp; O &amp; X \<br>X &amp; O &amp; O &amp; X<br>\end{Bmatrix}<br>$$</p>
<p>首先，前2α中每一组种每个dichotomy前3个是一致的，因此只看前3列，$\alpha + \beta \leq B(3,3)$，再看前α组的第一行的前3个，它们每两个必然不能shatter，否则加上第四列的就会出现3个样本被shatter的情况，因此$\alpha \leq B(3,2)$.</p>
<p>总的来说共有$2\alpha + \beta$种，它是小于等于B(3,3)+B(3,2)的。推广到更大的N，这个也依然是成立的，我简单说明一下其中的道理：</p>
<p>B(N-1,k-1)的dichotomy每个后面都增加一个O或者X，那么个数会翻倍，而且可以shatter的样本个数加一，这就是B(N,k)的一部分，其余部分的前N-1个元素不会出现相同的情况，如果相同，则前N-1个元素与之前的2*B(N-1,k-1)个必然会有k-1个被shatter，加上最后的一列会有k个被shatter，这与前提是矛盾的，而且剩余的个数是小于$B(N-1,k) - B(N-1,k-1)$的，不然依然会与条件矛盾。</p>
<p>因此，我们可以填满这张表格了：</p>
<table>
<thead>
<tr>
<th>B(N,k)</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">…</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">…</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">3</td>
<td style="text-align:center">4</td>
<td style="text-align:center">4</td>
<td style="text-align:center">4</td>
<td style="text-align:center">…</td>
<td>4</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:center">1</td>
<td style="text-align:center">4</td>
<td style="text-align:center">7</td>
<td style="text-align:center">8</td>
<td style="text-align:center">8</td>
<td style="text-align:center">…</td>
<td>8</td>
</tr>
<tr>
<td>4</td>
<td style="text-align:center">1</td>
<td style="text-align:center">5</td>
<td style="text-align:center">11</td>
<td style="text-align:center">15</td>
<td style="text-align:center">16</td>
<td style="text-align:center">…</td>
<td>16</td>
</tr>
<tr>
<td>5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">6</td>
<td style="text-align:center">16</td>
<td style="text-align:center">26</td>
<td style="text-align:center">31</td>
<td style="text-align:center">…</td>
<td>32</td>
</tr>
</tbody>
</table>
<p>那么B(N,k) = B(N-1,k-1) +B(N-1,k) ,利用上面的表格一路上去，我们可以使用数学归纳法证明下式成立：<br>$$<br>B(N,k) \leq \sum _{i=0} ^{k-1} C_N^i<br>$$<br>实际上等号也是成立的，但是证明需要更加复杂的数学理论。</p>
<p>而$C_N^i$的上限是$N^i$，那么$B(N,k)$首项最高项就是$N^{k-1}$，这是一个好消息，因为它的增长速度不够快。所以$m_H(N)$我们可以使用$N^{k-1}$来代替了（当$N \leq 2,k \leq 3$时）。</p>
<p>但是它能否直接带入原来的不等式呢？还是有点问题，实际上，我们无法保证</p>
<p>$$<br>P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|&gt;\epsilon] \leq 2 m_H(N) e^{-2\epsilon ^2N}<br>$$</p>
<p>我们最终得到的是下面的样子：</p>
<p>$$<br>P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|&gt;\epsilon] \leq 2 \cdot 2 m_H(2N) \cdot e^{-2 \cdot \frac 1 {16} \epsilon ^2 N}<br>$$</p>
<p>严格的证明需要很高的数学技巧以及数学理论，但是可以从以下3个方向简单解释下原因：</p>
<h4 id="1-finite-E-in-and-infinite-E-out"><a href="#1-finite-E-in-and-infinite-E-out" class="headerlink" title="1. finite $E_{in}$ and infinite $E_{out}$"></a>1. finite $E_{in}$ and infinite $E_{out}$</h4><p>我们的这些证明都是在只考虑了$E_{in}$的基础上，在泛化的过程中是有问题的。首先，对于dataset，$E_{in}$的个数是有限的，因为只要有break point，我们一定可以根据N与k找到h种类的上限，但是$E_{out}$的个数是无限的。虽然同一类h它们的$E_{in}$可能一致，但是它们的$E_{out}$并不一致。</p>
<p>如何对付这个无限的$E_{out}$？我们可以再从总体种抽出一个数目为N的dataset，它用H得到的错误率记为$E’<em>{in}$，然后我们用$E</em>{in}$与$E’<em>{in}$来解决这个问题，因为同样，$E’</em>{in}的个数是有限的$。</p>
<p>从下图中可以看出来，当$|E_{in}-E_{out}| \geq \epsilon$时候，$|E_{in}-E’_{in}| \geq \epsilon$的概率大概为1/2，当然可能会更大。</p>
<p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/XU%5DTY%7DQ%24SSE4X%40B%24_A1ZORN.png" alt=""></p>
<p>不过实际上的其他情况下，$|E_{in}-E’_{in}| \geq \epsilon$也是有可能会发生的，因此</p>
<p>$$<br>\frac 1 2 P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)| &gt; \epsilon] \leq P[∃h \ln H s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]<br>$$</p>
<p>为什么要对${\epsilon}$除以2，我也不清楚。$E_{out}$是无限的，如果$E_{out}$与$E_{in}$是一一对应的关系，那么不除以二上式也是成立的。也许因为是更严格的数学限制，但是不管怎么说经过复杂的数学证明（超出我的能力界限，交给统计学家与数学家吧），上式一定是成立的。</p>
<p>因此我们将无限的换成了有限的，这样离终点就进了一步。我们可以携程下面的样子：</p>
<p>$P[Baddata] \leq 2P[∃h \ln H s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$</p>
<h4 id="2-decompose-H-by-kind"><a href="#2-decompose-H-by-kind" class="headerlink" title="2. decompose H by kind"></a>2. decompose H by kind</h4><p>这一步，需要使用$m_H(N)$来处理上式的$∃h \ln H$，但是值得注意的是，因为我们后来又取了N个样本来做$E’_{in}$，因此所有的样本量是2N，需要替换为$m_H(2N)$,得到下面的结果：</p>
<p>$P[Baddata] \leq 2 m_H(2N) P[fixed h s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$</p>
<h4 id="3-hoeffding-without-replacement"><a href="#3-hoeffding-without-replacement" class="headerlink" title="3. hoeffding without replacement"></a>3. hoeffding without replacement</h4><p>第三个，就要用来处理$P[fixed h s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$了。实际上，我们可以将上式写成下面的样子：</p>
<p>$$<br>P[fixed h s.t. |E_{in}(h) - \frac {E’<em>{in}(h)+E</em>{in}(h)} 2 | &gt; \frac {\epsilon} 4 ]<br>$$</p>
<p>仔细观察，上面其实就是hoeffding不等式的一种，只不过这时候的bin不是无限大了，但是最后结果是一样的。（从2N个抽出N个，算出错误的比率，与实际上2N的错误的比率的差）（<font color="red">实际上我对这个解释是存有疑虑的，这个随机抽出2N个应该是从整体出发的，而不是从2N个中抽出来N个，算这个期望差，也许可以从数学上证明二者概率是一致的吧</font>）。</p>
<p>代入hoeffding不等式可以得到最终的结果：<br>$$<br>P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|&gt;\epsilon] \leq 2 \cdot 2 m_H(2N) \cdot e^{-2 \cdot \frac 1 {16} \epsilon ^2 N}<br>$$</p>
<p>这就是对怎么得到最终结果的简单的说明。严格的证明是非常复杂的。不过我们好歹似乎明白了那么一点点其中的道理。</p>
<h2 id="VC-bound"><a href="#VC-bound" class="headerlink" title="VC bound"></a>VC bound</h2><p>上面的简单证明得到的结果，叫做Vapnik Chervonenkis Bound，简称为VC bound。</p>
<p>引入一个新的定义，叫做VC dimension，它的定义与break point非常类似，VC dimension = k - 1，也就是最后一个可以在某种dataset下被shatter的dataset的大小。</p>
<p>现在我们尝试推算一下 perceptrons 的 VC dimension.</p>
<p>对于1维的来说很简单， 它的VC dimension 是 2.</p>
<p>对于2维的来说，由之前的也可以得到是 3.</p>
<p>那么对于d维的perceptron，我们可以猜测，它的vc dimension 难道是 d+1吗？</p>
<p>为了证明V(d) = d+1,我们需要证明两点：1. $V(d) \geq d+1$ 2. $ V(d) \leq d+1$.</p>
<p><strong>证明$V(d) \geq d+1$：</strong></p>
<p>首先，构造下面一个d+1*d+1的矩阵：</p>
<p>$$<br>\begin{bmatrix}<br>1&amp;0&amp;0&amp;0&amp;0&amp;…&amp;0 \<br>1&amp;1&amp;0&amp;0&amp;0&amp;…&amp;0 \<br>1&amp;0&amp;1&amp;0&amp;0&amp;…&amp;0 \<br>…\<br>1&amp;0&amp;0&amp;0&amp;0&amp;…&amp;1<br>\end{bmatrix}<br>$$</p>
<p>上述矩阵每一行都是一个样本的，是d维的，不过会加上额外的$x_0$维度。<br>共有d+1个样本。</p>
<p>回想perceptron，$XW = Y$(在本例中),而上述矩阵是可逆的，则$W = YX_{-1}$，因此不管Y怎么变，都有W可以使得它成立，因此至少上面的这个dataset可以被H shatter，所有$V(d) \geq d+1$.</p>
<p><strong>证明$V(d) \leq d+1$：</strong></p>
<p>为了证明上式，我们要再加入一个样本，证明无论如何d+2个样本是不能被shatter的。</p>
<p>我们再上面的矩阵里再加一个非零的行向量$X_{d+2}$，那么由线性代数可以知道:<br>$$<br>X_{d+2} = \sum _{i = 1}^{d+1} a_iX_i<br>$$</p>
<p>因此 $X_{d+2}W = \sum _{i = 1}^{d+1} a_iX_iW$.</p>
<p>则 y = ${sign(a_1),sign(a_2),…sign(a_{d+1}) ,-1 }$这种情况就一定是不能生成的($a_iX_iW$后每一项都是大于等于0的)。<br>所以d+2个样本是无法被shatter的.</p>
<p>如果前d+1个样本都不能被shatter，就更不用说d+2个可以被shatter了。</p>
<p>所以我们可以得到，V(d) = d+1.</p>
<p>VC dimension 实际上是自由度，一般来说，它是互不依赖的可以变动的参数个数（并不一定总是这样）。</p>
<h2 id="Interpreting-of-VC-dimension"><a href="#Interpreting-of-VC-dimension" class="headerlink" title="Interpreting of VC dimension"></a>Interpreting of VC dimension</h2><p>Hoeffding 告诉我们坏事情发生的概率，我们现在反推，好事情发生的概率，很简单如下：</p>
<p>$P[|E_{in}(g) - E_{out}(g)|&lt; \epsilon ] \geq 1 -  4(2N)^{d_{vc}}e^{- \frac 1 8 \epsilon ^2 N} $</p>
<p>如果将大于等于后复杂的那一部分（VC bound）列为$\delta$，那么经过推算可以得到：</p>
<p>$$<br>\epsilon = \sqrt {\frac 8 N \ln  {(\frac {4(2N)^{d_{vc}}} {\delta })}}<br>$$</p>
<p>那么我们可以在$1 - \delta$的概率下获得保证$E_{out}$在这个范围内：</p>
<p>$$<br>\left [ E_{in}(g) - \sqrt {\frac 8 N \ln {(\frac {4(2N)^{d_{vc}}} {\delta })}}, E_{in}(g) + \sqrt {\frac 8 N \ln {(\frac {4(2N)^{d_{vc}}} {\delta })}} \right ]<br>$$<br>我们比较重视右边的部分，也就是$E_{out}$最坏是多少。我们称$\sqrt {…}$为penalty for model complexity，记为${\Omega (N,H,\delta)}$.</p>
<p>一般来说，有个以下的关系图：</p>
<p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/M%29P32DW%29EE9%7BWB%246A08T8%29X.png" alt=""></p>
<p>从上面可以看出来，如果样本个数一定而且保证很高的probability，一味增加维度（增加新的特征）可能会出现过拟合的情况，因为它增加了模型复杂度。这启发了我们在机器学习时候不一定非要增加过多的特征量，或者一味地去降低$E_{in}$，从而导致泛化能力不强。</p>
<p>此外，我们还需要注意一点，如果我们利用VC bound去求所需要的数据量，往往得到一个很大的值，但是实际上一般来说只要10$d_{vc}$就差不多足够了，这说明VC bound是很宽松的。因为我们一直取的都是上限，但是我们也很难在包容这么多分布的情况下找到一个更好的界限。</p>
<p>到这里，就说的差不多了，我们证明了如果有VC dimension，那么在N足够大的情况，可以取得不错的学习效果。同时也启发了以后我们在机器学习上的一些做法。</p>
<h2 id="p-s"><a href="#p-s" class="headerlink" title="p.s."></a>p.s.</h2><ol>
<li><p>用程序生成B(4,3)，我使用的是很简单的程序，但是应该可以证明这样生成的dichotomy个数就是最大的个数。程序如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">(result,l)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> in_a <span class="keyword">in</span> [[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]:</span><br><span class="line">        exist = [<span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">8</span>)]</span><br><span class="line">        size = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            temp = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> bit <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                temp+=(i[in_a[bit]]&lt;&lt;bit)</span><br><span class="line">            <span class="keyword">if</span> exist[temp] == <span class="number">0</span>:</span><br><span class="line">                exist[temp] = <span class="number">1</span></span><br><span class="line">                size+=<span class="number">1</span></span><br><span class="line">        temp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> bit <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            temp += (l[in_a[bit]] &lt;&lt; bit)</span><br><span class="line">        <span class="keyword">if</span> exist[temp] == <span class="number">0</span>:</span><br><span class="line">            exist[temp] = <span class="number">1</span></span><br><span class="line">            size += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> size == <span class="number">8</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">four_three</span><span class="params">()</span>:</span></span><br><span class="line">    l = []</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">16</span>):</span><br><span class="line">        temp = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">            temp.append((i&gt;&gt;j)&amp;<span class="number">1</span>)</span><br><span class="line">        l.append(temp)</span><br><span class="line"></span><br><span class="line">    result.append(l[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">16</span>):</span><br><span class="line">        <span class="keyword">if</span> check(result,l[i]):</span><br><span class="line">            result.append(l[i])</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    result = four_three()</span><br><span class="line">    print(len(result))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">        print(i)</span><br></pre></td></tr></table></figure>
</li>
<li><p>hoeffding不等式是无需知道数据分布情况的，也就是对于任何分布它都适用，这也是为何VC bound很宽松的一个原因。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wlsdzyzl.com/2018/08/11/机器学习——VC-bound/" data-id="cjnyn0h5i002951lt34udhop6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mathematics/">mathematics</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/08/12/机器学习——Noise-and-Error/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习——Noise and Error
        
      </div>
    </a>
  
  
    <a href="/2018/08/06/机器学习——（基石）作业1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习——（基石）作业1</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/信息论/">信息论</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客建设/">博客建设</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/图形学/">图形学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学/">数学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据学习课程/">数据学习课程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/灌水/">灌水</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算摄像学/">计算摄像学</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/LFD-class/">LFD class</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LaTex/">LaTex</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Matrix/">Matrix</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/casual-note/">casual note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/classification/">classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/code/">code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/computational-photography/">computational photography</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/computer-graphics/">computer graphics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/depth-image/">depth image</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/exponential-family/">exponential family</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/homework/">homework</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/information-theory/">information theory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mathematics/">mathematics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/overfitting/">overfitting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/polynomial/">polynomial</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/quality-assessment/">quality assessment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/regression/">regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/regularization/">regularization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tips/">tips</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/transformation/">transformation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/validation/">validation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/visualization/">visualization</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/LFD-class/" style="font-size: 11.67px;">LFD class</a> <a href="/tags/LaTex/" style="font-size: 10px;">LaTex</a> <a href="/tags/Matrix/" style="font-size: 10px;">Matrix</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/casual-note/" style="font-size: 11.67px;">casual note</a> <a href="/tags/classification/" style="font-size: 15px;">classification</a> <a href="/tags/code/" style="font-size: 11.67px;">code</a> <a href="/tags/computational-photography/" style="font-size: 10px;">computational photography</a> <a href="/tags/computer-graphics/" style="font-size: 13.33px;">computer graphics</a> <a href="/tags/depth-image/" style="font-size: 10px;">depth image</a> <a href="/tags/exponential-family/" style="font-size: 10px;">exponential family</a> <a href="/tags/homework/" style="font-size: 16.67px;">homework</a> <a href="/tags/information-theory/" style="font-size: 15px;">information theory</a> <a href="/tags/machine-learning/" style="font-size: 20px;">machine learning</a> <a href="/tags/markdown/" style="font-size: 10px;">markdown</a> <a href="/tags/mathematics/" style="font-size: 18.33px;">mathematics</a> <a href="/tags/overfitting/" style="font-size: 11.67px;">overfitting</a> <a href="/tags/polynomial/" style="font-size: 10px;">polynomial</a> <a href="/tags/quality-assessment/" style="font-size: 10px;">quality assessment</a> <a href="/tags/regression/" style="font-size: 15px;">regression</a> <a href="/tags/regularization/" style="font-size: 10px;">regularization</a> <a href="/tags/tips/" style="font-size: 10px;">tips</a> <a href="/tags/transformation/" style="font-size: 10px;">transformation</a> <a href="/tags/validation/" style="font-size: 10px;">validation</a> <a href="/tags/visualization/" style="font-size: 13.33px;">visualization</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/01/信息论——连续随机变量的熵和互信息/">信息论——连续随机变量的熵和互信息</a>
          </li>
        
          <li>
            <a href="/2018/11/01/信息论——Fano不等式/">信息论——Fano不等式</a>
          </li>
        
          <li>
            <a href="/2018/10/31/信息论——the-Convexity/">信息论——the Convexity</a>
          </li>
        
          <li>
            <a href="/2018/10/29/Learning-From-Data——Generalize-Learning-Algorithm/">Learning From Data——Generalize Learning Algorithm</a>
          </li>
        
          <li>
            <a href="/2018/10/29/信息论——Basic-Conception/">信息论——Basic Conception</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 無聊時的自娛自樂<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
</body>
</html>
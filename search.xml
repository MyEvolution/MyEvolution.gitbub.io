<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>SLAM——刚体运动以及Eigen</title>
      <link href="/2018/11/07/SLAM%E2%80%94%E2%80%94%E5%88%9A%E4%BD%93%E8%BF%90%E5%8A%A8%E4%BB%A5%E5%8F%8AEigen/"/>
      <url>/2018/11/07/SLAM%E2%80%94%E2%80%94%E5%88%9A%E4%BD%93%E8%BF%90%E5%8A%A8%E4%BB%A5%E5%8F%8AEigen/</url>
      
        <content type="html"><![CDATA[<p>这次主要介绍一些刚体运动中需要的数学知识以及Eigen库的基本使用。<br><a id="more"></a></p><p>什么是刚体运动？运动过程中不会发生形变。所以实际上刚体的运动也就只有两种：旋转和平移。</p><p>对于三维空间的旋转平移表示，之前的计算机图形学中介绍的比较清楚了。不过还有一些别的概念没有接触，在这里做个补充。</p><h2 id="旋转向量"><a href="#旋转向量" class="headerlink" title="旋转向量"></a>旋转向量</h2><p>之前的旋转使用的是旋转矩阵，旋转矩阵是单位正交矩阵（行列式为1）。实际上会有个问题：旋转操作只需要3个自由度，但是却用了9个量来表示。这说明使用旋转矩阵是有冗余的。因此这里介绍旋转向量。</p><p>我们知道任何旋转都可以使用一个旋转轴和旋转角来描述。旋转向量是一个非常聪明的做法。它的方向代表了旋转轴，而它的长度代表了旋转的角度。</p><p>那么旋转向量与旋转矩阵如何转换呢？如果旋转轴（单位向量）为$\mathbf{n}$，旋转角度为$\theta$，那么旋转向量为$\theta\mathbf{n}$，旋转矩阵可以使用Rodrigues公式来计算出来：</p><script type="math/tex; mode=display">R = \cos \theta I + (1-\cos \theta)\mathbf{nn}^T + \sin \theta \mathbf{n}^\^</script><p>$\mathbf{n}^\^$为向量$\mathbf{n}$的对偶矩阵。这个公式也在之前的图形学博客中做过介绍了。</p><p>如何从旋转矩阵得到旋转向量？</p><p>首先，对于旋转角：</p><script type="math/tex; mode=display">\begin{aligned}\tr(R) &= \cos\theta \tr(I) +(1 - \cos \theta) tr(\mathbf{nn}^T) + \sin \theta \tr (\mathbf{n}^\^)\\&= 3\cos \theta + (1-\cos \theta)\\&= 1+ 2\cos\theta\end{aligned}</script><p>所以根据上式可以很简单求得：</p><script type="math/tex; mode=display">\theta = \arccos\left( \frac{\tr(R)-1}{2}\right)</script><p>至于\mathbf{n}，由于旋转轴的向量旋转后不会发生变化，因此$R\mathbf{n} = \mathbf{n}$.</p><p>所以$\n$为矩阵R特征值为1的对应的特征向量。</p><h2 id="欧拉角"><a href="#欧拉角" class="headerlink" title="欧拉角"></a>欧拉角</h2><p>旋转向量以及旋转矩阵对于人的角度来说都不够直观。因此有了欧拉角的诞生。其实欧拉角就是将一个旋转转化为3个绕坐标轴的转动。因此这个转动的顺序就不唯一了。在航空里可能经常听到“偏航-俯仰-滚转”（yam-pitch-roll），实际上就是欧拉角的一种，等价与ZYX轴的旋转。</p><p>因此欧拉角就是用一个向量$[ r,p,y ]^T$（3个角度）来表示一个旋转。但是欧拉角有个著名的万能锁问题。如果pitch转动了$\pm90\degree$,则最后一个转动绕的轴实际上和z轴一样，这就使得损失了一个自由度，这被称为奇异性问题（？）。因此欧拉角不适用与插值和迭代，往往用于人工交互。</p><h2 id="四元数"><a href="#四元数" class="headerlink" title="四元数"></a>四元数</h2><p>旋转矩阵用9个量描述，有冗余，而旋转向量和欧拉角却具有奇异性。实际上我们找不到不带奇异性的三维向量描述方式。<br>因此在这里再介绍一个四元数。它用四个量来描述旋转足够紧凑同时也没有奇异性。</p><p>一个四元数$\mathbf{q} = q_0+q_1i+q_2j+q_3k$,有一个实部，3个虚部。其中虚部满足下面的一组式子：</p><script type="math/tex; mode=display">\left\{\begin{aligned}i^2 = j^2 = k^2 = -1\\ij=k,ji = -k\\jk=i,kj = -i\\ki=j,ik = -j\end{aligned}\right.</script><p>有时候也使用一个标量和一个向量来表示四元数：</p><p>$\mathbf{q} = [ s,\mathbf{v} ],s = q_0 \in \mathbb{R},\mathbf{v} = [ q_1,q_2,q_3 ]^T \in \mathbb{R}^3 $.</p><p>如果实部为0,称为虚四元数，如果虚部为0称为实四元数。</p><p>我们能用单位四元数表示三维空间中的任意旋转。不过由于复数的引入，它的表示是有点反直觉的。假如旋转向量为$\mathbf{n} \theta$，则对应的四元数为：</p><script type="math/tex; mode=display">\mathbf{q} = [ \cos \frac \theta 2, n_x\sin \frac \theta 2 ,n_y \sing \frac \theta 2,n_z,\frac \theta 2]^T.</script><p>因此从单位四元数中也很容易得到对应的旋转轴和旋转角度：</p><script type="math/tex; mode=display">\left \{\begin{aligned}\theta = 2 \arccos q_0;[ n_x,n_y,n_z] = [ q_1, q_2,q_3]^T / \sin \frac \theta 2\end{aligned}\right .</script><p>这个式子确实反直觉，给我们赚了一般的感觉。如果对$\theta $加上$2\pi$，相当于没有转动，但是他们对应的四元数却变成原来的相反数了。因此，互为四元数的相反数表示同一个旋转。</p><p>四元数的概念的话现在还很懵比，不知道为什么要这样来表示一个旋转。但是能发展到现在还留下来的一定是有自己的道理。因为四元数每个值都是经过处理的轴和角结合，因此它方便进行插值。听说四元数在游戏开发里应用广泛。具体这些以后再去弄明白，先看一看四元数的基本运算吧。</p><h3 id="加减"><a href="#加减" class="headerlink" title="加减"></a>加减</h3><p>$\mathbf{q}_a \pm \mathbf{q}_b = [ s_a \pm s_b ,\mathbf{v}_a \pm \mathbf{v}_b] $</p><h3 id="乘法"><a href="#乘法" class="headerlink" title="乘法"></a>乘法</h3><p>乘法就是各项轮着相称，最后相加，虚部要按照虚部的规则来乘，最后得到结果：</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{q}_a \mathbf{q}_b &= s_as_b - x_ax_b - y_ay_b - z_az_b\\&+(s_ax_b+x_as_b+y_az_b-z_ay_b)i\\&+(s_ay_b - x_az_b + y_as_b + z_ax_b)j\\&+(s_az_b+x_ay_b-y_ax_b+z_as_b)\end{aligned}</script><p>如果写成向量形式：</p><script type="math/tex; mode=display">\mathbf{q}_a \mathbf{q}_b  = [ s_as_b - \mathbf{v}_a^T\mathbf{v}_b, s_a\mathbf{v}_b + s_b\mathbf{v}_a + \mathbf{v}_a\times \mathbf{v}_b]</script><p>由于最后一项存在，四元数的乘法通常是不可交换的。</p><h3 id="共轭"><a href="#共轭" class="headerlink" title="共轭"></a>共轭</h3><p>$\mathbf{q}_a^* = s_a - x_ai - y_aj-z_ak = [ s_a,-\mathbf{v}_a]$</p><p>$\mathbf{q^ <em>q} = \mathbf{qq^ </em>} = [s_a^2 + \mathbf{vv}^T ,0]$ </p><p>可以看到四元数和共轭相称得到一个实数。</p><h3 id="模长"><a href="#模长" class="headerlink" title="模长"></a>模长</h3><script type="math/tex; mode=display">\Vert \mathbf{q}\Vert = \sqrt{s^2 +x^2+y^2+z^2}</script><p>可以验证：$\Vert \mathbf{q}_a\mathbf{q}_b \Vert = \Vert  \mathbf{q}_a\Vert \Vert  \mathbf{q}_b\Vert$.</p><p>这保证了单位四元数的乘积依然为单位四元数。</p><h3 id="逆"><a href="#逆" class="headerlink" title="逆"></a>逆</h3><p>$\mathbf{q}^{-1} = \frac {\mathbf{q}^*}{\Vert \mathbf{q}\Vert^2}$</p><p>$\mathbf{q}^{-1}\mathbf{q} = \mathbf{qq}^{-1} = 1$</p><p>同时可以知道，单位四元数的逆就是单位四元数的共轭，因为$\mathbf{qq}^* = 1$.</p><p>乘积的逆和矩阵的逆有同样的性质：$(\mathbf{q_a}\mathbf{q_b})^{-1} = \mathbf{q_b}^{-1}\mathbf{q_a}^{-1}$</p><h3 id="数乘和点乘"><a href="#数乘和点乘" class="headerlink" title="数乘和点乘"></a>数乘和点乘</h3><p>$k\mathbf{q} = [ks,k\mathbf{v} ]$</p><p>$\mathbf{q_a} \cdot \mathbf{q_b} = s_as_b + x_ax_b + y_ay_b + z_az_b$</p><h3 id="用四元数表示旋转"><a href="#用四元数表示旋转" class="headerlink" title="用四元数表示旋转"></a>用四元数表示旋转</h3><p>对于一个三维点$p=[x,y,z ]$,绕着转轴$\mathbf{n}\theta$旋转，变为$p’$.我们知道使用矩阵的话，可以这样描述：$p’ = Rp$.但是使用四元数如何描述呢？</p><p>我们把空间的点用虚四元数来描述，则$\mathbf{p} = [0,x,y,z ]$.</p><p>用$\mathbf{q}$来表示旋转: $\mathbf{q} = [\cos \frac \theta 2,\mathbf{n} \sin \theta 2]$.</p><p>则：$\mathbf{p}’ = \mathbf{qpq}^{-1}$.</p><p>可以验证的是经过计算的实部为0,虚部对应的就是$q’$的坐标点。</p><p>可以看到使用四元数来旋转的话也是非常方便的。</p><h3 id="四元数和旋转矩阵的转换"><a href="#四元数和旋转矩阵的转换" class="headerlink" title="四元数和旋转矩阵的转换"></a>四元数和旋转矩阵的转换</h3><p>四元数与旋转矩阵的转换，我们可以想到的是利用旋转向量来做中间的桥梁。不过其中有个arccos函数代价较大，但是实际上可以通过一定的技巧绕过。在这里直接给出四元数到旋转矩阵的转换结果（省略推导过程）：</p><p>设四元数为：$\mathbf{q} = q_0+q_1i+q_2j+q_3k$,则：</p><script type="math/tex; mode=display">R = \begin{bmatrix}1-2q_2^2 - 2q_3^2&2q_1q_2 - 2q_0q_3& 2q_1q_3 + 2q_0q_2\\2q_1q_2+2q_0q_3& 1-2q_1^2-2q_3^2& 2q_2q_3 - 2q_0q_1 \\2q_1q_3-2q_0q_2&2q_2q_3+2q_0q_1&1 - 2q_1^2 - 2q_2^2\end{bmatrix}</script><p>如果知道了旋转矩阵，想要得到四元数：</p><p>$q_0 = \frac{\sqrt{\tr(R) + 1}{2},q_1 = \frac{r_{2,3} - r_{3,2}}{4q_0},q_2 = \frac{r_{3,1} - r_{1,3}}{4q_0},q_3 = \frac{r_{1,2} - r_{2,1}}{4q_0}$</p><p>这里面$r_{i,j}$表示$R$的第i行j列。在计算过程中，如果$q_0$接近于0,则其他3个量就会很大，这是很需要考虑别的方式来表示旋转。</p><h2 id="相似，仿射，射影变换"><a href="#相似，仿射，射影变换" class="headerlink" title="相似，仿射，射影变换"></a>相似，仿射，射影变换</h2><h3 id="相似变换"><a href="#相似变换" class="headerlink" title="相似变换"></a>相似变换</h3><p>相似变换比之前的欧式变换多了一个自由度：</p><script type="math/tex; mode=display">T_S = \begin{bmatrix}sR&\mathbf{t}\\0&1\end{bmatrix}</script><p>这个s允许我们对物体进行均匀缩放。</p><h3 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h3><script type="math/tex; mode=display">T_A = \begin{bmatrix}A&\mathbf{t}\\0&1\end{bmatrix}</script><p>仿射变换不要求A为正交矩阵，只要可逆即可。仿射变换又叫正交投影变换。</p><h3 id="射影变换"><a href="#射影变换" class="headerlink" title="射影变换"></a>射影变换</h3><p>射影变换是最易般的变换。</p><script type="math/tex; mode=display">T_P = \begin{bmatrix}sR&\mathbf{t}\\\mathbf{a}^T&v\end{bmatrix}</script><p>左上角可逆，右上角为平移t,左下角为缩放$\mathbf{a}^T$</p><p>从真实世界到相机照片的变换可以看作为一个射影变换。如果焦距为无限远，则为仿射变换。</p><h2 id="Eigen"><a href="#Eigen" class="headerlink" title="Eigen"></a>Eigen</h2><p>最后介绍一些Eigen库相关的东西。Eigen是一个C++开源线性代数库.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;eigen/core&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;eigen/dense&gt;</span></span></span><br><span class="line"><span class="comment">/*3*3矩阵float型*/</span></span><br><span class="line">Eigen::Matrix&lt;<span class="keyword">float</span>,<span class="number">3</span>,<span class="number">3</span>,&gt; matrix_33;</span><br><span class="line"><span class="comment">/*3维向量，但实际上就是Eigen::Matrix&lt;double,3,1&gt;*/</span></span><br><span class="line">Eigen::Vector3d v_3d;</span><br><span class="line"><span class="comment">//输入</span></span><br><span class="line">v_3d&lt;&lt;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>;</span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;v_3d&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line"><span class="comment">//访问i行j列</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;v_3d(<span class="number">1</span>,<span class="number">0</span>);</span><br><span class="line"><span class="comment">//转置</span></span><br><span class="line">matrix_33.transpose();</span><br><span class="line"><span class="comment">//各项和</span></span><br><span class="line">matrix_33.sum();</span><br><span class="line"><span class="comment">//迹</span></span><br><span class="line">matrix_33.trace();</span><br><span class="line"><span class="comment">//逆</span></span><br><span class="line">matrix_33.inverse();</span><br><span class="line"><span class="comment">//行列式</span></span><br><span class="line">matrix_33.determinant();</span><br><span class="line"><span class="comment">//特征值和特征向量，实对称矩阵确保对角化成功</span></span><br><span class="line">Eigen::SelfAdjointEigenSolver&lt;Eigen::Matrix3d&gt; eigen_solver(matrix_33*matrix_33.transpose());</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; eigen_solver.eigenvalues() &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt; eigen_solver.eigenvectors() &lt;&lt; <span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>Module</th><th>Header file</th><th>Contents</th></tr></thead><tbody><tr><td>Core</td><td>#include<eigen core=""></eigen></td><td>Matrix和Array类，基础的线性代数运算和数组操作</td></tr><tr><td>Geometry</td><td>#include<eigen geometry=""></eigen></td><td>旋转、平移、缩放、2维和3维的各种变换</td></tr><tr><td>LU</td><td>#include<eigen lu=""></eigen></td><td>求逆，行列式，LU分解</td></tr><tr><td>Cholesky</td><td>#include <eigen cholesky=""></eigen></td><td>LLT和LDLT Cholesky分解</td></tr><tr><td>Householder</td><td>#include<eigen householder=""></eigen></td><td>豪斯霍尔德变换，用于线性代数运算</td></tr><tr><td>SVD</td><td>#include<eigen svd=""></eigen></td><td>SVD分解</td></tr><tr><td>QR</td><td>#include<eigen qr=""></eigen></td><td>QR分解</td></tr><tr><td>Eigenvalues</td><td>#include<eigen eigenvalues=""></eigen></td><td>特征值，特征向量分解</td></tr><tr><td>Sparse</td><td>#include<eigen sparse=""></eigen></td><td>稀疏矩阵的存储和一些基本的线性运算</td></tr><tr><td>稠密矩阵</td><td>#include<eigen dense=""></eigen></td><td>包含Core/Geometry/LU/Cholesky/SVD/QR/Eigenvalues模块</td></tr><tr><td>矩阵</td><td>#include<eigen eigen=""></eigen></td><td>包括Dense和Sparse(整合库)</td></tr></tbody></table></div><p>这些东西都被整合在dense模块中。</p><h3 id="eigen几何模块："><a href="#eigen几何模块：" class="headerlink" title="eigen几何模块："></a>eigen几何模块：</h3><p>旋转矩阵直接使用 Matrix3d 或 Matrix3f：</p><p>Eigen::Matrix3d rotationMatrix=Eigen::Matrix3d::Identity();//初始化为一个单位阵。</p><p>旋转向量使用 AngleAxis：</p><p>Eigen::AngleAxisd rotationVector(M_PI/4,Eigen::Vector3d(0,0,1)); //角+轴：沿 Z 轴旋转 45 度</p><p>欧拉角：</p><p>Eigen::Vector3d ea0(yaw,pitching,droll);</p><p>旋转向量-&gt;旋转矩阵：rotationMatrix=rotation_vector.toRotationMatrix();</p><p>旋转向量-&gt;四元数：Eigen::Quaterniond q = Eigen::Quaterniond ( rotation_vector );</p><p>旋转矩阵-&gt;四元数：Eigen::Quaterniond q = Eigen::Quaterniond ( rotation_matrix );</p><p>四元素-&gt;旋转矩阵：Eigen::Matrix3d Rx = q.toRotationMatrix();</p><p>旋转向量-&gt;欧拉角：Eigen::Vector3d eulerAngle=rotationVector.matrix().eulerAngles(0,1,2);</p><p>旋转矩阵-&gt;欧拉角：Eigen::Vector3d euler_angles = rotation_matrix.eulerAngles ( 2,1,0 ); // ZYX顺序，即roll pitch yaw顺序</p><h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>这一讲最后说明了世界坐标和相机坐标的转换。世界坐标下的坐标为$\mathbf{p}_w$，相机坐标下的坐标为$mathbf{p}_c$，则二者转换为：</p><script type="math/tex; mode=display">\mathbf{p}_w = T_{c2w}\mathbf{p}_c</script><script type="math/tex; mode=display">\mathbf{p}_c = T_{w2c}\mathbf{p}_w</script><p>值得注意的是，它提到了一般更常用的是从世界坐标到相机坐标的转换，但是从相机坐标到世界坐标的转换却更直观。因为如果相机坐标$\mathbf{p}_c$下为0,则世界坐标$\mathbf{p}_w$就是相机在世界坐标的位置:</p><script type="math/tex; mode=display">\mathbf{p}_w = T_{c2w} = t_{c2w}</script><p>上式中$t_{c2w}$正是相机的位置。也是平移向量。</p><p>所以从相机坐标到世界坐标的转换可以直接看到相机位置。这也是因为从相机坐标到世界坐标的转换是先旋转后平移的特性。先旋转后平移，则平移向量是不用改变的。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> Eigen </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——基本介绍</title>
      <link href="/2018/11/06/SLAM%E2%80%94%E2%80%94%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/"/>
      <url>/2018/11/06/SLAM%E2%80%94%E2%80%94%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>不出意外的话，以后我的方向应该就是三维重建方向了，而SLAM是一个逃不开的东西。<a id="more"></a></p><p>SLAM（simultaneous localization and mapping），即时定位与地图构建。它是个什么东西？就是将一个机器人放到一个陌生的环境，它能够自我定位并构建出当前环境的三维地图。我们实验室的有一个项目：<a href="http://luvision.net/FlashFusion/" target="_blank" rel="noopener">FlashFusion</a>，和SLAM也有这千丝万缕的关系。</p><p>SLAM已经诞生了30多年了，也取得了很长足的进步吸引了很多学术界的关注，但是一直达不到业界使用的要求。</p><p>SLAM学习的门槛比较高，因为对知识储备以及工程能力都有较高的要求。</p><p>我的这个SLAM打算利用高翔的《SLAM十四讲》来完成。首先第一章是一些大概的介绍以及一些编程的环境的搭建。实际上我对linux还不够熟悉，对于CMake也使用较少。所以这篇博客也会介绍一些这方面的东西。</p><h2 id="传感器介绍"><a href="#传感器介绍" class="headerlink" title="传感器介绍"></a>传感器介绍</h2><p>首先，SLAM需要的一些传感器，有激光，也有相机。实际上我们的重点在于相机，因为相机便宜，而激光很贵。相机分为单目相机，双目相机（Stereo）以及深度相机（RGBD），事件相机（Event）。一般来说使用较多的Stereo和RGBD，单目没有深度，只能同过移动相机来想办法产生深度，Stereo相机通过两个镜头来获得深度，而RGBD相机通过一定的物理手段来获取深度（如红外线，结构光等）。而到后面我们会知道，深度对于SLAM是非常重要的一个信息。</p><p>当我们拍摄一张照片的时候，从3D到2D，会损失了很多信息。所以我们需要深度才能构建三维模型。单目相机，只能通过运动来推算距离（远的运动慢，近的运动快），但是计算比较复杂，也经常出问题，不能避免很多不确定性。</p><h2 id="视觉SLAM框架"><a href="#视觉SLAM框架" class="headerlink" title="视觉SLAM框架"></a>视觉SLAM框架</h2><ul><li>前端（Visual Odometry）</li><li>后端（Optimization）</li><li>回环检测（Loop Closure Detection）</li><li>建图（Mapping）</li></ul><p>这些模块每个都需要很多的知识和精力来学习，所以这里只列出来框架。以后学习完毕之后，在给它们加上超链接。</p><h2 id="数学描述"><a href="#数学描述" class="headerlink" title="数学描述"></a>数学描述</h2><p>我们假设地图是由路标描述的，路标有N个，则路标分别为：$\mathbf{y}_1,…,\mathbf{y}_N$. 而各个时刻的机器人的位置表示为$\mathbf{x}_1,…,\mathbf{x}_k$.其中k为时刻。</p><p>则我们可以用下面两个式子来描述SLAM:</p><script type="math/tex; mode=display">\left \{\begin{aligned}\mathbf{x}_k = f(\mathbf{x}_{k-1},\mu_k,\mathbf{w}_k)\\z_{k,j} = h(\mathbf{y}_j,\mathbf{x}_k,\mathbf{v}_{k,j})\end{aligned}\right.</script><p>上式中，$\mu_k$为传感器读数,$\mathbf{w}_k$为噪声。第一个式子为运动方程，也就是我们通过之前的位置和运动传感器的输入得到了目前时刻的位置。</p><p>第二个式子为观测方程，z为观测数据，$\mathbf{v}_{k,j}$为观测噪声。观测方程中$z$是我们直接观测到的。</p><p>如果我们可以得到$\mathbf{x}_k$与$\mathbf{y}_k$的值，不就实现了定位与建图吗？</p><h2 id="CMake"><a href="#CMake" class="headerlink" title="CMake"></a>CMake</h2><p>在SLAM中C++语言是占有绝对优势的。任何程序都可以使用g++编译，但是对于过于复杂的工程，g++的命令会太长不好操作，因此我们需要使用CMake工具。</p><p>CMake是一种跨平台编译工具，比make更为高级，使用起来要方便得多。CMake主要是编写CMakeLists.txt文件，然后用cmake命令将CMakeLists.txt文件转化为make所需要的makefile文件，最后用make命令编译源码生成可执行程序或静态库(.a)或者共享库（.so(shared object)）。</p><p>实际上，CMake的使用主要在于CMakeList.txt的编写。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.cmake verson，指定cmake版本 </span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.project name，指定项目的名称，一般和项目的文件夹名称对应</span></span><br><span class="line"><span class="keyword">PROJECT</span>(test_sqrt)</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.head file path，头文件目录</span></span><br><span class="line"><span class="keyword">INCLUDE_DIRECTORIES</span>(</span><br><span class="line"><span class="keyword">include</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.source directory，源文件目录</span></span><br><span class="line"><span class="keyword">AUX_SOURCE_DIRECTORY</span>(src DIR_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.set environment variable，设置环境变量，编译用到的源文件全部都要放到这里，否则编译能够通过，但是执行的时候会出现各种问题，比如"symbol lookup error xxxxx , undefined symbol"</span></span><br><span class="line"><span class="keyword">SET</span>(TEST_MATH</span><br><span class="line"><span class="variable">$&#123;DIR_SRCS&#125;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#6.add executable file，添加要编译的可执行文件</span></span><br><span class="line"><span class="keyword">ADD_EXECUTABLE</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> <span class="variable">$&#123;TEST_MATH&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#7.add link library，添加可执行文件所需要的库，比如我们用到了libm.so（命名规则：lib+name+.so），就添加该库的名称</span></span><br><span class="line"><span class="keyword">TARGET_LINK_LIBRARIES</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> m)</span><br></pre></td></tr></table></figure><p>aux_source_directory(&lt; dir &gt; &lt; variable &gt;)</p><p>搜集所有在指定路径下的源文件的文件名，将输出结果列表储存在指定的变量中。<br>如果想要生成库文件：<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#静态库</span></span><br><span class="line"><span class="keyword">add_library</span>( name libname.cpp)</span><br><span class="line"><span class="comment">#共享库</span></span><br><span class="line"><span class="keyword">add_library</span>(name_shared SHARED libname.cpp)</span><br></pre></td></tr></table></figure></p><p>当然，Cmake工具还有更多使用的技巧，需要平时做项目的时候去积累。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> 3D reconstruction </tag>
            
            <tag> CMake </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Covariance Matrix Derivation</title>
      <link href="/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Covariance-Matrix-Derivation/"/>
      <url>/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Covariance-Matrix-Derivation/</url>
      
        <content type="html"><![CDATA[<p>上周的数据学习课程布置了一个作业，主要做的是对多维高斯分布下求得协方差矩阵的取值。这个和之前将的Generative Learning Algorithm很相关，但是当时是直接给出了协方差矩阵的取值。结果是异常简单的，但是其中的证明可能要费点功夫。<br><a id="more"></a></p><p>题目描述如下：</p><p>Linear Discriminant Analysis (LDA) is a special case of Gaussian Discriminant Analysis (GDA) which assumes that the classes have a common covariance matrix $\Sigma_j = \Sigma, \forall j$. Now suppose all the $\Sigma_j$’s are not equal, and we will get the Quadratic Discriminant Analysis (QDA). The estimations for QDA are similar to those for LDA, except that separate covariance matrices must be estimated for each class. Give the maximum likelihood estimate of Σ j ’s for the case K = 2.</p><p>题目中说，之前博客中介绍的各个分类的$\Sigma$都是一样的，那叫做LDA，如果每个类别都有自己的$\Sigma_j$，则是QDA。让我们推导QDA的协方差矩阵应该是什么样子。</p><p>实际上，对于QDA还是LDA，协方差矩阵的推导是大致一样的，而QDA的最后结果也是非常简单。至于$\phi_j,\mu_j$等相比之下更简单，结果也和之前一样，就不在这里进行证明了。</p><p>这篇博客实际上就是把之前的写的作业发出来，因为我们作业要求为英文，因此下面的证明将为英文。</p><p>Firstly,  we need to know the log Maximum Likelihood Estimate:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}&\log L(\mu_1,...,\mu_k,\Sigma_1,...,\Sigma_k,\phi_1,...,\phi_k)\\ &= \log \prod_{i=1}^m p(x_i,y_i;\mu_1,...,\mu_k,\Sigma_1,...,\Sigma_k,\phi_1,...,\phi_k)\\ &=\log \prod_{i=1}^m p(x_i|y_i;\mu_{y_i},\Sigma_{y_i})p(y_i;\phi_{y_i})\\ &=\log \prod_{i=1}^m \prod_{j=1}^k \mathbf{1}\{y_i=j\} \frac{1}{(2\pi)^{\frac n 2}\vert \Sigma_j\vert ^{\frac 1 2}} e^{-\frac 1 2(x_i-u_j)^T\Sigma^{-1}(x_i-u_j)}p(y_i=k;\phi_{k}) \\ &= \sum_{i=1}^m  \sum_{j=1}^k \mathbf{1}\{y_i=j\}( - \frac 1 2(x_i-u_j)^T\Sigma^{-1}(x_i-u_j) -\frac n 2 \log (2\pi) + \frac 1 2 \log\vert \Sigma_j\vert+\log p(y_i;\phi_{y_i}))\\\end{aligned}\end{equation*}</script><p>If we want to find the Maximum, we need to get the derivative of Sigma. If we cut the useless parts,the function will be look like this:</p><script type="math/tex; mode=display">l = \frac 1 2\sum_{i=1}^m  \sum_{j=1}^k \mathbf{1}\{y_i=j\}(\log\vert \Sigma_j\vert - (x_i-u_j)^T\Sigma^{-1}(x_i-u_j))</script><p>I need to tell some basic rules about derivative of matrix:</p><script type="math/tex; mode=display">\begin{align}\frac { \partial \vert A\vert}{\partial A} = |A|(A^{-1})^T\\\frac {\partial A^{-1}}{\partial x} = A^{-1}\frac{\partial A}{\partial x} A^{-1}     \end{align}</script><p>We could use the (1) to get the $\log |\Sigma_k|$ ‘s derivative. Because of the SPD, we could get:</p><script type="math/tex; mode=display">\begin{align}\frac {\partial \log \vert \Sigma_j \vert}{\partial \Sigma_j} = (\Sigma_j^{-1})^T = \Sigma_j^{-1}\end{align}</script><p>Then, use the rule (2). Because the x is a scalar, so we need to separate the process.First let’s try to find the derivative of $\Sigma_{k,(i,j)}$:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}} &= \Sigma_k^{-1} \frac{\partial \Sigma_k}{ \Sigma_{k,(i,j)}}\Sigma_k^{-1}\\(x_i-u_j)^T\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}}(x_i-u_j)&=  (x_i-u_j)^T\Sigma_k^{-1} \frac{\partial \Sigma_k}{ \Sigma_{k,(i,j)}}\Sigma_k^{-1}(x_i-u_j)\end{aligned}\end{equation*}</script><p>We noticed that $(x_i-u_j)^T\Sigma_k^{-1} = (\Sigma_k^{-1}(x_i-u_j))^T $.</p><p>And the matrix $\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}}$ will be like a n $\times$ n matrix with the exception that the value of the position(i,j) will be 1.</p><p>So we could get:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}(x_i-u_j)^T\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}}(x_i-u_j)&=  (x_i-u_j)^T\Sigma_k^{-1} \frac{\partial \Sigma_k}{ \Sigma_{k,(i,j)}}\Sigma_k^{-1}(x_i-u_j)\\&= [(\Sigma_k^{-1}(x_i-u_j)) (\Sigma_k^{-1}(x_i-u_j))^T]_{(i,j)}\end{aligned}\end{equation*}</script><p>So:</p><script type="math/tex; mode=display">\begin{align}(x_i-u_j)^T\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}}(x_i-u_j) = (\Sigma_k^{-1}(x_i-u_j)) (\Sigma_k^{-1}(x_i-u_j))^T\end{align}</script><p>Now use (3) and (4),we could get: </p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\frac{\partial l}{\partial \Sigma_j} &=\frac 1 2\sum_{i=1}^m \mathbf{1}\{y_i=j\} (\Sigma_j ^{-1}-   (\Sigma_k^{-1}(x_i-u_j)) (\Sigma_k^{-1}(x_i-u_j))^T)\\ &=\frac 1 2\sum_{i=1}^m \mathbf{1}\{y_i=j\} (\Sigma_j ^{-1}-   \Sigma_j^{-1}(x_i-u_j)(x_i-u_j)^T\Sigma_j^{-1})\end{aligned}\end{equation*}</script><p>Because we want to let $\frac{\partial l}{\partial \Sigma_j} = \mathbf{0}$:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\frac 1 2\sum_{i=1}^m  \mathbf{1}\{y_i=j\} (\Sigma_j ^{-1}-   \Sigma_j^{-1}(x_i-u_j)(x_i-u_j)^T\Sigma_j^{-1}) = \mathbf{0}\\\sum_{i=1}^m\mathbf{1}\{y_i=j\} (I - \Sigma_j^{-1}(x_i-u_j)(x_i-u_j)^T) = \mathbf{0}\\\sum_{i=1}^m\mathbf{1}\{y_i=j\} I = \Sigma_j^{-1}\sum_{i=1}^m \mathbf{1}\{y_i=j\}(x_i-u_j)(x_i-u_j)^T\end{aligned}\end{equation*}</script><p>So,for QDA,the $\Sigma_j$ will be like this:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\Sigma_j = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=j\}(x_i - \mu_{j}) (x_i - \mu_{j})^T}{\sum_{i=1}^m \mathbf{1}\{y_i=j\}}\end{aligned}\end{equation*}</script><p>where $j=1,2$.</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LFD class </tag>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Neural Network</title>
      <link href="/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Neural-Network/"/>
      <url>/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Neural-Network/</url>
      
        <content type="html"><![CDATA[<p>这周上的数据学习，主要讲了一些神经网络相关的知识。神经网络是目前最流行的机器学习算法了，甚至由它诞生了一个新的学科：deep learning。因此一篇博客，只能浅浅介绍一些神经网络的基本内容。<br><a id="more"></a></p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LFD class </tag>
            
            <tag> machine learning </tag>
            
            <tag> deep learning </tag>
            
            <tag> neural network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Kernel Logistic Regression</title>
      <link href="/2018/11/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Kernel-Logistic-Regression/"/>
      <url>/2018/11/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Kernel-Logistic-Regression/</url>
      
        <content type="html"><![CDATA[<p>在我们的生活中，其实大部分使用的都是soft-margin SVM，很少会有人真正去使用hard-margin，因为我们无法避免噪声。现在想想，能否将soft-margin svm与我们之前的losgistic regress结合起来，会得到什么样的学习算法？<br><a id="more"></a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——Lossless Encoding</title>
      <link href="/2018/11/02/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Lossless-Encoding/"/>
      <url>/2018/11/02/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Lossless-Encoding/</url>
      
        <content type="html"><![CDATA[<p>信息论算是应用数学，因此我们希望用熵，互信息这些东西来解决一些实际的问题。首先介绍下无失真编码定理，它早已经被广泛用在我们生活当中了。<br><a id="more"></a></p><p>首先，说到无失真编码，我们首先想到的是无损压缩了。无损压缩实际上是一个最大熵的问题。这样的情况下，能包含最多的信息，如果信息量一定，也就是最大熵的情况下需要平均较小的比特数（比如一个均匀分布随机变量X的熵为3,另一个非均匀分布随机变量熵Y也为3，那么|Y|&gt;|X|,如果普通编码的话，Y的编码更长，但是它们包含的信息量却是一样的）。我们都知道的是，在均匀分布的时候熵是最大的。但是我们不能选择信源的分布，因为信源就在那里已经确定了。我们能否通过一个映射，一一对应的映射，使得一个非等概分布逐渐走向等概呢？答案是，可以，但是这太反直觉了。是啊虽然反直觉，但是它不反数学，所以它就是对的。</p><h2 id="渐进等同分割性质（Asymptotic-Equipartition-Property）"><a href="#渐进等同分割性质（Asymptotic-Equipartition-Property）" class="headerlink" title="渐进等同分割性质（Asymptotic Equipartition Property）"></a>渐进等同分割性质（Asymptotic Equipartition Property）</h2><h3 id="大数定律（Law-of-Large-Number）"><a href="#大数定律（Law-of-Large-Number）" class="headerlink" title="大数定律（Law of Large Number）"></a>大数定律（Law of Large Number）</h3><p>这里只介绍伯奴利大数定律(弱大数定律)。实际上所有的大数定律都在说一件事：当实验次数非常大的时候，频率趋向于概率（经验分布逼近于统计分布）。</p><script type="math/tex; mode=display">\frac{S_n}{n} \underrightarrow{p}p</script><p>更精确一点的说法：</p><script type="math/tex; mode=display">\forall N, \exists \epsilon >0,\sigma>0, \text{while }n > N,p(\vert \frac{s_n}{n} - p\vert \geq \epsilon) <\sigma.</script><p>而且也可以表述如下：</p><script type="math/tex; mode=display">\begin{align}\frac 1 n \sum_{i=1}^n \underrightarrow{p} EX\end{align}</script><p>渐进等同分割性质定义如下：</p><p>如果$X_1,X_2,…$是独立同分布的离散随机变量，分布服从$p(x)$,则</p><p>$-\frac 1 n \log p(X_1,X_2,…,X_n) \underrightarrow{p} H(X)$</p><p>使用上面的更准确的写法如下：</p><script type="math/tex; mode=display">\forall N, \exists \epsilon>0, \sigma >0, \text{while }n > N,p(\vert - \frac 1 n \log p(X_1,X_2,...,X_n) - H(X)\vert \geq \epsilon) <\sigma.</script><p>即$p(X_1,X_2,…,X_n)\approx 2^{-nH(X)}$.</p><p>这个定理可以使用弱大数定理地证明：</p><script type="math/tex; mode=display">\begin{aligned}&-\frac 1 n \log p(X_1,X_2,...,X_n)\\& = -\frac 1 n \log p(X_1)p(X_2)...p(X_n)\\&=-\frac 1 n \sum_{i=1}^n \log p(X_i)\end{aligned}</script><p>因为我们知道，$X_1,X_2,…,X_n$是互相独立的，因此，$\log X_1,\log X_2,…,\log X_n$也是互相独立同分布的。利用(1)：</p><script type="math/tex; mode=display">\begin{aligned}-\frac 1 n \sum_{i=1}^n \log p(X_i) &= -E(\log p(X))\\ &= \sum_{x \in \mathcal{X}} (-p(x)\log p(x)) \\&= H(X)\end{aligned}</script><p>这意味着，当n很大的时候，一个序列出现的概率是几乎相等的，这个概率为$2^{-nH(X)}$.</p><h2 id="（弱）典型序列（Typical-Sequence）"><a href="#（弱）典型序列（Typical-Sequence）" class="headerlink" title="（弱）典型序列（Typical Sequence）"></a>（弱）典型序列（Typical Sequence）</h2><p>典型序列定义如下：<br>相对于分布$p(x)$和序列$(x_1,x_2,…,x_n) \in X_n$,典型序列集合$A_\epsilon ^ {(n)}$定义为满足下列不等式约束的所有序列$\mathbf{x}$的集合：</p><script type="math/tex; mode=display">2^{-n(H(X)+\epsilon) \leq p(\mathbf{x}) = p(x_1,x_2,...,x_n) \leq 2^{-n(H(X)-\epsilon)}}</script><p>所以典型序列具有以下性质：</p><ol><li>若$\mathbf{x} \in A_\epsilon ^ {(n)}$,则$H(X)-\epsilon \leq -\frac 1 n \log p(\mathbf{x}) \leq H(X) + \epsilon$.</li><li>若$n$足够大，$Pr(A_\epsilon ^{(n)}) \geq 1 - \epsilon $</li><li>$\vert A_\epsilon ^{(n)}\vert \leq 2^{n(H(X)+\epsilon)}$</li><li>$\vert A_\epsilon ^{(n)}\vert \geq (1-\epsilon)2^{n(H(X)-\epsilon)}$</li></ol><p>性质1,2可以用定义得到。因此这里证明3和4.</p><p>3.</p><script type="math/tex; mode=display">\begin{aligned}1 &= \sum_{x^n \in \mathcal{X}}P(x^n)\\&\geq \sum_{x^n \in A_\epsilon ^{(n)}} p(x^n)\\&\geq \sum_{x^n \in A_\epsilon ^{(n)}} 2^{-n(H(x)+\epsilon)}\\&= 2^{-n(H(x)+\epsilon)}\vert A_\epsilon ^{(n)} \vert\end{aligned}</script><p>4的证明首先要使用性质2。</p><script type="math/tex; mode=display">\begin{aligned}1 - \epsilon &\leq Pr\{A_\epsilon ^{(n)}\}\\&\leq \sum_{x^n \in A_\epsilon ^{(n)}} 2 ^{-n(H(X) - \epsilon)}\\&= 2 ^{-n(H(X) - \epsilon)} \vert A_\epsilon ^{(n)}\vert \end{aligned}</script><p>所有可能出现的序列一共有$|X|^n$种，大多数情况下，$ 2^{m(H(X)+\epsilon)} &lt;&lt; |X|^n$.所以典型序列集合只是所有可能集合的一个很小（尤其是原来分布远离均匀分布的时候）的子集。但是它几乎一定会出现，而且每个典型序列出现的概率几乎一样。这是很好的消息，为我们刚开始提出来的映射提供了很好的思路。</p><h2 id="定长编码定理-香农第一定理"><a href="#定长编码定理-香农第一定理" class="headerlink" title="定长编码定理(香农第一定理)"></a>定长编码定理(香农第一定理)</h2><p>假设$X^n$是由独立同分布离散随机变量$X~{}p(X)$构成的序列。对于任意正数$\epsilon$，总有足够大的n，可以找到一个一一映射，将$X^n$映射到二进制序列，且满足:</p><script type="math/tex; mode=display">E\left[\frac 1 n l(X^n) \right] \leq H(X)+\epsilon</script><p>上式中，$l(X^n)$表示的是编码需要的bit数。</p><p>接下来提供证明：</p><script type="math/tex; mode=display">\begin{aligned}E(l(X^n)) &= \sum_{x \in \mathcal{X}} p(x) l(x)\\&= \sum_{x \in A_\epsilon ^{(n)}} p(x) l(x) + \sum_{x \in \overline{A_\epsilon ^{(n)}}} p(x) l(x)\\& \leq \sum_{x \in A_\epsilon ^{(n)}} p(x) [ n(H(X)+\epsilon)+1+1 ] + \sum_{x \in \overline{A_\epsilon ^{(n)}}} p(x) [ n\log \vert X\vert +2 ]\\&=[ n(H(X)+\epsilon)+1+1 ] Pr\{ A_\epsilon ^{(n)}\} +  [ n\log \vert X\vert +2] Pr\{\overline{A_\epsilon ^{(n)}}\} \\&\leq n(H(X)+\epsilon)+2 +  n\epsilon \log\vert X\vert+2\epsilon= n(H(X) + \epsilon ')\end{aligned}</script><p>其中 $\epsilon’ = \epsilon + \epsilon \log \vert X \vert X + \frac {2\epsilon}{n}$,可以看到的是$n \rightarrow \infty,epsilon’ \rightarrow 0$.</p><p>上面证明过程中值得注意的事情是，为什么要加2？第一个加一是为了处理log后为非整数的情况，第二个+1是留一个比特位置来区分典型序列与非典型序列的编码。</p><p>但是，定长编码定理是无法应用到工业界的。因为它需要对序列长度为n来进行编码，由于精确度的要求，这个n往往很大（上亿），这在现实中是无法实现的。</p><h2 id="码的类型"><a href="#码的类型" class="headerlink" title="码的类型"></a>码的类型</h2><h3 id="非奇异码"><a href="#非奇异码" class="headerlink" title="非奇异码"></a>非奇异码</h3><p>若一个码C可以将不同的x映射为不同的$D^*$中 的序列，即：</p><script type="math/tex; mode=display">x \ne x' \rightarrow C(x) \ne C(x')</script><p>则该码为非奇异码。</p><p>但是仅仅是非奇异码的序列可能会有歧义（很好笑）。$x_1 \rightarrow 0,x_2 \rightarrow 1,x_3 \rightarrow 01$，那么我收到$01$就不知道该如何介绍它了。</p><h3 id="唯一可译码"><a href="#唯一可译码" class="headerlink" title="唯一可译码"></a>唯一可译码</h3><p>唯一可译码是非奇异码的子集。称码$C^<em>$为码$C$的扩展，当$C^</em>$是有限长X的序列到有限长D序列的映射，且满足：</p><script type="math/tex; mode=display">C(x_1,x_2,...,x_n) = C(x_1)C(x_2)...C(x_n)</script><p>则该码为唯一可译码。</p><p>从另一方面来说，如果码的扩展为非奇异码，则该码为唯一可译码。</p><p>换句话说，没有码字是码字的组合。</p><p>这样的也是有缺点的，因为解码器复杂度要求较高。如$x_1 = 01,x_2 = 10,x_3 = 0111$,当收到0110的时候，在前三个的时候解码器预测可能是个$x_3$,但是最后一个不满足，因此就需要回退。</p><h3 id="即时码（前缀码）"><a href="#即时码（前缀码）" class="headerlink" title="即时码（前缀码）"></a>即时码（前缀码）</h3><p>前缀码大家就比较熟悉了。前缀码是唯一可译码的子集。如常用的霍夫曼编码。它的意思是没有什么码字是另一个码字的前缀。所以解码器只要发现有认识的，立马就可以解码了，所以叫即时码。</p><p>莫尔斯电码是非奇异码，但不是唯一可译码。汉语也不是唯一可译码，因为断句不对就会引起歧义。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——连续随机变量的熵和互信息</title>
      <link href="/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E8%BF%9E%E7%BB%AD%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%86%B5%E5%92%8C%E4%BA%92%E4%BF%A1%E6%81%AF/"/>
      <url>/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E8%BF%9E%E7%BB%AD%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%86%B5%E5%92%8C%E4%BA%92%E4%BF%A1%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<p>如何将离散随机变量的这些概念推广到连续随机变量？<br><a id="more"></a></p><p>使用黎曼积分，我们可以得到：</p><script type="math/tex; mode=display">\begin{align}H(X) &= -\sum_{x} p(x)\Delta x \log p(x) \Delta x\\&= -\sum_{x}p(x)\log p(x)\Delta x - -\sum_{x}p(x)\log \Delta x\Delta x \end{align}</script><p>上式中，最后一项是趋于负无穷的。</p><p>这意味着连续随机变量包含的信息是无穷的。但是无穷的是无法研究的，因此香农重新给了一个微分熵的定义，它在数学上不够严格，但是在实际上却非常有用。</p><script type="math/tex; mode=display">h(X) = \int _{-\infty }^{+\infty} p(x)\log p(x) dx</script><p>可以看到它在形式上与离散形式的熵是非常相似的。</p><p>同时也有联合熵：</p><script type="math/tex; mode=display">h(X,Y) = -\int p(x,y)\log p(x,y) dxdy</script><p>条件熵：</p><script type="math/tex; mode=display">h(X|Y) = -\iint p(x,y) \log p(x|y) dxdy = -\int p(y) \int p(x|y) \log p(x|y) dx dy</script><p>不等式关系：<br>$<br>h(X,Y) = h(X) + h(Y|X) = h(Y) + h(X|Y)<br>$</p><p>$<br>h(X|Y) \leq h(X), h(Y|X) \leq h(Y)<br>$</p><p>$<br>h(X,Y)\leq h(X) + h(Y)<br>$</p><p>这些不等式都是存在的，与离散形式一致，但是要注意的是h(X)不一定是非负的了。</p><p>例如：</p><script type="math/tex; mode=display">X:p(x) = \left \{ \begin{array}{c}     \frac 1 {b-a} , a \leq x \leq b;\\    0, otherwise;    \end{array}    \right.</script><p>那么它的微分熵实际上等于$\log(b-a)$.当$b-a&lt;1$的时候，这个熵是小于0的。</p><h3 id="高斯分布的微分熵"><a href="#高斯分布的微分熵" class="headerlink" title="高斯分布的微分熵"></a>高斯分布的微分熵</h3><p>高斯分布概率密度如下：</p><p>$X:p(x) = \frac{1}{\sqrt {2 \pi \sigma}} exp [-\frac{(x-m)^2}{2\sigma ^2}]$</p><p>而它的微分熵为$h(x) = \frac 1 2 \log 2 \pi e \sigma^2$.</p><p>这个需要记住。当然只要带进定义就可以推算出来的。值得注意的是，它的微分熵和m（期望）是无关的</p><p>给定m和$\sigma$的情况下，当连续变量服从高斯分布的时候，微分熵最大。</p><h3 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a>互信息</h3><p>$I(X;Y) = \iint p(x,y) \log \frac{p(x,y)}{p(x)p(y)}dxdy$</p><p>可以直接使用黎曼积分得到，与离散的情况也非常一致。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——Fano不等式</title>
      <link href="/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Fano%E4%B8%8D%E7%AD%89%E5%BC%8F/"/>
      <url>/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Fano%E4%B8%8D%E7%AD%89%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>从$X$到$Y$到$\hat{X}$，其中$\hat {X}$是对原有的$X$的估计,而Y可以看作是一个中间过程，可以想象类似于编码解码的过程。这之间有什么联系？<br><a id="more"></a></p><p>Fano不等式如下：</p><script type="math/tex; mode=display">P_e = Pr(X \ne \hat{X})\\H(P_e) + P_e log|X| \geq H(X|\hat{X}) \geq H(X|Y)</script><p>证明如下：</p><script type="math/tex; mode=display">E =\left \{    \begin{array}{c}    0,X = \hat{X}\\    1,X \ne \hat{X}    \end{array} \right.</script><p>则：$H(E) = H(P_e)$.注意：当不等的时候为$1$,这个E可以看为错误。</p><p>现在考虑$H(E,X|\hat{X})$.由之前的条件熵可以知道：</p><script type="math/tex; mode=display">\begin{align}H(E,X|\hat {X}) &= H(X|\hat{X}) + H(E|X,\hat{X}) &-----(1)\\&=H(E|\hat{X})+H(X|E,\hat{X}) &-----(2)\end{align}</script><p>很容易知道(1)中，$H(E|X,\hat{X}) = 0$,因为E的值就是由$X,\hat{X}$确定的。</p><p>(2)中，$H(E|\hat{X}) \leq H(P_e)$.而第二项$H(X|E,\hat{X})$满足：</p><script type="math/tex; mode=display">H(X|E,\hat{X}) = P_e H(X|X \ne \hat{X},\hat{X}) + (1-P_e) H(X|X = \hat{X},\hat{x}).</script><p>这步还是比较难懂的。</p><p>上式中，$P_e H(X|X \ne \hat{X},\hat{X}) \leq P_e \log |X|,H(X|X = \hat{X},\hat{x}) = 0 $.</p><p>因此组合起来： $H(X|\hat{X}) \leq  H(P_e) + \log |X|$.<br>这就得到了Fano不等式的第一个不等号。</p><p>接下来证明$I(X;Y)\geq I(X;\hat{X})$.</p><script type="math/tex; mode=display">\begin{align}I(X;Y,\hat{X}) &= I(X;Y) + I(X;\hat{X}|Y)\\&= I(X;\hat{X}) + I(X; Y|\hat{X})\end{align}</script><p>上式中， $I(X;\hat{X}|Y) = 0$.除去Y的信息，$X,\hat{X}$是统计独立的,而两个系统的互信息是大于等于0的。所以可以得到：</p><script type="math/tex; mode=display">I(X,Y) \geq I(X;\hat{X}).</script><p>这告诉我们编码过程中，原有信息只会衰减，而不可能增大。</p><p>得到上式后，第二个不等式很快就可以得出：</p><script type="math/tex; mode=display">H(X) - H(X|Y) \geq H(X) - H(X|\hat {X})\\H(X|\hat{X})\geq H(X|Y)</script><p>所以整个不等式就得到了：</p><p>$H(P_e) + P_e \log|X| \geq  H(X|\hat {X}) \geq H(X|Y)$.</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——the Convexity</title>
      <link href="/2018/10/31/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94the-Convexity/"/>
      <url>/2018/10/31/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94the-Convexity/</url>
      
        <content type="html"><![CDATA[<p>这篇博客来介绍熵，互信息，鉴别信息的凸性，与优化有着重要的关系。<a id="more"></a></p><h2 id="凸集-Convex-Set"><a href="#凸集-Convex-Set" class="headerlink" title="凸集(Convex Set)"></a>凸集(Convex Set)</h2><p>凸集：在欧氏空间中，凸集是对于集合内的每一对点，连接该对点的直线段上的每个点也在该集合内的集合。</p><p>凸集有：实数，概率矢量集合等。整数，有理数等不是凸集。</p><p>想要研究凸函数，首先凸函数一定要定义在凸集上。而概率矢量集合为凸集，是一个好消息。</p><p>凸函数有个坑。就是中国教材总是叫凸函数和凹函数，但是实际上中国的凸函数，是有最大值的函数，而非国外的convex function（最小值）。另外一种比较好的叫法是上凸和下凸，这个就容易区分了，上凸函数有最小值，下图函数有最大值。</p><p>严格的数学定义：</p><ul><li>定义在凸集D上的函数f(x)如果满足$f(\lambda \alpha + (1-\lambda)\beta) \leq \lambda f(\alpha) + (1-\lambda) f(\beta)$,则为下凸函数。</li></ul><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/ConvexFunction.svg/768px-ConvexFunction.svg.png" alt=""></p><ul><li>定义在凸集D上的函数f(x)如果满足$f(\lambda \alpha + (1-\lambda)\beta) \geq \lambda f(\alpha) + (1-\lambda) f(\beta)$,则为上凸函数。</li></ul><h2 id="Jenson不等式"><a href="#Jenson不等式" class="headerlink" title="Jenson不等式"></a>Jenson不等式</h2><p>如果f是下凸函数，且X是离散随机变量，则$Ef(X)\geq f(EX)$,并且如果f是严格下凸函数，则上式中等号说明X为常数，及X与EX以概率1相等。（其中E为平均取值）。</p><p>由Jenson不等式可以推出<strong>对数求和不等式</strong>：<br>对于非负实数$a_1,a_2,…,a_n;b_1,b_2,…,b_n$有</p><script type="math/tex; mode=display">\sum _{i=1}^n a_i \log \frac{a_i}{b_i} \geq \left(\sum_{i=1}^na_i \right) \log \frac{\sum _{i=1}^n a_i}{\sum _{i=1}^n b_i}</script><p>这个式子的证明如下：</p><p>首先，当$t&gt;0$时，$t \log t$为一个严格下凸函数.可自行用导数证明。<br>由Jenson不等式可以得到：</p><script type="math/tex; mode=display"> Et \log Et \leq \ E(t \log t)\\i.e. \sum \alpha_i f(t_i) \geq  f(\sum \alpha _i t_i)\\</script><p>令$\alpha _i = \frac {b_i}{B},t_i=\frac {a_i}{b_i}, B = \sum_{b_i}$，代入上式可以得到：</p><script type="math/tex; mode=display"> \sum \frac{b_i}{B}\frac{a_i}{b_i} \log (\frac{a_i}{b_i}) \geq(\sum \frac{b_i}{B}\frac{a_i}{b_i}) \log(\sum \frac{b_i}{B}\frac{a_i}{b_i})\\ \sum \frac{a_i}{B} \log (\frac{a_i}{b_i}) \geq (\sum \frac{a_i}{B}) \log{\sum \frac {a_i}{B}}\\ \sum a_i \log {\frac {a_i}{b_i}} \geq (\sum a_i) \log {\frac {\sum a_i}{\sum b_i}}</script><p>在这里要学会如何构造去证明这个不等式。</p><h2 id="凸性"><a href="#凸性" class="headerlink" title="凸性"></a>凸性</h2><h3 id="鉴别信息的凸性"><a href="#鉴别信息的凸性" class="headerlink" title="鉴别信息的凸性"></a>鉴别信息的凸性</h3><p>$D(p\Vert q)$是$(p,q)$的下凸函数。即若存在$(p_1,q_1)$和$(p_2,q_2)$,则$\lambda D(p_1\Vert q_1) + (1 - \lambda) D(p_2\Vert q_2) \geq D(\lambda p_1 + (1-\lambda)p_2 \Vert \lambda q_1+(1 - \lambda)q_2)$对所有的$0\leq \lambda \1$成立。</p><p>证明如下：</p><script type="math/tex; mode=display">\begin{align}D(\lambda p_1 + (1-\lambda)p_2 \Vert \lambda q_1+(1 - \lambda)q_2)&=\sum_{x \in \mathcal{X}} \left [ \lambda p_1(x)+ \overline {\lambda} p_2(x) \right] \log \frac{\lambda p_1(x)+ \overline {\lambda} p_2(x)}{\lambda q_1(x)+ \overline {\lambda} q_2(x)}\\& \leq \sum_{x \in \mathcal{X}} \lambda p_1(x) \log {\frac{p_1(x)}{q_1(x)}} +  \overline {\lambda} p_2(x) \log \frac{p_2}{q_2}\\&= \sum_{x \in \mathcal{X}} \lambda D(p_1 \Vert q_1) + \overline {\lambda} D(p_2 \Vert q_2)\end{align}</script><p>可以看到上式的证明利用到了之前的对数求和不等式。</p><h3 id="熵的凸性"><a href="#熵的凸性" class="headerlink" title="熵的凸性"></a>熵的凸性</h3><p>知道了鉴别信息的下凸性质，证明熵的凸性就非常容易。</p><p>$H(X) = \log |X| - D(p\Vert u)$</p><p>上式中，u不变，是均匀分布的情况，这时候D是一个下凸函数，而很明显$\log |X|$不变，因此$H(X)$是一个上凸函数。其实大家也很容易理解。因为均匀分布式的熵最大，也就是有最大值。</p><h3 id="互信息的凸性"><a href="#互信息的凸性" class="headerlink" title="互信息的凸性"></a>互信息的凸性</h3><p>下面来证明互信息的凸性。</p><p>互信息定义为下：</p><script type="math/tex; mode=display">I(X;Y) = I(p;Q) =  \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x)q(y|x)\log \frac{q(y|x)}{\sum _{x \in \mathcal{X}}p(x)q(y|x)}</script><p>这样的写法，对于信道传输的模型更有帮助。</p><p>首先如果给定Q，这意味着给定了信道：</p><p>Fix Q =[g(y|x)]</p><script type="math/tex; mode=display">\begin{align}I(X;Y) &= H(Y) - H(Y|X)\\&= H(Y) - \sum_{x \in \mathcal{X}} p(x)H(Y|X=x)\\&= H(Y) - \sum_{x \in \mathcal{X}} p(x) \sum_{y in \mathcal{Y}} q(y|x) \log \frac{q(y|x)}\end{align}</script><p>上式中既然Q已经给定，因此H(Y|X)也就是p(x)线性组合。因此整个函数为上凸减去线性，依然为上凸函数。</p><p>如果给定p：</p><p>Fix p(x):</p><script type="math/tex; mode=display">\begin{align}I(X;Y) = D(p(x,y)\Vert p(x)(y))\\p(x,y) = p(x)q(y|x)\\p(y) = \sum_{x \in \mathcal{X}} p(x)q(y|x)\end{align}</script><p>因此p(x,y),p(y),p(x)p(y)都是q(y|x)的线性组合。而D本身是下凸函数。所以互信息固定p(x)时候为下凸函数。可用于有失真编码。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Generative Learning Algorithm</title>
      <link href="/2018/10/29/Learning-From-Data%E2%80%94%E2%80%94Generative-Learning-Algorithm/"/>
      <url>/2018/10/29/Learning-From-Data%E2%80%94%E2%80%94Generative-Learning-Algorithm/</url>
      
        <content type="html"><![CDATA[<p>之前我们介绍的分类算法，包括，logistic regression，PLA甚至加上linear regression，他们都是试图找到一条线然后来将两种类别分开。这种算法叫做Discriminative Learning Algorithm，他们的由来，都是直接去估计$P(Y|X)$,这样的话根据新样本的X，从而预测Y。<a id="more"></a></p><p>接下来我们想介绍的是另外一种思路来解决分类问题。我们不再直接估计$P(Y|X)$,而是估计$P(X|Y)$.也就是，我们希望从当前的样本中学到X的特征看上去应该是什么样子，从鸡的样本中学到鸡的样子，从狗的样本中学到狗的样子。这样的算法叫做Generative Learning Algorithm（生成学习算法）。当然，我们最后要知道的还是$P(Y|X)$,不过根据Bayes理论可以知道：</p><script type="math/tex; mode=display">P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}</script><p>我们知道：</p><p>$argmax_yp(y|x) = argmax_y \frac{p(x|y)p(y)}{p(x)} = argmax_y p(x|y)p(y) = WhatWePredict$</p><p>所以我们真正需要解决的是$P(x|y)P(y)$.</p><p>当然，如果想要求得P(X),可以通过全概率公式：$P(X) = P(y=1)\cdot P(X|y=1) +P(y=0)\cdot P(X|y=0)$.</p><p>下面介绍两个最常见的生成学习算法：Gaussian Discriminant Analysis(高斯判别分析)与Naive Beyas(朴素贝叶斯模型)。</p><h3 id="Gaussian-Discriminate-Analysis"><a href="#Gaussian-Discriminate-Analysis" class="headerlink" title="Gaussian Discriminate Analysis"></a>Gaussian Discriminate Analysis</h3><p>高斯判别模型主要用于输入是连续的时候，也就是X的特征值是属于实数集的。首先来复习一下多维高斯分布模型，它是高斯判别模型的基础：</p><p>一般来说，多维高斯分布简写为：X ~{} N(\mu,\Sigma).</p><ul><li>$\mu \in \mathbb{R}^n$ 是平均向量。</li><li>$\Sigma \in \mathbb{R}^{n \times n}$是协方差矩阵。$\Sigma$是对称的SPD（ symmetric and positive definite matrix）.</li></ul><p>它的概率密度函数如下：</p><script type="math/tex; mode=display">p(x;\mu,\Sigma) = \frac{1}{(2\pi)^{\frac n 2}\vert \Sigma\vert ^{\frac 1 2}} e^{-\frac 1 2(x-u)^T\Sigma^{-1}(x-u)}</script><p>均值和协方差对分布有什么影响？利用一个二维的向量来说的话，有下面几张图可以看看：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/mg1.png" alt=""></p><p>这三张图分别对应着协方差矩阵为$I，2I,\frac 1 2 I$的情况。其中<br>$I = \begin{bmatrix}<br>1&amp;0\\<br>0&amp;1<br>\end{bmatrix}$.</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/mg2.png" alt=""></p><p>从上图又可以看出来，协方差矩阵非对角线的数字变化的时候，对它的图形似乎扭向一边了。实际上这代表了两个特征间的相关程度。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/mg3.png" alt=""></p><p>最后一个就是$mu$的变化，很显而易见，图形的中心改变了。</p><p>现在假如有一个分类问题，其中$X \in \mathbb{R}^n$,利用高斯判别模型的话，我们会有以下假设：</p><script type="math/tex; mode=display">y\~{} Bernuolli(\Phi)\\p(x|y=0)\~{}N(\mu_0,\Sigma)\\p(x|y=1)\~{}N(\mu_1,\Sigma)</script><p>从上面看出来，我们对于两个模型的生成采用的$\mu$不一样，但是$\Sigma$一样，这样不光保证了两个模型的形状一样，简化了计算过程，最后可以用它们接触点的切线来当做分割线，从而实现与之前Discriminative学习算法的比较。</p><p>Note:现在n为向量的维度，而m为样本个数。</p><p>和往常一样，我们求它的log极大似然估计：</p><script type="math/tex; mode=display">\begin{align}l(\Phi,\mu_0,\mu_1,\Sigma)&= \log \prod_{i=1}^{m}p(X_i,y_i;\Phi,\mu_0,\mu_1,\Sigma)\\&= \log \prod_{i=1}^m p(X_i|y_i;\mu_0,\mu_1,\Sigma)p(y_i;\Phi) \end{align}</script><p>上述的式子中的参数取值如下：</p><script type="math/tex; mode=display">\Phi = \frac 1 m \sum_{i=1}^m \mathbf{1}\{ y_i = 1\}\\\mu_b = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=b\}X_i}{\sum_{i=1}^m \mathbf{1}\{y_i=b\}},b=0,1\\\Sigma = \frac 1 m \sum_{i=1}^m(X_i - \mu_{y_i})(X_i - \mu_{y_i})^T</script><p>我们希望生成的模型如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0366.JPG" alt=""></p><p>如果画等高线图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/mg4.png" alt=""> </p><p>我们会发现找到一条线，它属于0或者1的概率是相等的。因此我们就找到了这条线。</p><h4 id="GDA与Logistic-Regression"><a href="#GDA与Logistic-Regression" class="headerlink" title="GDA与Logistic Regression"></a>GDA与Logistic Regression</h4><p>在上面的推导过程中我们发现：</p><script type="math/tex; mode=display">\begin{align}P(y=1|X;\Phi,\mu_0,\mu_1,\Sigma) &=  \frac{p(X|y=1)p(y=1)}{p(X|y=1)p(y=1)+p(X|y=0)p(y=0)}\\&=\frac {1}{1+e^{-\theta ^TX}}\end{align}</script><p>上式中：$\theta = \begin{bmatrix} \log \frac{1-\Phi}{\Phi} - \frac 1 2(\mu_0^T\Sigma^{-1}\mu_0 - \mu_1^T \Sigma^{-1}\mu_1) \ \Sigma ^{-1}(\mu_0 - \mu_1)\end{bmatrix}$.</p><p>如果还记得上次讲过的exponential family，我们应该知道对于伯奴利分布$(y|x ~{} B(\psi))$的canonical link funtion是 $\log \frac{\psi}{1-\psi}$.</p><p>因此$\theta ^X = \log \frac{\psi}{1-psi} = \log \frac{p(y=1|X)}{p(y=0|X)} = \log \frac {p(X|y=1)p(y=1)}{p(X|y=0)p(y=0)}$</p><p>这意味着：如果$p(x|y)~{}N(\mu,\Sigma)$,则$p(y|x)$是logistic function.但是从logistic regression是无法推出来GDA的。</p><p>如果我们的假设正确，GDA模型更高效，效果也更好，但是logistic regression因为比较简单，对于即使假设错误了依然有很好的鲁棒性。GDA最大化联合分布，而LR最大化的是概率分布。</p><p>所以我们发现，GDA并不像普通的学习算法那样需要去进行cost funtion的优化。这得益于我们假设整个正样本的X服从一个高斯分布。而之前的学习方法，每个样本因为X不同各个样本之间服从分布的参数都会不一致，也就是每个样本在给定y的时候有一个自己的分布（如逻辑回归，每个样本都有不同的概率，而它预测的是伯奴利分布，也就是每个样本服从不同的伯奴利分布；又如线性回归，每个样本有不一样的$\mu$）。</p><h3 id="Naive-Beyas"><a href="#Naive-Beyas" class="headerlink" title="Naive Beyas"></a>Naive Beyas</h3><p>下面介绍朴素贝叶斯模型。它用来处理输入为离散数据时候的情况。假如有这么一个例子：垃圾邮件分类。如何定义邮件的特征？当然定义的是其中的单词了。但是这个世界上单词有很多很多，而垃圾邮件很可能更包含了很多无意义的字符组合，这样特征就更多了。</p><p>假设给一个大小为n的字典（这个n可能很大，50000或者100000），而一个邮件的特征值会像下面的样子：</p><script type="math/tex; mode=display">\begin{bmatrix}1\\0\\.\\.\\.\\1\\.\\.\\.\end{bmatrix} \begin{matrix}a\\aadjsa\\.\\.\\.\\b\\.\\.\\.\end{matrix}</script><p>1或者0代表了在这个邮件中是否出现了。</p><p>现在希望对$P(X|Y)$建模。对于一封垃圾邮件：</p><script type="math/tex; mode=display">p(x_1,x_2,...,x_n|y) = p(x_1|y)p(x_2|y,x_1),...,p(x_n|y,x_1,...,x_{n-1})</script><p><em>使用了概率论中的链式法则。这个规则我也不了解，概率论还需要学习</em></p><p>这样的计算是非常复杂的。因此朴素贝叶斯模型中有一个假设：$x_i$在给定y之后是条件独立的。这意味着：$p(x_n|y,x_1,…,x_{n-1}) = p(x_n|y)$.</p><p>所以$p(x_1,x_2,…,x_n|y) = \prod _{i=1}^np(x_i|y)$.</p><h4 id="多变量伯奴利事件模型"><a href="#多变量伯奴利事件模型" class="headerlink" title="多变量伯奴利事件模型"></a>多变量伯奴利事件模型</h4><p>$p(x,y) = p(y)p(x|y) = p(y) \prod _{i=1}^n p(x_i|y)$.</p><p>这个模型假设了每封邮件是以$\Phi_y$随机生成的。如果给定y，每个单词是独立的包含在信息里的，而这个概率为$p(x_i=1|y) = \Phi_{i|y}$.</p><p>这个模型参数如下：</p><ul><li>$\Phi_y = p(y=1)$</li><li>$\Phi_{i|y=0} = p(x=1|y=0)$</li><li>$\phi_{i|y=1} = p(x=1|y=1)$</li></ul><p>同样的，接下来要做的依然是求log极大似然估计：</p><script type="math/tex; mode=display">\begin{align}L(\Phi_y \Phi_{i|y=1},\Phi_{i|y=0}) &=\log \prod_{i=1}^m p(X_i,y_i)\\ &= \log \prod_{i=1}^m p(X_i|y_i)p(y_i)\\ &= \log \prod_{i=1}^m \prod_{j=1}^np(x_j|y_i)\end{align}</script><p>不难想象，各个参数的取值如下：</p><script type="math/tex; mode=display">\Phi_y = p(y=1) = \frac 1 m \sum_{i=1}^m \mathbf{1}\{y_i=1\}\\\Phi_{j|y=b} = \frac {\sum_{i=1}^m \mathbf{1}\{y_i = b\} \cdot \mathbf{1}\{ x_j=1\} }{\sum_{i=1}^m \mathbf{1}\{y_i = b\} },b=0,1</script><p>当给了一个新的样本的时候，我们计算$p(y=1|x)$:</p><script type="math/tex; mode=display">\begin{align}p(y=1|X) &= \frac{p(X|y=1)p(y=1)}{p(X)}\\&= \frac{p(y=1)\prod _{i=1}^n p(x_i|y=1)}{p(X|y=1)+p(X|y=0)}\\&=\frac{p(y=1)\prod _{i=1}^n p(x_i|y=1)}{p(y=0)\prod _{i=1}^n p(x_i|y=0)+ p(y=1)\prod _{i=1}^n p(x_i|y=1)}\end{align}</script><p>然后根据概率是否大于0.5来进行预测。</p><h4 id="Laplace-Smoothing"><a href="#Laplace-Smoothing" class="headerlink" title="Laplace Smoothing"></a>Laplace Smoothing</h4><p>这个模型是有一个缺点的：如果新的样本的单词从来没有在训练集合里出现过，那么：</p><script type="math/tex; mode=display">\Phi_{j|y=b} = \frac {\sum_{i=1}^m \mathbf{1}\{y_i = b\} \cdot \mathbf{1}\{ x_{i,j}=1\} }{\sum_{i=1}^m \mathbf{1}\{y_i = b\} } = 0,b=0,1</script><p>也就是垃圾邮件和非垃圾邮件里出现它的概率都为0.那么最后预测结果为$\frac 0 0$,这就没法计算了。</p><p>所以我们需要进行Laplace平滑。对于没有出现过的词，我们给他赋一个较小值，而不是让他为0：</p><script type="math/tex; mode=display">\Phi_j = \frac{\sum_{i=1}^m \mathbf{1}\{z_i = j\}+1}{m+k}</script><p>为了最后使得$\Phi_j$的和为0,所以k为类比的个数，即$\sum_{i=1}^k\Phi_i = 1$。</p><p>所以最后的估计就成了下面的样子：</p><script type="math/tex; mode=display">\Phi_{j|y=b} = \frac {\sum_{i=1}^m \mathbf{1}\{y_i = b\} \cdot \mathbf{1}\{ x_{i,j} = 1\} +1}{\sum_{i=1}^m \mathbf{1}\{y_i = b\} +2},b=0,1</script><p>除此之外其他地方是一样的。</p><h4 id="Naive-Bayes-and-Multinomial-Event-Model"><a href="#Naive-Bayes-and-Multinomial-Event-Model" class="headerlink" title="Naive Bayes and Multinomial Event Model"></a>Naive Bayes and Multinomial Event Model</h4><p>现在有一个新的方法，就是多项式模型。</p><p>现在$x_i \in {1,…,\vert V \vert}$,其中|V|为字典的长度。而n为信息的长度，也就是现在每个样本的特征数已经不一样了，因为我们没法保证每封信长度一样。</p><p>对字典中每个词都进行编号：</p><div class="table-container"><table><thead><tr><th>dictionary id</th><th>1</th><th>2</th><th>…</th><th>1300</th><th>…</th><th>2400</th><th>…</th></tr></thead><tbody><tr><td>word</td><td>a</td><td>aa</td><td>…</td><td>free</td><td>…</td><td>gift</td><td>…</td></tr></tbody></table></div><p>多项式模型中有下面几个假设：</p><ul><li>信息随机地被以概率$p(y)$生成</li><li>$x_1,x_2,…,x_n$独立同分布</li><li>$p(x_1,x_2,…,x_n,y) = p(y)\prod _{i=1}^n p(x_i|y)$</li></ul><p>假设$p(x_i=k|y)$对所有的$k$来说都相等。<br>则该模型参数如下：</p><ul><li>$\Phi_y = p(y)$ </li><li>$\Phi_{k|y=1} = p(x_j = k|y=1)$ for any $j \in \{1,…,n\}$</li><li>$\Phi_{k|y=1} = p(x_j = k|y=0)$ for any $j \in \{1,…,n\}$</li></ul><p>则出现训练样本的概率为:</p><script type="math/tex; mode=display">\begin{align}L(\Phi_y,\Phi_{k|y=0},\Phi_{k|y=1}) &= \prod_{i=1}^m p(x_i,y_i)\\&= \prod_{i=1}^m p(y_i)p(x_i|y_i)\\&=\prod_{i=1}^m p(y_i) \prod_{j=1}^{n_i} p(x_{i,j}|y_i;\Phi_y,\Phi_{k|y=1},\Phi_{k|y=0})\end{align}</script><p>各个参数取值如下：</p><script type="math/tex; mode=display">\Phi_y = \frac 1 m \sum_{i=1}^m \mathbf{1}\{y_i=1\}\\\Phi_{k|y=1} = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=1\}\cdot (\sum_{j=1}^{n_i}\mathbf{1}\{x_i=k\}) +1}{\sum_{i=1}^m \mathbf{1}\{y_i=1\}+|V|}\\\Phi_{k|y=0} = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=0\}\cdot (\sum_{j=1}^{n_i}\mathbf{1}\{x_i=k\}) +1}{\sum_{i=1}^m \mathbf{1}\{y_i=0\}+|V|}</script><p>最后，预测值为：$p(y=1|x) = \frac{p(x|y=1)p(y)} {p(x|y=1)+p(x|y=0)}$</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LFD class </tag>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
            <tag> classification </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——Basic Conception</title>
      <link href="/2018/10/29/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Basic-Conception/"/>
      <url>/2018/10/29/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Basic-Conception/</url>
      
        <content type="html"><![CDATA[<p>开一个栏目来记录信息论的学习。希望今年这门课不要挂掉。<a id="more"></a></p><h2 id="信息熵-Entropy"><a href="#信息熵-Entropy" class="headerlink" title="信息熵(Entropy)"></a>信息熵(Entropy)</h2><p>香农定义了信息熵，从而为通信时代奠定了数学基础。首先直观的说明一下什么是信息？香农说：信息是用来消除随机不确定性的东西。这个说法实在是太抽象了。</p><p>考虑两个简单的例子：1,明天太阳从东方升起；2，明天太阳要爆炸。哪句话包含了更多的信息？</p><p>直观上来讲，明显是第二句。因为第一句是句“废话”。所以我们可以这样理解，概率越小的事它的信息量越大。如果一件事发生概率为1，那它包含的信息为0.如果一件事发生概率为0，它的信息量为$\infty$.另外，如果两个事件是独立的，他们两个发生的信息量是二者之和。所以写成函数形式：<br>如果有两个独立事件a,b,假如f(x)表示x的信息量，则：</p><script type="math/tex; mode=display">If p(a)>p(b), f(a)< f(b);\\f(0) = \infty, f(1) = 0;f(a,b) = f(a)+f(b)</script><p>通过上面的性质，结合概率，其实我们还是比较容易想到的是log函数。 f(x) = -log p(x),满足上面的所有条件。不过这是直观猜测，后面去证明一下log函数是唯一满足信息的定义的函数。</p><p>现在说明一下信息熵的定义：$H(X) =- \sum _{x \in \mathcal{X}} p(x) \log p(X)$.信息熵是用来衡量一个系统的信息量，如果基于之前对事件信息的定义的话，从直观来讲这个定义是合理的。现在证明它不光是合理的，而且是唯一的。</p><p>香农给出信息熵函数满足的三个条件：</p><ul><li>连续性</li><li>等概时的单调递增特性</li><li>可加性</li></ul><p>用数学语言描述如下：</p><ul><li>$H(X) = H(P_x)$ is continuous on $P_x$.</li><li>$g(N) - f(\frac 1 N,\frac 1 N,…,\frac 1 N)$. If $M &gt; N, g(M)&gt;g(N).$</li><li>$f(P_1,p_2,…,P_N) = f(P_1+P_2+…+P_M,P_{M+1},…,P_N) + (P_1+…+P_M)f(P_1’+P_2’+…+P_M’),P_i’ = \frac{P_i}{\sum_{j=1} ^M P_j}$</li></ul><p>现在根据上面三个假设来证明我们之前猜测的信息度量函数不光是正确的而且是唯一的。</p><p>首先考虑均匀分布的情况：</p><p>$X~Unif:$</p><script type="math/tex; mode=display">\begin{align}g(MN) &= f(\frac 1 {MN},...,\frac{1}{MN})\\&=f(\frac 1 M,\frac 1 {MN},...,\frac 1 {MN}) + \frac 1 M (\frac 1 N,...,\frac 1 N)\\ &= f(\frac 1 M,...,\frac 1 M) +\sum_{i=1}^M \frac 1 M ( \frac 1 N ,...,\frac 1 N)\\ &= g(M) + g(N)\end{align}</script><p>由以上的推论：</p><script type="math/tex; mode=display">g(S^m) = g(S) \cdot g(S^{m-1}) = mg(s) ---------------------(1)</script><p>取四个正整数$s,m,t,n \in N$,使得$s^m \leq t^n &lt; s^{m+1}$,由于单调增可以得到：</p><script type="math/tex; mode=display">g(s^m) \leq g(t^n) < g(s^{m+1}) \\mg(s) \leq ng(t) < (m+1)g(s) \\\frac m n \leq \frac {g(t)}{g(s)} < \frac {m+1}{n}</script><p>可以得到：</p><script type="math/tex; mode=display">\left\vert \frac m n - \frac {g(t)}{g(s)} \right\vert \leq \frac 1 n ---------(2)</script><p>如果讲上面的4个整数应用到log函数上，可以得到:</p><script type="math/tex; mode=display">m\log s\leq n\log t < (m+1) logs\\\left\vert \frac m n - \frac {\log t }{\log s} \right\vert \leq \frac 1 n -------(3)</script><p>利用$|a ± b| \leq |a|+ |b|$,结合不等式(2),(3)：</p><script type="math/tex; mode=display">\left \vert \frac {g(t)}{g(s)} - \frac {\log t}{\log s} \right \vert \leq \frac 2 n</script><p>当N取足够大时，$\frac {g(t)}{g(s)} -&gt; \frac {\log t}{\log s}$</p><p>因此我们可以得到：$g(t) = C \log t = -\sum _{i=1}^T \frac 1 t \log \frac 1 t$.</p><p>下来我们要考虑非均匀分布的情况。</p><p>假设$X~P_x(x)$,令$P(n) = \frac{m_n}{\sum_{i=1}^N m_i} = \frac{m_n}{M}$.</p><p>实际上上面各个字母意思可以用摸球来考虑：$m_1$个红球，$m_2$个绿球，…,共M个球,N种颜色，而$P(1)$也就是摸到红球的概率。考虑：</p><script type="math/tex; mode=display">\begin{align}g(M) &= f(\frac 1 M,...,\frac 1 M)\\&=f(\frac {m_1} {M},\frac {m_2}{M},...,\frac{m_N}{M}) +\sum _{i=1}^N \frac {m_i} {M}f(\frac {1}{m_i},...,\frac {1}{m_i})\\&= f(P_1,P_2,...,P_N) + \sum_{i=1}^N P_ig(m_i)\end{align}</script><p>对上面等式稍加变形：</p><script type="math/tex; mode=display">\begin{align}f(P_1,P_2,...,P_N) &= g(M) - \sum_{i=1}^N P_ig(m_i)\\&= C \log M (\sum_{i=1}^N P_i)- \sum_{i=1}^N P_ig(m_i)\\&= C\sum _{i=1}^N P_i(\log M - \log m_i )\\&= -C\sum_{i=1}^N P_i \log P_i\end{align}</script><p>这就得到了我们对熵的度量函数的形式。在不同的信息度量中常数C以及log的底数是不同的，而最常用的log底数为2，也就产生了bit。</p><p>现在X的分布是有理数，但是即使是无理数也是成立的。具体的证明就不展开了。</p><p>对于信息度量的假设条件，实际上香农的定义不是唯一的。数学家A.I.Khinchin曾经给出这样的假设：</p><ul><li>连续性</li><li>可加性</li><li>极值条件<script type="math/tex; mode=display">max f(p_1,p_2,...,p_N) = f(\frac 1 N,...,\frac 1 N)</script></li><li>零概率事件不影响不确定性<script type="math/tex; mode=display">f(p_1,p_2,...,p_N) = f(p_1,p_2,...,p_N,0)</script></li></ul><p>实际上这个条件中的3,4条件等价于香农的第二个条件。证明如下：</p><script type="math/tex; mode=display"> f(\frac 1 N,...,\frac 1 N)  =  f(\frac 1 N,...,\frac 1 N,0)< f(\frac 1 {N+1},\frac 1 {N+1},...,\frac 1 {N+1})</script><p>而上式实际上就是等概时候的单调性。</p><h3 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h3><p>Definition:<br>$H(X,Y) = -\sum _{x \in \mathcal{X}}\sum_{y \in \mathcal{Y}} P(x,y) \log P(x,y)$</p><p>$H(X,Y)$实际上是X与Y系统的联合包含的信息量。需要考虑的问题：$H(X,Y) ? H(X)+H(Y)$。</p><h3 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h3><p>Definition:</p><script type="math/tex; mode=display">\begin{align}H(Y|X) &= \sum_{x \in \mathcal{X}} p(x)H(Y|X=x)\\ &= - \sum_{x \in \mathcal{X}}p(x) \sum_{y \in \mathcal{Y}} p(y|x)\log p(y|x)\\ &= - \sum_{x \in \mathcal{X}}\sum_{y \in \mathcal{Y}} p(x,y) \log p(y|x)\end{align}</script><p>请不要以为$H(Y|X) = -\sum_{x \in \mathcal{X}}\sum_{y \in \mathcal{Y}} p(y|x) \log p(y|x)$.</p><p>条件熵的实际上是知道X的信息之后，Y的剩余信息量。</p><p>值得注意的是H(Y|X=x)不是一个条件熵，条件熵是根据两个系统而言的，而在这个中，实际上只有一个加了条件的系统：$Y|X=x$.</p><p>当X,Y独立时，$H(Y|X) = H(Y),H(X|Y) = H(X)$.在直觉上这个也是非常正确的。同时我们用物理思维理解这件事，应该可以得到：$H(X,Y) = H(X) + H(Y|X)$.</p><p>现在用严格的数学证明来证明上面的式子是成立的：</p><p>首先我们希望简化一下熵的写法：$H(X) = \mathbb{E}_x \log \frac 1 {p(X)}$($\mathbb{E}$表示数学期望).</p><p>有了这个写法，证明变得就很简单：</p><script type="math/tex; mode=display">P(X,Y) = P(X)P(Y|X)\\\log P(X,Y) = \log P(X)+ \log P(Y|X)\\\mathbb{E}_{X,Y}P(X,Y) = \mathbb{E}_{X,Y} \log P(X) + \mathbb{E}_{X,Y} \log P(Y|X)\\H(X,Y) = H(X) + H(Y|X)</script><p>上述证明没有写清负号，但是完全不影响结果。</p><p>根据上面可以推断出别的结论(如果利用画图就更好理解)：</p><ul><li><p>$H(X,Y|Z) = H(X|Z) + H(Y|X,Z)$</p><p>推论：$H(X_1,X_2,…,H_n) =  \sum _{i=1} ^N H(X_i|X_{i-1},…,X_1)$</p></li></ul><h3 id="信息熵的性质"><a href="#信息熵的性质" class="headerlink" title="信息熵的性质"></a>信息熵的性质</h3><ul><li><p>对称性：<br>$H(P_1,P_2,…,P_N) = H(P_{k(1)},P_{k(2)},…,P_{k(N)})$</p></li><li><p>非负性： $H(P) \geq 0$</p></li><li><p>可加性： $H(X,Y) = H(X) + H(Y|X)$</p></li><li><p>条件减少熵： $H(X|Y) \leq H(X)$<br>(条件熵，而非针对Y的某一特定取值，也就是不意味着$H(X|Y=y) \leq H(X)$)</p></li><li><p>最大离散熵定理：$H(p_1,p_2,…,p_n) \leq H(\frac 1 N ,…,\frac 1 N) = \log N = \log |X|$.</p></li></ul><h2 id="互信息-Mutual-Information"><a href="#互信息-Mutual-Information" class="headerlink" title="互信息(Mutual Information)"></a>互信息(Mutual Information)</h2><p>互信息描述了两个系统之间的关系。互信息的定义：$I(X;Y) = H(X) - H(X|Y)$.</p><p>也可以直接定义互信息为:$I(X;Y)= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}}p(x,y) \log \frac{p(x,y)}{p(x)p(y)}$.</p><p>互信息还有另一种写法：$I(X;Y) = I(p;Q) =  \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x)q(y|x)\log \frac{q(y|x)}{\sum _{x \in \mathcal{X}}p(x)q(y|x)}$.式子中Q为知道x后y的条件概率矩阵。</p><p>从另一方面来说：$I(X;Y) = H(X)+H(Y) - H(X,Y)$.从直观上也是很容易理解的。</p><p>很明显互信息$I(X;Y) = I(Y;X)$,具有对称性。如果X与Y独立，$I(X;Y)=0$；如果X与Y一一对应，则$I(X;Y) = H(X) = H(Y)$.</p><p>互信息和信道容量有着千丝万缕的关系。信源这边为X，信道尾部为Y，那么I(X;Y)越大的话信道容量越大。</p><h3 id="多变量的互信息"><a href="#多变量的互信息" class="headerlink" title="多变量的互信息"></a>多变量的互信息</h3><p>如果有随机变量X，Y，Z，则$I(X;Y,Z) = H(X) - H(X|Y,Z) = H(Y,Z) - H(Y,Z|X)$.</p><p>或者从数学定义上：</p><script type="math/tex; mode=display">I(X;Y,Z)= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} \sum_{z \in \mathcal{Z}}p(x,y,z) \log \frac{p(x|y,z)}{p(x)} = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} \sum_{z \in \mathcal{Z}}p(x,y,z) \log \frac{p(x,y,z)}{p(x)p(y,z)}</script><h3 id="条件互信息"><a href="#条件互信息" class="headerlink" title="条件互信息"></a>条件互信息</h3><p>定义I(X;Y|Z)为知道Z的信息之后，X与Y之间的互信息。它的定义如下：</p><p>$I(X;Y|Z) = H(X|Z) - H(X|Y,Z)= H(Y|Z) - H(Y|X,Z)$.</p><p>也可以直接定义条件互信息为:</p><script type="math/tex; mode=display">I(X;Y|Z) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} \sum_{z \in \mathcal{Z}} p(x,y,z) \log {p(x,y|z)}{p(x|z)p(y|z)}</script><script type="math/tex; mode=display">I(X;Y|Z) = H(X|Z) - H(X,Y|Z) + H(Y|Z)</script><script type="math/tex; mode=display">\begin{align}I(X;Y|Z) = &H(X,Z) - H(Z) - H(X,Y,Z) + H(Z)+H(Y,Z) - H(Z)\\&=H(X,Z)+H(Y,Z)-H(X,Y,Z)-H(Z)\end{align}</script><p>有条件减少熵，但是没有条件减少互信息。条件互信息非负。</p><ul><li><p>对称性 $I(X;Y)=I(Y;X)$</p></li><li><p>非负性 $I(X;Y) \geq 0$</p></li><li><p>极值性 $I(X;Y) \leq min\{H(X),H(Y)\}$</p></li><li><p>可加性 $I(X_1,X_2,…,X_n;Y) = \sum_{i=1} ^n I(X_i;Y|X_{i-1},…,X_1)$</p></li></ul><p>可加性用画图来表示的话也更清晰。</p><p>下面介绍一个用互信息来解决的题目。如果有25个小球，其中只有一个重量和其他的不一致。有一个天平，可以检测轻重，或者一样重。那么最少用几次才能一定找出不一样重量的小球?也许你能找到3次的方法，但是如何证明2次是不可以？</p><p>只有一个重量不一样，如果是均匀分布，则信息熵为$H(X) = \log_2^{25}$.假设进行了N次实验，则互信息为$I(X^N;X)$.</p><script type="math/tex; mode=display">\begin{align}I(X^N;X) &\leq H(X^N) \leq H(X_1,X_2,...,X_N)\\       &\leq H(X_1)+...+H(X_n)\\       &= N\log _2^3.\\\end{align}</script><p>我们希望的是互信息和原来的熵一样大，这样才能反应它的情况。</p><script type="math/tex; mode=display">\begin{align}H(X) = I(X^N;X) \leq N \log_2^3\\      \log 2^{25} \leq N log_2^3\\      N \geq 3\end{align}</script><p>所以可以得到N必须大于等于3.信息论很多时候给了我们一个上界。</p><h2 id="鉴别信息-K-L-divergence"><a href="#鉴别信息-K-L-divergence" class="headerlink" title="鉴别信息(K-L divergence)"></a>鉴别信息(K-L divergence)</h2><p>鉴别信息表示两个分布之间的距离，定义如下：</p><script type="math/tex; mode=display">D(p\Vert q) = \sum_{x \in \mathcal{X}}p(x)\log \frac{p(x)}{q(x)}</script><ul><li>当p = q的时候，D(p\Vert q) =0. </li><li>鉴别信息具有非负性。</li></ul><p>但是鉴别信息不能说是严格的信息度量。它不具有对称性，也不满足三角不等式（？？）。</p><h3 id="鉴别信息，熵，互信息"><a href="#鉴别信息，熵，互信息" class="headerlink" title="鉴别信息，熵，互信息"></a>鉴别信息，熵，互信息</h3><ul><li>$H(X) = \log |X| - D(\mathbf{p}\Vert \mathbf{u})$</li></ul><p>上式中u表示平均分布。证明如下：</p><script type="math/tex; mode=display">\begin{align}H(X) &= -\sum _{x \in \mathcal{X}}p(x)\log p(x) \\&=\log N - \log N+ \sum_{x \in \mathcal{X}}p(x) \log p(x)\\&= \log |X| + \sum_{x \in mathcal{X}} p(x)\log \frac 1 N + \sum_{x \in \mathcal{X}}p(x) \log p(x)\\&= \log |X| -  D(\mathbf{p}\Vert \mathbf{u})\end{align}</script><ul><li>$I(X;Y) = D(p(x,y)\Vert p(x)p(y)) $</li></ul><p>这个证明两边根据定义展开就可以直接得到。</p><p>信息论真是抽象啊。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——Homework1</title>
      <link href="/2018/10/26/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Homework1/"/>
      <url>/2018/10/26/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Homework1/</url>
      
        <content type="html"><![CDATA[<p>完成第一个作业（实际上是第二个）。这个作业还是比较费劲的，一个原因是对OpenGL十分不熟悉。<br><a id="more"></a></p><p>首先，openGL中，Z轴指向屏幕外，Y轴指向上侧，X轴指向右侧。这是一个需要注意的地方。</p><p>其次，openGL中3D的呈现，实际上是模拟一个相机再看这个物品。在作业中，可以知道的是茶壶放在世界坐标的原点，而刚开始的视点是(0,0,5).</p><p>作业要完成左右旋转，而实际上就是视点相对于视点相对于世界坐标要转动。在这里，我规定的转动方向是向左的话，看到茶壶的左侧，也就是视点向左侧转动，而不是让茶壶向左侧转动（那样的话我们能看到的实际上变成了右侧）。其他方向也是一样的道理。</p><p>为了让视点的坐标转动，首先要完成rotate函数的定义，这个函数直接使用Rodrigues公式就可以求得旋转矩阵。代码如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mat3 Transform::rotate(<span class="keyword">const</span> <span class="keyword">float</span> degrees, <span class="keyword">const</span> vec3&amp; axis) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">  <span class="comment">// You will change this return call</span></span><br><span class="line">vec3 _axis = glm::normalize(axis);</span><br><span class="line"><span class="keyword">float</span> theta = degrees/<span class="number">360</span>* pi;</span><br><span class="line">mat3 a_ta = mat3(_axis.x*_axis.x, _axis.x*_axis.y, _axis.x*_axis.z, _axis.y*_axis.x, _axis.y*_axis.y, _axis.y*_axis.z, _axis.z*_axis.x, _axis.z*_axis.y, _axis.z*_axis.z);</span><br><span class="line">mat3 I = mat3(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">mat3 Astar = mat3(<span class="number">0</span>, -_axis.z, _axis.y, _axis.z, <span class="number">0</span>, -_axis.x, -_axis.y, _axis.x, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> a_ta + (I - a_ta)*<span class="built_in">cos</span>(theta) + Astar * <span class="built_in">sin</span>(theta);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>很尴尬的是我不知道OpenGL中有什么简洁的办法计算$\mathbf{a}\mathbf{a}^T$，因此用手把它敲出来了。</p><p>第二个就是定义向左的函数。OpenGL中，除了视点坐标以外还有一个up向量，表示视点坐标向上的方向，也就是我们头发所指的方向。因为我们需要用两个向量来确定视点坐标系（这个后面再说）。所以我们在移动视点的时候也要移动up向量。</p><p>左右转的时候，很容易，我们不需要改变up向量，因为我们就是绕着up向量转的。所以这个很简单就可以写出来（需要注意的是转动角度的方向和转动轴向量也是符合右手定则的，这是之前推公式的结果。向左转的话，$\theta$应该取负，然而代码中<strong>我并没有取负，依然得到想要的结果</strong>）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Transform::left(<span class="keyword">float</span> degrees, vec3&amp; eye, vec3&amp; up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">mat3 r = rotate(degrees,up);</span><br><span class="line">eye = r * eye;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而上下转的时候就需要注意了，我们绕的轴就变了，实际上上下转的时候我们绕的轴是up向量与视点向量叉乘的结果，而up向量转动后也要作相应的转变。还记得up向量与eye始终垂直，那么可以看作是它的法向量。因此，法向转换就用到了:$(M^{-1})^T$.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Transform::up(<span class="keyword">float</span> degrees, vec3&amp; eye, vec3&amp; up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE </span></span><br><span class="line">mat3 r = rotate(degrees, -glm::cross(eye, up));</span><br><span class="line">up = glm::transpose(glm::inverse(r))*up;<span class="comment">//up vector is not easy to compute</span></span><br><span class="line">eye = r * eye;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后一个就是lookAt函数。要想写出来lookAt函数，首先要知道lookAt在做什么。lookAt函数是做的事情，是把茶壶投影到视点坐标当中。如果lookAt返回的是0向量，那么我们看到的茶壶的内部。</p><p>这就要求我们要建立一个坐标系出来了。之前讲过建坐标的方法，但是u,v,w只要符合右手定则就好，其他的不做要求。但是OpenGL中，z轴是朝着平面外的，因此我们就必须规定视点的向量就是z轴的方向，对应着w。接着用叉乘（up与eye向量）做出u轴，朝右的向量，最后求得v轴即可。这就建立了视点坐标。</p><p>建立视点坐标后又如何得到原来的点在该坐标系下的坐标呢？我们可以看出来这需要两步：旋转和平移。旋转和平移是不可逆的，因此我们首先要注意顺序。这个问题有点棘手。在lookAt函数中，我们需要做的是先平移再旋转（为毛我觉得是先旋转后平移？可能我对OpenGL又有什么误解。如果是移动坐标系的话是先平移后旋转的）。</p><p>（好吧，经过实际计算了之后我明白了。其实想象移动点的话是比较抽象的，但是点的移动实际上就是坐标系的相对运动。因此lookAt函数可以看作将世界坐标系移动到相机坐标系。而这个时候的移动比较容易理解的是先平移后旋转，因为如果先旋转了，平移时候加上相机坐标得到的并不是原相机的位置，因为坐标轴方向变了。而对应到点，一样也是先平移后旋转的。</p><p>至于为什么gluLookAt需要物体的中心坐标，我是因为物体本身也有一个自己的局部坐标系，需要用中心坐标（世界坐标），才能通过将局部坐标进行一个偏移，得到世界坐标后，继续上面的平移旋转操作，本题中中心坐标为(0,0,0)，所以没有便宜，局部坐标就是世界坐标）</p><p>如果理解了之前的旋转矩阵，我们就知道旋转矩阵实际上就是坐标系的三个单位向量，而旋转后的结果就是该点在该坐标系的坐标值，因此很容易得到：<br>$r = \begin{bmatrix}<br>\mathbf{u}\\<br>\mathbf{v}\\<br>\mathbf{w}<br>\end{bmatrix}$.</p><p>而平移的量实际上就是当前$eye$取负。这个也很好理解。然后得到了平移旋转矩阵：<br>$\begin{bmatrix}<br>R_{3 \times 3}&amp; R_{3 \times 3}\mathbf{eye}_{3 \times 1}\\<br>0_{1\times 3}&amp;1<br>\end{bmatrix}$</p><p>这就得到了最后的lookAt函数。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mat4 Transform::lookAt(vec3 eye, vec3 up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">vec3 w = glm::normalize(eye);</span><br><span class="line">vec3 u = glm::normalize(glm::cross(up, eye)) ;</span><br><span class="line">vec3 v = glm::normalize(glm::cross(w, u));</span><br><span class="line">mat3 r = mat3(u,v,w );</span><br><span class="line">vec3 t = vec3(-glm::dot(u,eye), -glm::dot(v,eye), -glm::dot(w,eye));</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; t.x &lt;&lt; t.y &lt;&lt; t.z &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">mat4 result = mat4(r[<span class="number">0</span>][<span class="number">0</span>], r[<span class="number">0</span>][<span class="number">1</span>], r[<span class="number">0</span>][<span class="number">2</span>], t.x, r[<span class="number">1</span>][<span class="number">0</span>], r[<span class="number">1</span>][<span class="number">1</span>], r[<span class="number">1</span>][<span class="number">2</span>], t.y, r[<span class="number">2</span>][<span class="number">0</span>], r[<span class="number">2</span>][<span class="number">1</span>], r[<span class="number">2</span>][<span class="number">2</span>], t.z, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">return</span> glm::transpose(result);</span><br><span class="line">  <span class="comment">// You will change this return call</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我一直不明白为什么最后要加一个transpose.</p><p>现在我知道了OpenGL（glm）中矩阵构造时候是列优先的，如m[0][1],指的是第0列第1行。所以我构造出来的所有矩阵都应该加个转置，这也解释了为什么上面代码degree没有取负依然得到了正确的结果。正确代码如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">mat3 Transform::rotate(<span class="keyword">const</span> <span class="keyword">float</span> degrees, <span class="keyword">const</span> vec3&amp; axis) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">  <span class="comment">// You will change this return call</span></span><br><span class="line">vec3 _axis = glm::normalize(axis);</span><br><span class="line"><span class="keyword">float</span> theta = degrees/<span class="number">180</span>* pi;</span><br><span class="line">mat3 a_ta = mat3(_axis.x*_axis.x, _axis.x*_axis.y, _axis.x*_axis.z, _axis.y*_axis.x, _axis.y*_axis.y, _axis.y*_axis.z, _axis.z*_axis.x, _axis.z*_axis.y, _axis.z*_axis.z);</span><br><span class="line">mat3 I = mat3(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">mat3 Astar = mat3(<span class="number">0</span>, -_axis.z, _axis.y, _axis.z, <span class="number">0</span>, -_axis.x, -_axis.y, _axis.x, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> glm::transpose(a_ta + (I - a_ta)*<span class="built_in">cos</span>(theta) + Astar * <span class="built_in">sin</span>(theta));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Transforms the camera left around the "crystal ball" interface</span></span><br><span class="line"><span class="keyword">void</span> Transform::left(<span class="keyword">float</span> degrees, vec3&amp; eye, vec3&amp; up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line"></span><br><span class="line">mat3 r = rotate(-degrees,up);</span><br><span class="line"></span><br><span class="line">eye = r * eye;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; eye.x &lt;&lt; eye.y &lt;&lt; eye.z &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Transforms the camera up around the "crystal ball" interface</span></span><br><span class="line"><span class="keyword">void</span> Transform::up(<span class="keyword">float</span> degrees, vec3&amp; eye, vec3&amp; up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE </span></span><br><span class="line">mat3 r = rotate(-degrees, -glm::cross(eye, up));</span><br><span class="line">up = glm::transpose(glm::inverse(r))*up;<span class="comment">//up vector is not easy to compute</span></span><br><span class="line">eye = r * eye;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Your implementation of the glm::lookAt matrix</span></span><br><span class="line">mat4 Transform::lookAt(vec3 eye, vec3 up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">vec3 w = glm::normalize(eye);</span><br><span class="line">vec3 u = glm::normalize(glm::cross(up, eye)) ;</span><br><span class="line">vec3 v = glm::normalize(glm::cross(w, u));</span><br><span class="line">mat3 r = mat3(u,v,w );</span><br><span class="line">vec3 t = vec3(-glm::dot(u,eye), -glm::dot(v,eye), -glm::dot(w,eye));<span class="comment">//-r * eye;</span></span><br><span class="line">mat4 result = mat4(r[<span class="number">0</span>][<span class="number">0</span>], r[<span class="number">0</span>][<span class="number">1</span>], r[<span class="number">0</span>][<span class="number">2</span>], t.x, r[<span class="number">1</span>][<span class="number">0</span>], r[<span class="number">1</span>][<span class="number">1</span>], r[<span class="number">1</span>][<span class="number">2</span>], t.y, r[<span class="number">2</span>][<span class="number">0</span>], r[<span class="number">2</span>][<span class="number">1</span>], r[<span class="number">2</span>][<span class="number">2</span>], t.z, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">return</span> glm::transpose(result);</span><br><span class="line">  <span class="comment">// You will change this return call</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>最后结果：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0296.GIF" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> homework </tag>
            
            <tag> computer graphics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——Transformation</title>
      <link href="/2018/10/25/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Transformation/"/>
      <url>/2018/10/25/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Transformation/</url>
      
        <content type="html"><![CDATA[<p>上次博客最后一个主题矩阵，只说了句矩阵可以完成很多转换。而这次就主要来说明各种转换。<br><a id="more"></a></p><p>所有的转换我们都是通过矩阵和向量完成的。</p><h3 id="缩放（Scale）"><a href="#缩放（Scale）" class="headerlink" title="缩放（Scale）"></a>缩放（Scale）</h3><script type="math/tex; mode=display">Scale(s_x,s_y,s_z) = \begin{pmatrix}s_x&0&0\\0&s_y&0\\0&0&s_z\end{pmatrix} \ Scale^{-1}(s_x,s_y,s_z) = \begin{pmatrix}s_x^{-1}&0&0\\0&s_y^{-1}&0\\0&0&s_z^{-1}\end{pmatrix}</script><p>上述中$s_x,s_y,s_z$分别为各个坐标轴的缩放倍数。实际的转换过程如下：</p><script type="math/tex; mode=display">\begin{pmatrix}s_x&0&0\\0&s_y&0\\0&0&s_z\end{pmatrix} \begin{pmatrix}x\\y\\z\end{pmatrix} = \begin{pmatrix}s_xx\\s_yy\\s_zz\end{pmatrix}</script><h3 id="错切（Shear）"><a href="#错切（Shear）" class="headerlink" title="错切（Shear）"></a>错切（Shear）</h3><p>错切可以将一个矩形转换成平行四边形。</p><script type="math/tex; mode=display">Shear(s_x,s_y) = \begin{pmatrix}s_x&a\\0&s_y\end{pmatrix} \ Shear^{-1}(s_x,s_y) = \begin{pmatrix}s_x&-a\\0&s_y\end{pmatrix}</script><p>上面式子主要完成的是对于y&gt;0的点前移，y&lt;0的点后移，而各点的y坐标不变。从而产生了错切的感觉。得到的结果：$y’=y,x’=x+ay$.</p><h3 id="旋转（Rotation）"><a href="#旋转（Rotation）" class="headerlink" title="旋转（Rotation）"></a>旋转（Rotation）</h3><p>2维空间的旋转变换次序是没有影响的，但是对于三维空间却可能得到不一样的结果。</p><h4 id="2D-rotation"><a href="#2D-rotation" class="headerlink" title="2D rotation"></a>2D rotation</h4><p>这里说的旋转是绕着原点旋转。</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix} = \begin{bmatrix}\cos \theta & - \sin \theta\\\sin \theta &\cos \theta\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}</script><p>有趣的是：$R^T R = I$</p><h4 id="3D-rotation"><a href="#3D-rotation" class="headerlink" title="3D rotation"></a>3D rotation</h4><p>3D的rotation相比于2D的要复杂很多。但是实际上我们可以这样去理解：二维的旋转，相当于绕着Z轴旋转，因为z坐标不会变。</p><p>因此可以得到绕各个坐标轴旋转的矩阵：</p><script type="math/tex; mode=display">R_z = \begin{pmatrix}\cos \theta & - \sin \theta & 0\\\sin \theta &\cos \theta & 0\\0&0&1\end{pmatrix}</script><p>同样的道理也就可以得到绕x轴与绕y轴的旋转：</p><script type="math/tex; mode=display">R_x = \begin{pmatrix}1&0&0\\0&\cos \theta & - \sin \theta \\0&\sin \theta &\cos \theta \\\end{pmatrix} \ R_y = \begin{pmatrix}\cos \theta & 0&- \sin \theta \\0&1&0\\\sin \theta &0 &\cos \theta\end{pmatrix}</script><p>同样的:$R^TR = I$.</p><p>如果我们仔细观察可以发现，3D中R的各个行（列）向量满足一个三维坐标系的要求：单位向量且正交。因此如果我们将旋转矩阵写成下面的形式：</p><script type="math/tex; mode=display">R = \begin{pmatrix}x_u & y_u & z_u\\x_v & y_v & z_v\\x_w & y_w & z_w\end{pmatrix}</script><p>则</p><script type="math/tex; mode=display">R_p = \begin{pmatrix}x_u & y_u & z_u\\x_v & y_v & z_v\\x_w & y_w & z_w\end{pmatrix}\begin{pmatrix}x_p\\y_p\\z_p\end{pmatrix} = \begin{pmatrix}\mathbf{u} \cdot \mathbf{p} \\\mathbf{v} \cdot \mathbf{p} \\\mathbf{z} \cdot \mathbf{p}\end{pmatrix}</script><p>上式最后一项正是$\mathbf{p}$在uvw坐标轴下的坐标值。因此旋转的本质实际上是将它映射到另一个坐标系当中了。</p><p>对于旋转矩阵如何求逆？因为旋转矩阵是正交矩阵，所有$R^{-1} = R^T$.</p><p>3D旋转是不可交换的。</p><p>但是上面的旋转矩阵相对来说比较简单，因为是绕着坐标轴旋转的。那么有没有办法绕着任意一个向量旋转$\theta$的公式？</p><h5 id="罗德里格旋转-Rodrigues-公式"><a href="#罗德里格旋转-Rodrigues-公式" class="headerlink" title="罗德里格旋转(Rodrigues)公式"></a>罗德里格旋转(Rodrigues)公式</h5><p>接下来这个公式就是用来解决上述问题的。假设向量（点）$b$绕着单位向量$\mathbf{a}$旋转$\theta$.</p><p>$\mathbf{b}=\mathbf{b}_{∥}+\mathbf{b}_{⊥}$，分布表示平行与垂直于$\mathbf{a}$的分量。很容易知道，$\mathbf{b}_{∥}$在旋转过程中是不变的。</p><p>$\mathbf{b}_{∥} = \mathbf{a} \cdot \mathbf{b} \mathbf{a}$</p><p>$\mathbf{b}_{⊥} = 1 -\mathbf{b}_{∥}$</p><p>然后我们要考虑到$\mathbf{b}_{⊥}$是如何旋转的。实际上它旋转的平面是垂直于$\mathbf{a}$与$\mathbf{b}$的，容易想到利用叉乘来构造：</p><p>$\mathbf{c} = \mathbf{a} \times \mathbf{b}$，而且由于叉乘的性质，$\mathbf{c}$的长度恰好等于$\mathbf{b}_{⊥}$.</p><p>现在旋转角度是$\theta$，则旋转后的向量在$\mathbf{b}_{⊥}$与$\mathbf{c}$方向上的投影分别是$\mathbf{b}_{⊥} \cos \theta$与$\mathbf{c} \sin \theta$.</p><p>旋转后的向量边上上述向量之和，并且希望写成旋转矩阵的形式（矩阵乘以向量）：</p><script type="math/tex; mode=display">\begin{align}b' &= \mathbf{b}_{⊥} \cos \theta +\mathbf{c} \sin \theta + \mathbf{b}_{∥}\\&= (\mathbf{b} -\mathbf{a} \cdot \mathbf{b} \mathbf{a} )\cos \theta +\mathbf{a} \times \mathbf{b} \sin \theta +\mathbf{a} \cdot \mathbf{b} \mathbf{a}\\&= \mathbf{a}\mathbf{a}^T \mathbf{b} + (I -\mathbf{a}\mathbf{a}^T)\mathbf{b} \cos \theta + A^* \sin \theta \mathbf{b} \end{align}</script><p>所以$R(\mathbf{a},\theta) =\mathbf{a}\mathbf{a}^T+ (I -\mathbf{a}\mathbf{a}^T)\cos \theta + A^* \sin \theta$.</p><p>上式是计算机图形学中很重要的一个基础公式。</p><h3 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h3><p>如果要回到原来的样子，可以对所有的转换求逆。但是要注意的是：$M = M_1M_2M_3,M^{-1} = M_3^{-1}M_2^{-1}M_1^{-1}$.</p><h3 id="齐次坐标转换（Homogeneous-Coordinates）"><a href="#齐次坐标转换（Homogeneous-Coordinates）" class="headerlink" title="齐次坐标转换（Homogeneous Coordinates）"></a>齐次坐标转换（Homogeneous Coordinates）</h3><p>不知道有没有人有这么一个疑问：为什么没有平移？？平移应该是最简单的转换，但是实际起来的实现却没有那么容易。首先做个尝试：</p><script type="math/tex; mode=display">\begin{pmatrix}x'\\y'\\z'\end{pmatrix} = \begin{pmatrix}?&?&?\\?&?&?\\?&?&?\end{pmatrix}\begin{pmatrix}x\\y\\z\end{pmatrix}=\begin{pmatrix}x+5\\y\\z\end{pmatrix}</script><p>中间的矩阵怎么做？有人会说将第一行第一列写为$\frac 5 z$即可，但是这就失去了转换矩阵的意义。转换矩阵中不应该包含我们要转换的坐标的信息。</p><p>计算机图形学中，解决这个问题的方法就说用齐次坐标，先看一下下面的转换：</p><script type="math/tex; mode=display">\begin{pmatrix}x'\\y'\\z'\\w'\end{pmatrix} = \begin{pmatrix}1&0&0&5\\0&1&0&0\\0&0&1&0\\0&0&0&1\end{pmatrix}\begin{pmatrix}x\\y\\z\\1\end{pmatrix}=\begin{pmatrix}x+5\\y\\z\\1\end{pmatrix}</script><p>通过加入一个其次坐标w而实现了平移。而加入这个量不会对上面提到的旋转等操作产生影响，而且他有很多的好处，因此被普遍用于图形相关的软件与硬件中。</p><h4 id="平移-Translate"><a href="#平移-Translate" class="headerlink" title="平移(Translate)"></a>平移(Translate)</h4><script type="math/tex; mode=display">\begin{pmatrix}x'\\y'\\z'\\w'\end{pmatrix} = \begin{pmatrix}1&0&0&T_x\\0&1&0&T_y\\0&0&1&T_z\\0&0&0&1\end{pmatrix}\begin{pmatrix}\mathbf{p}_x\\\mathbf{p}_y\\\mathbf{p}_z\\1\end{pmatrix}=\begin{pmatrix}\mathbf{p}_x+T_x\\\mathbf{p}_y+T_y\\\mathbf{p}_z+T_z\\1\end{pmatrix} = \mathbf{p}+T</script><p>主要旋转平移矩阵和平移旋转矩阵是不一样的，因为平移矩阵实际上需要的是最右侧的一个向量：</p><p>旋转平移矩阵：</p><script type="math/tex; mode=display">\begin{bmatrix}R_{3 \times 3}&T_{3 \times 1}\\0_{1 \times 3}&1\end{bmatrix}</script><p>平移旋转矩阵:</p><script type="math/tex; mode=display">\begin{bmatrix}R_{3 \times 3}&R_{3 \times 3}T_{3 \times 1}\\0_{1\times 3}&1\end{bmatrix}</script><p>仔细推导就可以得到上面的结果。</p><h3 id="法向转换（Normal-Transformation）"><a href="#法向转换（Normal-Transformation）" class="headerlink" title="法向转换（Normal Transformation）"></a>法向转换（Normal Transformation）</h3><p>法向的转换并不会按照平面各个点的转换进行。</p><p>假如原来的切线向量为$\mathbf{t}$,原来的法向向量为$\mathbf{n}$，转换矩阵为$M$，则切线向量是会依照原来的转换而改变的：$\mathbf{t}’ = M\mathbf{t}$.</p><p>假设转换完成后的法向向量为$\mathbf{n}’ = Q\mathbf{n}$.</p><p>当然不管什么时候，法向与切向都应该是垂直的：$\mathbf{n}’^T\mathbf{t’} = 0$</p><p>可以得到：</p><script type="math/tex; mode=display">\mathbf{n}^TQ^TM \mathbf{t} = 0.</script><p>因此我们希望$Q^TM = I$,所以得到：$Q = (M^{-1})^T$.</p><p>当然上面的解并不是唯一解，但是计算机图形学是工程学科，我们希望的是能够解决这个问题即可。</p><p>需要注意的是：$M$为3×3矩阵。因为法向和切向是向量，所以平移不会影响法向和切向。</p>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> computer graphics </tag>
            
            <tag> transformation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——Basic Math</title>
      <link href="/2018/10/24/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Basic-Math/"/>
      <url>/2018/10/24/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Basic-Math/</url>
      
        <content type="html"><![CDATA[<p>加入了智能成像实验室，但是我对计算机图形学了解还太浅，因此需要学习一些图形学的基础知识。本篇博客先介绍一些很简单的数学基础。<br><a id="more"></a></p><h3 id="右手坐标系"><a href="#右手坐标系" class="headerlink" title="右手坐标系"></a>右手坐标系</h3><p>首先是XYZ坐标轴，一般我们使用的坐标轴是符合右手定则的。这也是大多数数学教材使用的坐标轴的定义。右手定则即用右手从X轴方向握向Y轴方向，这时候伸出大拇指，大拇指的朝向就是Z轴的方向。实际上这是一个很基础的知识，但是我过去没多久才发现自己一直不知道这个东西。直到计算第二型曲面积分时候发现结果总是相反才发现。</p><h3 id="向量点乘和叉乘"><a href="#向量点乘和叉乘" class="headerlink" title="向量点乘和叉乘"></a>向量点乘和叉乘</h3><h4 id="点乘（Dot-Product）"><a href="#点乘（Dot-Product）" class="headerlink" title="点乘（Dot Product）"></a>点乘（Dot Product）</h4><p>$\mathbf{a} \cdot \mathbf{b} = \vert a \vert \vert b\vert \cos {\theta}$</p><p>$\theta = \cos ^{-1} \frac {\mathbf{a} \cdot \mathbf{b}}{\vert a \vert \vert b\vert}$</p><p>实际上在笛卡尔坐标系中求解两个向量的点乘是非常容易的：</p><p>$\mathbf{a} = x_a \mathbf{x} + y_a \mathbf{y},\mathbf{b} = x_b \mathbf{x} + y_b \mathbf{y}$</p><p>则：$\mathbf{a} \cdot \mathbf{b} = x_a x_b + y_a y_b$</p><p>因此点乘可以用来求两个向量的夹角。</p><p>另一个点乘的应用是求某个向量到另一个向量上的投影，如$\mathbf{a}$在$\mathbf{b}$上的投影长度实际上是$\vert \mathbf{a} \vert \cos \theta$，而$\vert \mathbf{a} \vert \cos \theta = \frac {\vert \mathbf{b}\vert\vert \mathbf{a} \vert \cos \theta}{\mathbf{b}} = \frac {\mathbf{a} \cdot \mathbf{b}}{\vert \mathbf{b}\vert}$.</p><p>同样的想要求投影之后的向量也很简单，只要用长度乘上$\mathbf{b}$方向的单位向量即可：<br>$\mathbf{p} =  \frac {\mathbf{a} \cdot \mathbf{b} \mathbf{b}}{\vert \mathbf{b}\vert ^2}$.</p><h4 id="叉乘（Cross-Product）"><a href="#叉乘（Cross-Product）" class="headerlink" title="叉乘（Cross Product）"></a>叉乘（Cross Product）</h4><p>$\vert \mathbf{a} \times \mathbf{b} \vert= \vert \mathbf{a} \vert \vert \mathbf{b}\vert \sin \theta$</p><p>上面为叉乘的长度，除此之外，叉乘得到的是一个向量，它的方向符合右手定则，也与原来两个向量垂直。</p><p>从右手定则可以很容易推导出：$\mathbf{a} \times \mathbf{b} = - \mathbf{b} \times \mathbf{a}$.</p><p>同时也有以下的一些等式：</p><script type="math/tex; mode=display">\mathbf{x} \times \mathbf{y} = \mathbf{z},\mathbf{y} \times \mathbf{x} = -\mathbf{z}</script><script type="math/tex; mode=display">\mathbf{a} \times \mathbf{a} = \mathbf{0}</script><script type="math/tex; mode=display">\mathbf{a} \times (\mathbf{b} + \mathbf{c}) = \mathbf{a} \times \mathbf{b}+ \mathbf{a} \times \mathbf{c}</script><script type="math/tex; mode=display">\mathbf{a} \times (k\mathbf{b}) = k(\mathbf{a} \times \mathbf{b})</script><p>在笛卡尔坐标系下，叉乘的计算也不算困难：</p><script type="math/tex; mode=display">\mathbf{a}\times \mathbf{b} = \begin{vmatrix} \mathbf{x}&\mathbf{y}&\mathbf{z}\\x_a&y_a&z_a\\x_b&y_b&z_b\end{vmatrix} = \begin{pmatrix} y_az_b - y_bz_a,\\z_ax_b - x_az_b,\\x_ay_b - y_ax_b \end{pmatrix}</script><p>而且也可以写成下面的形式：</p><script type="math/tex; mode=display">\mathbf{a}\times \mathbf{b} = A^* \mathbf{b}\begin{pmatrix}0&-z_a&y_a\\z_a&0&-x_a\\-y_a&x_a&0\end{pmatrix} \begin{pmatrix}x_b\\y_b\\z_b\\\end{pmatrix}</script><p>上式中$A^*$被成为向量$\mathbf{a}$的对偶矩阵。</p><h3 id="坐标系-Coordinate-Frames"><a href="#坐标系-Coordinate-Frames" class="headerlink" title="坐标系(Coordinate Frames)"></a>坐标系(Coordinate Frames)</h3><p>坐标系并不是只有XYZ，XYZ只是标识而已。任何满足下面条件的三个向量，都可以作为坐标系：</p><ul><li>$\vert \mathbf{u} \vert = \vert \mathbf{v} \vert = \vert \mathbf{w} \vert = 1$</li><li>$\mathbf{u} \cdot \mathbf{v} = \mathbf{v} \cdot \mathbf{w} = \mathbf{u} \cdot \mathbf{w} = 0$</li><li>$\mathbf{w} = \mathbf{u} \times \mathbf{v}$</li></ul><p>任何一个向量可以写成各个坐标系的投影之和：</p><script type="math/tex; mode=display">\mathbf{p}  = (\mathbf{p} \cdot \mathbf{u} ) \mathbf{u} + (\mathbf{p} \cdot \mathbf{v}) \mathbf{v} + (\mathbf{p} \cdot \mathbf{w})\mathbf{w}</script><p>如何使用两个非零非同方向的向量创造一个坐标系（在三维重建中可能会经常碰到）？</p><script type="math/tex; mode=display"> \mathbf{u} = \frac {\mathbf{a}}{ \vert \mathbf{a}\vert},\mathbf{w} = \frac {\mathbf{a} \times \mathbf{b}}{\vert \mathbf{a} \times \mathbf{b} \vert}, \mathbf{v}= \mathbf{w} \times \mathbf{v}.</script><p>从上面我们可以看到叉乘对于创建一个坐标系的作用。</p><h3 id="矩阵（Matrix）"><a href="#矩阵（Matrix）" class="headerlink" title="矩阵（Matrix）"></a>矩阵（Matrix）</h3><p>$(AB)^{-1} = B^{-1}A^{-1}$,因为$ AB B^{-1} A^{-1} = I$.</p><p>通过矩阵可以实现空间点的各种转换。</p>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mathematics </tag>
            
            <tag> computer graphics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>计算摄像学——Depth image quality assessment</title>
      <link href="/2018/10/24/%E8%AE%A1%E7%AE%97%E6%91%84%E5%83%8F%E5%AD%A6%E2%80%94%E2%80%94Depth-image-quality-assessment/"/>
      <url>/2018/10/24/%E8%AE%A1%E7%AE%97%E6%91%84%E5%83%8F%E5%AD%A6%E2%80%94%E2%80%94Depth-image-quality-assessment/</url>
      
        <content type="html"><![CDATA[<p>最近导师让我调查一下关于深度图像品质评估的方法。<br><a id="more"></a></p><p>首先说明一下深度图像。在Quora上一个用户回答得很有意思：Depth-Image给了一个物体的深度信息，或者说它的“z”轴信息。</p><p>简而言之，深度图像就是描述了图像中各个点到相机之间的距离信息。平时拍的照片，将3D的物品投影到了2D的照片上，但仅仅从一张照片想要了解到目标的3D模型是做不到的（多张照片可能做到，如多视图三维重建），因为从3D到2D会缺失很多信息，比如距离信息。投影到2D之后我们不知道哪个前，哪个后。所以说Quora的回答很有趣，深度图像给了我们“z”轴的信息，因此结合深度图进行三维重建是可以的。</p><p>实际上深度图在很多3D应用中扮演了很重要的角色，高品质的深度图像可以帮助解决计算机视觉中的很多挑战。实际中深度图像可以通过深度相机（Kinect）或者立体图像获取，得到的深度图像经常因为闭塞，重复纹理或者传感器噪声导致深度图像的品质不够好。</p><p>因为深度图像的广泛应用，对于深度图像品质的评估就显得很重要。</p><h3 id="Compare-with-its-ground-truth-depth-image"><a href="#Compare-with-its-ground-truth-depth-image" class="headerlink" title="Compare with its ground truth depth image"></a>Compare with its ground truth depth image</h3><p>可以想到的简单的方法是通过与它的ground truth depth image（找不到一个很好的翻译来翻译这个术语）作比较。这个方法可以准确的衡量深度图像的品质，但是ground truth depth image在大多数实际应用中并没有那么容易获得。</p><p>(<em>What’s the ground truth depth image?Here are some answers I searched:</em></p><blockquote><p>The ground truth depth image depends on what kind of object you want to detect, but usually the ground truth is done by experts in the area.</p><p>If you need ground truth information for real images, you need a way to label the pixels in your image with the information, which object they belong to. This can be a manual (and very time-consuming) process or be semi-automatic (run some segmentation algorithms and only correct wrong pixel manually).</p></blockquote><p><em>So We can clearly know that the ground truth image is not easy to get. If we have this, Why do I still need a depth image??</em>)</p><h3 id="Evaluate-the-quality-of-the-reconstructed-color-image-obtained-by-the-tested-depth-image"><a href="#Evaluate-the-quality-of-the-reconstructed-color-image-obtained-by-the-tested-depth-image" class="headerlink" title="Evaluate the quality of the reconstructed color image obtained by the tested depth image"></a>Evaluate the quality of the reconstructed color image obtained by the tested depth image</h3><p>另一种办法是评估通过这张深度图重建的普通场景图片。如果我们有一个物品的深度图像以及该物品的部分视图图片，我们可以通过这些对物体进行3D建模，当然可以渲染别的部分的视图图片。然后通过该图片与真实的视图图片作比较，从而评估深度图像的品质。</p><p>不过这个算法也是有缺点的，因为这需要几对真实照片，这个并不一定那么容易获取。另外渲染算法的好坏也会影响到评估结果。</p><h3 id="RR-DQM-Use-A-pair-of-color-image-and-depth-image"><a href="#RR-DQM-Use-A-pair-of-color-image-and-depth-image" class="headerlink" title="RR-DQM(Use A pair of color image and depth image)"></a>RR-DQM(Use A pair of color image and depth image)</h3><p>我在网络上查到了一篇关于仅仅使用一张色彩图和深度图的深度图品质评估方法的论文。实际上一般的深度相机在得到深度图像的时候也会得到对应的灰度图像。而因为各种原因造成的深度图片失真，在灰度图上并不会出现。因此一种可行的办法是对比与对应的灰度图的各个特征来评估深度图的失真情况。</p><p>论文中，先通过制造水平与垂直方向的噪声（人工数据），来观察合成图片的失真情况，发现深度图像失真的对于合成图片的影响力大小依赖于灰度图的特点。因此深度失真与图片特点的关系可以用来衡量深度图的质量。</p><p>论文中，首先会利用Gabor滤波器以及Susan算子进行纹理以及边缘检测。Gabor滤波器从0°，45°，90°，135°进行Gabor energy(融合了条纹以及边缘的获取)的计算，而Susan算子则通过检测边缘以及边缘方向，与深度图结合得到深度图的局部失真。当一个像素处于非边缘的情况时，则通过它周围的8个像素点来得到失真情况。最后通过将Gabor滤波与Susan算子得到的结果结合得到某个像素点的全局失真情况。最后通过将所有可用像素点（因为有部分深度图中的像素点因为位于高反射区域而得到错误的深度值，这些部分的像素点被称为outlier，不参与计算当中）的global distortion相加求评价，得到整张深度图的失真情况，从而进行深度图片的品质评估。</p><p>论文链接：<a href="https://link.springer.com/article/10.1007/s11042-016-3392-4" target="_blank" rel="noopener">A new depth image quality metric using a pair of color and depth images</a>.</p><h3 id="FDQM-fast-quality-metric-for-depth-maps"><a href="#FDQM-fast-quality-metric-for-depth-maps" class="headerlink" title="FDQM(fast quality metric for depth maps)"></a>FDQM(fast quality metric for depth maps)</h3><p>文章在刚开始介绍了很多一般图片的品质评估算法，而这些算法在MVD（the multiview video plus depth）应用中也可以用来评估深度图像的质量，然而通过对比一个参考深度图以及它的失真版本来进行对比，想要得到较好的效果需要较大的时间复杂的。也就是没有对于深度图的品质评估上还没有发展出比较好的评估算法。在深度图上的小错误可能会导致中间合成图质量严重降低。这篇论文提出的算法可以高效地衡量深度图的错误在合成2D图上的影响。</p><p>首先通过需要将参考与失真图的深度值转换为参考图与失真深度图之间的差异，然后测量由视差引起的合成像素失真，最后通过空间汇集方式整合像素失真，得到FDQM指数。</p><p>这个算法需要左视与右视两张RGB图，对于该算法，逐像素计算时候依然需要结合各个点权重，而物品边界的像素相对于平滑区域的需要更大的权重，因此需要计算颜色图与差异图的梯度图。通过左右视图逐像素地处理得到总的失真衡量。</p><p>论文链接：<a href="http://mcl.korea.ac.kr/~dotol1216/Publications/2015_TCSVT_WDJANG.pdf" target="_blank" rel="noopener">FDQM: Fast Quality Metric for Depth Maps<br>Without View Synthesis</a></p><h3 id="其他链接："><a href="#其他链接：" class="headerlink" title="其他链接："></a>其他链接：</h3><p><a href="https://ieeexplore.ieee.org/document/5877203" target="_blank" rel="noopener">A novel depth map quality metric and its usage in depth map coding</a></p><p><a href="https://www.researchgate.net/publication/261387264_A_comprehensive_evaluation_of_full_reference_image_quality_assessment_algorithms" target="_blank" rel="noopener">A comprehensive evaluation of full reference image quality assessment algorithms</a></p><p>对于深度图像的品质评估我可以搜到的论文不够多，而且这些论文普遍引用量不够高，因此质量无法评定。</p>]]></content>
      
      
      <categories>
          
          <category> 计算摄像学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> computational photography </tag>
            
            <tag> depth image </tag>
            
            <tag> quality assessment </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Generalized Linear Model</title>
      <link href="/2018/10/22/Learning-From-Data%E2%80%94%E2%80%94Generalized-Linear-Model/"/>
      <url>/2018/10/22/Learning-From-Data%E2%80%94%E2%80%94Generalized-Linear-Model/</url>
      
        <content type="html"><![CDATA[<p>这次数据学习课上，讲的是Generalized Linear Model。我心里想着是要概况线性模型，我应该都清楚吧。上课了之后才发现，这实际上是广义线性模型，有很多新东西。然而我还是睡着了。<br><a id="more"></a></p><p>首先引入一个概念，叫做<strong>指数族分布</strong>。</p><h3 id="Exponential-Family"><a href="#Exponential-Family" class="headerlink" title="Exponential Family"></a>Exponential Family</h3><p>如果一个分布可以被写成下面的形式：</p><script type="math/tex; mode=display">p(y;\eta) = b(y)e^{\eta ^T T(y) - a(\eta)}</script><p>那么这个分布属于Exponential Family。其中：</p><p>$\eta$: natural/canonical parameter(自然参数) </p><p>$T(y)$: suﬃcient statistic of the distribution(充分统计量) </p><p>$a(η)$: log partition function(对数划分函数)</p><p>其中$a(\eta)$是一个归一化常数的对数。也就是：</p><p>$p(y;\eta) = b(y)e^{\eta ^T T(y) - a(\eta)} = \frac {b(y)e^{\eta^T T(y)} } {e^{a(\eta)} }$</p><p>$\sum_{y} p(y;\eta) = 1(or \int _y p(y;\eta) dy = 1) $</p><p>我们可以得到：<br>$a(\eta) = \log {\left(\sum _y b(y)e^{\eta ^T T(y)} \right)}$</p><p>指数分布族有很多成员，实际上我们熟悉的很多分布都是指数分布族的。下面举几个例子：</p><h4 id="Bernoulli-Distribution"><a href="#Bernoulli-Distribution" class="headerlink" title="Bernoulli Distribution"></a>Bernoulli Distribution</h4><p>伯努利分布应该是最简单的分布之一了。$y \in {1,0}$，而且$p(y=1) = φ,p(y=0) = 1 - φ$，因此它的分布可以写成下面的样子：</p><p>$p(y;φ) = φ^y(1-φ)^{1-y}$</p><p>如何将它转化为指数族的形式？</p><ul><li><p>$\eta = \log {\frac {\phi } {1-\phi} }$</p></li><li><p>$T(y) = y$</p></li><li><p>$a(\eta) = \log {(1 + e^{\eta})}$ </p></li><li><p>$b(y) = 1$</p></li></ul><h4 id="Gaussian-Distribution-unit-variance"><a href="#Gaussian-Distribution-unit-variance" class="headerlink" title="Gaussian Distribution(unit variance)"></a>Gaussian Distribution(unit variance)</h4><p>高斯分布也是很常见的分布，这里我们先说明一下unit variance的情况，也就是$\sigma = 1$。它的概率密度如下：</p><script type="math/tex; mode=display">p(y;\mu) = \frac 1 {\sqrt{2 \pi} } exp\left(- \frac {(y - \mu)^2}{2} \right)</script><ul><li><p>$\eta = \mu$</p></li><li><p>$ T(y) = y$</p></li><li><p>$a(\eta) = \frac {\eta ^2} {2}$</p></li><li><p>$b(y) = \frac 1 {\sqrt{2 \pi} } e^{-\frac {y^2}{2} } $</p></li></ul><h4 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h4><p>现在将目标放到普通的高斯分布上。</p><script type="math/tex; mode=display">p(y;\mu) = \frac 1 {\sqrt{2 \pi \sigma ^ 2} } exp\left(- \frac {(y - \mu)^2}{2\sigma ^ 2} \right)</script><ul><li><script type="math/tex; mode=display">\eta = \left[\begin{matrix} \frac {\mu}{\sigma^2} \\ -\frac {1}{2\sigma^2} \end{matrix}\right]</script></li><li><script type="math/tex; mode=display">  T(y) = \left[ \begin{matrix} y \\y^2 \end{matrix}\right]</script></li><li><p>$a(\eta) = \frac {\mu^2}{2\sigma^2} + \log {\sigma}$</p></li><li><p>$b(y) = \frac 1 {\sqrt {2 \pi} }$</p></li></ul><p>这里情况变得就稍微复杂了点。</p><h4 id="Poisson-Distribution-Poisson-lambda"><a href="#Poisson-Distribution-Poisson-lambda" class="headerlink" title="Poisson Distribution:Poisson($\lambda$)"></a>Poisson Distribution:Poisson($\lambda$)</h4><p>泊松分布平时我们接触不如前两项多。泊松分布一般可以用在估计一个固定的时间段内某个事情发生的次数，假设各个事件之间互相独立，它们发生有一个固定的比率$\lambda$.</p><p>泊松分布的概率密度函数如下：</p><script type="math/tex; mode=display">p(y;\lambda) = \frac {\lambda ^y e ^{- \lambda} }{y!}</script><ul><li><p>$\eta = \log {\lambda}$</p></li><li><p>$T(y) = y$</p></li><li><p>$a(\eta) = e^{\eta}$</p></li><li><p>$b(y) = \frac {1}{y!}$</p></li></ul><h3 id="Generalized-Linear-Models"><a href="#Generalized-Linear-Models" class="headerlink" title="Generalized Linear Models"></a>Generalized Linear Models</h3><p>所以什么是广义线性模型？GLM是从来自于指数族分布$y|X;\theta$一种构造线性模型的方法。</p><p>广义线性模型的设计动机为：</p><ul><li>相应变量y可以是任意分布</li><li>允许y的任意函数（链接函数）可以随输入值x线性变化</li></ul><p>广义线性模型形式化定义有下面几个假设：</p><ol><li>$y|x;\theta$ ~ Exponential Family(\eta),如高斯分布，伯努利分布，泊松分布等</li><li>假设目标函数是$h(x) = \mathbb{E}[T(y)|x]$</li><li>自然常数$\eta$和输入$X$是线性相关的：$\eta = \theta^TX$ or $\eta_i = \theta_i^T X (\eta = \Theta^T X)$ </li></ol><p>将自然参数与分布平均值连接得到：$\mathbb{E}[T(y);\eta]$.</p><p>权威响应函数（Canonical response function）g给出了分布平均值：$g(\eta) = \mathbb{E}[T(y);\eta]$.</p><p>则 $\eta = g^{-1}(\mathbb{E}[T(y);\eta])$,被称为权威链接函数（canonical link function）。</p><p>写成广义线性模型，可以得到：$\mathbb{E}(y;\eta)=\frac{d}{d\eta}a({\eta})$（证明较为复杂）。因此，可以很轻易得求出假设函数。</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><h4 id="Ordinary-Least-Square"><a href="#Ordinary-Least-Square" class="headerlink" title="Ordinary Least Square"></a>Ordinary Least Square</h4><p>应用GLM到下面的假设：</p><ol><li><p>$y|X;\theta ~ N(\mu,1)$,则$\eta = \mu,T(y) = y$.</p></li><li><p>Derive Hypothesis function $h_\theta(X) = \mathbb{E}[y|X;\theta] = \mu = \eta$.</p></li><li><p>Adopt linear model $\eta = \theta ^TX $: $h_\theta (X) = \eta = \theta ^T X$.</p></li></ol><p>Canonical response function:$g(\eta) = \mu = \eta$</p><p>Canonical link function:$\eta = g^{-1}(\mathbb{E}[T(y);\eta] = g’(\mu) = mu$</p><h4 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h4><ol><li><p>$y|X;\theta ~ Bernoulli(\phi)$，则$\eta = \log {\left(\frac {\phi}{1 - \phi}\right)},T(y) = y$</p></li><li><p>Derive hypothesis function $h_\theta(X) = \mathbb{E}[y|X;\theta] = \phi = $,则$\phi = \frac {1}{1 + e^{-\eta} }$</p></li><li><p>Adopt linear model $\eta = \theta ^T X$: $h_\theta(X) = \phi = \frac {1}{1 + e^{-\theta^TX} }$</p></li></ol><p>Canonical response function:$ φ = g(η) = sigmoid(η)$ </p><p>Canonical link function : $η = g^{−1}(φ) = logit(φ)$</p><h4 id="Possion-Regression"><a href="#Possion-Regression" class="headerlink" title="Possion Regression"></a>Possion Regression</h4><ol><li><p>$y|X;\theta ~ P(\lambda)$,则$\eta = \log{\lambda},T(y) = y$</p></li><li><p>Derive hypothesis function $h_\theta(X) = \mathbb{E}[y|X;\theta] = \lambda = e^{\eta}$</p></li><li><p>Adopt linear model $\eta = \theta^TX$: $h_\theta (X) = \lambda = e^{\theta^TX}$</p></li></ol><p>Canonical response function:$\lambda = g(\eta) = e^{\eta}$</p><p>Canonical link function:$\eta = g^{-1}(\lambda) = log(\lambda)$</p><h4 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h4><p>最后我们来推断下Softmax Regression，因为softmax是多维的分布，所以还是有点难度的。</p><p>首先我们应该写出它的分布函数如下：</p><script type="math/tex; mode=display">p(y;\theta) = \prod_{i=1}^k \phi_i^{\mathbf{1}\{y = i\} }</script><p>然后需要做的是把它写成Exponential Family的形式.</p><p>如果照着平时的思路下来，我们会发现，$a(\eta) = 0$,这是不允许发生的（Why？）。因此我们需要想办法，如果把$\phi_k$移到最后，又如何保证前面没有$y$的影响？</p><p>仔细观察上式，我们发现可以将上式写为：$\prod _{i=1}^k \left(\frac{\phi_i}{\phi_k} \right)^{\mathbf{1}\{y=i\} } \phi_k$. (!!!Genius!).</p><ul><li><p>$\eta = \left [ \begin{matrix}<br>\log{\frac {\phi_1}{\phi_k} }\\<br>\log{\frac {\phi_2}{\phi_k} }\\<br>…\\<br>\log{\frac{\phi_{k-1} }{\phi_k} }<br>\end{matrix} \right ]$</p></li><li><p>$T(y) = \left[<br>  \begin{matrix}<br>  \mathbf{1}\{y=1\}\\<br>  \mathbf{2}\{y=2\}\\<br>  …\\<br>  \mathbf{k-1}\{y=k-1\}<br>  \end{matrix}<br>  \right]$</p></li><li><p>$b(y) = 1$</p></li><li><p>$a(\eta) = -\log{(\phi_k)}$</p></li></ul><p>有了上面的格式，如何运用线性模型就比较顺理成章了。</p><ol><li><p>$y|X;\theta ~ P(\Phi)$,则$\eta ,T(y)$如上。</p></li><li><p>Derive hypothesis function :</p><script type="math/tex; mode=display">h_\theta(X) = \mathbb{E}[y|X;\theta] = \Phi =</script><script type="math/tex; mode=display">\begin{bmatrix} \frac {e^{\eta_1} }{\sum _{i=1}^k e^{\eta_i} }\\\frac {e^{\eta_2} }{\sum _{i=2}^k e^{\eta_i} }\\...\\1 - \frac {e^{\eta_k} }{\sum _{i=1}^k e^{\eta_i} }\end{bmatrix}</script><p>(注意，在这里为了方便我们定义$\eta_k = \log { {\eta_k}{\eta_k} } = 0$)</p></li><li><p>Adopt linear model $eta = \Theta^TX$:</p><p>$ h_\Theta (X)  =\begin{bmatrix}<br>\frac {e^{\theta_1^TX} }{\sum _{i=1}^k e^{\theta_i^TX} }\\<br>\frac {e^{\theta_2^TX} }{\sum _{i=1}^k e^{\theta_i^TX} }\\<br>…\\<br>1 - \frac {e^{\theta_k ^TX} }{\sum _{i=1}^k e^{\eta_i^TX} }<br>\end{bmatrix} $</p></li></ol><p>Canonical response function:$\phi_i = g(\eta) =\frac  {e^{\eta_i} }{\sum _{i=2}^k e^{\eta_i} }$</p><p>Canonical link function:$\eta_i = g^{-1}(\phi) = \log {\frac {\phi_i}{\phi_k} }$.</p><p>因此，根据广义线性模型，我们可以推出需要的hypothesis funtion的形式，从而进行进一步的学习。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LFD class </tag>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
            <tag> exponential family </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Softmax Regression</title>
      <link href="/2018/10/16/Learning-From-Data%E2%80%94%E2%80%94Softmax-Regression/"/>
      <url>/2018/10/16/Learning-From-Data%E2%80%94%E2%80%94Softmax-Regression/</url>
      
        <content type="html"><![CDATA[<p>Learning From Data是研究生修的一门课，其实也就是机器学习的另一种叫法。第一门课中介绍了Linear Regression，Logistic Regression，Softmax Regression.虽然前两个都学过，但是还是有一些收获，比如另外的解释方法等等。<a id="more"></a></p><h2 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h2><p>这次Linear Regression主要学习到的新的东西是，从概率角度来理解为什么使用Least Square.</p><p>假设目标函数是 $Y = W^Tx+ \epsilon$，其中$\epsilon$是N维向量.假设$\epsilon$是独立同分布（IID）的，而且满足高斯分布$N(0,\sigma)$,则:</p><script type="math/tex; mode=display">p(y_n|X_n,W) = \frac 1 {\sqrt{2\pi }\sigma } exp \left(-\frac{(Y_n - W^TX_n)^2}{2\sigma ^2} \right)</script><p>而出现这个样本的概率如下：</p><p>$L(W) = p(Y|X,W) = \prod _{n=1}^N p(y_n|X_n,W)$.</p><p>我们想要求得最大概率估计（Maximum Likelihood Estimation）:$W_{MLE} = argmax_W(L{W})$.</p><p>展开之前我们应该加个log，因为我们喜欢sum而不是prod。如下：</p><script type="math/tex; mode=display">\begin{array} {l}\log{L(W)} &= \sum _{n=1}^N(\log{\frac 1 {\sqrt {2 \pi} \sigma}}- \frac 1 {2\sigma ^2 } (Y_n - W^TX_n)^2 \log e )\\ &= m \log{\frac 1 {\sqrt {2 \pi }\sigma}} - \frac 1 {2\sigma ^2 }  \sum_{n=1}^N  (Y_n - W^TX_n)^2 \end{array}</script><p>所以，$argmax_{W} (L(W)) = argmin_{W} (\sum_{n=1}^N  (Y_n - W^TX_n)^2 )$.这也正是我们的cost function的定义。</p><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>Logistic Regression学习了从另一种角度思考得到另一种定义cost function的方法，当然最终效果是一致的。</p><p>之前的logsitic regression对于$P(X_i \bigcap y_i)$的估计如下：</p><script type="math/tex; mode=display">P(X_i \bigcap y_i) =\frac {(y_i+1)} 2 P(X_i) \times P(y_i = +1|X_i) +\frac {(1 - y_i)} 2 P(X_i) \times (1 - P(y_i = +1|X_i))</script><p>实际上有另外一种可以达到一样的效果,不过此时我们需要的就是另外一种对$y$的定义了：$y \in {0,1}$:</p><script type="math/tex; mode=display">P(X_i \bigcap y_i) = (P(X_i) \times P(y_i = 1|X_i))^{y_i} (P(X_i) \times (1 - P(y_i = 1|X_i)))^{1-y_i}</script><p>因此出现这个样本的概率为：</p><script type="math/tex; mode=display">L(W) = \prod _{i=1}^N (P(X_i \bigcap y_i) = P(X_i) \times h_w(X_i) )^{y_i} (P(X_i) \times (1-h_W(X_i)))^{1-y_i} .</script><p>我们可以略去这些$P(X_i)$,因为这是确定的而且也不是我们需要注意的。<br>这时候log之后，得到最后的cost funtion的形式与之前就有了一些不同：</p><script type="math/tex; mode=display">f(W) = -(\sum _{i=1}^N y_i \log h_W{X_i} + (1 - y_i)\log{ (1 -h_W{X_i})})</script><p>接下来要做的就是求这个函数的梯度，但是为了看的清楚，首先说明下各个函数的意义：</p><script type="math/tex; mode=display">h_W(X) = \frac 1 {1 - e^{-g_W(X)}}</script><script type="math/tex; mode=display">g_W(X) = W^TX</script><p>求梯度过程如下：</p><script type="math/tex; mode=display">\begin{array}{l}\nabla f(W) &= -(\sum _{i=1} ^N (y_i log(h_W(X_i)) + (1-y_i) log(1-h_W(X_i))))\\&= -(\sum_{i=1}^N \left[ \frac {y_i}{h_W(X_i)} - \frac {1-y_i}{1-h_W(X_i)} \right] h_W'(x))\\&= -(\left[y_i + \frac {1-y_i}{e^{-g_W(X_i)}} \right] \frac {e^{-g_W(X_i)}}{1 - e^{-g_W(X_i)}} g_W'(X_i)) \\\ &= -(\left[ \frac 1 {1 - e^{-g_W(X_i)}} - y_i \frac {1 - e^{-g_W(X_i)}}{1 - e^{-g_W(X_i)}} \right] g_W'(X_i))\\&=-(y_i - h_W(X_i))X_i  \end{array}</script><p>而且这个cost function的好处是，利用梯度下降的时候它和线性回归的步骤是非常相似的,线性回归中：</p><script type="math/tex; mode=display">\frac {\partial f(W)}{\partial w_j} = \sum _{i=1}^N(y_i - g_{W}(X_i))x_{i,j}.</script><p>即</p><script type="math/tex; mode=display">\nabla f(W) = \sum_{i=1}^N (y_i - g_{W}(X_i))X_i.</script><p>最后回到两种不同的cost funtion，实际上两者本质没有太大的区别，只是negative，positive的标识数字不同。最后得到的结果可能也不一样，但是差距不会太大，都会得到比较理想的结果。</p><h2 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h2><p>Softmax Regression是一种多维分类算法。依然是站在概率的角度来讨论。</p><p>假设共有k类，即$y \in {1,…,k}$.我们先给出一个概率估计，之前得概率估计是logistic函数，现在我们给出另一种情况：</p><script type="math/tex; mode=display">h_W(X_i) = \left [    \begin{matrix}p(y_i = 1|X_i;W_1)\\p(y_i=2|X_i;W_2)\\...\\p(y_i=k|X_i;W_k) \end{matrix}\right] = \frac 1 {\sum _{j=1}^k e^{W_j^TX_i}}  \left[\begin{matrix} e^{W_1^TX_i}\\ e^{W_2^TX_i}\\ ...\\ e^{W_k^TX_i} \end{matrix}\right]  = softmax(W,X_i)</script><p>同时我们定义:$softmax(z_i) = p{y = i|X,W} = \frac {e^{z_i}}{\sum _{j=1}{k} e^{z_j}}$，此时$i \in {1,…,k}$.</p><p>当然，W参数也会发生变化：</p><script type="math/tex; mode=display">W = \left[\begin{matrix}-W_1^T-\\-W_2^T-\\...\\-W_k^T- \end{matrix}\right]</script><p>因此我们确定了给定$W$和$X$的时候，$y$的概率。</p><p>而出现当前样本的概率（我们忽略$P(W,X)$,像之前一样它不会影响结果）：</p><script type="math/tex; mode=display">L(W) = \prod_{i=1}^{N} P(y_i|X_i,W).</script><p>其实我们可以想象的是这个式子展开了后会很复杂，因为对$y_i$可能的各个情况也要连乘。不如先log好了：</p><script type="math/tex; mode=display">\begin {array}{l} F(W) = \log{L(W)} &= \sum_{i=1}^N \log {p(y_i|X_i,W) }\\ &= \sum_{i=1}^N \log{\prod_{j=1}^k p_{W_j}(j|X_i,W)^{\mathbf{1}\{y_i = j\}}}\\ &= \sum_{i=1}^N \sum_{j=1}^k \mathbf{1}\{y_i = j\} \log { \frac {e^{W_jX_i}}{\sum _{l=1}^k e^{W_l^TX_i}}}\end {array}</script><p>这个东西，其实我推算的时候对他的符号表示已经很头大了。但是它虽然复杂但原理不难懂，和logistic regression的道理基本上一样的。</p><p>最后，我们就是要求这个函数的梯度了。这个函数的梯度求解想必是非常复杂的，但是实际上没有想象的那么麻烦。最后的结果也非常的简单：</p><script type="math/tex; mode=display">\nabla _{W_j} F(W) = \sum _{i=1}^m \left( \mathbf{1}\{y_i = j\} \log {\frac {e^{W_j^TX_i}}{\sum _{l=1}^k e^{W_l^TX_i}}} + \mathbf{1}\{y_i \ne j\} \log {\frac {e^{W_{y_i}^TX_i}}{\sum _{l=1}^k e^{W_l^TX_i}}} \right)</script><p>我们仔细观察原式就可以化简上面的样子。为了简化后面的步骤，假设$g(W_l) = W_l^TX_i$.<br>第一种情况$ {y_i = j}$：</p><script type="math/tex; mode=display">f_1(W) = \log {\frac {e^{g(W_j)}}{\sum_{l=1}^k e^{g(W_l)}}}</script><script type="math/tex; mode=display">\begin{array}{l}\nabla _{W_j} f_1(W)  &= \frac {\sum_{l=1}^k e^{g(W_l)}}{e^{g(W_j)}} \cdot \frac { -e^{2g(W_j)}+ (\sum_{l=1}^k e^{W_l})e^{W_j}}{(\sum_{l=1}^k e^{g(W_l)})^2} \cdot g'(W_j)\\&= \frac{\sum_{l=1}^k e^{g(W_l) - e^{g(W_j)}}}{\sum_{l=1}^k e^{g(W_l)}} \cdot g'(W_j) \\\ &= (1 - p(y_i = l|X_i,W))X_i\end{array}</script><p>第二种情况$y_i \ne j$,假设$y_i = q \ne j$:</p><script type="math/tex; mode=display">f_2(W) = \log {\frac {e^{g(W_q)}}{\sum_{l=1}^k e^{g(W_l)}}}</script><script type="math/tex; mode=display">\begin{array}{c}\nabla _{W_j} f_2(W) &=\frac {\sum_{l=1}^k e^{g(W_l)}}{e^{g(W_q)}} \cdot \frac { -e^{g(W_j) e^{g(W_q)}}}{(\sum_{l=1}^k e^{g(W_l)})^2} \cdot g'(W_j)\\&= - p(y_i = l|X_i,W)X_i\end{array}</script><p>也是两种情况的差别只有前面是否加一个1。合并两种情况，可以得到：</p><script type="math/tex; mode=display">\nabla _{W_j} F(W) = \sum _{i=1} ^N [(\mathbf{1}\{y_i=j\} - p(y_i=l|X_i,W))X_i]</script><p>上面推出来的要注意是我们想要最大化的函数。</p><p>而cost funtion的梯度应该是： $\sum _{i=1} ^N [(-\mathbf{1}\{y_i=j\} + p(y_i=l|X_i,W))X_i] $</p><p>对于softmax regression我们需要知道，它的参数$W_j$之间并不是独立的，因为各个概率加起来为1，有这个约束后实际上，只要知道$k-1$个参数，就可以确定这个模型。</p><p>实际上，可以很容易证明logistic regression 是 softmax regression的特殊情况。</p><p>以上就是上节课学到的所有新东西。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LFD class </tag>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数学——Newton Method</title>
      <link href="/2018/10/16/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Newton-Method/"/>
      <url>/2018/10/16/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Newton-Method/</url>
      
        <content type="html"><![CDATA[<p>梯度下降时候，有时候我们可以使用Newton Direction.牛顿迭代法其实大家听起来很熟悉的。<br><a id="more"></a></p><p>首先来说明下，简单的牛顿迭代法的原理。牛顿迭代法是求近似解的一个办法，很多时候解无法算出来，我们只能用牛顿迭代法来一步步逼近。</p><p>首先给个很直观的例子，也就是一维的函数。先观看一下下面的gif。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/NewtonIteration_Ani.gif" alt=""></p><p>为了求得$f(x) = 0$,我们从图上直观看到可以一直这样逼近，最终会逼近到f(x) = 0的解。</p><p>原理是，如果我们将f(x)一阶泰勒展开,得到：</p><script type="math/tex; mode=display">f(x) \approx f(x_0)+f'(x_0)(x - x_0) = g(x)</script><p>而上式g(x) = 0是很容易解决的：$x = x_0 - \frac {f(x_0)}{f’(x_0)}$.</p><p>因为泰勒只是近似，因此上述得到的解并不是真正的解，只是离原有的解更接近了。也就是，牛顿迭代法种，下一步更新策略为:$x_{n+1} =x_n - \frac {f(x_n)}{f’(x_n)} $.</p><p>如何将牛顿迭代法用来解决优化问题？我们知道优化问题，想要得到最小值，或者最大值，在该点导数是为0的，这个问题就变成了，如何找到导数为0的点，那么就很简单了，对于一维函数的优化问题迭代步骤如下:$x_{n+1} =x_n - \frac {f’(x_n)}{f’’(x_n)} $.</p><p>多维函数来说，情况较为复杂一点，因为高纬度的二阶导数实在是很多。不过原理也是变化不大的，我们需要利用Hessian矩阵：</p><p>$x_{n+1} = x_{n+1}-H_f^{-1}(x_n)\nabla f(x_n)$.</p><p>Hessian矩阵定义如下：</p><script type="math/tex; mode=display">H_f = \begin{bmatrix} \frac {\partial^2f}{\partial x_1^2}& \frac {\partial^2f}{\partial x_1 \partial x_2}&...&\frac {\partial^2f}{\partial x_1 \partial x_n} \\\frac {\partial^2f}{\partial x_2 \partial x_1}& \frac {\partial^2f}{\partial x_2 \partial x_2}&...&\frac {\partial^2f}{\partial x_2 \partial x_n} \\...\\\frac {\partial^2f}{\partial x_n \partial x_1}& \frac {\partial^2f}{\partial x_n \partial x_2}&...&\frac {\partial^2f}{\partial x_n^2} \end{bmatrix}</script><p>可以看到的是，如果维度较高，这个海森矩阵的求逆是非常耗费时间的。一般来说，优化问题时候，维度较低的情况下，它的效果还是非常好的，比梯度下降更快。</p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Soft-Margin Support Vector Machine</title>
      <link href="/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Soft-Margin-Support-Vector-Machine/"/>
      <url>/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Soft-Margin-Support-Vector-Machine/</url>
      
        <content type="html"><![CDATA[<p>之前提到的之前的SVM会overfitting除了模型过于复杂，另一个问题就是它要将样本分类在训练集上做到完全正确。这时候一些噪声就会很大程度上影响结果。为了适应这些噪声，不得不做出很复杂的模型。<a id="more"></a></p><p>因此有时候我们希望可以容忍一些样本被错误分类。因此原有的数学条件就需要改变一下了。</p><p>现在我们回到最开始描述的问题：</p><p><strong>min</strong>  $\frac 1 2 W^TW$</p><p>$s.t.  y_n(W^TX_n+b) \ge 1,n =1,2,…,N $.</p><p>现在我们不要求所有的$ y_n(W^TX_n+b) \ge 1$,可以容忍一些错误。当然这个错误不能无限大。假设现在被分错的样本犯的错误是$\xi _n$,那么问题可以被描述为下：</p><p><strong>min</strong>  $\frac 1 2 W^TW + C\sum_{n=1}^N\xi_n$</p><p>$s.t.  y_n(W^TX_n+b) \ge 1 - \xi_n,n =1,2,…,N $.</p><p>$\xi_n \ge 0,n=1,2,…,N$</p><p>仔细看上面的描述我们可以发现，如果一个样本没有犯错，那么它对应的$\xi_n = 0$.如果一个样本犯错了，那么它对应的$\xi_n = 1 - y_n(W^TX_n+b)$.</p><p>因此实际上上面的问题也可以被描述成下面的形式：</p><p><strong>min</strong>  $\frac 1 2 W^TW + C\sum_{n=1}^N \ell(y_i,W^TX_i+b)$</p><p>where  $\ell(\cdot,\cdot)$ is the hinge loss defined by $\ell(x,y) \triangleq max\{1-yz,0\}$.</p><p>常数$C$的作用在于我们可以接受的犯错程度大小。可以想象的是如果$C$比较大，整个目标既然在最小化上面的式子，那么$\xi_n$的值就会变得非常小，也就是我们可以对划分错误的容忍度是比较小的，如果$C$比较大，那么容忍度则较大，因此这里也有一个权衡。</p><p>我们从上面的描述出发继续推导这个问题的Lagrange Dual Problem：</p><script type="math/tex; mode=display">\frac 1 2||W||^2 + C\sum_{n=1}^N \xi_n + \sum_{n=1}^N \alpha_n(1 - \xi_n - y_n(W_TX_n+b)) + \sum_{n=1}^N(-\beta \xi_n)</script><p>这个时候，实际上所有的关于$W,b$的偏导数与之前都是一致的。在这里就不详细推导了，只是最后我们需要对$\xi_n$求偏导：</p><script type="math/tex; mode=display">\frac {\partial \ell} {\partial \xi_n} = 0 = C - \alpha_n - \beta _n</script><p>由上式可以得到：$\beta _n = C - \alpha_n$因为我们有参数限制，$\alpha_n \ge 0,\beta_n \ge 0,n=1,…,N$,因此实际上我们可以得到的约束是：$ 0 \leq \alpha_n \leq C$.</p><p>同时由上面的结论，再结合原来的式子，还可以消掉的是$\xi$.</p><p>因此最后得到的那些KKT条件与原来HardMagin唯一的不同就在于$\alpha_n$的限制变了。从这里可以看出来$C$的作用:$C$很大的时候，说明这个限制相对原来较小，也就是要求犯错较少（因为原来的情况我们是不允许犯错误的）。</p><p>通过二次规划，我们可以一样得到$\alpha_n $的值，从而得到$W$，与$b$.但是需要注意的是$b$与之前的算法不一样了。</p><p>之前我们通过$a_n(1 - y_n(W^TX_n+b)) = 0$，通过找到是支持向量的点（$a_n \ne 0$）,从而通过该点计算出来$b = y_n - W^TX_n$.</p><p>而此时，我们想要计算的$b = y_n - y_n \xi_n - W^TX_n$.</p><p>有个问题，我们不知道$\ell_n$的值啊（其实我们是知道的$\xi_n = max(1 - y_n(W^TX_n+b),0)$，不过这是要等$b$求出来之后）。但是我们知道另一个信息$\beta_n \xi_n = (C - \alpha_n) \xi_n = 0$，这意味着如果$\alpha_n \ne C$的点，$\xi = 0$.所有实际上我们需要的是$0&lt;\alpha_n &lt; C$的点，这时候$\xi= 0$,可以计算出$b = y_n - W^TX_n$，这样的点叫free Support Vector.个别时候我们无法找到$free Support Vector$，那么这个$b$的值只能用kkt条件来限制了。</p><p>这里，我们希望可以仔细思考一下$\alpha_n$背后是否有什么指示。</p><p>如果$\alpha_n = 0$，那么$1 - \xi_n - y_n(W^TX_n +b) \leq 0$，可以得到的是这些点一般是完全没有错误的，这点和之前是一样的。</p><p>否则，$C&gt;\alpha_n &gt; 0$，则我们通过上面的推导也知道$\xi_n = 0$.这意味着，它们对应的$y_n(W^TX_n+b) = 1$.所以这些点是Support Vector，它们定义了最宽的分界线。</p><p>还有一种情况，$\alpha_n = C$.这种点就是被分错的点了，$\xi \ne 0$，但是$ 1 - \xi - y_n(W^TX_n+b) = 0$.要注意的是这里的分错并不一定是分类结果错误，还有可能是在分到margin中间去了。</p><p>上面的内容就是Soft Margin SVM，但是值得注意的是，我们需要调一个参数：C，如果C过大，仍然可能会overfitting。</p><p>Soft Margin SVM可以与Kernel结合，在实际中使用比Hard Margin SVM更加频繁。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Kernel Support Vector Macine</title>
      <link href="/2018/10/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Kernel-Support-Vector-Macine/"/>
      <url>/2018/10/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Kernel-Support-Vector-Macine/</url>
      
        <content type="html"><![CDATA[<p>上次遇到的问题是，Q矩阵的计算，仍然可能需要耗费很大计算量，也就是对于很高维度的特征转换，我们不一定能高效解决，更不用说无限维度。<a id="more"></a></p><p>因此这次引入了核函数，告诉我们如何高效地对待特征转换地问题。</p><h2 id="Polynomial-Kernel"><a href="#Polynomial-Kernel" class="headerlink" title="Polynomial Kernel"></a>Polynomial Kernel</h2><p>为了方便起见，我们希望可以把原来问题描述中的$X$换为$Z$,表示$Z$是$X$经过特征转换之后得到的高维度空间，而假设$X$维度是较低的。因此，现在的问题描述如下：</p><p>$min_{\alpha} \frac 1 2 \sum_{n=1}^N \sum_{m=1}^N a_na_my_ny_mZ_n^TZ_m - \sum_{n=1}^N \alpha_n$</p><p> <strong>subject to</strong> $\sum_{n=1}^N y_n\alpha_n = 0;a_n \ge 0,n=1,…,N$</p><p>上次我们也介绍了Q矩阵的计算，其中$q_{n,m} = y_ny_mZ_n^TZ_m$.这其中包含了对$Z$向量的乘积，因此隐含了很大的计算量。</p><p>假设，我们对$X$到$Z$向量的转换表示如下：$Z = \phi(X)$,那么上式中$Z_n^TZ_m = \phi(X_n)^T\phi(X_m)$.</p><p>我们知道，对于单单$X_n^TX_m$的计算是容易完成的，那么能不能通过什么办法用上面的计算来代替原来的硬算？</p><p>假设如下：$\phi(X) = {1,x_1,x_2,x_3…x_d,x_1^2,x_1x_2,…x_2x_1,x_2^2,…,x_dx_1,…x_d^2}$.</p><p>那么$\phi(X_n)^T\phi(X_m) = 1 + \sum_{i=1}^{d}x_i^nx_i^m + \sum_{i=1}^d\sum_{j=1}^d x_i^nx_j^nx_i^mx_j^m $</p><p>$\phi(X_n)^T \phi(X_m) = 1+X_n^TX_m + \sum_{i=1}^{d}x_i^nx_i^m  \sum_{j=1}^{d} x_j^n x_j^m = 1+X_n^TX_m + (X_n^TX_m)^2 $.</p><p>可以发现，通过这样的变换，我们很轻易地计算出$Z_n^TZ_m$.</p><p>在这里，我们称$k(X,X’) = 1+X^TX’ + (X^TX’)^2 $为一种核函数。如果我们对特征转换再进行一些处理，比如：$\phi(X) = {1,\sqrt 2 x_1,\sqrt 2 x_2,\sqrt 2 x_3…\sqrt 2 x_d,x_1^2,x_1x_2,…x_2x_1,x_2^2,…,x_dx_1,…x_d^2}$,</p><p>那么最后得到的是$k(x,x’) = (1+X^TX’)^2$。实际上，我们也可以转换到更高维的空间，继续推广到更一般的：$K(x,x’) = (\zeta + \xi x^Tx’)^d$. 这就是很有名的Polynomial Kernel。</p><p>当然，通过多项式核函数，我们无法实现无限维度的转换。</p><h2 id="Gaussian-Kernel-RBF-Kernel"><a href="#Gaussian-Kernel-RBF-Kernel" class="headerlink" title="Gaussian Kernel(RBF Kernel)"></a>Gaussian Kernel(RBF Kernel)</h2><p>对于高斯Kernel的介绍，我们尝试用另一种办法来推导。为了方便起见，我们假设维度只有一维，即$X = {x}$.</p><p>在这里直接给出$K(X,X’)$的定义如下：$K(X,X’) = e^{-(x -x’)^2}$.</p><p>然后我们一步步推向前推导，说明它其实是无限维度转换后的$X^TX$.</p><script type="math/tex; mode=display">\begin{align}K(X,X') &= e^{-(x - x')^2}\\&= e^{-x^2} e^{-(x')^2}e^{2xx'} \\&=Taylor=>e^{-x^2}e^{-(x')^2}(\sum _{i=0} ^ {\infty} \frac {(2xx')^2}{i!})\\&= \sum_{i=0}^{\infty} \frac {(\sqrt 2 x)^i}{\sqrt{i!}}e^{-x^2} \frac {(\sqrt 2 x')^i}{\sqrt{i!}} e^{-(x')^2}\end{align}</script><p>因此，这个转换就是 $\phi(x) = exp(-x^2)(1,\sqrt{\frac 2 {1!}}X,\sqrt{\frac {2^2}{2!}}X^2,…)$</p><p>可以证明的是，上升到多维度，Gaussian Kernel：</p><p>$K(X,X’)$ = $e^{-\gamma ||X - X’||^2}$ with $\gamma &gt; 0$.</p><p>这就是高斯核函数。但是需要注意的一点，高斯核函数放大无限维度空间，所以如果参数$\gamma$不当，仍然有可能overfitting.如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/TAE0Z%7D9NZWU7D%291%7EI8C1SLY.png" alt=""></p><h2 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h2><p>还有一个核函数，叫线性核函数：$K(x,x’) = x^Tx’$.</p><p>这个核函数，简单，也迅速，但是能力有限。</p><p>多项式核函数：$K(x,x’) = (\zeta + \xi x^tx’)^d$.</p><p>相对于线性核函数，它的能力强了很多，但是调参很难，因为有3个参数。相应的它的速度没有线性那么快。而且如果d很大,要么结果很接近0，要么很大，不会取得很好的结果。因此，它一般来说，只在d比较小的时候适用。</p><p>高斯核函数：$K(X,X’)$ = $e^{-\gamma ||X - X’||^2}$</p><p>高斯核函数很强大，计算速度比线性的略慢，但是也不差。但是它可能太过强大了，需要慎重适用，因为可能出现过拟合的情况。但是总体来说，一般来说高斯核函数是最常用的。</p><p>当然，还有很多别的核函数，只需要满足Mercer定理即可。</p><blockquote><p>Mercer定理：</p><p>如果函数K是$\mathcal{R}^n \times \mathcal{R}^n-&gt;\mathcal{R}$上的映射（也就是从两个n维向量映射到实数域）。那么如果K是一个有效核函数（也称为Mercer核函数），那么当且仅当对于训练样例${x_1,x_2,…x_n}$，其相应的核函数矩阵是对称半正定的。</p></blockquote><p>我们可以发现，kernel的区别实际上是特征转换的区别，只不过某些特征转换可以更容易地计算Q矩阵。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Dual Support Vector Machine</title>
      <link href="/2018/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Dual-Support-Vector-Machine/"/>
      <url>/2018/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Dual-Support-Vector-Machine/</url>
      
        <content type="html"><![CDATA[<p>之前说明了linear SVM的，但是实际上依然还有一些问题。虽然在一定程度上，linear SVM会减小特征转换带来的复杂度，但是另一方面，它依然依赖着d.<a id="more"></a>如果d过大，即使使用很多现有的QP工具，依然很难得到结果。如何处理数据维度很大，甚至是无穷维的情况？这是我们想要解决的问题。</p><p>但是要注意的事，实际上的数学推导非常复杂，因此在这里我只会做简单的推导，来慢慢达到自己的目标。</p><p>首先我们拿出来上次讨论到最后的成型的问题：</p><p><strong>min</strong>  $\frac 1 2 W^TW$</p><p>$s.t.  y_n(W^TX_n+b) \ge 1,n =1,2,…,N $.</p><p>我们可以想到的是利用拉格朗日乘数，类似于之前的正则化，来构造一个函数$\zeta(W,b,\alpha)$,定义如下：</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) = \frac 1 2 W^TW + \sum _{n = 1} ^{N} \alpha_n (1 - y_n(W^TX_n+b))</script><p>我们要做的SVM是：$min_{W,b}(max_{all \alpha_n \ge 0} \zeta (W,b,\alpha) )$,很神奇的，我们需要的那些约束都融入到一个式子当中了。在这里，希望简单可以说明一下，实际上我们上面的SVM与原来的效果是一样的。</p><p>首先，如果原来的约束不满足，则：$y_n(W^TX_n+b) <1$，那么$(1 -="" y_n(w^tx_n+b))="">0$，而要最大化$\zeta(W,b,\alpha)$，$\alpha$又大于等于0，那么可以肯定的是$\sum _{n = 0} ^{N} \alpha_n (1 - y_n(W^TX_n+b)) $最后的结果是无穷大了，它一定不会被选上；</1$，那么$(1></p><p>如果原来的约束满足的话，$(1 - y_n(W^TX_n+b)) \leq 0$,因为它小于0，要最大化$\zeta(W,b,\alpha)$，只能使得$\sum _{n = 0} ^{N} \alpha_n (1 - y_n(W^TX_n+b)) $等于0，也就是最后得到的结果是$\zeta(W,b,\alpha) = \frac 1 2 W^TW$，因此实际上最终求的的最大值，依然是满足条件的。</p><p>通过这样就很巧妙地将条件与我们想要做的优化问题融合成了一个式子。</p><p>而且我们很容易知道的事：$\mathbf{min}_{W,b}(\mathbf{max}_{text{all} \alpha_n \ge 0} \zeta (W,b,\alpha) ) \ge \mathbf{min}_{W,b} \zeta (W,b,\alpha ‘)$,上式中$\alpha’$是个定值，<br>也就可以推断出来：$mathbf{min}_{W,b}(\mathbf{max}_{text{all }\alpha_n \ge 0} \zeta (W,b,\alpha) ) \ge mathbf{max}_{text{all } \alpha_n \ge 0}( min_{W,b} \zeta (W,b,\alpha ‘))$.</p><p>更令人兴奋的是，在这些条件下：</p><p>1.convex primal</p><p>2.feasible primal（true if separable）</p><p>3.linear constraints</p><p>上式的等号是成立的。</p><p>因此我们只需要解决右边的部分就好了。这就是Lagrange Duality，拉格朗日对偶。（为何不解左边？emmm，$\alpha$ 是一个向量，N维的，一般来说N&gt;&gt;d+1）</p><p>嗯，但是似乎这个式子，还是很复杂，全部写出来看一下：</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) = \frac 1 2 W^TW + \sum _{n = 1} ^{N} \alpha_n (1 - y_n(W^TX_n+b))</script><p>首先，要在把$\alpha$看作定值的情况下找到最小值，那么我们知道它一定满足的条件：</p><script type="math/tex; mode=display">\frac {\partial \zeta}{\partial b} = \sum _{n=1}\alpha_n y_n = 0</script><p>因此，上面的式子变成了：</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) = \frac 1 2 W^TW + \sum _{n = 1} ^{N} \alpha_n (1 - y_nW^TX_n)</script><p>简化了很大一部分。然后求$W$的偏导：</p><script type="math/tex; mode=display">\frac {\partial \zeta}{\partial W} = W - \sum_{n=1}^N \alpha_n y_nX_n = 0</script><p>我们可以得到$  \sum_{n=1}^N \alpha_n y_nX_n = W$,因此最后式子简化为：</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) =   \sum _{n = 1} ^{N} \alpha_n - \frac 1 2 W^TW.</script><p>式子又简单了很多。同时我们再继续将$W$替换:</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) =   \sum _{n = 1} ^{N} \alpha_n - \frac 1 2 ||\sum_{n=1}^N \alpha_n y_nX_n||^2.</script><p>而且不要忘了我们最之前推导的： $\alpha_n (1 - y_n(W^TX_n+b)) = 0$.</p><p>因此，现在的式子里面已经没有$W$与$b$了，我们要做的就是</p><p>$max_{all a_n \ge 0,\sum y_n \alpha_n = 0,W =\sum \alpha_n y_nX_n } - \frac 1 2 ||\sum_{n=1}^N \alpha_n y_nX_n||^2 +  \sum _{n = 1} ^{N} \alpha_n$.</p><p>总结一下，要解决对偶问题得到上面的结果，需要达到的条件：</p><p>1.primal feasible： $y_n(W^TX_n+b) \ge 1$</p><p>2.dual feasible: $a_n \ge 0$</p><p>3.dual-inner optimal:$\sum y_n \alpha_n = 0;W =\sum \alpha_n y_nX_n$</p><p>4.primal-inner optimal: $\alpha_n (1 - y_n(W^TX_n+b)) = 0$.</p><p>上面的这些条件，被称为KKT（Karush-Kuhn-Tucker）条件，对于优化问题是非常必要的。哇，之前听过的高大上的名词逐渐拨开云雾见青天了。</p><p>我们将上面的式子继续展开：</p><script type="math/tex; mode=display">-\frac 1 2 \sum_{n=1}^N \sum_{m=1}^N a_na_my_ny_mX_n^TX_m + \sum_{n=1}^N \alpha_n.</script><p>接下来我们开始尝试最大化上面的这个式子,首先依然我们把最大化问题转化成为最小化问题，用数学语言描述：</p><p>$min_{\alpha} \frac 1 2 \sum_{n=1}^N \sum_{m=1}^N a_na_my_ny_mX_n^TX_m - \sum_{n=1}^N \alpha_n$</p><p> <strong>subject to</strong> $\sum_{n=1}^N y_n\alpha_n = 0;a_n \ge 0,n=1,…,N$</p><p> 因为式子中没有$W$,我们暂时将约束中的$W$去掉，专注这个问题，最后再尝试计算出$W$.</p><p> 而这个如果仔细观察，我们会发现它是一个QP问题。也就是通过现成的工具，可以计算出最佳的$\alpha$.</p><p> 计算出最佳的$\alpha$，可以很轻易地计算出$W$，而且通过约束也能轻易地计算出$b$.而且我们可以通过约束发现，其实相当一大部分$\alpha_n=0$，而$\alpha \ne 0$的那些点，也正是我们的支撑向量。</p><p> 最后，我们提出一个疑问：这个计算方法，真的和维度没关系了吗？恐怕不是，维度隐含在了计算$Q$矩阵当中了.这还是没有达到我们的目的。这需要下一个改进：kernel。</p><h2 id="p-s-QP问题的解决"><a href="#p-s-QP问题的解决" class="headerlink" title="p.s. QP问题的解决"></a>p.s. QP问题的解决</h2><p> 一般来说，解决QP问题的工具，需要提供下面几个参数：</p><p>optimal $\alpha$ $\leftarrow$ $QP(Q,mathbf{p},A,mathbf{c})$</p><p> $min_{\alpha}$  $\frac 1 2 \alpha ^T Q \alpha + p^T\alpha$</p><p>subject to $a_i^T \alpha \ge C_i$, for i = 1,2,…</p><p>因此，在本例中，Q：<br>$q_{n,m} = y_ny_mX^nX^m;$</p><p>$\mathbf{p} = -1_N;$</p><p>$a_1 = Y ,a_2 = -Y;a_3 = 1_N$</p><p>$c_1 = 0,c_2 = 0,c_3 = 0;$</p><p>当然，具体的参数类型还要看具体的工具包，但是所需参数都不难从已知的条件转换得到。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Linear Support Vector Machine</title>
      <link href="/2018/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Linear-Support-Vector-Machine/"/>
      <url>/2018/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Linear-Support-Vector-Machine/</url>
      
        <content type="html"><![CDATA[<p>这个名字真是很奇怪。想要了解为何叫这么奇怪的名字，就要深入了解这个东西。<br><a id="more"></a><br>首先需要回顾的是之前的Perceptron Learning Algorithm。如果这个资料线性可分，使用PLA算法，一定可以找到一个很好的线或者超平面（hyperplane）来将这个资料分开，但是这个线或者是超平面的个数可能是无数个，它们是否是一样好的？如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/JRN%5BZGK%29K_J5YLHU4I3EBGF.png" alt=""></p><p>上面3条线，对于PLA算法来说是一样好的，因此运行到哪一条，都是无法预测的。但是从我们的角度来看，我们会选择第三条，因为这条线更robust，可以容忍更多测量误差，如第一条，有一个离红色点很近的样本的话，它更大概率是negative的，但是第一条就会将它归类到positive。因此，选择第三条线，可以更好地避免overfitting。</p><p>为了想解决这个问题，我们需要将问题提炼成数学语言。首先我们想要求的是灰色区域最大的：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/9Y%60%60IZO%7BW%285P%28RI%24KPP14LP.png" alt=""></p><p>我们称灰色区域为margin。而这个margin，实际上是最近的两个点到中间这条线的距离。</p><p>那么我们就要先想象，点到平面（或者超平面）的距离如何计算？</p><p>如果一个超平面的方程为$W^TX + b = 0$,则任意两个在该平面的点$x’$与$x’’$都应该满足上式，也就是</p><script type="math/tex; mode=display">\left\{\begin{array} W^TX'+b = 0\\W^TX''+b = 0\end{array}\right</script><p>因此可以得到：$W^T(X’-X’’) = 0$.<br>而$(X’-X’’)$可以表示平面上的任何一个向量，这说明了，$W$是该平面的法向量。</p><p>而一个点到平面的距离，实际上就是该点到任何平面上一点连接得到的向量对该平面法向量的一个投影。计算投影长度的办法其实很简单,首先我们有$ab = |a||b|cos\theta$,因此只要规定a的长度为1，那么这两个向量的数量积的绝对值就是向量的长度。因此我们可以得到：</p><script type="math/tex; mode=display">d = |\frac {W^T }{||W||}(X - X')| = |\frac 1 {||W||}(W^TX + b)|.</script><p>这样，我们就得到了一个点到一个超平面的距离。</p><p>实际上一个超平面的表示方法是无穷的，比如$WTX+b = 0$与$2W^TX+2b= 0$是一个平面，如果我们将经过距离超平面最近的点的与超平面平行的平面表示为:$W^X+b = ±1$，那么d的形式就更简单了：$d = \frac 1 {||W||}$.</p><p>上面的距离中还是加了绝对值，但是因为这个问题的前提是将所有的点都分类正确，因此$y_i(WX_i+b)\ge 0$.</p><p>所以用数学语言描述我们的问题如下：</p><p>max $\frac 1 {||W||}$</p><p>$s.t. min_{n = 1,…,N} y_n(W^TX_n+b) = 1$.</p><p>注意的是为什么最小的点$y_n(W^TX_n+b) = 1$,因为距离较远的话，根据距离公式$(W^TX+b)$会更大。</p><p>上面的问题依然是很难解决的，我们希望可以继续放松这个约束。如果是所有点$y_n(W^TX_n+b) \ge 1$如何呢？</p><p>这里利用反证法证明，放宽到上面的约束依然没有问题，距离直线最近的点依然是满足$y_n(W^TX_n+b) = 1$：</p><p>如果我们找到最近的点$X_n$，它满足的是$y_n(W^TX_n+b) =a (a&gt;1)$，而且得到了最大的$\frac 1 {||W||}$，那么对上式左右同时除以a,而$\frac W a$比$W$更小，也就是这个$\frac 1 {||W||}$并不是最大的。这就矛盾了。因此依然只有在$y_n(W^TX_n+b) =1$的时候才能取得最大值。所以放大这个约束，我们依然可以得到一样的最终结果。</p><p>之前我们一直在求得是最小值，我们希望在这里也可以转换成为求最小值，同时范数是需要根号的，而因为范数和范数的平方是单调递增的，因此转化为范数的平方不会影响结果，同时再添上一个$\frac 1 2$，为了以后计算的方便。</p><p>因此，最终的用数学语言描述我们的问题的版本如下：</p><p>min  $\frac 1 2W^TW$</p><p>$s.t.  y_n(W^TX_n+b) \ge 1,n =1,2,…,N $.</p><p>这个问题实际上是一个QP（二次规划）问题。而二次规划问题，我们可以借助很多工具，提供必要的参数，求得最佳解。</p><p>上术问题就是svm问题。为什么叫support vector machine？我们需要注意的是，实际上决定最终线的，只有可能是最边上的点，而决定最终结果的点，就叫做支持向量。</p><p>当我们面对线性无法可分的情况，就需要使用之前介绍的特征转换（nonlinear transform），将当前的点转换到更高维度的空间中去，使其成为线性可分。</p><p>最后，我们在这里想要简单说明一下这背后的理论基础，为什么寻找最粗的那条线，可以获得更好的robustness？</p><p>这就又回到了vc dimension.假设我们找到的比较粗的线（margin较大），是我们要的标准。那么具有这么大margin的线，能将空间中的N个样本分成的dichotomy的个数就会少很多，也就是有效vc dimension会变低。当然，这个问题无法像PLA时候那样分析，因为具体能分多少，与样本之间的距离也很重要，具体样本得到的结果也不同，但是可以证明的是,如果这些样本在一个半径为R的圆内，margin长度为ρ：</p><script type="math/tex; mode=display">d_{vc}(\mathcal{A}_{\rho}) \leq min(\frac {R^2}{ρ^2} ,d)+1 \leq d+1</script><p>之前介绍的feature transform有个问题是太过于复杂导致vc dimension会变得很大，而我们可以看出来通过SVM我们某种程度上可以处理好这种情况。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数学——Lagrange Multiplier</title>
      <link href="/2018/10/09/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Lagrange-Multiplier/"/>
      <url>/2018/10/09/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Lagrange-Multiplier/</url>
      
        <content type="html"><![CDATA[<p>拉格朗日乘数法，是我们大学或者考研过来的耳熟能详的名词了。我们接触他的时候，应该是在求条件极值的时候。<br><a id="more"></a><br>求$f(x,y)$在$g(x,y)=0$的条件下的极值。需要利用拉格朗日乘数构造新的式子：</p><p>$w(x,y,\lambda ) = f(x,y)+\lambda g(x,y)$</p><p>让$w(x,y,\lambda)$分别对$x,y,\lambda$求偏导，并令其为0：</p><script type="math/tex; mode=display">\left \{\begin {array }    w'_x(x,y,\lambda) = f'_x(x,y)+\lambda g'_x(x,y) = 0\\    w'_y(x,y,\lambda) = f'_y(x,y)+ \lambda g'_y(x,y) = 0\\    w'_{\lambda}(x,y,\lambda) = g(x,y) = 0\end{array}\right</script><p>不过大学的时候，我虽然会这么计算，但是却不知道原理。现在希望从原理解释一下，为什么要这么算。</p><p>暂时我想到了两种解释办法：</p><p>1.我们首先要知道的一个前提是，$g(x,y) = 0$在任意一点$(x_0,y_0)$切线的法向量为$(g’_x(x_0,y_0),g’_y(x_0,y_0))$.想象现在有一个点在约束的这条线上移动，为了找到让$f(x,y)$值最小的点，首先我们求出$f(x,y)$在当前点的梯度，梯度也就是朝着这个方向（或者反方向）前进，$f(x,y)$的值会变大（或者变小）,因此只要梯度与这条线上该点的法向量不平行，我们总是可以将梯度投影到该点的切线上，也就是依然能抄着切线的某个方向运动，让$f(x,y)$的值变小（如果要找到最大值，就是变大）。当梯度与法向量平行的时候，不论朝着哪个方向，都无法让$f(x,y)$的值变小，因此这个点就是一个极值小点。</p><p>而我们知道的，上面的法向量，实际上是$g(x,y)$在该点的梯度，因此我们有在极值点的时候：</p><script type="math/tex; mode=display"> \nabla f(x,y) = \lambda \nabla g(x,y)</script><p>上式中，$\lambda$的正负取决于要的是极大值点还是极小值点。而上面的式子，实际上就与方程组的前两个方程一致。</p><p>2.另一个办法，画出等高线图。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/2012101621500549.png" alt=""></p><p>可以比较清晰地看出来，当$g(x,y)=0$与等高线相切的点是极小值。因为你只能在$g(x,y)=0$的这条线上移动，那么别的地方总会比它大（或者大）。那怎么求相切的部分的点呢？首先，等高线的方程，实际上是曲线到(x,y)平面的投影，方程为$f(x,y)=C$,同样的，既然相切，那么他们在该点的法向量一定是平行的。计算法向量，又回到了前面的内容：</p><script type="math/tex; mode=display">  \nabla f(x,y) = \lambda \nabla g(x,y)</script><p>联立$g(x,y)=0$即可得到原来的方程组。</p><p>现在我们知道了条件极值如何解出来，但是这只是拉格朗日乘数法的一部分。拉格朗日乘数法是一种寻找变量受一个或多个条件所限制的多元函数的极值的方法。首先上面的条件限制只有一个，另外上面的条件也很简单，是在$g(x,y)=0$，如果我们要的是$g(x,y) \leq 0$的呢？</p><p>如果$f(x,y)$极值点本身就在上面的约束范围内，那么相当于没有约束，也就是$\lambda = 0$，否则在边界上，又回到了上面的问题：$g(x,y)=0$.总之，$\lambda g(x,y) = 0$.因此我们需要改变联立条件即可。</p><p>上面的式子，都是$\lambda$也会变化的情况。但是，在机器学习的正则化中，我们往往给出的式子是形如这样$E_{in} + \frac \lambda N ||W||^2$.而且这个$\lambda$可能是个定值。如果$\lambda$固定，得到的又是什么值？</p><p>我们可以推断出来的是如果$E_{in}$找到了最小的地方，那么$W$也就为0，否则$\nabla E_{in}$与$W$的比值是一个定值。从这些里得不到很有用的信息。但是从另一个角度来说，它确实限制了$W$的大小，虽然目前不知道具体限定到哪个范围。$||W_{reg}|| \leq ||W_{lin}||$是一定的，可以从反证法证明：如果$||W_{lin}||&lt;||W_{reg}||$,那么E_{in}也会小，正则项也更小，所以这时候的$E_{reg}$比使用$W_{reg}$的更佳，也就是前面找到的不可能是最小值。</p><p>另一个拉格朗日乘数法重要的在机器学习中的应用，是在SVM中。 </p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）作业4</title>
      <link href="/2018/10/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A4/"/>
      <url>/2018/10/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A4/</url>
      
        <content type="html"><![CDATA[<p>机器学习基石的最后一次作业，总共20道题目。<br><a id="more"></a><br><strong>1. Deterministic noise depends on $\mathcal{H}$, as some models approximate $f$ better than others. Assume $\mathcal{H}’\subset \mathcal{H}$ and that $f$ is fixed. In general (but not necessarily in all cases), if we use $\mathcal{H}’$ instead of $\mathcal{H}$, how does deterministic noise behave?</strong></p><p>a. In general, deterministic noise will decrease.</p><p>b. In general, deterministic noise will increase.</p><p>c. In general, deterministic noise will be the same.</p><p>d. If $d_{\text{vc}}(\mathcal{H}’) \le \frac{1}{2} d_{\text{vc}}(\mathcal{H})$, deterministic noise will increase, else it will decrease.</p><p>e. If $d_{\text{vc}}(\mathcal{H}’) \le \frac{1}{2} d_{\text{vc}}(\mathcal{H})$, deterministic noise will decrease, else it will increase.</p><p>deterministic noise出现的原因，是$H$无法完美的模拟f.而$H’$是$H$的子集，也就是它的模型复杂度更低，一般来说更无法模拟目标函数，它的deterministic noise应该是上升的，选b。</p><p><strong>2. Consider the following hypothesis set for $\mathbf{x} \in \mathbb{R}^dx$ defined by the constraint:</strong></p><script type="math/tex; mode=display">\mathcal{H}(d, d_0) = \{ h ~|~ h(\mathbf{x}) = \mathbf{w}^\mathrm{T}\mathbf{x}; w_i = 0 \hspace{1 mm} \mbox{for} \hspace{1mm} i \geq d_0 \},</script><p><strong>which of the following statements is correct?</strong></p><p>a. $H(10,3)⊂H(10,4)$</p><p>b. $H(10,3)∪H(10,4)=\{\}$</p><p>c. $H(10,3)⊃H(10,4)$</p><p>d. $H(10,3)∩H(10,4)=\{\}$</p><p>e. none of the other choices</p><p>这个题目的约束不算难，也就是有一个额外的参数$d_0(d_0 \leq d)$,w下标比$d_0$大的固定为0.选项中$d_0$只有3与4两个选项，而$d_0 = 3$的$H$是包含在$d_0=4$的$H$中的，因为对于前者来说，$w_3$的值也确定了，自由度为3，后者自由度为4，$w_0$可以为0也可以为其他值.因此答案选a.</p><p>For Questions 3-4, consider the augmented error $E_{\text{aug}}(\mathbf{w}) = E_{\text{in}}(\mathbf{w}) + \frac{\lambda}{N} \mathbf{w}^T \mathbf{w}$ with some $\lambda &gt; 0$.</p><p><strong>3. If we want to minimize the augmented error $E_{\text{aug}}(\mathbf{w})$ by gradient descent with $\eta$ as learning rate, which of the following is a correct update rule?</strong></p><p>a. $w(t+1)⟵w(t)+ηλ\nabla E \in (w(t))$.</p><p>b. $w(t+1)⟵w(t)-ηλ\nabla E \in (w(t))$.</p><p>c. $w(t+1)⟵(1− \frac {2\eta \lambda} {N})w(t)−η\nabla E \in (w(t))$.</p><p>d. $w(t+1)⟵(1+ \frac {2\eta \lambda} {N})w(t)−η\nabla E \in (w(t))$.</p><p>e. none of the other choices</p><p>这个题目也是比较简单的。梯度下降就是朝着梯度的反方向前进，因此只用求出来梯度就可以。$W^TW$的梯度很简单是$2W$，其他的与之前的一致，因此答案选c。</p><p><strong>4. Let $\mathbf{w}_{\text{lin}}$ be the optimal solution for the plain-vanilla linear regression and $\mathbf{w}_{\text{reg}}(\lambda)$ be the optimal solution for minimizing $E_{\text{aug}}$ in Question 3, with $E_{\text{in}}$ being the squared error for linear regression. Which of the following is correct?</strong></p><p>a. none of the other choices</p><p>b. $||W_{reg}(\lambda)|| \leq ||W_{lin}||$ for any $\lambda &gt; 0$</p><p>c. $||W_{reg}(\lambda)|| \geq ||W_{lin}||$ for any $\lambda &gt; 0$</p><p>d. $||W_{reg}(\lambda)||$ is always a non-decreasing function of $\lambda$ for $\lambda \ge 0$</p><p>e. $||W_{reg}(\lambda)||$ is always a constant function of $\lambda$ for $\lambda \ge 0$</p><p>要明白这个题目，首先要知道什么是$||W||$，这个意思是$W$向量的范数，也就等于$W^TW$.对于之前题目添加的regularization来说，限制实际上是$W^W \leq C$.如何推导？<br>最低点$\nabla E_{aug} = 0$，也就是$\nabla E_{in} = - \frac {2\lambda} {N} W$,因此最低点$\nabla E_{in}$与$W$的长度比值是一定的，也就是$W$向量的长度被确定到了一个值。而因为一直在朝约束条件下最低点走，因次$\nabla E_{in}$也是接近平缓的也就是值比较小，所以这意味着$W$最后是比较小的。</p><p>从另一个角度来看，范数一定是大于零的，为了找到最低点当然是让范数尽量小，也就是正则化相当于给各个参数增加了惩罚，想让他们变得更小。</p><p>因此这个题目的答案选择b.如果没有约束情况下得到的最好的$W$也满足约束，也就是等于的情况，其他时候$||W_{lin}|| &gt; ||W_{reg}||$</p><p><strong>5. You are given the data points: $(-1,0)$, $(\rho,1)$, $(1,0)$,$ \rho \ge 0$, and a choice between two models:</strong></p><ul><li>constant $h_0(x)=b_0$ and</li><li>linear $h_1(x)=a_1x+b_1$</li></ul><p>For which value of $\rho$ would the two models be tied using leave-one-out cross-validation with the squared error measure?</p><p>a. $\sqrt{\sqrt {3}+4}$</p><p>b. $\sqrt{\sqrt{3} - 1}$</p><p>c. $\sqrt{9+4 \sqrt{6}}$</p><p>d. $\sqrt{9 - \sqrt{6}}$</p><p>e. none of the other choice</p><p>使用Leave-One-Out Cross验证来得到$E_{val}$。对于第一种情况，$h(x)=b_0$是个常量。对于第二种情况是个直线。首先要计算出两种模型的$E_{val}$.</p><p>第一种模型：</p><ul><li>第一个为验证集：则$E_{in} = \frac 1 2 ((b_0-1)^2 + b_0^2)$,则$E_{in}$最小的时候$b_0 = 0.5$，$err = 0.5 \times 0.5 = 0.25$.</li><li>第二个为验证集：则$E_{in} = b_0^2$,因此$b_0 = 0$,err = 1.</li><li>第三个为验证集，情况与第一种情况一致，$err =0.25$.</li></ul><p>因此这时候的$E_{val} = (1+0.25+0.25)/3 = 0.5$.</p><p>第二种模型：</p><ul><li>第一个为验证集：则计算出来得到$a_1 = \frac 1 {p-1},b_1 = \frac 1 {1-p}$,则预测值是$\frac 2 {1-p}$,$err = \frac 4 {(1-p)^2}$.</li><li>第二个为验证集，得到的是一个常熟：$h(x) = 0$.这种情况下$err = 1$.</li><li>第三个为验证集，则计算出来得到$a_1 = \frac 1 {p+1},b_1 = \frac 1 {1+p}$,则预测值是$\frac 2 {1+p}$,$err = \frac 4 {(1+p)^2}$.</li></ul><p>这时候的$E_{val} =(1 + \frac 4 {(1-p)^2} + \frac 4 {(1+p)^2} )/3$.</p><p>题目中说了，两个模型都适用到该样本集。那么上面两个应该是相等的。可以解出来：$p^2 = 9±4\sqrt {6}$,而$9-4 \sqrt 6 &lt; 0$，因此正确答案是 $9+ 4 \sqrt {6}$.答案选c。 </p><p>For Questions 6-7, suppose that for 5 weeks in a row, a letter arrives in the mail that predicts the outcome of the upcoming Monday night baseball game.</p><p><strong>6. Assume there are no tie. You keenly watch each Monday and to your surprise, the prediction is correct each time. On the day after the fifth game, a letter arrives, stating that if you wish to see next week’s prediction, a payment of NTD $1000$ is required. Which of the following statement is true?</strong></p><p>a. There are 31 win-lose predictions for 5 games.</p><p>b. If the sender wants to make sure that at least one person receives correct predictions on all 5 games from him, the sender should target to begin with at least 5 people.</p><p>c. To make sure that at least one person receives correct predictions on all 5 games from the sender, after the first letter `predicts’ the outcome of the first game, the sender should target at least 16 people with the second letter.</p><p>d. To make sure that at least one person receives correct predictions on all 5 games from him, at least 64 letters should be sent before the fifth game.</p><p>e. none of the other choice</p><p>这个题目讲的是一个小把戏。5场比赛，每场比赛只有正负两个情况。因此一共可能出现的情况有$2^5=32$种。a错误。32种情况，当然要32个人，因此b错误。至少发出去的信有（32+16+8+4+2=62）封，d错误。而c，第一个结果出来后，会有一半的人收到错误的预测，因此第二封信只需要发给正确的那些人就好了，也就是16个人.</p><p><strong>7. If the cost of printing and mailing out each letter is NTD 10. If the sender sends the minimum number of letters out, how much money can be made for the above `fraud’ to succeed once? That is, one of the recipients does send him NTD 1000 to receive the prediction of the 6-th game?</strong></p><p>a. NTD 340</p><p>b. NTD 370</p><p>c. NTD 400</p><p>d. NTD 430</p><p>e. NTD 460</p><p>上面一道题目推断出来，至少要发送62封信才能保证有个人收到所有预测结果。而最后一个人收到的全部正确的预测后还要在加发一封，来骗钱。也就是63封，所以答案是NTD 370，选b.</p><p>For Questions 8-10, please read the following story first. In our credit card example, the bank starts with some vague idea of what constitutes a good credit risk. So, as customers $\mathbf{x}_1, \mathbf{x}_2,…,\mathbf{x}_N$ arrive, the bank applies its vague idea to approve credit cards for some of these customers based on a formula $a(\mathbf{x})$. Then, only those who get credit cards are monitored to see if they default or not.</p><p><strong>8. For simplicity, suppose that the first $N=10000$ customers were given credit cards by the credit approval function $a(\mathbf{x})$. Now that the bank knows the behavior of these customers, it comes to you to improve their algorithm for approving credit. The bank gives you the data $(\mathbf{x}_1, y_1), … , (\mathbf{x}_N, y_N)$. Before you look at the data, you do mathematical derivations and come up with a credit approval function. You now test it on the data and, to your delight, obtain perfect prediction.</strong></p><p>What is $M$, the size of your hypothesis set?</p><p>a. $1$</p><p>b. $N$</p><p>c. $2^N$</p><p>d. $N^2$</p><p>e. We have no idea about it.</p><p>利用数学推理想到了一个函数做出了很好的预测，因此这个vc dimension是无法计算的，但是因为没有经过数据的学习，这个H的大小应该是1，选择a.</p><p><strong>9. With such an $M$, what does the Hoeffding bound say about the probability that the true average error rate of $g$ is worse than $1\%$ for $N=10,000$?</strong></p><p>a. $\leq 0.171$</p><p>b. $\leq 0.221$</p><p>c. $\leq 0.271$</p><p>d. $\leq 0.321$</p><p>e. none of the other choices</p><p>霍夫丁不等式的简单应用：$P[\nu  - \upsilon|&gt; \epsilon ] \leq 2 e^{-2\epsilon ^2N}$。上述中$\epsilon = 0.01,N = 10000$,得到答案为0.2706705664732，答案选c.</p><p><strong>10. You assure the bank that you have a got a system $g$ for approving credit cards for new customers, which is nearly error-free. Your confidence is given by your answer to the previous question. The bank is thrilled and uses your $g$ to approve credit for new customers. To their dismay, more than half their credit cards are being defaulted on. Assume that the customers that were sent to the old credit approval function and the customers that were sent to your g are indeed i.i.d. from the same distribution, and the bank is lucky enough (so the “bad luck” that “the true error of gg is worse than $1\%$’’ does not happen). Which of the following claim is true?</strong></p><p>a. By applying $a(\mathbf{x}) \mbox{ NOR } g(\mathbf{x})$ to approve credit for new customers, the performance of the overall credit approval system can be improved with guarantee provided by the previous problem.</p><p>b. By applying $a(\mathbf{x}) \mbox{ NAND } g(\mathbf{x})$ to approve credit for new customers, the performance of the overall credit approval system can be improved with guarantee provided by the previous problem.</p><p>c. By applying $a(\mathbf{x}) \mbox{ OR } g(\mathbf{x})$ to approve credit for new customers, the performance of the overall credit approval system can be improved with guarantee provided by the previous problem.</p><p>d. By applying $a(\mathbf{x}) \mbox{ AND } g(\mathbf{x})$ to approve credit for new customers, the performance of the overall credit approval system can be improved with guarantee provided by the previous problem.</p><p>e. none of the other choices</p><p>这个题目中说到，利用之前的推断出来的g，本应该有很好的表现，但是却得到了很差的表现。为什么？我们要注意一个事：Sample Bias。虽然题目中说了，新的顾客和之前系统的顾客是来自于同一分布的，但是我们得到的test数据的分布并不是原先的顾客分布。test数据中，顾客的信息并不是随机得到的，而是先经过了$a(x)$的筛选。上面的霍夫曼不等式的理论保证是在同一分布的前提下，因此首先要经过$a(x)$的筛选，然后再用$g(x)$来判断。因此答案选d.</p><p>For Questions 11-12, consider linear regression with virtual examples. </p><p><strong>11. That is, we add $K$ virtual examples $(\tilde{\mathbf{x}}_1, \tilde{y}_1),(\tilde{\mathbf{x}}_2, \tilde{y}_2),\dots, (\tilde{\mathbf{x}}_K, \tilde{y}_K)$ to the training data set, and solve$<br>\min \limits _{\mathbf{w}} \frac{1}{N+K} \left(\sum_{n=1}^N (y_n - \mathbf{w}^T \mathbf{x}_n)^2 + \sum_{k=1}^K (\tilde{y}_k - \mathbf{w}^T \tilde{\mathbf{x}}_k)^2\right)$.We will show that using some “special” virtual examples, which were claimed to be a possible way to combat overfitting in Lecture 9, is related to regularization, another possible way to combat overfitting discussed in Lecture 10. Let $\tilde{\mathbf{X}} = [\tilde{\mathbf{x}}_1 \tilde{\mathbf{x}}_2 \ldots \tilde{\mathbf{x}}_K]^T$, and $\tilde{\mathbf{y}} = [\tilde{y}_1, \tilde{y}_2, \ldots, \tilde{y}_K]^T$. What is the optimal $\mathbf{w}$ to the optimization problem above, assuming that all the inversions exist?</strong></p><p>a. $(\mathbf{X}^T\mathbf{X})^{-1}(\widetilde {\mathbf{X}}^T\widetilde{\mathbf{y}})$</p><p>b. $(\mathbf{X}^T\mathbf{X})^{-1}(\mathbf{X}^T \mathbf{y}+\widetilde {\mathbf{X}}^T\widetilde{y})$</p><p>c. $(\mathbf{X}^T\mathbf{X} + \widetilde{\mathbf{X}}^T\widetilde{\mathbf{X}})^{-1}(\widetilde {\mathbf{X}}^T\widetilde{\mathbf{y}})$</p><p>d. $(\mathbf{X}^T\mathbf{X} + \widetilde{\mathbf{X}}^T\widetilde{\mathbf{X}})^{-1}(\mathbf{X}^T \mathbf{y} +\widetilde {\mathbf{X}}^T\widetilde{\mathbf{y}} )$</p><p>e. none of the other choice</p><p>这个题目说起来也容易。既然把虚拟数据也融合进去了，当然各部分都要计算，很容易排除其他答案,选择d。</p><p><strong>12. For what $\tilde{\mathbf{X}} and $\tilde{\mathbf{y}}$ will the solution of the linear regression problem above equal to</strong></p><script type="math/tex; mode=display">\mathbf{w}_{\text{reg}} = \mathrm{argmin}_{\mathbf{w}} \frac{\lambda}{N} \|\mathbf{w}\|^2 + \frac{1}{N} \|\mathbf{X}\mathbf{w}-\mathbf{y}\|^2?</script><p>a. $\tilde{\mathbf{X}} = I, \tilde{\mathbf{y}} = 0$</p><p>b. $\tilde{\mathbf{X}} = \sqrt {\lambda}I, \tilde{\mathbf{y}} = 0$</p><p>c. $\tilde{\mathbf{X}} = \lambda I, \tilde{\mathbf{y}} = \mathbf{1}$</p><p>d. $\tilde{\mathbf{X}} = \sqrt{\lambda} \mathbf{X}, \tilde{\mathbf{y}} = \mathbf{y}$</p><p>e. none of the other choice</p><p>这个问题乍一看，摸不着头脑。一个是矩阵中求逆操作，另一个是最小化一个函数（argmin(f(x))的定义之前已经说过）。但是换个办法的话，其实很容易解决，我们可以想象一下11题中需要最小化的函数$E_{in}$，则可以得到：</p><script type="math/tex; mode=display">W_{vir} = argmin_w \frac 1  {N+K} (||\tilde{\mathbf{X}}\mathbf{w} - \tilde{\mathbf{y}}||^2 +  ||\mathbf{X}\mathbf{w} - \mathbf{y}||^2).</script><p>最小化的话无论前面有没有$\frac 1 N$或者其他常数都是无所谓的。<br>想要让二者最后结果相等，使得去掉常数之后相等即可，则，$\tilde{\mathbf{X}} = \sqrt {\lambda}I, \tilde{\mathbf{y}} = 0$.因此这道题目答案选b。</p><p><strong>13. Consider regularized linear regression (also called ridge regression) for classification</strong></p><script type="math/tex; mode=display">\mathbf{w}_{\text{reg}} = \mbox{argmin}_{\mathbf{w}} \left(\frac{\lambda}{N} \|\mathbf{w}\|^2 + \frac{1}{N} \|\mathbf{X}\mathbf{w}-\mathbf{y}\|^2\right) .</script><p>Run the algorithm on the following data set as $\mathcal{D}$:<br><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw4_train.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw4_train.dat</a></p><p>and the following set for evaluating $E_{out}$:<br><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw4_test.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw4_test.dat</a></p><p>Because the data sets are for classification, please consider only the 0/1 error for all Questions below.</p><p>Let $\lambda = 10$, which of the followings is the corresponding $E_{in}$and $E_{out}$?</p><p>a. $E_{in} = 0.015,E_{out} = 0.020$</p><p>b. $E_{in} = 0.030,E_{out} = 0.015$</p><p>c. $E_{in} = 0.035,E_{out} = 0.020$</p><p>d. $E_{in} = 0.050,E_{out} = 0.045$</p><p>e. $E_{in} = 0.020,E_{out} = 0.010$</p><p>这道题目是线性回归的一个改进。相对于之前的代码也只要做些许的改进就可以了。利用之前的第12题的结论，我们依然可以一步得到结果。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sign</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> +<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(data,W=[])</span>:</span></span><br><span class="line">    nx = []</span><br><span class="line">    ny = []</span><br><span class="line">    ox = []</span><br><span class="line">    oy = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> data[i][<span class="number">-1</span>] == <span class="number">-1</span>:</span><br><span class="line">            nx.append(data[i][<span class="number">0</span>])</span><br><span class="line">            ny.append(data[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ox.append(data[i][<span class="number">0</span>])</span><br><span class="line">            oy.append(data[i][<span class="number">1</span>])</span><br><span class="line">    plt.scatter(nx,ny,marker=<span class="string">"x"</span>,c=<span class="string">"r"</span>)</span><br><span class="line">    plt.scatter(ox,oy,marker=<span class="string">"o"</span>,c=<span class="string">"g"</span>)</span><br><span class="line">    <span class="keyword">if</span> len(W)!=<span class="number">0</span> :</span><br><span class="line">        print(W)</span><br><span class="line">        x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">50</span>)</span><br><span class="line">        y = -W[<span class="number">1</span>] / W[<span class="number">2</span>] * x - W[<span class="number">0</span>] / W[<span class="number">2</span>]</span><br><span class="line">        plt.plot(x, y, color=<span class="string">"black"</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ridge_regression_one_step</span><span class="params">(data,_lambda)</span>:</span></span><br><span class="line">    X_matrix = []</span><br><span class="line">    Y_matrix = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        temp = [<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data[i])<span class="number">-1</span>):</span><br><span class="line">            temp.append(data[i][j])</span><br><span class="line"></span><br><span class="line">        X_matrix.append(temp)</span><br><span class="line">        Y_matrix.append([data[i][<span class="number">-1</span>]])</span><br><span class="line">    X = np.mat(X_matrix)</span><br><span class="line">    hatX = math.sqrt(_lambda)*np.eye(len(data[<span class="number">0</span>]))</span><br><span class="line">    <span class="comment">#print(hatX)</span></span><br><span class="line">    hatY = np.mat([ <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> data[<span class="number">0</span>]]).T</span><br><span class="line">    Y = np.mat(Y_matrix)</span><br><span class="line">    W = (X.T*X + hatX.T*hatX).I*(X.T*Y+hatX.T*hatY)</span><br><span class="line">    <span class="keyword">return</span> W.T.tolist()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Ein</span><span class="params">(data,W)</span>:</span></span><br><span class="line">    err_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        res = W[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,len(W)):</span><br><span class="line">            res += W[j]*data[i][j<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> sign(res) != data[i][<span class="number">-1</span>]:</span><br><span class="line">            err_num+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> err_num</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataFrom</span><span class="params">(path)</span>:</span></span><br><span class="line">    separator = re.compile(<span class="string">'\t|\b| |\n'</span>)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">with</span> open(path,<span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        s = f.readline()[:<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">while</span> s:</span><br><span class="line">            temp = separator.split(s)</span><br><span class="line">            result.append([float(x) <span class="keyword">for</span> x <span class="keyword">in</span> temp])</span><br><span class="line">            s = f.readline()[:<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line">    data = readDataFrom(<span class="string">"./train.dat"</span>)</span><br><span class="line">    <span class="comment">#print(data)</span></span><br><span class="line">    data_test =  readDataFrom(<span class="string">"./test.dat"</span>)</span><br><span class="line">    W = ridge_regression_one_step(data,<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"Ein"</span>,Ein(data,W)/len(data))</span><br><span class="line">    print(<span class="string">"Eout"</span>,Ein(data_test,W)/len(data_test))</span><br><span class="line">    visualize(data,W)</span><br></pre></td></tr></table></figure></p><p>可以得到最后的运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ein 0.05</span><br><span class="line">Eout 0.045</span><br></pre></td></tr></table></figure></p><p>因此答案选择d.</p><p><strong>14. Following the previous Question, among $\log_{10} \lambda= \left\{2, 1, 0, -1, \ldots, -8, -9, -10 \right\}$. What is the $\lambda$ with the minimum $E_{in}$? Compute $\lambda$ and its corresponding $E_{in}$ and $E_{out}$ then select the closest answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log_{10}^{\lambda} = -2,E_{in} = 0.030,E_{out} = 0.040$</p><p>b. $log_{10}^{\lambda} = -4,E_{in} = 0.015,E_{out} = 0.020$</p><p>c. $log_{10}^{\lambda} = -6,E_{in} = 0.030,E_{out} = 0.040$</p><p>d. $log_{10}^{\lambda} = -8,E_{in} = 0.015,E_{out} = 0.020$</p><p>e. $log_{10}^{\lambda} = -10,E_{in} = 0.030,E_{out} = 0.040$</p><p>这个题目只需要对上面题目的执行函数做一些改动即可：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    minEin = <span class="number">1</span></span><br><span class="line">    minEout = <span class="number">1</span></span><br><span class="line">    minEinI = <span class="number">-1</span></span><br><span class="line">    minEoutI = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">-10</span>,<span class="number">3</span>):</span><br><span class="line">        _lambda = math.pow(<span class="number">10</span>,i)</span><br><span class="line">        data = readDataFrom(<span class="string">"./train.dat"</span>)</span><br><span class="line">        <span class="comment"># print(data)</span></span><br><span class="line">        data_test = readDataFrom(<span class="string">"./test.dat"</span>)</span><br><span class="line">        W = ridge_regression_one_step(data, _lambda)</span><br><span class="line">        ein = Ein(data, W) / len(data)</span><br><span class="line">        eout = Ein(data_test, W) / len(data_test)</span><br><span class="line">        print(i,<span class="string">"Ein:"</span>, ein,<span class="string">"Eout:"</span>, eout)</span><br><span class="line">        <span class="keyword">if</span> ein&lt;=minEin:</span><br><span class="line">            minEin = ein</span><br><span class="line">            minEinI = i</span><br><span class="line">        <span class="keyword">if</span> eout &lt;= minEout:</span><br><span class="line">            minEout = eout</span><br><span class="line">            minEoutI = i</span><br><span class="line">    print(<span class="string">"minEin:"</span>,minEinI,<span class="string">"minEout:"</span>,minEoutI)</span><br></pre></td></tr></table></figure></p><p>得到结果：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">-10</span> Ein: <span class="number">0.015</span> Eout: <span class="number">0.02</span></span><br><span class="line"><span class="number">-9</span> Ein: <span class="number">0.015</span> Eout: <span class="number">0.02</span></span><br><span class="line"><span class="number">-8</span> Ein: <span class="number">0.015</span> Eout: <span class="number">0.02</span></span><br><span class="line"><span class="number">-7</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.015</span></span><br><span class="line"><span class="number">-6</span> Ein: <span class="number">0.035</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-5</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-4</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-3</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-2</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-1</span> Ein: <span class="number">0.035</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">0</span> Ein: <span class="number">0.035</span> Eout: <span class="number">0.02</span></span><br><span class="line"><span class="number">1</span> Ein: <span class="number">0.05</span> Eout: <span class="number">0.045</span></span><br><span class="line"><span class="number">2</span> Ein: <span class="number">0.24</span> Eout: <span class="number">0.261</span></span><br><span class="line">minEin: <span class="number">-8</span> minEout: <span class="number">-7</span></span><br></pre></td></tr></table></figure></p><p>可以看到Ein最小的是$\lambda = 10^{-8}$(相等取最大的),因此答案选d.</p><p><strong>15. Following the previous Question, among $\log_{10} \lambda= \left\{2, 1, 0, -1, \ldots, -8, -9, -10 \right\}$. What is the $\lambda$ with the minimum $E_{out}$? Compute $\lambda$ and its corresponding $E_{in}$ and $E_{out}$ then select the closest answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log_{10}^{\lambda} = -1,E_{in} = 0.015,E_{out} = 0.015$</p><p>b. $log_{10}^{\lambda} = -3,E_{in} = 0.015,E_{out} = 0.015$</p><p>c. $log_{10}^{\lambda} = -5,E_{in} = 0.015,E_{out} = 0.030$</p><p>d. $log_{10}^{\lambda} = -7,E_{in} = 0.030,E_{out} = 0.015$</p><p>e. $log_{10}^{\lambda} = -9,E_{in} = 0.030,E_{out} = 0.030$</p><p>答案在上个题目中已经得到了。答案选d.</p><p><strong>16. Now split the given training examples in $\mathcal{D}$ to the first 120 examples for $\mathcal{D}_{\text{train}}$ and 80 for $\mathcal{D}_{\text{val}}$. $\textit{Ideally, you should randomly do the 120/80 split. Because the given examples are already randomly permuted, however, we would use a fixed split for the purpose of this problem.}$</strong></p><p><strong>Run the algorithm on $\mathcal{D}_{\text{train}}$ to get $g^-_\lambda$, and validate $g^-_\lambda$ with $\mathcal{D}_{\text{val}}$. Among $\log_{10} \lambda= \left\{2, 1, 0, -1, \ldots, -8, -9, -10 \right\}$. What is the $\lambda$ with the minimum $E_{train}(g^-_\lambda)$? Compute $\lambda$ and the corresponding $E_{train}(g^-_\lambda)$, $E_{val}(g^-_\lambda)$ and $E_{out}(g^-_\lambda)$ then select the closet answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log _10^{\lambda} = 0,E_{train}(g_{\lambda}^-) = 0.000,E_{val}(g_{\lambda}^-) = 0.050,E_{out}(g_{\lambda}^-) = 0.025$</p><p>b. $log _10^{\lambda} = -2,E_{train}(g_{\lambda}^-) = 0.010,E_{val}(g_{\lambda}^-) = 0.050,E_{out}(g_{\lambda}^-) = 0.035$</p><p>c. $log _10^{\lambda} = -4,E_{train}(g_{\lambda}^-) = 0.000,E_{val}(g_{\lambda}^-) = 0.010,E_{out}(g_{\lambda}^-) = 0.025$</p><p>d. $log _10^{\lambda} = -6,E_{train}(g_{\lambda}^-) = 0.010,E_{val}(g_{\lambda}^-) = 0.010,E_{out}(g_{\lambda}^-) = 0.025$</p><p>e. $log _10^{\lambda} = -8,E_{train}(g_{\lambda}^-) = 0.000,E_{val}(g_{\lambda}^-) = 0.050,E_{out}(g_{\lambda}^-) = 0.025$</p><p>这道题目依然用之前的程序就可以完成，只需要修改主函数。这里使用到了验证集，需要添加的就是验证相关的代码。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    minEtrain = <span class="number">1</span></span><br><span class="line">    minEval = <span class="number">1</span></span><br><span class="line">    minEout = <span class="number">1</span></span><br><span class="line">    minEvalI = <span class="number">-1</span></span><br><span class="line">    minEtrainI = <span class="number">-1</span></span><br><span class="line">    minEoutI = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">-10</span>,<span class="number">3</span>):</span><br><span class="line">        _lambda = math.pow(<span class="number">10</span>,i)</span><br><span class="line">        data = readDataFrom(<span class="string">"./train.dat"</span>)</span><br><span class="line">        data_train = data[<span class="number">0</span>:<span class="number">120</span>]</span><br><span class="line">        data_val = data[<span class="number">120</span>:<span class="number">200</span>]</span><br><span class="line">        <span class="comment"># print(data)</span></span><br><span class="line">        data_test = readDataFrom(<span class="string">"./test.dat"</span>)</span><br><span class="line">        W = ridge_regression_one_step(data_train, _lambda)</span><br><span class="line">        etrain = Ein(data_train, W) / len(data_train)</span><br><span class="line">        eval = Ein(data_val,W)/len(data_val)</span><br><span class="line">        eout = Ein(data_test, W) / len(data_test)</span><br><span class="line">        print(i,<span class="string">"Etrain:"</span>, etrain,<span class="string">"Eval:"</span>,eval,<span class="string">"Eout:"</span>, eout)</span><br><span class="line">        <span class="keyword">if</span> etrain&lt;=minEtrain:</span><br><span class="line">            minEtrain = etrain</span><br><span class="line">            minEtrainI = i</span><br><span class="line">        <span class="keyword">if</span> eval &lt;= minEval:</span><br><span class="line">            minEval = eval</span><br><span class="line">            minEvalI = i</span><br><span class="line">        <span class="keyword">if</span> eout &lt;= minEout:</span><br><span class="line">            minEout = eout</span><br><span class="line">            minEoutI = i</span><br><span class="line">    print(<span class="string">"minEtrain:"</span>,minEtrainI,<span class="string">"minEval:"</span>,minEvalI,<span class="string">"minEout"</span>,minEoutI)</span><br></pre></td></tr></table></figure></p><p>最后输出如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">-10</span> Etrain: <span class="number">0.008333333333333333</span> Eval: <span class="number">0.125</span> Eout: <span class="number">0.04</span></span><br><span class="line"><span class="number">-9</span> Etrain: <span class="number">0.0</span> Eval: <span class="number">0.1</span> Eout: <span class="number">0.038</span></span><br><span class="line"><span class="number">-8</span> Etrain: <span class="number">0.0</span> Eval: <span class="number">0.05</span> Eout: <span class="number">0.025</span></span><br><span class="line"><span class="number">-7</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-6</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-5</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-4</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-3</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-2</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-1</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.022</span></span><br><span class="line"><span class="number">0</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.028</span></span><br><span class="line"><span class="number">1</span> Etrain: <span class="number">0.075</span> Eval: <span class="number">0.125</span> Eout: <span class="number">0.08</span></span><br><span class="line"><span class="number">2</span> Etrain: <span class="number">0.3416666666666667</span> Eval: <span class="number">0.4125</span> Eout: <span class="number">0.414</span></span><br><span class="line">minEtrain: <span class="number">-8</span> minEval: <span class="number">0</span> minEout <span class="number">-2</span></span><br></pre></td></tr></table></figure></p><p>因此答案选择e.</p><p><strong>17. Following the previous Question, among $\log_{10} \lambda= \left\{2, 1, 0, -1, \ldots, -8, -9, -10 \right\}$.What is the $\lambda$ with the minimum $E_{val}(g^-_\lambda)$? Compute $\lambda$ and the corresponding $E_{train}(g^-_\lambda)$, $E_{val}(g^-_\lambda)$ and $E_{out}(g^-_\lambda)$ then select the closet answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log _10^{\lambda} = 0,E_{train}(g_{\lambda}^-) = 0.033,E_{val}(g_{\lambda}^-) = 0.038,E_{out}(g_{\lambda}^-) = 0.028$</p><p>b. $log _10^{\lambda} = -3,E_{train}(g_{\lambda}^-) = 0.000,E_{val}(g_{\lambda}^-) = 0.028,E_{out}(g_{\lambda}^-) = 0.038$</p><p>c. $log _10^{\lambda} = -6,E_{train}(g_{\lambda}^-) = 0.066,E_{val}(g_{\lambda}^-) = 0.038,E_{out}(g_{\lambda}^-) = 0.038$</p><p>d. $log _10^{\lambda} = -9,E_{train}(g_{\lambda}^-) = 0.033,E_{val}(g_{\lambda}^-) = 0.028,E_{out}(g_{\lambda}^-) = 0.028$</p><p>e. $log _10^{\lambda} = -10,E_{train}(g_{\lambda}^-) = 0.066,E_{val}(g_{\lambda}^-) = 0.028,E_{out}(g_{\lambda}^-) = 0.028$</p><p>答案在上面已经给出。答案选择a.</p><p><strong>18. Run the algorithm with the optimal $\lambda$ of the previous Question on the whole $\mathcal{D}$ to get $g_\lambda$. Compute $E_{in}(g_\lambda)$ and $E_{out}(g_\lambda)$ then select the closet answer.</strong></p><p>a. $E_{in}(g_{\lambda}) = 0.015,E_{out}(g_{\lambda}) = 0.020$</p><p>b. $E_{in}(g_{\lambda}) = 0.025,E_{out}(g_{\lambda}) = 0.030$</p><p>c. $E_{in}(g_{\lambda}) = 0.035,E_{out}(g_{\lambda}) = 0.020$</p><p>d. $E_{in}(g_{\lambda}) = 0.045,E_{out}(g_{\lambda}) = 0.030$</p><p>e. $E_{in}(g_{\lambda}) = 0.055,E_{out}(g_{\lambda}) = 0.020$ </p><p>根据17题选出来最佳的$\lambda = 0$，因此在全数据集上再次进行学习，得到的结果在14题的分析中已经呈现，答案是c.</p><p>可以看到的是利用验证，我们选出来了一个很贴近最佳$E_{out}$的答案了。</p><p>For Questions 19-20, split the given training examples in $\mathcal{D}$ to five folds, the first $40$ being fold 1, the next $40$ being fold 2, and so on. Again, we take a fixed split because the given examples are already randomly permuted.</p><p><strong>19.  What is the $λ$ with the minimum $E_{cv}$, where $E_{cv}$ comes from the five folds defined above? Compute $\lambda$ and the corresponding $E_{cv}$ then select the closet answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log_{10}^{\lambda} = 0,E_{cv} = 0.030$</p><p>b. $log_{10}^{\lambda} = -2,E_{cv} = 0.020$</p><p>c. $log_{10}^{\lambda} = -4,E_{cv} = 0.030$</p><p>e. $log_{10}^{\lambda} = -6,E_{cv} = 0.020$</p><p>d. $log_{10}^{\lambda} = -8,E_{cv} = 0.030$</p><p>这个题目要做交叉验证。因此需要写一个新的交叉验证的函数cv。同时也要需要修改主函数。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#添加的函数cv</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cv</span><span class="params">(data,fold_count,_lambda)</span>:</span></span><br><span class="line">    <span class="comment"># disorder data</span></span><br><span class="line">    ecv = <span class="number">0</span></span><br><span class="line">    each_c = len(data)/fold_count</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(fold_count):</span><br><span class="line">        val = data[int(i*each_c):int((i+<span class="number">1</span>)*each_c)]</span><br><span class="line">        train = data[<span class="number">0</span>:int(i*each_c)]</span><br><span class="line">        train.extend(data[int((i+<span class="number">1</span>)*each_c):<span class="number">-1</span>])</span><br><span class="line">        W = ridge_regression_one_step(train,_lambda)</span><br><span class="line">        ecv +=Ein(val,W)/len(val)</span><br><span class="line">    <span class="keyword">return</span> ecv/fold_count</span><br></pre></td></tr></table></figure></p><p>最后得到结果如下：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">-10</span> Ecv: <span class="number">0.05</span></span><br><span class="line"><span class="number">-9</span> Ecv: <span class="number">0.05</span></span><br><span class="line"><span class="number">-8</span> Ecv: <span class="number">0.03</span></span><br><span class="line"><span class="number">-7</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-6</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-5</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-4</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-3</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-2</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-1</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">0</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">1</span> Ecv: <span class="number">0.06</span></span><br><span class="line"><span class="number">2</span> Ecv: <span class="number">0.28500000000000003</span></span><br><span class="line">minEcv: <span class="number">-8</span></span><br></pre></td></tr></table></figure></p><p>因此答案选择d.</p><p><strong>20. Run the algorithm with the optimal $\lambda$ of the previous problem on the whole $\mathcal{D}$ to get $g_\lambda$. Compute $E_{in}(g_\lambda)$ and $E_{out}(g_\lambda)$ then select the closet answer.</strong></p><p>a. $E_{in}(g_\lambda) = 0.005,E_{out}(g_\lambda) = 0.010$</p><p>b. $E_{in}(g_\lambda) = 0.015,E_{out}(g_\lambda) = 0.020$</p><p>c. $E_{in}(g_\lambda) = 0.025,E_{out}(g_\lambda) = 0.020$</p><p>d. $E_{in}(g_\lambda) = 0.035,E_{out}(g_\lambda) = 0.030$</p><p>e. $E_{in}(g_\lambda) = 0.045,E_{out}(g_\lambda) = 0.020$</p><p>上面得到的最好的$\lambda = 10^{-8}$，全部数据去学习的话，得到的$E_{in}$和$E_{out}$在14题目解析中也能看到,答案选b。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）总结</title>
      <link href="/2018/10/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E6%80%BB%E7%BB%93/"/>
      <url>/2018/10/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>到了现在机器学习基石的课程就结束了。最后有一些实际利用学习的原则和小tips，用来作为总结。<br><a id="more"></a></p><h2 id="Occam’s-Razor"><a href="#Occam’s-Razor" class="headerlink" title="Occam’s Razor"></a>Occam’s Razor</h2><p>Entities must not be multiplied beyond necessity.</p><p>使用的模型要尽量简单。我们知道越复杂的模型可以解释的样本更多，但是一个样本集如果被简单的模型所解释，那么从另一方面来说这个数据集更可能存在一定的规律性。因为即使是随机产生的样本，复杂的模型依然可以解释。而对于完全随机的样本是没有学习的必要的（可见No Free Lunch定理）。因此我们尽量使用简单的模型去解释样本，在泛化能力上等等相对于复杂模型来说都会更好。越简单越好。</p><h2 id="Sampling-Bias"><a href="#Sampling-Bias" class="headerlink" title="Sampling Bias"></a>Sampling Bias</h2><p>1948年美国总统大选，Truman versus Dewey.一家报社为了提前预测大选结果，利用电话进行民意调查，得到的结果是Dewey Defeat Truman，然而最后的结果是Truman赢得了大选。而民意调查既没有出错，也没有出现运气不好的情况，为何会这样？当年电话是比较昂贵的，因此接受民意调查的都是比较富有的阶级，在这些人中对Dewey的支持率更高，但是占了大多数人的中下阶级对Truman的支持更好，因此出现了这样的结果。</p><p>在我们所有的上述的这些理论推论中，我们都假设训练与测试集，都来自同一分布。而现实中，比如上面的例子，这样的情况并不是经常会碰到。保证我们获得的训练集与真实的数据来自同一分布是比较困难的。因此在实际操作中我们要注意尽可能让训练集与测试集来自同一分布。比如在预测电影时，可能每个人看的前7部电影是训练集，后三步用来测试，这就不是同一分布，因为观影顺序可能是很重要的,有一定的意向，而不是随机的。因此在学习时需要适当加重后面几部电影的权重，或者利用后面几部来做验证集。总之，Sampling Bias也是常见的影响学习效果的原因。</p><h2 id="Data-Snooping"><a href="#Data-Snooping" class="headerlink" title="Data Snooping"></a>Data Snooping</h2><p>数据“偷窥”。这是之前也一直提到的，如用自己的眼睛来决定学习算法。这时候可能会算上意外的VC dimension，但是我们却不知道。但是实际上，不光用眼睛，很多时候Data snooping很难以避免，一些小小的动作就会影响到这些东西。比如一直在前人的模型上改进发表论文，虽然你可能没有去看数据，但是确实利用了之前的模型，它就在一定程度上包含了数据的信息。偷窥数据的结果就是使得自己学习的模型过于乐观，可能会造成overfitting，这也是overfitting很难处理的一个原因。</p><p>有几个小的建议，就是在不看数据之前，想好需要用到的特征量；保证测试数据的封锁，使其不受到污染。对于避免Data Snooping的做法可能需要多年的经验，其中的机制因为组合太多很复杂，因此这个需要慢慢体会。</p><p>机器学习是人工智能，数据挖掘，统计理论的交集，它为今天人类生活带来了很多便利，如语音处理人脸识别等等。希望自己可以学好这门课程并且付诸实践。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> tips </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Validation</title>
      <link href="/2018/09/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Validation/"/>
      <url>/2018/09/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Validation/</url>
      
        <content type="html"><![CDATA[<p>上次regularization最后留下了一个问题：$\lambda$的选择。其实仔细想想，从学习机器学习到现在，我们面临的选择，可不止一个$\lambda$.<br><a id="more"></a></p><p>模型的选择（PLA，POKCET，Linear Regression，Logistic Regression），特征转换的方法（用什么样的多项式转换），Regularizer的选择等等，这些组合起来足够让人头大。而实际上，也没有一种永远都表现得很好的组合，对于不同的问题需要不同的方法，也就是做选择是必须的。</p><p>为了简化问题，我们就仅以不同的假说的选择为例。其他的选择也与这个类似。</p><p>假设我们目前有2个$H$，一个$H_2$,另一个$H_{10}$，应该选择哪一个？</p><p>一个简单的想法，是利用$E_{in}$去判断。但是这个想法太naive了。我们之前讲过过拟合了，如果用$E_{in}$去判断，那就不用想了，因为$H_{10}$一定比$H_2$要好，而且如果两个模型一个加了$regularization$，它的表现一定不如另一个.而且如果两个$H$没有交集，从两个$E_{in}$中选择一个好的，那么实际上是在两个$H$的并集中选择，这也就意味着增大了代价，更容易得到不好的$E_{out}$。</p><p>另一种简单的想法，用测试数据来判断。这是一个很好的办法。我们知道$E_{test}$与$E_{out}$是满足霍夫丁不等式的，因此可以得到：</p><script type="math/tex; mode=display">E_{out} \leq E_{test}+O(\sqrt {\frac{\log M}{N_{test}}})</script><p>所以用测试集来从模型中选择一个最好的是可行的。但是测试集从哪里来？</p><p>一般来说，测试集是锁在老板的柜子中。测试集相当于考试试卷，用来评判最终的分数.我们无法得到测试集，这就像考试前你想让自己做到最好，你没法用考试的卷子来测试自己，这叫作弊。</p><p>但是我们可以自己测验自己。这就是validation。</p><p>从给到的训练集当中，我们随机挑出一部分（保证iid），用来当作val集，其余部分用来训练模型。然后通过val集来选出表现最好的g’.为什么不是g？因为毕竟它的训练集相对于之前要少了很多，所以加个标识以区分。</p><p>一般来说，得到g’以后，也就是选出了我们想要的那个$H$，然后我们要做的就是将验证集再次融合回去，用这个整体的训练集在该假说上训练。毕竟某种程度上来说，N越大，得到的模型是越好的。而且</p><script type="math/tex; mode=display">E_{out}(g_{H_{chosen}}) < E_{out}(g'_{H_{chosen}})</script><p>上式是实际中的一个很常见的式子，但理论上要这么保证还需要一定的限制条件。</p><p>假设我们从N个训练样本中挑出K个来做验证集，当然这个K的大小是会影响结果的。如果K很大，那么很开心，$E_{val}$与$E_{out}$更有可能很接近，这对于选择g’来说是很好的，但是K过大意味着留下来的训练样本过少，g’与g差别很大，可能导致我们无法找到应该选择的那个$H$；另一方面，K很小，g与g’相差很小，但是$E_{val}$与$E_{out}$可能实际上差的很远，也不能得到好的结果。因此这又是一个难题。<br>一般来说有下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%7ELN%7EMS5IB6G61%40DWBDM51OE.png" alt=""><br>可以看到如果K过大，导致训练g’的训练集很小，使得它的学习效果很差，甚至不如不用验证的情况。</p><p>为了解决这个问题，引入一种新的工具：交叉验证。</p><p>首先我们考虑一种很极端的情况：K=1.每次留出一个来做验证，对于单个样本来说它当然无法代表$E_{out}$.但是如果我们对这个过程进行N次，所有的样本都曾做过验证集，最后求出来$E_{val}$的平均值，可以证明它就能代表g’的$E_{out}$.上面的办法，叫做leave-one-out cross validation.假设它得到的错误我们称为$E_{looc}$，则有下面的证明：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/VQVY7%5B%60%5BQA%40AT%7BQ_S24LDQ4.png" alt=""><br>(上面的证明我是看不大懂的)</p><p>这似乎是个很好的方法，但是它有个很致命的缺陷：计算量（N）倍的力气去计算g’。</p><p>因此，实际中我们很少用leave one out cross，而使用V-Fold Cross。将样本分为10（或者其他数）份，然后留一份作为val集，像上面一样交叉验证。这样需要的力气就是10倍，可以接受，而且能得到比非交叉验证更好的结果。</p><p>对于其他情况的选择，也可以用这样的办法，因为我们最终目的是得到尽量好的$E_{out}$。</p><p>最后，validation依然是为了做选择，因此它的结果依然是比较optimistic，算法最终的衡量还是要通过测试集，而不是将最好的validation结果作为衡量标准，这是自欺欺人的表现。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> validation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Regularization</title>
      <link href="/2018/09/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Regularization/"/>
      <url>/2018/09/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Regularization/</url>
      
        <content type="html"><![CDATA[<p>上篇博客说了overfitting的情况，有一些比较高级的处理overfitting的办法，其中有一个就是regularization，中文中叫做正则化。<br><a id="more"></a></p><p>从前面的nonlinear transform中也说明了，复杂的假说一般会包括了简单的假说。例如一个2次的假说，与10次的假说，他们的区别，就是10次的比二次的多了更多三次及以上的特征。也就是二次假说实际上是十次假说加上了一个限制：三次及以上的特征前面的权重（w）为0.这样就使得假说变得简单了不少.</p><p>如果放宽这个限制，假如较为简单的模型特征量有r个，在复杂模型中，最多有r个特征的权重不为0，在一定程度上，也可以很好的减少这个复杂度。只不过让人遗憾的是，在这样的假说中选出最佳的$\mathbf w$（权重向量）被证明了是一个NP-hard问题，没有一个很好的解决办法.</p><p>如果个数是整数，要挑出最好的，很容易有NP-hard问题，但是将这个拓宽到实数领域，我们往往可以通过数学工具得到最佳解。例如在这里，我们继续拓宽这个限制：让这些$w^2$和小于一个常数$C$，似乎也可以起到类似的效果。</p><p>为了简化问题，举个很简单的例子如：对于只有一个特征量的样本集，$H_2 = w_0+w_1x+w_2X^2$，而$H_{10} = w_0+w_1x+w_2x^2+…+w_{10}x^{10}$.</p><p>对于$H_2$来说，$H_{10}$中限制为$w_3 = w_4 = w_5 = …= w_{10} = 0$.</p><p>对于上面说的第二种假设，$H_{10}$限制为:$\sum _{n = 0} ^{10} [[w_n \ne 0]] \leq 3$.</p><p>对于第三种假设，$H_{10}$限制为:$\sum_{n = 0}^{10} w_n^2 \leq C$ 即$W^TW \leq C$.</p><p>那么，我们已经知道了最后一个才有可能求得最佳解。如何去做？</p><p>高维度的figure我们无法想象，我也不知道怎么去称呼，但是如果是二维，这个限制是一个圆，如果是三维，这个限制是一个球。假设我们依然称这个限制为一个球，而没有限制的最低点不在这个球内。因此梯度下降的结果就是达到了球的边缘，但是依然想要走下坡路。无路可走的情况，是梯度与该法向量的方向平行了，而只要梯度与该法向量的方向不不平行，我们总是可以朝着某个方向走使得$E_{in}$继续减少。因此这个过程终止的时候，就是该点的法向量与$E_{in}$的梯度平行了，而值得注意的是边缘某点的法向量实际上就是$W$.如果我们称做这个结果$W$为$W_{REG}$，那么有个结果：$W_{REG} = \lambda ▽E_{in}$.</p><p>其中这个$lambda$是一个常熟.我们知道，线性回归中梯度为$▽E_{in} = \frac 2 N (X^TX - Y^TXW)$，为了简化，我们将$\lambda$写为$ \frac {2\lambda} N$,最后得到：</p><script type="math/tex; mode=display">▽E_{in}+ \frac 2 N \lambda W_{REG} = 0.</script><p>如果$\lambda$提前知道，那么我们就可以求得$W_{REG}$的值.</p><p>如果对上式左边求积分可以得到： </p><script type="math/tex; mode=display">f(W) = E_{in} + \frac \lambda N W_{REG}</script><p>所以可以很神奇地发现，对于原来的问题的求解可以很有效地转变成了求$f(W)$的最小值，它就是正则化后的$E_{in}$，因此新的$cost-function$变成了下面的样子：</p><script type="math/tex; mode=display">min_{W \in R^{Q+1}} \frac 1 N \sum _{n = 0} ^N (\mathbf{w}^T \theta(X_n) - y_n)^2 + \frac {\lambda} N \sum {q=0} ^Q w_q^2</script><p>tips：对于多项式正则化，因为一般来说我们会将特征值的范围限定到$[-1,1]$(原因以后再探讨),这导致高次项的影响可能变得非常小，为了处理这种情况需要用到一个正交化处理，关键词“Legendre polynomial”。效果更好。需要了解更多的话可以去搜索.</p><p>$\lambda$由$C$确定（这是不严谨的说话。但是实际中给定\lambda就可与将$W$限定到一个范围，因此给出C的人也更容易给出一个$\lambda$），实际应用时，给$\lambda$一个很小的值就可与很好地处理过拟合的情形，如果过大，可能会出现欠拟合的情况.</p><p>接下来需要继续说明的是regularization，与vc理论之间的关系。实际上，即使加上了regularization，对于一个假说来说，在数学计算上它的vc dimention依然很大，依然会付出很大的代价。但是regularization的作用是什么？它将我们需要寻找的范围局限在了一定范围内，在这个范围内，可能都是比较好的$h$,因此有效的vc dimension减少了，也就更有可能得到比较好的$E_{out}$。</p><p>如何选择regularizer？</p><p>1.首先，如果我们知道目标函数的一些特点，就可以指引我们选择一些好的regularizer，比如：如果知道目标函数是偶函数，可以只对奇次项的特征进行正则化。</p><p>2.选择平滑的，如$\sum _{q=0} ^ Q |w_q|$.这个也叫L1 regularizer（L1正则化）.相对于L2来说它效果往往更好一点，因为更加平滑，但是不好解。</p><p>3.选择好优化的，如L2，也就是上文提到的。</p><p>除此之外，还有$\lambda$的选择。如图，不同的noise级别需要的$lambda$也不同：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/QWA_KMVHC_%7DZWJF3%607C%5DQYA.png" alt=""></p><p>如何选择一个合适的$\lambda$也非常重要，这就需要用到下一节所讲的Validation。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> overfitting </tag>
            
            <tag> regularization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Overfitting</title>
      <link href="/2018/09/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Overfitting/"/>
      <url>/2018/09/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Overfitting/</url>
      
        <content type="html"><![CDATA[<p>Overfitting（过拟合）是机器学习中可能最让人头疼的问题了。对应Overfitting的是Underfitting（欠拟合），相比之下戏份就少了很多。<a id="more"></a></p><p>简单来说，Underfitting，是$E_{in}$高，$E_{out}$也很高。于是人们会想方设法地减少$E_{in}$，认为这样就可以得到较好地结果。但是不幸的是，有时候$E_{in}$已经很低了，这个模型依然有很高的$E_{out}$.这就很让人头疼。这就是overfitting。想要更好的解决Overfitting，理解一些数学理论如VC dimension是很有帮助的，给我们提供了更多出现这种情况的原因和解决的思路。</p><p>其实Overfitting我们之前也早有提及过。</p><p>首先来看一下overfitting的简单的例子：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/RPA%5DK%7D%5DD%5BU%251EL%7B1EM%29I%24W4.png" alt=""></p><p>对于目标函数产生的资料，加上了一点noise，在训练集样本很少的情况下，出现了上面的情况：目标函数的$E_{in}$，比我们得到的这个与目标函数差了十万八千里的函数的$E_{in}$更大。我们的算法选择的是$E_{in}$最小的，因此就选择了表现很差的模型。</p><p>从上面的样例我们想到了nonlinear transform，当我们进行特征转换的时候，vc dimension大大增加，使得付出的代价变得很高，在样本不够的情况下，很容易得到很差的$E_{out}$，这就是一种overfitting.于是又一次看到了这张图。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/M%29P32DW%29EE9%7BWB%246A08T8%29X.png" alt=""></p><p>当然，造成上面的结果有一点原因是噪声，但是即使没有噪声，最多最多，他们的$E_{in}$也是一样的，而且实际中，没有噪声的情况是很少出现的。这说明了造成overfitting的两个原因：1.noise过多。很好理解，更好的适应了noise，它的泛化能力当然不行；2.使用过于复杂的模型，去估计较为简单的目标函数。一般来说，简单的函数只是复杂模型的特例，而且因为噪声的原因往往目标函数不能完美拟合，但是复杂的模型就能做的非常完美。但是另一方面，它的泛化能力也大大下降了。</p><p>如果我们采用复杂的模型估计复杂的函数呢？在我们心里可能会想，这下总会好点了吧。因为复杂的目标函数，你不用复杂的模型，根本就不可能完美地估计出来。似乎有点道理，我们来看下面地例子：</p><p>用10次的多项式产生一些数据，加上噪声。我们分布用10次的$H$与2次的$H$来对它进行拟合：</p><p>目标函数：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%29L%29Y%40YB1U%7DTN%5BLRL%7BJ%7E_N%7E9.png" alt=""></p><p>拟合结果：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/Z%7DIA11%7BHHKFR%7EOFL6VV%60YH3.png" alt=""></p><p>通过对比，我们惊奇地发现，二次的拟合结果，虽然$E_{in}$做得不如，但是$E_{out}$比10次的更好！</p><p>如果我们使用二次的多项式，那首先我们不可能做到完美，但是我们发现，有时候它的表现比更复杂地模型模拟的更好，尽管原来的模型非常地复杂。</p><p>想要了解这其中的原因，我们来观察一下两个$H$的learning curve：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/9RVH8F%297JG%40RGRIUHHFJ%7EV2.png" alt=""></p><p>对于右侧的我们是熟悉的，观察右侧的$H_{10}$的学习曲线，我们发现，虽然当N区域无穷的时候，它有更好的性能，但是在灰色区域里，它是Overfitting的。因此，overfitting的最关键的原因：数据量不够多。</p><p>因为模型越复杂，可以走的路就越多，在资料量小的时候，可能很多条路都会完美走过这条道，而其他的部分可能差的很远。这依然可以用VC dimension来解释，代价太大了，为了降低代价，必须需要更大的N.</p><p>当然，上面的例子中依然有noise的存在。Noise或多或少影响了复杂模型的性能，而且越复杂模型它的影响可能越大。对于没有noise的模型，是否还有上面的结果？</p><p>利用50次目标函数产生的数据，依然用$H_2$与$H_{10}$去模拟：</p><p>目标函数：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/UTID8V4V%28O3TP%5BTE%24J%5BT_%24U.png" alt=""></p><p>拟合结果：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/T%7EY9M6%24%605S_DUHD8CPA0B9X.png" alt=""></p><p>可以看到二次函数依然比10次函数表现得更好。原因和上面一样。所以没有很多数据量的支撑，使用较为简单的模型往往效果更好。</p><p>这时候我们会纳闷，这明明没有noise啊，为什么会这样？过于复杂的模型与简单的假设似乎带来了和noise类似的结果。</p><p>在机器学习领域中，对于过于复杂的模型本身带来的类似于noise的效果，被称为Deterministic Noise.</p><p>对于普通的noise，我们假设为高斯噪声（Gaussian Noise）。对于Gaussian Noise与Deterministic Noise对于模型的影响，$Q_f$为目标函数的次数，那么可以用下面的图来形象展示出来：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%28%25V%25Z8QJM%29V8%5D2NS%240%254IZK.png" alt=""></p><p>可以看出来，两种噪声带来的效果相近，可以通过增加N来避免过拟合的情况。</p><p>值得注意的是，右侧图中，左下角依然有一块会过拟合。需要注意，上述图中$H$的次数是不变的，因此，如果$Q_f$小于$H$的次数，会出现第一种情况，power过强的情况.</p><p>实际上，deterministic noise与电脑产生伪随机数的原理很相似，过于复杂的模型，造成了随机噪声的效果。</p><p>总结一下，Overfitting出现的原因：<br>1.N太小<br>2.Stochastic(Gaussian) Noise<br>3.Deterministic Noise<br>4.Too Much Power</p><p>如何对付overfitting是个很复杂的话题。首先直观来说，降噪，增加样本。降噪，可以通过修正label与去除错误的样本来实现，而增加样本往往没有那么容易，某些情况下我们可以自己创造data.另外还有两种比较复杂的做法，也有很好的效果：Regularization 与 Validation.以后会专门写博客来介绍。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> overfitting </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）作业3</title>
      <link href="/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A3/"/>
      <url>/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A3/</url>
      
        <content type="html"><![CDATA[<p>总共20道题目。<a id="more"></a><br><strong>1. Consider a noisy target $y = {\bf w}_f^T{\bf x} + \epsilon$, where $\mathbf{x} \in \mathbb{R}^d$ (with the added coordinate $x_0=1$), $y\in\mathbb{R}$, $\mathbf{w}_f$ is an unknown vector, and $\epsilon$ is a noise term with zero mean and $\sigma^2$ variance. Assume $\epsilon$ is independent of ${\bf x}$ and of all other $\epsilon$’s. If linear regression is carried out using a training data set $\mathcal{D} = \{(\mathbf{x}_1, y_1), \ldots, ({\bf x}_N, y_N)\}$, and outputs the parameter vector $\mathbf{w}_{\rm lin}$, it can be shown that the expected in-sample error $E_{\rm in}$ with respect to $\mathcal{D}$ is given by:</strong></p><script type="math/tex; mode=display">\mathbb{E}_{\mathcal{D}}[E_{\rm in}(\mathbf{w}_{\rm lin})] = \sigma^2\left(1 - \frac{d + 1}{N}\right)</script><p>For $\sigma = 0.1$ and $d = 8$, which among the following choices is the smallest number of examples $N$ that will result in an expected $E_{\rm in}$ greater than 0.008?</p><p>a. 10</p><p>b. 25</p><p>c. 100</p><p>d. 500</p><p>e. 1000</p><p>这道题目中，已经给出了$E_{in}$的期望值如何计算，只需要将$\sigma = 0.1,d = 8$带入上式即可，算出来的是$N = 45$的时候，$E_{in}$的期望值为0.008，而为了使得期望值变得更大，$N$的值也要变得更大，因此上面选项中最小的大于45的$N$是100，选c（Note:Greater意思是更大，而不是更好）.</p><p><strong>2. Recall that we have introduced the hat matrix $\mathrm{H} = \mathrm{X}(\mathrm{X}^T\mathrm{X})^{-1}\mathrm{X}^T$ in class, where $\mathrm{X} \in \mathbb{R}^{N\times (d+1)}$ containing $N$ examples with $d$ features. Assume $\mathrm{X}^T\mathrm{X}$ is invertible and $N &gt; d+1$, which statement of $\mathrm{H}$ is true?</strong></p><p>a. none of the other choices</p><p>b. $\mathrm{H}^{1126} = \mathrm{H}$</p><p>c. $(d+1)$ eigenvalues of $\mathrm{H}$ are bigger than 1.</p><p>d. $N - (d+1)$ eigenvalues of $\mathrm{H}$ are 1</p><p>e. $\mathrm{H}$ is always invertible</p><p>从<a href="https://wlsdzyzl.top/2018/08/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression/#more" target="_blank" rel="noopener">linear regression</a>中，我们直到$H$矩阵的作用是在$X$空间做$Y$的投影，来得到$Y’$，而投影一次与投影10次没什么太大区别，因此b是正确的。$H$的自由度是$N - (d+1)$，而它的特征值应该是有(N - d+1)个不为0，而且特征值也不是一定的，只是与特征向量成比例，因此c，d是不对的。</p><p><strong>3. Which of the following is an upper bound of $[[sign(w^Tx)≠y]]$ for $y \in \{-1, +1\}$?</strong></p><p>a. $err(W) = \frac 1 2 e ^{(-yW^TX)}$</p><p>b. $err(W) = [W^TX \geq y]$</p><p>c. $err(W) = max(0,1 - yW^TX)$</p><p>d. $err(W) = max(0, -yW^TX)$</p><p>e. none of the other choices</p><p>这个题目最直观的看法依然是画图，a-red,b-blue,c-yellow,d-green,$[sign(W^TX) \neq y]$-black,按照上面的颜色画图如下：<br>当y = 1 时：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/8%5B%24IX%25Y9N86%5DB%2856AA%243TEE.png" alt=""><br>当 y = -1时：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%7BAK_J8U02WEX%247%5BMUS3O1%24B.png" alt=""><br>从上面的图中我们可以很直观看到只有yellow线是符合的，因此这个题目答案为c.</p><p><strong>4. Which of the following is a differentiable function of $\mathbf{w}$ everywhere?</strong></p><p>a. $err(W) = \frac 1 2 e ^{(-yW^TX)}$</p><p>b. $err(W) = [W^TX \geq y]$</p><p>c. $err(W) = max(0,1 - yW^TX)$</p><p>d. $err(W) = max(0, -yW^TX)$</p><p>e. none of the other choices</p><p>differentiable function 意思是可微函数。所以很明显答案是a.</p><p><strong>5. When using SGD on the following error functions and `ignoring’ some singular points that are not differentiable, which of the following error function results in PLA?</strong></p><p>a. $err(W) = \frac 1 2 e ^{(-yW^TX)}$</p><p>b. $err(W) = [W^TX \geq y]$</p><p>c. $err(W) = max(0,1 - yW^TX)$</p><p>d. $err(W) = max(0, -yW^TX)$</p><p>e. none of the other choices</p><p>PLA更新策略：</p><script type="math/tex; mode=display">W_{n+1} = W_{n} + yX</script><p>使用SGD，也就是随机选择一个样本求$err(W)$的导数来更新。对于梯度下降中，对于下一步的做法是：</p><script type="math/tex; mode=display">W_{n+1} = W_{n} - \alpha \frac {d_{err{W}}}{d_W}</script><p>其中$\alpha$是学习率，这道题目中应该为1.</p><p>因此主要是要求得导数。实际上，我们从上面的题目中可以轻易的看出，对于 a,b一定是不正确的，而c，d的导数是一样的：$\frac {d_{err{W}}}{d_W}  =  -yX$，因此就更新的步骤来说，它们两个都是合适的。</p><p>但是我们不能都选上，要注意PLA算法做更新的时候是找到错误的点，如果点是正确的，我们则不应该更新。而c选项是PLA的Upper bound，从上面题目的图中也可以看到，如果$y = -1，W^TX \in [-1,1]$之间PLA是不会更新的，而c在这个时候依然会选择更新。所以这个题目的正确答案是d.</p><p>For Questions 6-10, consider a function $E(u,v) = e^u + e^{2v} + e^{uv} + u^2 - 2 u v + 2 v^2 - 3 u - 2 v$.</p><p><strong>6. What is the gradient $\nabla E(u, v)$ around $(u, v)=(0, 0)$?</strong></p><p>a. $(0,-2)$</p><p>b. none of the other choices</p><p>c. $(-3,1)$</p><p>d. $(3,-1)$</p><p>e. $(-2,0)$</p><p>这道题目不算难。 $\nabla E(u,v) = (e^u+ve^{uv}+2u - 2v - 3, 2e^{2v}+ue^{uv}-2u +4v - 2)$，代入$(0，0)$得到$(-2,0)$，答案为e.</p><p><strong>7. In class, we have taught that the update rule of the gradient descent algorithm is $(u_{t+1}, v_{t+1}) = (u_t, v_t) - \eta \nabla E(u_t, v_t)$. Please start from $(u_0, v_0) = (0, 0)$, and fix $\eta=0.01$. What is $E(u_{5}, v_{5})$ after five updates?</strong></p><p>a. 4.904</p><p>b. 3.277</p><p>c. 2.825</p><p>d. 2.361</p><p>e. 1.436</p><p>这个题目虽然迭代次数不多，但是因为有$\exp$函数计算，还是比较复杂的。因此我编写梯度下降的程序来计算这道题目。</p><p>函数gradient_decent要传入4个参数：start开始值，get_gradicent 一个计算梯度的函数，eta学习率，i_times为迭代次数。</p><p>其他的函数包括计算梯度，更新W（update），以及计算$err$，程序代码如下：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_gradient</span><span class="params">(para)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [math.exp(para[<span class="number">0</span>])+para[<span class="number">1</span>]*math.exp(para[<span class="number">0</span>]*para[<span class="number">1</span>])+<span class="number">2</span>*para[<span class="number">0</span>]<span class="number">-2</span>*para[<span class="number">1</span>]<span class="number">-3</span>,<span class="number">2</span>*math.exp(<span class="number">2</span>*para[<span class="number">1</span>])+para[<span class="number">0</span>]*math.exp(para[<span class="number">0</span>]*para[<span class="number">1</span>] )- <span class="number">2</span>*para[<span class="number">0</span>]+<span class="number">4</span>*para[<span class="number">1</span>]<span class="number">-2</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_decent</span><span class="params">(start,get_gradient,eta,i_times)</span>:</span></span><br><span class="line">    last = copy.deepcopy(start)</span><br><span class="line">    <span class="keyword">while</span>(i_times&gt;<span class="number">0</span>):</span><br><span class="line">        i_times-=<span class="number">1</span></span><br><span class="line">        update(last,get_gradient(last),eta)</span><br><span class="line">    <span class="keyword">return</span> last</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(last,gradient,eta)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span>  range(len(last)):</span><br><span class="line">        last[i] = last[i] - eta * gradient[i]</span><br><span class="line">    <span class="keyword">return</span> last</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Ein</span><span class="params">(para)</span>:</span></span><br><span class="line">    u = para[<span class="number">0</span>]</span><br><span class="line">    v = para[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> math.exp(u)+math.exp(<span class="number">2</span>*v)+ math.exp(u*v)+math.pow(u,<span class="number">2</span>)<span class="number">-2</span>*u*v+<span class="number">2</span>*math.pow(v,<span class="number">2</span>)<span class="number">-3</span>*u - <span class="number">2</span>*v</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    print(gradient_decent([<span class="number">0</span>,<span class="number">0</span>],get_gradient,<span class="number">0.01</span>,<span class="number">5</span>))</span><br><span class="line">    print(Ein(gradient_decent([<span class="number">0</span>,<span class="number">0</span>],get_gradient,<span class="number">0.01</span>,<span class="number">5</span>)))</span><br></pre></td></tr></table></figure></p><p>最后输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[0.09413996302028127, 0.0017891105951028273]</span><br><span class="line">2.8250003566832635</span><br></pre></td></tr></table></figure></p><p>因此答案选c.</p><p><strong>8. Continuing from Question 7. If we approximate the $E(u + \Delta u, v + \Delta v)$ by $\hat{E}_2(\Delta u, \Delta v)$, where $\hat{E}_2$ is the second-order Taylor’s expansion of $E$ around $(u,v)$. Suppose $\hat{E}_2(\Delta u, \Delta v) = b_{uu} (\Delta u)^2 + b_{vv} (\Delta v)^2 + b_{uv} (\Delta u)(\Delta v) + b_u \Delta u + b_v \Delta v + b $, What are the values of $(b_{uu}, b_{vv}, b_{uv}, b_u, b_v, b)$ around $(u, v) = (0, 0)$?</strong></p><p>a. none of the other choices</p><p>b. $(3,8,-1,-2,0,3)$</p><p>c. $(3,8,-0.5,-1,-2,0)$</p><p>d. $(1.5,4,-0.5,-1,-2,0)$</p><p>e. $(1.5,4,-1,-2,0,3)$</p><p>这个题目不算难，实际上是一个多维函数的二阶泰勒展开，而$b{_uu}$则是对$u$求二阶偏导再除以$2!$。只要一项项计算上面的值就可以了。<br>$b_{uu} = 3,b_{vv} = 8,b_{uv} = -1,b_{u} = -2,b_{v} = 0,b = 3$，二元泰勒展开因此答案是e.   </p><p><strong>9. Continue from Question 8 and denote the Hessian matrix to be $\nabla^2 E(u, v)$, and assume that the Hessian matrix is positive definite. What is the optimal $(\Delta u, \Delta v)$ to minimize $\hat{E}_2(\Delta u, \Delta v)$? (The direction is called the Newton Direction.)</strong></p><p>a. $+(\nabla^2E(u,v))^{-1}\nabla E(u,v)$</p><p>b. $-(\nabla^2E(u,v))^{-1}\nabla E(u,v)$</p><p>c. none of the other choices</p><p>d. $+\nabla ^2 E(u,v) \nabla E(u,v)$</p><p>e. $-\nabla ^2 E(u,v) \nabla E(u,v)$</p><p>其实这个题目我不是很清楚。这其中涉及到了海森矩阵以及牛顿方向。通过简单的了解，如果一个点的梯度为0向量，而且在该点的海森矩阵为正定矩阵，那么该点为极小值点。题目中说明了海森矩阵为正定矩阵，因此找这个极值点，如果不知道牛顿方向，我就会按照梯度下降的来。而查阅了牛顿方向之后，牛顿方向就是e选项。所以选择b.</p><p>当然，这个题目实际上就是搜出来的答案，真正想要理解需要更加深入地去看线性代数。</p><p><strong>10. Use the Newton direction (without \eta) for updating and start from $(u_0, v_0) = (0, 0)$. What is $E(u_{5}, v_{5})$ after five updates?</strong></p><p>a. 4.904</p><p>b. 3.277</p><p>c. 2.825</p><p>d. 2.361</p><p>e. 1.436</p><p>这道题目，当然我还是想借助程序来完成，不过这次的程序相比之前会更麻烦一点。因为之前设置好了接口，也就是在梯度下降的时候传入求得梯度的函数，因此这里我们只需要写出计算 $\nabla ^2 E(u,v) \nabla E(u,v)$的函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Newton_direction</span><span class="params">(para)</span>:</span></span><br><span class="line">    u = para[<span class="number">0</span>]</span><br><span class="line">    v = para[<span class="number">1</span>]</span><br><span class="line">    hs = [[math.exp(u)+math.pow(v,<span class="number">2</span>)*math.exp(u*v)+<span class="number">2</span>,math.exp(u*v)+v*u*math.exp(u*v)<span class="number">-2</span>],</span><br><span class="line">          [math.exp(u*v)+v*u*math.exp(u*v)<span class="number">-2</span>,<span class="number">4</span>*math.exp(<span class="number">2</span>*v)+math.pow(u,<span class="number">2</span>)*math.exp(u*v)+<span class="number">4</span>]]</span><br><span class="line">    m = mat(hs)</span><br><span class="line">    <span class="keyword">return</span> (m.I*mat([get_gradient([u,v])]).T).T.tolist()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p><p>最后在主函数中修改传入的学习率与求梯度的函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Ein(gradient_decent([<span class="number">0</span>,<span class="number">0</span>],Newton_direction,<span class="number">1</span>,<span class="number">5</span>)))</span><br></pre></td></tr></table></figure></p><p>得到结果：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">因此答案选d.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**11. Consider six inputs $\mathbf&#123;x&#125;_1 = (1, 1)$, $\mathbf&#123;x&#125;_2 = (1, -1)$, $\mathbf&#123;x&#125;_3 = (-1, -1)$, $\mathbf&#123;x&#125;_4 = (-1, 1)$, $\mathbf&#123;x&#125;_5 = (0, 0)$, $\mathbf&#123;x&#125;_6 = (1, 0)$. What is the biggest subset of those input vectors that can be shattered by the union of quadratic, linear, or constant hypotheses of $\mathbf&#123;x&#125;$?**</span><br><span class="line"></span><br><span class="line">a. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_2,\mathbf&#123;x&#125;_3$</span><br><span class="line"></span><br><span class="line">b. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_2,\mathbf&#123;x&#125;_3,\mathbf&#123;x&#125;_4,\mathbf&#123;x&#125;_5,\mathbf&#123;x&#125;_6$</span><br><span class="line"></span><br><span class="line">c. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_2,\mathbf&#123;x&#125;_3,\mathbf&#123;x&#125;_4$</span><br><span class="line"></span><br><span class="line">d. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_3$</span><br><span class="line"></span><br><span class="line">e. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_2,\mathbf&#123;x&#125;_3,\mathbf&#123;x&#125;_4,\mathbf&#123;x&#125;_5$</span><br><span class="line"></span><br><span class="line">首先，我们可以看到特征量的个数是2（$d=2$），而由前面的推导可以知道，最高次为2次时候，它可以组成的新的特征值的个数为5，而它的vc dimension是小于等于6的.一种可行的办法是将x空间投影到z空间以后，用线性的办法来shatter这6个点，再返回看原来的x组合而成的特征是否能够满足这6个特征量。但是实际上这还是复杂的。也可以利用梯度下降，跑程序来对上述选项来进行排除。具体答案是多少还需要进一步进行排除。这个答案是b.可以shatter6个点.</span><br><span class="line"></span><br><span class="line">**12. Assume that a transformer peeks the data and decides the following transform $\boldsymbol&#123;\Phi&#125;$ &quot;intelligently&quot; from the data of size $N$. The transform maps $\mathbf&#123;x&#125; \in \mathbb&#123;R&#125;^d$ to $\mathbf&#123;z&#125; \in \mathbb&#123;R&#125;^N$, where**</span><br><span class="line">$$</span><br><span class="line">(\boldsymbol&#123;\Phi&#125;(\mathbf&#123;x&#125;))_n = z_n = \left[\left[ \mathbf&#123;x&#125; = \mathbf&#123;x&#125;_n \right]\right]</span><br><span class="line">$$</span><br><span class="line">Consider a learning algorithm that performs PLA after the feature transform.Assume that all $\mathbf&#123;x&#125;_n$ are different, $30%$ of the $y_n$&apos;s are positive, and $sign(0)=+1$. Then, estimate the $E_&#123;out&#125;$ of the algorithm with a test set with all its input vectors $\mathbf&#123;x&#125;$ different from those training $\mathbf&#123;x&#125;_n$&apos;s and $30%$ of its output labels $y$ to be positive. Which of the following is not true?</span><br><span class="line"></span><br><span class="line">a. PLA will halt after enough iterations.</span><br><span class="line"></span><br><span class="line">b. $E_&#123;out&#125; = 0.7$</span><br><span class="line"></span><br><span class="line">c. $E_&#123;in&#125; = 0.7$</span><br><span class="line"></span><br><span class="line">d. All $\mathbf&#123;Z&#125;_n$&apos;s are orthogonal to each other.</span><br><span class="line"></span><br><span class="line">e. The transformed data set is always linearly separable in the $\mathcal&#123;Z&#125;$ space.</span><br><span class="line"></span><br><span class="line">要明白这个题目首先要读懂题意。</span><br><span class="line">题目中对原来的向量进行了特征转换，原来向量为d维，新的向量为N维，每一个样本对应的新的Z向量是 $[ [[x_i = x_1]], [[x_i = x_2]],...,[[x_i = x_n]]]^T$,题目中已经告知，$X_n$是各不相同的，因此我们可以直到$Z$向量会类似于：$[1,0,...,0]^T,[0,1,...,0]^T,...,[0,0,...,1]$.在这样的样本上进行PLA算法。我们可以知道这种情况是最好的情况，是可以被shatter的，PLA一定会停止，而且他们是互相正交的。因此答案就在b，c中选择。而既然PLA会停止说明找到了最小的$E_&#123;in&#125;$，此时$E_&#123;in&#125;$为0.因此答案选c.</span><br><span class="line"></span><br><span class="line">至于c为何是正确的，首先，因为测试集的样本与原来的训练集样本也没有一致的，因此他们得到的转换后的z向量为n维0向量.而题目中说明了$sign(0)=+1$，因此它会将所有的测试样本都判别为positive，而实际上只有30%为positive，因此测试得到的$E_&#123;out&#125;$为70%.</span><br><span class="line"></span><br><span class="line">For Questions 13-15, consider the target function:</span><br><span class="line">$$</span><br><span class="line">f(x_1, x_2) = \mbox&#123;sign&#125;(x_1^2 + x_2^2 - 0.6)</span><br><span class="line">$$</span><br><span class="line"></span><br><span class="line">**13. Generate a training set of N = 1000N=1000 points on $X=[−1,1]$ with uniform probability of picking each $\mathbf&#123;x&#125; \in \mathcal&#123;X&#125;$. Generate simulated noise by flipping the sign of the output in a random $10\%$ subset of the generated training set.**</span><br><span class="line"></span><br><span class="line">Carry out Linear Regression without transformation, i.e., with feature vector:</span><br><span class="line">$$</span><br><span class="line">(1,x_1,x_2)</span><br><span class="line">$$</span><br><span class="line"></span><br><span class="line">to find the weight $\mathbf&#123;w&#125;_&#123;\rm lin&#125;$, and use $\mathbf&#123;w&#125;_&#123;\rm lin&#125;$ directly for classification. What is the closest value to the classification $(0/1)$ in-sample error ($E_&#123;\rm in&#125;$)? Run the experiment $1000$ times and take the average $E_&#123;\rm in&#125;$ in order to reduce variation in your results.</span><br><span class="line"></span><br><span class="line">a. 0.1</span><br><span class="line"></span><br><span class="line">b. 0.3</span><br><span class="line"></span><br><span class="line">c. 0.5</span><br><span class="line"></span><br><span class="line">d. 0.7</span><br><span class="line"></span><br><span class="line">e. 0.9</span><br><span class="line"></span><br><span class="line">这次作业与之前不一样了，很早就遇到编程题目了，而且前面有几道题目虽然不是编程题目，我也依然是用程序计算出来的。</span><br><span class="line"></span><br><span class="line">这个题目想要用程序解答其实也不是非常难。在这里我使用的是一步求法，而不是梯度下降那样迭代。首先是要生成数据：</span><br><span class="line">```py</span><br><span class="line">def make_data():</span><br><span class="line">    result = []</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        x1 = random.random()*2-1</span><br><span class="line">        x2 = random.random()*2-1</span><br><span class="line">        result.append([x1,x2,sign(pow(x1,2)+pow(x2,2)-0.6)])</span><br><span class="line">    return result</span><br></pre></td></tr></table></figure></p><p>为了检查做的数据是否正确，对生成的数据进行了可视化（因为输出长宽比例不同，所以这个圆看上去不是正圆）：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(data,W=[])</span>:</span></span><br><span class="line">    nx = []</span><br><span class="line">    ny = []</span><br><span class="line">    ox = []</span><br><span class="line">    oy = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> data[i][<span class="number">-1</span>] == <span class="number">-1</span>:</span><br><span class="line">            nx.append(data[i][<span class="number">1</span>])</span><br><span class="line">            ny.append(data[i][<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ox.append(data[i][<span class="number">1</span>])</span><br><span class="line">            oy.append(data[i][<span class="number">2</span>])</span><br><span class="line">    plt.scatter(nx,ny,marker=<span class="string">"x"</span>,c=<span class="string">"r"</span>)</span><br><span class="line">    plt.scatter(ox,oy,marker=<span class="string">"o"</span>,c=<span class="string">"g"</span>)</span><br><span class="line">    theta = np.linspace(<span class="number">0</span>, <span class="number">2</span> * np.pi, <span class="number">800</span>)</span><br><span class="line">    x, y = np.cos(theta) * <span class="number">0.77459666924148</span>, np.sin(theta) * <span class="number">0.77459666924148</span><span class="comment"># sqrt 0.6</span></span><br><span class="line">    plt.plot(x, y, color=<span class="string">'blue'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(W)!=<span class="number">0</span>:</span><br><span class="line">        print(W)</span><br><span class="line">        x = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">50</span>)</span><br><span class="line">        y = -W[<span class="number">1</span>] / W[<span class="number">2</span>] * x - W[<span class="number">0</span>] / W[<span class="number">2</span>]</span><br><span class="line">        plt.plot(x, y, color=<span class="string">"black"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/RE%40%60F%29JRPQT_KE%7EFIVEC17K.png" alt="生成数据"></p><p>然后通过线性回归得到$W = (X^TX)^{-1}X^TY$:<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_regression_one_step</span><span class="params">(data)</span>:</span></span><br><span class="line">    X_matrix = []</span><br><span class="line">    Y_matrix = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        temp = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data[i])<span class="number">-1</span>):</span><br><span class="line">            temp.append(data[i][j])</span><br><span class="line">        X_matrix.append(temp)</span><br><span class="line">        Y_matrix.append([data[i][<span class="number">-1</span>]])</span><br><span class="line">    X = np.mat(X_matrix)</span><br><span class="line">    Y = np.mat(Y_matrix)</span><br><span class="line"></span><br><span class="line">    W = (X.T*X).I*X.T*Y</span><br><span class="line">    <span class="keyword">return</span> W.T.tolist()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p><p>最后通过分类计算$E_{in}$：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Ein</span><span class="params">(data,W)</span>:</span></span><br><span class="line">    err_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(W)):</span><br><span class="line">            res += W[j]*data[i][j]</span><br><span class="line">        <span class="keyword">if</span> sign(res) != data[i][<span class="number">-1</span>]:</span><br><span class="line">            err_num+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> err_num</span><br></pre></td></tr></table></figure></p><p>运行1000次取输出为：<code>0.50614</code></p><p>因此答案选c.其实我们也可以想象得到这个错误率是接近0.5的，可视化的结果如下：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/_%7BA%60P%28N%255%7B4U8%25%25NQ%24H%408O9.png" alt=""></p><p>不管怎么画这条线，总会有接近一半的区域被分错.</p><p><strong>14. Now, transform the training data into the following nonlinear feature vector:$(1,x_1,x_2,x_1x_2,x_1^2,x_2^2)$.Find the vector $\tilde{\mathbf{w}}$ that corresponds to the solution of Linear Regression, and take it for classification. Which of the following hypotheses is closest to the one you find using Linear Regression on the transformed input? Closest here means agrees the most with your hypothesis (has the most probability of agreeing on a randomly selected point).</strong></p><p>a. $g(x_1,x_2) = sign(-1-1.5x_1+0.08x_2+0.13x_1x_2+0.05x_1^2+1.5x_2^2)$</p><p>b. $g(x_1,x_2) = sign(-1-1.5x_1+0.08x_2+0.13x_1x_2+0.05x_1^2+0.05x_2^2)$</p><p>c. $g(x_1,x_2) = sign(-1-0.05x_1+0.08x_2+0.13x_1x_2+1.5x_1^2+15x_2^2)$</p><p>d. $g(x_1,x_2) = sign(-1-0.05x_1+0.08x_2+0.13x_1x_2+1.5x_1^2+1.5x_2^2)$</p><p>e. $g(x_1,x_2) = sign(-1-0.05x_1+0.08x_2+0.13x_1x_2+15x_1^2+1.5x_2^2)$</p><p>经过特征转换后进行线性回归，找到最相似的W向量。实际上，每次输出的向量不容易看出来他们的相似性，最好的办法就是从z空间转回去看实际的分类效果。<br>为了完成这道题目，需要添加一些新的函数。首先是一个特征转换的函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform_data</span><span class="params">(data)</span>:</span></span><br><span class="line">    t_data = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        temp = [<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        temp.append(data[i][<span class="number">1</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">2</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">1</span>]*data[i][<span class="number">2</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">1</span>]*data[i][<span class="number">1</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">2</span>]*data[i][<span class="number">2</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">-1</span>])</span><br><span class="line">        t_data.append(temp)</span><br><span class="line">    <span class="keyword">return</span> t_data</span><br></pre></td></tr></table></figure></p><p>另外，我重新写了一个可视化的函数，来画出学习后分类的结果，并且与原始的界限做对比。实际上，如果不通过可视化，单单从W向量我们不是很容易能看出来他们之间的相似度，如：</p><script type="math/tex; mode=display">W = [-1.233493970901365, 0.0289716107001069, -0.04249028735529122, -0.06563216707578017, 1.8906604891218894, 2.014485177474217]</script><p>得到的分类效果如下：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%24NF51V%5BFC0ELUWH8QXJ%7D%5BDE.png" alt=""></p><p>而其他几个选项按照a,b,c,d,e的顺序分别得到下面的分类效果：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/XZSCVFU97%28EH4V5%29X%5DDT%7E70.png" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/V%28%7D%7BZ%5BQ2L%402145%5D%7D%5D9FW%7E_B.png" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/R67TAG1%7BEXKD2%406Y_WS%28SZA.png" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%5BI13AGR586%24DR9%5BG3%5D038%40F.png" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/2HM1%5D84NO9J%29%7BUA%7DNI%7E2%5D90.png" alt=""></p><p>可以很明显的看出来，答案选择d.</p><p><strong>15. Following Question 14, what is the closest value to the classification out-of-sample error $E_{\rm out}$ of your hypothesis? Estimate it by generating a new set of 1000 points and adding noise as before. Average over 1000 runs to reduce the variation in your results.</strong></p><p>a. 0.1</p><p>b. 0.3</p><p>c. 0.5</p><p>d. 0.7</p><p>e. 0.9</p><p>这道题目需要来测量$E_{out}$，并且要加上噪声。其实还是很简单的，只需要做简单的改动，来计算$E_{out}$.</p><p>既然是$E_{out}$，那就需要每次都重新生成数据，这就是和$E_{in}$的区别，再加个转换，除此之外是一样的，因此可以复用$E_{in}$函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Eout</span><span class="params">(W)</span>:</span></span><br><span class="line">    data = make_data()</span><br><span class="line">    t_data = transform_data(data)</span><br><span class="line">    <span class="keyword">return</span> Ein(t_data,W)</span><br></pre></td></tr></table></figure></p><p>然后运行1000次就可以了，最后得到的错误率：<code>0.126856</code>,答案选a.</p><p>For Questions 16-17, you will derive an algorithm for the multinomial (multiclass) logistic regression model.<br><strong>16. For a $K$-class classification problem, we will denote the output space $\mathcal{Y} = \{1, 2, \ldots, K\}$. The hypotheses considered by the model are indexed by a list of weight vectors $(\mathbf{w}_1, \mathbf{w}_2, \ldots, \mathbf{w}_K)$, each weight vector of length $d+1$. Each list represents a hypothesis</strong></p><script type="math/tex; mode=display">h_y( X) = \frac {e^{W_y^TX}} {\sum _{k=1} ^{K} e^{W_k^TX}}</script><p>that can be used to approximate the target distribution $P(y|\mathbf{x})$P. The model then seeks for the maximum likelihood solution over all such hypotheses.(Note:$X$ = $\mathbf{x}$)</p><p>For general $K$, derive an $E_{\text{in}}(\mathbf{w}_1, \cdots, \mathbf{w}_K)$ like page 11 of Lecture 10 slides by minimizing the negative log likelihood. What is the resulting $E_{\text{in}}$?</p><p>a. \frac 1 N \sum _{n = 1}^N \left ( \sum _{k=1} ^K (W_k^TX_n - W_{y_n}^TX_n)\right)</p><p>b. \frac 1 N \sum _{n = 1}^N \left  (\sum _{k=1} ^K W_k^TX_n - W_{y_n}^TX_n\right)</p><p>c. \frac 1 N \sum _{n = 1}^N \left ( \ln (\sum _{k=1} ^K e^{W_k^TX_n}) - W_{y_n}^TX_n\right)</p><p>d. none of the other choices</p><p>e. \frac 1 N \sum _{n = 1}^N \left ( \ln (\sum _{k=1} ^K e^{W_k^TX_n} - e^{W_{y_n}^TX_n})\right)</p><p>这是一个很有意思的概率的定义，它保证了分到各个分类的概率和加起来为1，而之前的假设是不能保证这个问题的。</p><p>对于$E_{in}$的处理，也是一致的。按照之前的想法来一步一步做。首先，计算出在该$W$的情况下，出现当前分类的概率，可以知道的是互相连乘，最后为了让他变成加法，以及最小化（而非最大化），需要加一个负号，忽略P(X=X_i)。</p><p>可以得到下面的过程：</p><script type="math/tex; mode=display">\prod_{i=n}^{N} \frac {e^{W_{y_n}^TX_{n}}} {\sum _{k=1} ^{K} e^{W_k^TX_n}}</script><script type="math/tex; mode=display">=> -\sum_{n = 1}^N( \ln (e^{W_{y_n}^TX_n}) - \ln (\sum _{k = 1}^K e^{W_{k}^TX_n}))</script><script type="math/tex; mode=display">  =>\sum _{n = 1}^N \left ( \ln (\sum _{k=1} ^K e^{W_k^TX_n} - W_{y_n}^TX_n)\right)</script><p>最后除以N，得到选项c.</p><p><strong>17. For the $E_{\text{in}}$ derived above, its gradient $\nabla E_{\text{in}}$ can be represented by $\left(\frac{\partial E_{\text{in}}}{\partial\mathbf{w}_1}, \frac{\partial E_{\text{in}}}{\partial\mathbf{w}_2}, \cdots, \frac{\partial E_{\text{in}}}{\partial\mathbf{w}_K}\right)$, write down $\frac{\partial E_{\text{in}}}{\partial\mathbf{w}_i}$ .</strong></p><p>a. \frac 1 N \sum _{n=1}^N \left(\sum _{i = 1} ^K(e^{W_i^TX_n} - [[y_n=i]])X_n\right)</p><p>b. \frac 1 N \sum_{n=1}^N ((h_i(x_n)-1)x_n)</p><p>c. none of the other choices</p><p>d. \frac 1 N \sum _{n=1}^N \left((h_i(x_n) - [[y_n=i]])X_n\right)</p><p>e. \frac 1 N \sum _{n=1}^N \left( \sum _(i = 1)^K(e^{W_i^TX_n}-1)X_n\right)</p><p>这个题目就是对上面的题目的选择结果进行求导即可。虽然比较复杂，但是不算难。一步步算下来就成，正确答案是d.</p><p>For Questions 18-20, you will play with logistic regression. Please use the following set for training:</p><p><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw3_train.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw3_train.dat</a></p><p>and the following set for testing:</p><p><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw3_test.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw3_test.dat</a></p><p><strong>18. Implement the fixed learning rate gradient descent algorithm for logistic regression. Run the algorithm with $\eta = 0.001$ and $T = 2000$. What is $E_{out}(g)$ from your algorithm, evaluated using the $0/1$ error on the test set?</strong></p><p>a. 0.475</p><p>b. 0.412</p><p>c. 0.322</p><p>d. 0.220</p><p>e. 0.103</p><p><strong>19. Implement the fixed learning rate gradient descent algorithm for logistic regression. Run the algorithm with $\eta = 0.01$ and $T = 2000$. What is $E_{out}(g)$ from your algorithm, evaluated using the $0/1$ error on the test set?</strong></p><p>a. 0.475</p><p>b. 0.412</p><p>c. 0.322</p><p>d. 0.220</p><p>e. 0.103</p><p><strong>20. Implement the fixed learning rate stochastic gradient descent algorithm for logistic regression. Instead of randomly choosing nn in each iteration, please simply pick the example with the cyclic order $n = 1, 2, \ldots, N, 1, 2, \ldots$,Run the algorithm with $\eta = 0.001$ and $T = 2000$. What is $E_{out}(g)$ from your algorithm, evaluated using the $0/1$ error on the test set?</strong></p><p>a. 0.475</p><p>b. 0.412</p><p>c. 0.322</p><p>d. 0.220</p><p>e. 0.103</p><p>这3道题目，可以用一套方法做出来，可以引用第7题的程序中的梯度下降算法与13题程序中的对于$E_{in}$的估计。当然，对于之前代码的还需要进行一丝修改。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gradient_decent_7 <span class="keyword">as</span> gd</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> _linear_regression_13 <span class="keyword">as</span> lr</span><br><span class="line">now = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+math.exp(-x))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_logistic_gradient</span><span class="params">(lastW,data)</span>:</span></span><br><span class="line">    W = np.mat([lastW]).T</span><br><span class="line">    X = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        temp = data[i][<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">        temp.append(<span class="number">1</span>)</span><br><span class="line">        X.append(np.mat([temp]).T)</span><br><span class="line">    gra = logistic(-data[<span class="number">0</span>][<span class="number">-1</span>]*(W.T*X[<span class="number">0</span>])[<span class="number">0</span>][<span class="number">0</span>])*(-data[<span class="number">0</span>][<span class="number">-1</span>]*X[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(data)):</span><br><span class="line">        gra = gra + logistic(-data[i][<span class="number">-1</span>]*(W.T*X[i])[<span class="number">0</span>][<span class="number">0</span>])*(-data[i][<span class="number">-1</span>]*X[i])</span><br><span class="line">    <span class="comment">#print(gra)</span></span><br><span class="line">    <span class="keyword">return</span> ((<span class="number">1</span>/len(data))*gra).T.tolist()[<span class="number">0</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stochastic_gradient_init</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span>  now</span><br><span class="line">    now = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stochastic_gradient</span><span class="params">(lastW,data)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> now</span><br><span class="line">    <span class="keyword">if</span> now == len(data):</span><br><span class="line">        now = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    W = np.mat([lastW]).T</span><br><span class="line">    temp = data[now][<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">    temp.append(<span class="number">1</span>)</span><br><span class="line">    X = np.mat([temp]).T</span><br><span class="line">    gra = logistic(-data[now][<span class="number">-1</span>]*(W.T*X)[<span class="number">0</span>][<span class="number">0</span>])*(-data[now][<span class="number">-1</span>]*X)</span><br><span class="line">    now += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> gra.T.tolist()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataFrom</span><span class="params">(filename)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    separator = re.compile(<span class="string">'\t|\b| |\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(filename,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline()[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">        <span class="comment">#print(line)</span></span><br><span class="line">        <span class="keyword">while</span> line:</span><br><span class="line">            temp = separator.split(line)</span><br><span class="line">            <span class="comment">#print(temp)</span></span><br><span class="line"></span><br><span class="line">            abc = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> temp]</span><br><span class="line">            <span class="comment">#print(abc)</span></span><br><span class="line">            result.append(abc)</span><br><span class="line">            <span class="comment">#print(result)</span></span><br><span class="line">            line = f.readline()[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p><p>上面展示了5个函数，第一个logistic函数就是为了计算logistic函数的值，然后分别有两个计算梯度的函数，为了可以复用之前的代码，采用了一样的形式，不过值得注意的是多增加了一个data参数，这是之前没有的。为了实现题目中要求的顺序采取一个样本来做修正，使用了一个全局变量来记录当前的样本索引，同时有一个初始化函数，可以让样本索引归零。</p><p>还有一个readDataFrom不用多说，根据资料的输入形式进行适当调整。</p><p>最后在主函数中整合输出结果：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    data = readDataFrom(<span class="string">"./hw3_train.dat"</span>)</span><br><span class="line">    start = [<span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,len(data[<span class="number">0</span>]))]</span><br><span class="line">    i_times = <span class="number">2000</span></span><br><span class="line">    stochastic_gradient_init()</span><br><span class="line">    W1 = gd.gradient_decent(start,get_logistic_gradient,<span class="number">0.001</span>,i_times,data)</span><br><span class="line">    W2 = gd.gradient_decent(start,get_logistic_gradient,<span class="number">0.01</span>,i_times,data)</span><br><span class="line">    W3 = gd.gradient_decent(start,stochastic_gradient,<span class="number">0.001</span>,i_times,data)</span><br><span class="line">    err1 = lr.Ein(data,W1)</span><br><span class="line">    err2 = lr.Ein(data,W2)</span><br><span class="line">    err3 = lr.Ein(data,W3)</span><br><span class="line">    out_data = readDataFrom(<span class="string">"./hw3_test.dat"</span>)</span><br><span class="line">    err_out1 = lr.Ein(out_data,W1)</span><br><span class="line">    err_out2 = lr.Ein(out_data,W2)</span><br><span class="line">    err_out3 = lr.Ein(out_data,W3)</span><br><span class="line">    print(<span class="string">"Ein:"</span>,err1,err1/len(data),err2,err2/len(data),err3,err3/len(data))</span><br><span class="line">    print(<span class="string">"Eout:"</span>,err_out1,err_out1/len(out_data),err_out2,err_out2/len(out_data),err_out3,err_out3/len(out_data))</span><br></pre></td></tr></table></figure></p><p>我将起始的W设定为0向量，不同的起始向量可能得到不同的性能。</p><p>最后的结果，分别是3道题目的${E_in}$与$E_{out}$.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ein: 430 0.43 204 0.204 427 0.427</span><br><span class="line">Eout: 1354 0.4513333333333333 678 0.226 1352 0.45066666666666666</span><br></pre></td></tr></table></figure><p>因此我认为答案是a,d,a. 可以看到学习率过低的话可能会使得下降速度过慢，而且随机梯度下降的性能有时候不见得比普通的梯度下降差，但是速度却大大提高。</p><p>将迭代次数更新为10000，3个学习方法都取得了不错的效果，而步长大的性能反而不如之前，说明因为步长过大，它只能再最低点徘徊很难取得更低的位置，而步长小的依然没有达到极限：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ein: 236 0.236 206 0.206 235 0.235</span><br><span class="line">Eout: 779 0.25966666666666666 695 0.23166666666666666 776 0.25866666666666666</span><br></pre></td></tr></table></figure></p><h2 id="p-s"><a href="#p-s" class="headerlink" title="p.s."></a>p.s.</h2><p>1.python中的全局变量，list为引用，而赋值一个常数则会重新声明，为了避免歧义。因此想要改变全局变量的常数，需要添加关键词global。</p><p>2.牛顿方向与海森矩阵。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Nonlinear Transformation</title>
      <link href="/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Nonlinear-Transformation/"/>
      <url>/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Nonlinear-Transformation/</url>
      
        <content type="html"><![CDATA[<p>之前我们学习的所有模型，都是linear model。我们做的都是用一条直线（或者平面等）来分类，或者拟合，或者是通过该直线来预测概率。但是现实中很多时候线性不一定能做得很好。<a id="more"></a>如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/5%4014N%288G7K0JNSKXZF%29DU_7.png" alt=""></p><p>似乎用一个圆，能更好地对这些样本进行分类。实际上，上图的分类的依据是：</p><script type="math/tex; mode=display">h(X) = sign(0.6-x_1^2-x_2^2)</script><p>因此，这样我们就引入了二次假设（quadratic）。<br>在上式中，如果我们令$z_0 = x_0 = 1, z_1 = x_1^2 ,z_2 = x_2^2$，那么就发现，实际上上面中对于$x$的二次假设实际上转换为了对$Z$的线性假设。一个样本在x空间上是很难线性分割的，无论怎样都不能得到较好的$E_{in}$，但是展开到z空间上也许就是线性可分的了。</p><p>因此怎么做实际上很简单，之前的训练集是$D$，我们通过展开到z空间来得到训练集$D’$，用训练集来进行之前的用于线性模型的训练。</p><p>通过这个，我们仿佛进入了新世界：我们可以任意来构建多项式(特征转换)，达到非线性学习的结果。</p><p>但是世界上不会天上掉馅饼。我们知道不会有这么白白的好事发生。既然多项式这么强大，它必然会付出更多的代价，下面我们来简单说明下它的price。</p><p>假如原始特征有d个，我们构建的是最高次为Q的Q次多项式($Q \leq d$)。那么，构造的新的样本集会有多少个维度？</p><script type="math/tex; mode=display">\Phi _Q(X) = \left ( \begin{matrix}     1,\\    x_1,x_2,...,x_d,\\    x_1^2,x_1x_2,...,x_d^2,\\    ...,\\    x_1^Q,x_1^{Q-1}x_2,...,x_d^Q\\        \end{matrix}   \right )</script><p>假如我们乘转换后的维度是$\overline d$，则 $\overline d = C_{Q+d}^d-1 =&gt;O(Q^d)$(如何得到这个值需要排列组合知识，在此处知道即可).</p><p>这意味着$\overline W$是（$1+\overline d$）维的向量，而转换后的$vc dimension \leq \overline d+1$(之前的VC bound中证明过了二元分类维度为d的时候，vc dimension为d+1).vc dimension可能会增加很多，也就意味着我们需要非常多的资料可能才能得到较好的准确度，同时也会极大地增加存储空间，以及算法的学习速度。</p><p>我们列出次数为1-Q时候的维度如下：</p><script type="math/tex; mode=display">\Phi _0(x) = (1)</script><script type="math/tex; mode=display">\Phi _1(x) = (\Phi _0(x) , x_1,x_2,...,x_d)</script><script type="math/tex; mode=display">\Phi _2(x) = (\Phi _1(x) , x_1^2,x_1x_2,...,x_d^2)</script><p>…</p><script type="math/tex; mode=display">\Phi _Q(x) = (\Phi _{Q-1}(x),x_1^Q,x_1^{Q-1}x_2,...,x_d^Q)</script><p>因此：我们可以得到：</p><p>$H_0 \subset H_1 \subset H_2 \subset H_3 \subset … \subset H_Q$;</p><p>从而得到：</p><p>$ d_{vc}(H_0) \leq d_{vc}(H_1) \leq d_{vc}(H_2) \leq … \leq d_{vc}(H_Q)$;</p><p>而对于$E_in$来说，不错的消息是$E_{in}$是在不会变大的。因为它最多最好的线与之前一样：</p><p>$ E_{in} (g_0) \geq  E_{in} (g_1) \geq E_{in} (g_2) \geq … \geq E_{in}(g_Q)$;</p><p>更重要的一件事，不知道你是否还记得这个学习曲线：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/M%29P32DW%29EE9%7BWB%246A08T8%29X.png" alt=""></p><p>从上面可以看出来，维度个数增加，$E_{out}$并不是一直下降的，最好的维度个数是在中间某个地方。而$E_{in}$从来就不是我们关注的重点，我们尽可能减少他，是为了得到更好的$E_{out}$,而过分增加维度个数，可能会本末倒置。$E_{out}$才是我们想要的。</p><p>实际中，我们在学习时候应该先从低的维度开始，再慢慢向上增加，直到得到想要的$E_{in}$，往往线性的学习并不像人们想象中的那样效果很差，可能从较低的维度就可以得到较好的结果。如果一开始就用很多的维度，可能直接得到了很好的$E_{in}$，但是泛化能力却很差。</p><p>最后，要注意，有的人说，刚开始举得例子中，如果通过可视化，我们直接用 $s(X) = w_0 + W_1 x_1^2 + W_2x_2 ^2$，这样看起来，似乎维度只有3个，实际上类似的还有$s(x) = w_0 + W_1( x_1^2 + x_2 ^2)$,似乎维度只有两个，甚至是可以降到0个。但是这实际上是人脑学习的过程，我们已经替机器学习了不少，因此最后的泛化结果可能并不是我们想象的那么好，因为真实的代价还是存在的。而且，高纬度的可视化是很难做到的。</p><p>因此，使用多项式并不见得就是好的，我们要结合实际情况来进行学习。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> polynomial </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Multiclass（OVA and OVO）</title>
      <link href="/2018/09/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Multiclass/"/>
      <url>/2018/09/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Multiclass/</url>
      
        <content type="html"><![CDATA[<p>目前，我们对二元分类已经有了不少的了解，可以用多个线性模型去实现二元分类。但是生活中遇到的往往不是是非题，而是选择题，尤其是图像识别问题中，我们往往需要识别多个物体。如何通过之前实现的二元分类，来实现多元分类呢？<br><a id="more"></a><br>这里介绍两种思路，一个是OVA（One Vesus All），另一个是OVO（One Vesus One）。</p><h2 id="OVA-via-Logistic-Regression"><a href="#OVA-via-Logistic-Regression" class="headerlink" title="OVA(via Logistic Regression)"></a>OVA(via Logistic Regression)</h2><p>要想进行多元分类，我们首先想到的是对每一种类型进行是非判断。理想中，这样似乎不错，找个物体，哪一种类型的判断说是，就是该类型，但是现实往往不尽人意。</p><p>假如有下图所示的一个样本集：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/5%7ES9ZBTNV%25J%40NFF1X9ER%29%24Y.png" alt=""></p><p>可以看到一共有四类，分别对每个类型进行是非判断，可以得到下面的4条线来分类：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/K%240%7E%29%7E_4A%25I%60_5B%29B4KOG1X.png" alt=""></p><p>从左至右分别是正方体，菱形，三角形，五角星得到的线。</p><p>融合到原来的图形上：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/56XK%28P%242S%29VUE%7B47%24WLLDH3.png" alt=""></p><p>对于上图中，有几个部分区域的样本可以很明确的判断出来是什么类型，但是其他部分区域，要么是多个类型都说是，要么没有一个类型说是，这就让我们无法进行判断。</p><p>我们很容易想到既然用明确的是非无法进行判断，如果使用概率会不会好一点。因此要使用logistic regression。</p><p>使用logistic regression进行的还是上面的步骤，得到的是是各个类型的概率。选择概率最高的，就可进行分类。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/S%402ZQSW29UEE%7D3X%7B9I0P%60%7ET.png" alt=""></p><p>下面的分类图是利用上述方法进行分类得到的结果，可以看到对每个区域，都能为它制定一个类别。值得注意的是logistic function是单调增函数，因此比较概率的时候我们并不用真的求出来大小，而只用比较$s(X)$的大小即可。</p><p>具体步骤如下：</p><p>(1) for $k \in Y$, obtain W_{[k]} by running logistic regression on $D_{[k]} = \left \{ (X_n,y’_n = 2[y_n = k] - 1) \right\}_{n=1}^N$.<br>(2) return $g(X) = argmax_{k \in y}(W_{[k]}^TX) $</p><p><em>*</em>注：argmax是一种函数，函数y=f(x)，x0= argmax(f(x)) 的意思就是参数x0满足f(x0)为f(x)的最大值；换句话说就是 argmax(f(x))是使得 f(x)取得最大值所对应的变量x。arg即argument，此处意为“自变量”。在上式中为结果为某个k$(k \in y)$。</p><hr><p>上面的方法很简单的就可以实现了多元分类。但是上面的算法有个缺点，一对多，当种类k特别多时候，很容易造成不平衡的情况，一个不好的算法但是却得到了很好的$E_{in}$，影响最后的分类结果。因此希望可以找到一种方法来解决这个问题。</p><h2 id="OVO-via-Binary-Classification"><a href="#OVO-via-Binary-Classification" class="headerlink" title="OVO(via Binary Classification)"></a>OVO(via Binary Classification)</h2><p>OVO是一对一的算法，可以很好的解决上面最后留下来的问题。它的思想是这样的，从k个类别中挑出两种类别来进行学习，每次学习都可以得到一个用来区分的$W$，一共可以得到$C_k^2$种。</p><p>这里得到的$W_i$与上面的办法用途是不一样的，它直接用来做二元分类（+1 or -1），而不是得到一个概率。通过两两组合进行二元分类的学习，我们得到了$C_k^2$个分类器，每个分类器都会对放入的样本进行一个明确的分类。下图是上面的样本集得到的几个分类器：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/A%28PYVE%60M%404EFA73%25S531CMM.png" alt=""></p><p>从左到右，分别是对[菱形，方块]，[三角形，方块],[五角星，方块]，[菱形，三角形]，[菱形，五角星]，[三角形，五角星]进行二元分类。</p><p>进行预测时候，取一个样本，经过6个分类器来预测，6个分类器得到不同的结果，但是每个都会对该样本的类别进行明确的预测，类似于投票，最后我们选择得票最多的类别。</p><p>下图为用OVO分类得到的结果：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/7%28CYH%24KM%5BVTG%7EM%25UL3R%7D28F.png" alt=""></p><p>OVO算法的主要过程如下：</p><p>(1) for ($k,\zeta$) $\in Y \times Y$, obtain $W_{[k,\zeta]}$ by running linear binary classification on $D_{[k,\zeta]} = \left \{ (X_n,y’_n = 2[y_n = k] - 1):y_n = k or y_n = \zeta \right \}$ </p><p>(2) return $g(X) =$ $tournament$ $champion$ $\left \{W^T_{[k,\zeta]}\right \}$</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面就是两种用在多元分类上的算法，他们都是很简单并且非常常见的算法。两个算法运行速度都很快（OVO虽然增加了分类器的个数，但是用来学习的样本量会减少很多）。OVO的缺点是如果类别真的非常大，那么分类器个数可能过多，会占用较大的空间，一定程度上也会影响速度，但是它有较高的稳定性，减少出现不平衡的情况。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> classification </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——linear model for classification</title>
      <link href="/2018/09/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-model-for-classification/"/>
      <url>/2018/09/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-model-for-classification/</url>
      
        <content type="html"><![CDATA[<p>到目前为止，已经学习了3个线性模型了，他们都使用到了$score = W^TX$(后文中简写为$s$)，使用特征间线性组合来打分，通过分数来做后续的处理。<a id="more"></a></p><p>linear regression用于分类前面有一篇博客已经说明，现在我们想要知道，logistic regression 是否也可以用于分类？毕竟线性回归的错误对于二元分类来说是一个很大的上界，这意味着它的效果虽然不差，但可能错失更好的。而PLA找到一个最小的$E_{in}$是NP-hard问题，只能使用改进的POCKET算法。我们希望看到logistic regression用于二元分类可以有更好的表现。</p><p>与之前的步骤一样，逻辑回归中，$E_{in} = \sum_{n = 1}^{N} \ln{1 + e^{-y_nW^TX_n}}$，我们对比的是单个样本的错误，就写作$err_{name}$好了。</p><p>为了让这3种模型都有较为清晰的对比，我们对PLA以及线性回归的错误衡量也做处理，如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">method</th><th style="text-align:center">linear classification</th><th style="text-align:center">linear regression</th><th style="text-align:center">logistic regression</th></tr></thead><tbody><tr><td style="text-align:center"> err</td><td style="text-align:center">$[sign(ys \neq 1)]$</td><td style="text-align:center">$(sy-1)^2$</td><td style="text-align:center">$\ln{1+e^{-ys}}$</td></tr></tbody></table></div><p> 将它们的曲线绘制到一张图上，可以得到下面的结果：<br> <img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/87T%7EV%5DV75N992E1I%5B3M9%5DZK.png" alt=""><br> 其中蓝色是linear classification的错误，红色是linear regression的错误，绿色是logistic regression。坏了，绿色的线并不总是大于蓝色的线，这意味着我们无法像之前一样，简单地将$E_{in}(linear classification)$换成$E_{in}(logistic regression)$。</p><p> 实际上，之前我们选择用$ln$函数是因为这是最常见的，只是将乘法换成加法，理论上我们可以取任何对数，如，将对数函数换为$log_2^x$,就可以得到另外一副曲线图：<br> <img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/CCO%29%25RV4OG9Z8%7D60%40%404W6G0.png" alt=""></p><p> 这样就可以满足我们的需要，也方便下面的证明。<br>我们称使用$ln(x)$函数的错误为$err_{ce}$，使用$log_2(x)$的为$err_{sce}$，则由上图可以知道：</p><p>$err_{0/1}(s,y) \leq err_{sce}(s,y) = \frac 1 {\ln2} err_{ce}(s,y)$，<br>（由换底公式：$\frac {\ln x}{\ln2} = log_2x ）<br>也就可以知道：</p><script type="math/tex; mode=display">E_{in}^{0/1} \leq E_{in}^{sce} = \frac 1 {\ln2} E_{in}^{ce}</script><p>同样的道理：</p><script type="math/tex; mode=display">E_{out}^{0/1} \leq E_{out}^{sce} = \frac 1 {\ln2} E_{out}^{ce}</script><p>因此，我们可以像之前一样推导：</p><script type="math/tex; mode=display">E_{out}^{0/1} \leq E_{in}^{0/1}+ \Omega ^{0/1} \leq \frac 1 {\ln2} E_{in}^{ce}+\Omega ^{0/1}</script><p>同样，从另一个方向也可以推导：</p><script type="math/tex; mode=display">E_{out}^{0/1} \leq \frac 1 {\ln{2}} E_{out}^{ce} \leq \frac 1 {\ln2} E_{in}^{ce}+\Omega ^{ce}</script><p>无论哪个，都可以证明，logistic regression是可以用于二元分类的。而上面的图像也说明了，他的效果比线性回归更好，bound更紧一点。</p><p>在实际应用中，我们使用linear regression来初始化$W$，然后通过POCKET或者logistic regression来进行后面的步骤，而且logistic regression更为常用。</p><p><strong><em>注：上面推导中，判断都是以s=0为界定，对应到logistic regression也就是概率为0.5为界定。</em></strong></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> classification </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Gradient Decent</title>
      <link href="/2018/08/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Gradient-Decent/"/>
      <url>/2018/08/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Gradient-Decent/</url>
      
        <content type="html"><![CDATA[<p>Gradient Decent,即梯度下降。梯度下降是机器学习中非常重要的接近最优解的工具。<a id="more"></a>理论上只要得到梯度，就可以使用梯度下降。因此它同样可以用于linear regression，在数据量很大特征很多的情况下，因为矩阵求逆的时间复杂度很大，它往往比之前介绍的linear regression“一步登天”的做法性能更好。</p><p>首先，假设我们已经知道了$E_{in}$的梯度为$\nabla E_{in}$。首先，我们要知道一件事，梯度是所有方向上，“坡度”最陡的方向。梯度下降，使用了贪心的思想：每次都朝着坡度最陡的方向往下走。也许最后得到的不一定是全局最优解，但是一定是一个极小值点，通常也能取得不错的效果。</p><p>所以，有一个起始点为$W_0$，每次向下走一个单位的长度乘上一个未知的$\eta$，用来控制步长。在梯度方向上的单位向量等于$\frac {\nabla E_{in}}{|\nabla E_{in}|}$，当然，我们也可以很容易知道，我们要走的方向应该是梯度的反方向。因为求出来的梯度往往指向的是函数值增加最快的方向，而我们要的是尽可能减少$E_{in}$。所以就可以得到下面的式子：</p><script type="math/tex; mode=display">W_1 = W_0 - \eta \frac {\nabla E_{in}}{|\nabla E_{in}|}</script><p>每次朝着梯度方向走一步，理想中这个函数就会下降一点，因为当走动的距离很小时候，有以下近似式：</p><script type="math/tex; mode=display">E_{in}(W_0+\Delta) \approx E_{in} + \Delta \nabla E_{in} (W_0)</script><p>上式其实是多维函数泰勒展开式（一阶）。</p><p>接下来，就是对$\eta$的选择了。选择$\eta$时候，有下面几种情况：<br>1.$\eta$ 太小。 如果$\eta$很小，那么我们可以保证它最后一定可以走到一个很低的地方，不过速度太慢了。因为每一步步长太小。</p><p>2.$\eta$ 太大。如果$\eta$太大，那么之前的泰勒展开式就不适用，充满了不确定性。有可能一步太长走到对面，运气好的话函数值还在变小，运气不好函数值会增加，因此这样也是不可选的。</p><p>3.如下图，让$\eta$在变化。当梯度很大时候，步子迈的大一点，当梯度小了，意味着距离最低点很近了，步子小一点，谨慎一点走。上面三种情况如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/eta_choice.png" alt=""></p><p>很明显，我们应当选择的是第三种策略。如何控制$\eta$可变？简单的做法就是让$\eta$与$|\nabla E_{in}|$成正比，如果$\eta = \alpha|\nabla E_{in}| $就会抵消了原来式子中的分母部分，最后得到下式：</p><script type="math/tex; mode=display">W_{i+1} = W_i - \eta  {\nabla E_{in}}</script><p>可以看到式子变得更加简洁了。</p><p>上式中的$\eta$成为fixed learning rate，尽管学习率是固定的，但是每一步步长却在改变。当然，对于上式中的$\eta$我们也应该选择合适的值，否则还是会出现上述的两种情况，但是它改进了很多，使得算法效率得到了提升。</p><p>最后，梯度下降什么时候停止？当$\nabla E_{in} \approx 0 $或者进行了足够多次数的迭代之后，我们就应该停止了。因为在计算机中数值上得到一个完全为0的值是很困难的，而约等于0时候，我们就可以取得满意的结果。或者进行了足够多的次数，依然得不到满意的结果，我们需要考虑的是改进算法，是不是学习率值取得不够好等等。</p><p>以上就是梯度下降。</p><p>在这里，另外提到一个叫随机梯度下降（Stochastic Gradient Desent）的算法。上面介绍的梯度下降算法虽然可以很好的找到我们想要的结果，但是在n很大的时候，每次更新都需要进行求和平均，这就导致了算法速度可能受到影响。实际上，它的时间复杂度与POCKET算法是一样的。我们希望可以将复杂度提升到PLA的级别。</p><p>$E_{in}$的定义是对所有点的$err$加起来求平均，在n很大时候，平均值的期望值与随机抽取一个样本的值的期望值是接近的，因此随机梯度下降实际上就是每次随机选取一个点（或者少量点求平均），然后用它的$err$来计算梯度，并进行更正。它类似于PLA算法的步骤:</p><script type="math/tex; mode=display">SGD logistic regression:  W_{t+1} = W_t + \eta  \theta (-y_nW_t^TXn)(y_nX_n)</script><script type="math/tex; mode=display">PLA:W_{t+1} =  W_{t}+[y \neq sign(W_t^TX_n)] (y_nX_n)</script><p>当SGD logistic regression的错误非常离谱，它的更新效果实际上接近于PLA算法。</p><p>这个算法运行什么时候终结？一般来说运行足够长的时间之后或者此时的$E_{in}$已经足够小，我们就认为已经取得了不错的效果。它的优点是速度快，缺点是最终的结果相比于梯度下降还是差了一点。因此它是梯度下降算法的一个改进。</p><p>适用场景：1.n特别大 2.如果本身样本是一个一个来的，而不是一批一批来的，也可以适用这个方法，也就是可以适用于在线学习（online learning）。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——logistic Regression</title>
      <link href="/2018/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94logistic-Regression/"/>
      <url>/2018/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94logistic-Regression/</url>
      
        <content type="html"><![CDATA[<p>通过线性分类，我们预测的是一个样本是positive，还是negative，不过有时候我们并不想要那样明确的结果。<a id="more"></a>有时候，这种情况在医学中更为常见，我们想知道一个样本是正的概率，比如医院中对肿瘤良性与恶性的预测，来决定后续的治疗方式。概率是从0到1的实数，因此对概率的预测依然属于回归而非分类。</p><p>理想中，我们希望样本的样子是这样的：$\{X_1,0.9\},\{x_2,0.2\},\{x_3,0.65\}…$，即对每个样本，都已知它是positive的概率。但是实际上我们往往无法得到这样的结果，我们无法确切知道某个样本是正的概率。我们得到的样本，往往与分类问题的样本一样，对每个样本，知道它是negative，还是positive。不过我们可以假想，得到的训练集是理想情况+噪声造成的：如果是negative，我们可以说它是positive的概率为0，如果是positive，我们称该概率为1。我们希望可以预测出概率。</p><p>首先，有之前的pla与linear regression的基础，很容易想到，使用$WX$去得到预测值。但是预测值虽然是实数，但是因为是概率，所以它的分布仅在于$[0,1]$，因此仅仅使用$WX$是不符合预期的。</p><p>这里，将介绍一种函数叫logistic函数：$f(x) = \frac {1} {1+e^{-x}}$（在数学上这个定义更加严格一点，而此处是logistic函数的一种）.这个函数的图像如下：<br><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png" alt=""></p><p>它满足下面的条件：$\lim_{x \to +\infty} f(x) = 1$ &amp; $\lim_{x \to -\infty} f(x) = 0 $，它的值域是（0，1），这个性质目前很符合我们的期望。</p><p>接下来，我们需要定义的就是$E_{in}$，因为有$E_{in}$我们才能从H种找到一个g，它的$E_{in}$最小。但是$E_{in}$是不能随便定义的。之前的$E_{in}$，都是在找与真正对应的$y$之间的距离，这里我们不知道真正的$y$（也就是概率值），因此我们要换种考虑方法。</p><p>假如有一个理想的函数$f$，能知道样本为positive的真实概率，表示为：$P(y_i=+1|X_i) = f(X_i)$，那么该样本是现在这个样子的概率为：$P(X_i \bigcap y_i = +1) = P(X_i) \times P(y_i=+1|X_i)$，而当$y_i = -1$时，$P(X_i \bigcap y_i = -1) = P(X_i) \times (1-P(y_i=+1|X_i))$，合并两种情况，得到：$P(X_i \bigcap y_i) =\frac {(y_i+1)} 2 P(X_i) \times P(y_i = +1|X_i) +\frac {(1 - y_i)} 2 P(X_i) \times (1 - P(y_i = +1|X_i)) $.各个样本之间是独立的话，那么出现这个样本集的概率等于：$\prod_{i=1}^{n}P(X_i \bigcap y_i)$。</p><p>目前，我们不知道$f$，但是假如我们用$H$中的某个$h$来代替，这就意味着在函数h的情况下，出现这个样本集的概率，当然我们想要做的是令这个概率越大越好。平时处理的$E_{in}$都是和，而这次我们依然希望用和来处理，而不是连乘，因此我们为上式加上一个$\ln$，而因为P(X_i)的概率都是一定的，所以我们无需关注。省掉$P(X_i)$,再进行上面的处理之后变为：<br>$\frac{1}{N} \sum _{i = 1}^{n} \ln {(\frac {(y_i+1)} 2 h(X_i) +\frac {(1 - y_i)} 2 (1 - h(X_i)))}$.</p><p>但是这不符合$E_{in}$，因为我们想要的是$E_{in}$越小越好，而上面的式子是越大越好，因此需要加上一个负号，同时，如果我们使用之前的logistic function作为h，我们可以发现它有一个性质：1 - h(x) = h(-x)，因此,可以得到下面的式子：</p><script type="math/tex; mode=display">E_{in} = -\frac{1}{n}  \sum _{i = 1}^{n} \ln {(\frac {(y_i+1)} 2 h(X_i) +\frac {(1 - y_i)} 2 (1 - h(X_i)))} = -\sum _{i = 1}^{n} \ln h(y_iX_i).</script><p>将logistic function 带入上式：</p><script type="math/tex; mode=display">E_{in} =\frac{1}{n}  \sum _{i = 1}^{n} \ln(1+e^{-y_iW^TX_i})</script><p>从上式可以看出来，如果$y_i = 1$，而预测它为1的概率小于0.5（$W^TX_i&lt;0$），那么$E_{in}$的值会大于$ln2$，而$E_{in}$是没有上界的。错的越离谱，惩罚就越大。</p><p>接下来的问题，就是如何让$E_{in}$取到最小了。</p><p>首先，可以证明的是，这个$E_{in}$也是一个凸函数（证明办法需要用到更深入的线性代数知识），因此我们可以找到一个最小值。和线性回归时候遇到的情况一样，要得到极值点，就要找到梯度为0的点。因此首先要得到的是$E_{in}$的梯度。从微积分里，我们知道梯度的求法，也就是对每个方向求偏导，由它们组成的向量。为了得到梯度，我们首先应该求出$E_{in}$对每个$w_i$的偏导数，对于偏导数的求法在微积分中课程中我们也学习过，可以得到下面的结果：</p><script type="math/tex; mode=display">\frac {dE_{in}} {d{w_i}} =\frac{1}{N}  \sum _{n = 1}^N \frac {e^{-y_nW^TX_n} \times ( -y_nx_{n,i})} {1+e^{-y_nW^TX_n}}</script><p>注意：上式中为了方便，我们用$N$替代了之前的$n$，用$n$替代了$i$，并且用$i$代表了$W$向量中维度序列。</p><p>如果对上式向量化，我们可以得到 $\nabla E_{in}(\mathbf{w}) = \frac{1}{N} \sum\limits_{n=1}^N {\theta\left({-y_n \mathbf{w}^T \mathbf{x}_n}\right)} {\bigl(-y_n \mathbf{x}_n\bigr)}$. </p><p>上式中，$\theta(x) = \frac {1} {1+e^{-x}}$.</p><p>由此，我们求到了$E_{in}$的梯度。为了让这个梯度为0，首先我们想到的是，所有的$\theta\left({-y_n \mathbf{w}^T \mathbf{x}_n}\right)$等于0，这要求所有的$y_nW^TX_n$都是远大于0，这意味着原来的数据是线性可分的。</p><p>如果不是这种情况，原来的数据则不是线性可分（大多数情况下我们的数据都不是这么理想），想使得最终结果为0，那么各个数据是加权加起来最后得0.那么我们希望可以像线性回归一样通过某种表达式直接求得一个解，不过遗憾的是这个函数不是线性函数，我们没有办法一下求得这个解。我们能做的只能是步步逼近，类似于之前的PLA算法。</p><p>这就要介绍一个方法，叫<strong>梯度下降</strong>（gradient decent）。</p><p>梯度下降具体内容查看：<a href="https://wlsdzyzl.top/2018/08/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Gradient-Decent/" target="_blank" rel="noopener">Gradient Decent</a>。</p><p>通过梯度下降，我们可以找到一个合适的$W$，从而得到较好的逻辑回归效果。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>新生活——有点想回去</title>
      <link href="/2018/08/29/%E6%96%B0%E7%94%9F%E6%B4%BB%E2%80%94%E2%80%94%E6%9C%89%E7%82%B9%E6%83%B3%E5%9B%9E%E5%8E%BB/"/>
      <url>/2018/08/29/%E6%96%B0%E7%94%9F%E6%B4%BB%E2%80%94%E2%80%94%E6%9C%89%E7%82%B9%E6%83%B3%E5%9B%9E%E5%8E%BB/</url>
      
        <content type="html"><![CDATA[<p>27号，我坐上远离家乡的飞机，不过两个半小时，我就来到了深圳————这里，距离我的家，有1700多公里，距离太原，有2000公里。<a id="more"></a></p><p>我感慨飞机的速度真是快，实际上我还希望它能慢一点。我不想这么快就来。可是即使选择火车，该来还是要来，只不过路上更加折腾了。</p><p>现在距离我到深圳已经过了两天了，我还不是很适应这里的生活。我说不清楚心里什么滋味，也说不清楚到底为什么会有这种滋味。好像是有点麻木，对新的生活不是很期待。</p><p>一直以来，我都不是个擅长适应新环境的人，每次去结交新的朋友，我的心里都是在逼自己。初中和小学，我已经记不得了，到了高中，我记得我第一次坐座位和男神胡做同桌，而且还是上下铺。我说我喜欢打篮球，胡子说去斗牛，实际上我打的很烂。大学，我给杨龙炫耀我的海贼王情侣装，龙哥拿出来海绵宝宝情侣装，同时扔给我一堆情趣用品。我不擅长交朋友，但是我的心里有杆秤。对任何我觉得有兴趣的人，我的心里就像一个程序，不断执行：我先找他（她）d次，d次找完，他（她）仍然没有找过我，我自己就不再去找；如果对方主动找我了，次数重新刷新为d。对于60%的同学，d = 0，对于39%的同学，d = 1,对于1%的同学，d还会更大一点。我的心里没有刻意算计过这些东西，我只是用这个程序去模拟了我的内心。</p><p>这意味着我的社交圈是非常小的，毕竟我不是什么出众的人，谁会闲着没事找我。实际也确实是这样，现在高中还联系的朋友也就5，6个，大学说话的也只有几个室友和社团的朋友了。社团的朋友是非常热心的，再加上志同道合，我们关系非常好。</p><p>现在上着研究生，我还没交下什么朋友。</p><p>不是研究生的同学不友好，今天下大雨我没带伞，有热心肠的同学与我分享他的雨伞，最后我们都被淋湿。我也加了很多好友，有一个同学介绍的时候说曾经参军当过排长，我很羡慕这种经历，也想和他交流。有几个国外来的留学生，或者是华人或者是意大利新西兰，我也蛮想了解那些国外的生活，还有一些健身房大佬，我也想去健身房练练硬件，并向他们介绍跑酷与街健。今天自我介绍的时候，我还担心我说我喜欢跑酷，大家会哇，让我去露一手，露一手是不可能去露一手的，不过我想好了怎么推辞：跑酷是室外运动，而且我2个月没练了，在这么多人面前我紧张，怕出现危险……不过我介绍完之后，没什么人对我，以及我的跑酷展现出太大兴趣。之前的担心，变得稍微有些伤心。</p><p>就像我的自我介绍平淡无奇，我加了那些我有兴趣交朋友的同学作为好友后，也就没再联系。</p><p>似乎成年人，大家都把自己封闭了起来。况且我宿舍还没有同学在。我一个人与学长住，得到这个消息，我还有点兴奋。我享受独处的时光，比如现在我码这篇博客，没有人会在我身后看，我就不会不自在。</p><p>晚上有个心理讲座，我觉得我的心理可能有点问题，所以没去。</p><p>我渴望有个好朋友，我心里没拒绝任何人做我的好朋友，但是我就是主动不起来。和一个人从陌生人，变到知根知底，需要很久。我不想经历这个过程。但是友谊就是从这些过程中积累起来的，真是矛盾。我都想不起来之前的朋友怎么交的了，同处一室不得不交流吧，而且也得看对眼。</p><p>深圳这个雨，下得停不下来，我想下去跑跑步拉拉单杠，都没机会。</p><p>其实为啥会这样，我真说不清。这深圳太远，气候太湿；这同学们太优秀，英文无障碍交流，雅思托福考着当练手，而我六级444；大家喜欢打球，狼人杀，lol，我喜欢parkour，一个人默默打gta；之前有啥情绪藏心里，现在有了没啥人看的博客让我可以随意把矫情的情绪写出来；大家自我介绍临场发挥逗笑全班同学，而在跑酷社被称为“段子手”的我就只说出来了心里默念了几遍的几句：</p><blockquote><p>我叫张国庆，来自山西运城，本科读计算机科学与技术。我本科加入了跑酷社，所以这是我的爱好，但是练了4年，我依然不是很厉害。我还喜欢看电影动漫，画画。谢谢大家。</p></blockquote><p>其实我想说的是：</p><blockquote><p>我喜欢跑酷，曾经获得全国跑酷大赛冠军。当然我还喜欢吹牛。下面是我平时跑酷的视频：（<a href="">这里放上我的跑酷视频</a>）。你们可以加我微信，我跑完会发视频，可以可劲夸我帅。我还喜欢画画，你看我画的这些，（<a href="">这里放上我画的画</a>）虽然比不上专业的，但是糊弄糊弄普通人还是够了吧！是不是很惊艳，我甚至都没学过。我非常喜欢漫威，动漫喜欢海贼王，进击的巨人，还有龙珠。</p></blockquote><p>不过这些话，如果不熟我是说不出口的。</p><p>所以我有点想回去，我多年的朋友在那边，我最爱的人在那边，我的家在那边。  </p>]]></content>
      
      
      <categories>
          
          <category> 灌水 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> casual note </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——linear regression与linear classification</title>
      <link href="/2018/08/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression%E4%B8%8Elinear-classification/"/>
      <url>/2018/08/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression%E4%B8%8Elinear-classification/</url>
      
        <content type="html"><![CDATA[<p>上一篇博客介绍了线性回归模型，但是不知道大家是否有这样的感觉：它与之前的PLA算法似乎有很多类似之处。<br><a id="more"></a><br>这两个算法都在使用线性的方法，也就是它们都是通过$y_n = W^TX_n$来计算出$y_n$，只不过PLA算法通过$y_n$来判断第n个样本的分类，而线性回归直接使用$y_n$来作为它的预测值。</p><p>线性回归中，$y$的值的范围是整个实数，从另一方面想，线性classification的$y$取值只有+1，-1两个取值，这两个值当然也是实数，我们是否能将线性回归算法用作于线性分类中呢？</p><p>要思考这个问题，首先要决定如何将线性回归用于线性分类：对样本集$\{X_n,Y_n\}$利用线性回归来进行学习，得到$W$，然后通过$sign(y’_n)$（其中$y’_n = W^TX_n$）来对该样本进行分类。与PLA的区别是PLA一直在尝试各种不同的$W$，而线性回归直接得到一个自己认为最好的$W$。但是实际上它们的Hypothesis都是一样的。</p><p>这个算法是否可行，需要来检查它的泛化能力，也就是它的$E_{out}$是否像PLA算法一样有个上界。首先，我们观察两个算法对于错误的衡量有什么区别（注：以下错误都是单个样本的错误）：</p><div class="table-container"><table><thead><tr><th>category</th><th>$E_{in}$</th></tr></thead><tbody><tr><td> linear classification(PLA)</td><td>$y \neq y’$</td></tr><tr><td> linear regression</td><td>$(y - y’)^2$</td></tr><tr><td> linear regression to classification</td><td>$y \neq sign(y’)$</td></tr></tbody></table></div><p>在上面的表格中，我加了一行，也就是利用线性回归算法来进行线性分类时候的$E_{in}$，这意味着它们的$y’$是一样的(实际上$y’$代表的应该是最终的预测值，这里正确的写法应该是$h(X)$,此处只为了方便区分PLA)。</p><p>如果画出y = -1 与 y = +1 时候的曲线图，我们可以清晰地观察到，线性回归得到的错误永远是大于利用线性回归进行分类的错误的：</p><p>y = +1时：<br> <img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/W%24%40%7B0SE%246CEJRR%6098Y255E0.png" alt=""></p><p>y = -1时：<br> <img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/V%5D%5D%24DG%28R6%5B6G%7E0%29%5D%2588KLDE.png" alt=""> </p><p>而通过之前vc bound那一节我们可以知道：</p><script type="math/tex; mode=display">E_{out} \leq E_{in}(classification)+\sqrt {...}</script><p>也就可以得到：</p><script type="math/tex; mode=display">E_{out} \leq E_{in}(regression) +\sqrt {...}</script><p>这意味着，只要linear regression的$E_{in}$做的足够好，那么使用线性回归来做线性分类，往往也能取到比较好的效果。</p><p>实际中，我们也可以使用线性回归与PLA算法结合，先通过线性回归得到W，然后因为给了PLA或者POCKET算法一个好的初始点，它能更快得到最后好的结果。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> classification </tag>
            
            <tag> regression </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——linear regression</title>
      <link href="/2018/08/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression/"/>
      <url>/2018/08/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression/</url>
      
        <content type="html"><![CDATA[<p>终于完成了机器学习基石相对理论的部分，可以开始一些具体的算法的学习了。首先学习的第一个算法就是线性回归（linear regression）。<br><a id="more"></a><br>线性回归想做到的事情是，给出一堆点，使用一条直线（平面或者其他）来拟合这个dataset。而在之前的noise and error中提到了，它用来衡量错误的办法是$(y - y’)^2$。</p><p>和之前的机器学习算法也一致，因为VC bound在线性回归的例子中也一样适用，所以我们想做的是保证$E_{in}$越小越好。</p><p>对于线性回归的H集合是 $y’ = W^TX$，当然$X$，$W$都是列向量，向量的维度是d+1（d为特征量的个数）.为了minimize $E_{in}$，首先我们应该写出来$E_{in}$的表达式：</p><script type="math/tex; mode=display">E_{in} = \frac 1 n \sum _{i = 1} (h(X_n) - y)^2 =  \frac 1 n \sum _{i = 1} (W^TX_n - y_n)^2</script><p>这个表达式看着还比较复杂，有个求和符号在里面。首先，这后面有N个平方和，我们可以很轻松的想到向量的范数求法。因此，我们可以将原式写成对向量求范数的形式：</p><script type="math/tex; mode=display">E_{in} = \frac 1 n || XW - Y||^2</script><p>上式中</p><script type="math/tex; mode=display">X = \begin{bmatrix}...X_1^T... \\...X_2^T... \\..........\\...X_n ^T ...\end{bmatrix}</script><p>X是一个n*（d+1）的矩阵，n是样本个数，d是特征量个数。</p><p>因此$E_{in}$可以说是一个关于W的函数，而且可以证明的是，这个函数是连续的（continuous），可导的（differentiable）,并且是凸函数（convex）。因此我们一定可以求得最低点，也就是$E_{in}$的最小值。与实数的函数一样（实际上求的是W的各个方向的偏导数），在取最小值的那个点的时候，$E_{in}$关于$W$的导数是0，表明取得是极值，也就是梯度是0。</p><p>将上式展开可以得到：</p><script type="math/tex; mode=display">E_{in} = \frac 1 n (W^TX^TXW -2Y^TXW +Y^TY)，</script><p>将除了W之外的矩阵或者数字看成常量，则可以得到：</p><script type="math/tex; mode=display">E_{in} =  \frac 1 n (W^TAW-2BW+c)</script><p>为了求关于$W$的导数，我们首先想象一下如果是$W$一维的话的样子。</p><script type="math/tex; mode=display">E_{in} = aW^2-2bW+c ; \frac {dE_{in}} {dW} = 2aW-2b</script><p>对应到矩阵上来说:</p><script type="math/tex; mode=display">\frac {dE_{in}} {dW} = \frac 1 n 2AW-2B</script><p>可以看到的是梯度是一个向量。</p><p>为了使得$E_{in}$取得最小值，那么$X^TXW = X^TY$,如果$(X^TX)$的反矩阵存在，那么很简单:</p><script type="math/tex; mode=display">W = (X^TX)^{-1}X^TY</script><p>我们称$(X^TX)^{-1}X^T$为pseudo-inverse $X^{+}$。而且大多数时候我们遇到的都是可逆的，因为$n&gt;&gt;d+1$，这意味着首先对于X矩阵来说，它的秩很可能就是等于d+1的.这样它们相乘的秩很大可能也是d+1，也就是可逆。</p><p>但是如果遇到另外的情况，如不可逆，我们可以使用其他的方式来定义$X^{+}$，具体的数学原理需要更详细的线性代数知识，但是我们知道很多程序包里都实现了这些东西，用它一样可以得到比较好的结果。</p><p>综上，$W = X^{+}Y$,$Y’ = XW = XX^{+}Y$.</p><p>最后，这个算法之所以可以学习，我们可以使用VC bound来证明。但是还有另一种方法，也可以证明它泛化能力不错，可以取得良好的学习效果，当然，与VC bound一样，严格的证明需要更严密的数学推导，下面只是简要介绍。</p><p>首先，我们推导$\overline {E_{in}}$是很接近噪声的（噪声意味着我们无法通过学习进行改善的部分），而同样的步骤可以用在对$\overline {E_{out}}$的分析上，这样就说明了，平均来说我们的算法是可以取得很好的学习效果的。</p><p>首先，我们应该定义一下$\overline {E_{in}}$：</p><script type="math/tex; mode=display">\overline {E_{in}} = \epsilon _{D~P^N}\left\{\ E_{in}(W_{LIN} w.r.t. D)  \right\} = noise  level \cdot (1-\frac {d+1}{N})</script><p>具体的含义就是多个样本的$E_{in}$平均值，大概看起来会接近noise level，而当样本量越大，与noise level越接近。</p><p>首先，我们应该将线性回归得到的结果带入$E_{in}$的表达式中：</p><script type="math/tex; mode=display">E_{in} = \frac 1 N ||Y - \hat Y||^2 = \frac 1 N ||Y - XX^{+}Y ||^2 = \frac 1 N ||(I - X X^{+})Y||^2</script><p>我们称$XX^{+}$为hat matrix。</p><p>这里我们思考$\hat Y = XW$在做什么。Y是一个N维向量，而X可以看做是m个N维向量构成的矩阵，而实际上W的作用，是给每个矩阵中的N维向量分配一个参数，让他们做线性组合，最终得到一个新的N维向量。为了使得$\hat Y$尽量接近于$Y$，从另一个方面来说，就是让$Y - \hat Y \bot X’s span$，也就是让他们的差尽量垂直于X所展开的空间，当垂直时，$\hat Y$等于Y在X上的投影，这时候二者相差是最小的.</p><p>实际上，Y一般不可能被X完美表示，因为一般来讲$N&gt;&gt;d$.所以我们能做的就是上面说的。</p><p>所以，Hat的作用就是将Y投影到X上。而$(I-Hat)$就是将Y转换为$(Y-\hat Y)$的矩阵。<br>而且我们可以计算出来$trace (I - Hat) = n - (d+1)$，意味着$(I- Hat)$有$N - d- 1$个自由度。</p><p>如果$Y$来自与一些理想的$f(X)$与噪声的组合，那么如果只是理想的函数，则上述得到的差距实际上是由噪声造成的，因此：</p><script type="math/tex; mode=display">E_{in} = \frac 1 N ||Y - \hat Y||^2  = \frac 1 N ||(I - Hat)noise||^2 = \frac 1 N (N - d - 1)||noise||^2</script><p>而$\overline {E_{in}} = ( 1 - \frac{d+1}{N})noise level$<br>利用类似的办法，可以推断出来，$\overline {E_{out}} = ( 1 + \frac{d+1}{N})noise level$.</p><p>也就是平均来说，我们通过拟合样本，可以得到更小的错误率，但是泛化之后的错误率往往更大一点。</p><p>因此平均来说，我们可以将$E_{in}$与$E_{out}$画在一张图上：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/8P%292%25K%7DDKX0VSSRIW5WS%29JU.png" alt=""></p><p>如果对应到实际的机器学习，对于一些很少的样本量的机器学习过程，很容易拟合成功，得到很好的$E_{in}$，甚至是0，但是这时候泛化能力却很差。机器学习，不是一味地增加特征量减少$E_{in}$，而纠正过拟合的一种办法，就是增加样本量。</p><p>最后，我想说的是，上面的”证明”非常不严格，甚至有些地方让人费解。对于机器学习，理论部分严格的证明更多是数学和统计的事情，而学习计算机的人更多的是掌握各种算法，学习利用它来解决问题。即使这样，尽可能多地了解理论部分，对于实际的应用有很大的帮助。这个世界很复杂，永远保持一个好奇心吧。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）作业二</title>
      <link href="/2018/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A2/"/>
      <url>/2018/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A2/</url>
      
        <content type="html"><![CDATA[<p>总共20道题目。<br><a id="more"></a></p><p>Questions 1-2 are about noisy targets.</p><p><strong>1.Consider the bin model for a hypothesis $h$ that makes an error with probability $\mu$ in approximating a deterministic target function $f$ (both $h$ and $f$ outputs $\{-1, +1\}$).</strong><br> If we use the same $h$ to approximate a noisy version of $f$ given by</p><script type="math/tex; mode=display">P({\bf{x}},y) = P({\bf{x}})P(y|{\bf{x}})P(x,y)=P({\bf{x}})P(y∣ {\bf{x}})</script><script type="math/tex; mode=display">P(y|{\bf{x}}) = \left \{ \begin{matrix} \lambda & {y=f(x)} \\1-\lambda & \text{otherwise}\end{matrix} \right.​</script><p>What is the probability of error that $h$ makes in approximating the noisy target $y$?</p><p>a. $1-\lambda$</p><p>b. $\mu$</p><p>c. $\lambda(1-\mu)+(1-\lambda)\mu$</p><p>d. $\lambda\mu+(1-\lambda)(1-\mu)$</p><p>e. none of the other choices</p><p>这个题目半天看不懂，实际上意思是噪声的几率是($1-\lambda$)。算最后的错误率。所以，当预测错误时候，如果是非噪声，则最后还是错误；当预测正确时候，结果该样本是噪声，则会造成错误，将两种情况加起来，因此答案是 $\mu \lambda + (1-\lambda)(1-\mu)$，选d.</p><p><strong>2. Following Question 1, with what value of $\lambda$ will the performance of $h$ be independent of $\mu$?</strong></p><p>a. 0</p><p>b. 0 or 1</p><p>c. 1</p><p>d. 0.5</p><p>e. none of the other choices</p><p>这道题目很简单，意思是$\lambda$的值是多少的时候，h的性能与$\mu$无关。<br>很简单，将错误率展开：$\mu(2 \lambda - 1) + 1 - \lambda$，可以很容易看出来，$\lambda = 0.5$.</p><p>Questions 3-5 are about generalization error, and getting the feel of the bounds numerically.</p><p><strong>3. Please use the simple upper bound $N^{d_{\text{vc}}}$ on the growth function $m_{\mathcal{H}}(N)$,assuming that $N \geq 2$ and $d_{vc} \geq 2$.<br>For an $\mathcal{H}$ with $d_{\text{vc}} = 10$, if you want $95\%$ confidence that your generalization error is at most 0.05, what is the closest numerical approximation of the sample size that the VC generalization bound predicts?</strong></p><p>a. 420,000</p><p>b. 440,000</p><p>c. 460,000</p><p>d. 480,000</p><p>e. 500,000</p><p>这个题目考验的是VC bound.翻看直接我们推导出来的最终结果：</p><script type="math/tex; mode=display">\epsilon = \sqrt {\frac 8 N \ln {(\frac {4(2N)^{d_{vc}}} {\delta })}}</script><p>上式中，$\epsilon = 0.05(generalization error), \delta = 0.05 (confidence)$,带入上式中，可以计算出来以下结果：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\\ε^<span class="number">2</span> = (<span class="number">8</span>/N)*ln(((<span class="number">2</span>*N)^<span class="number">10</span>*<span class="number">4</span>)/<span class="number">0.05</span>) $\approx$ <span class="number">0.0025</span></span><br><span class="line">N = <span class="number">420</span>,<span class="number">000</span>  ε = <span class="number">0.0026817828255785</span></span><br><span class="line">N = <span class="number">440</span>,<span class="number">000</span>  ε = <span class="number">0.0025683417908949</span></span><br><span class="line">N = <span class="number">460</span>,<span class="number">000</span>  ε = <span class="number">0.0024644054978248</span></span><br><span class="line">N = <span class="number">480</span>,<span class="number">000</span>  ε = <span class="number">0.0023688152044852</span> </span><br><span class="line">N = <span class="number">500</span>,<span class="number">000</span>  ε = <span class="number">0.0022805941154291</span></span><br></pre></td></tr></table></figure></p><p>可以看到答案为 460，000.</p><p><strong>4. There are a number of bounds on the generalization error $\epsilon$, all holding with probability at least $1 - \delta$. Fix $d_{\text{vc}} = 50$d and $\delta = 0.05$ and plot these bounds as a function of N. Which bound is the tightest (smallest) for very large N, say N=10,000?<br>Note that Devroye and Parrondo &amp; Van den Broek are implicit bounds in $\epsilon$.</strong></p><p>a. Original VC bound: $ \epsilon \le \sqrt{\frac{8}{N}\ln\frac{4m_{\mathcal{H}}(2N)}{\delta}}$</p><p>b. Rademacher Penalty Bound: $ \epsilon \le \sqrt{\frac{2\ln(2Nm_{\mathcal{H}}(N))}{N}} + \sqrt{\frac{2}{N}\ln\frac{1}{\delta}} + \frac{1}{N}$</p><p>c. Parrondo and Van den Broek: $ \epsilon \le \sqrt{\frac{1}{N}(2\epsilon + \ln\frac{6m_{\mathcal{H}}(2N)}{\delta})}$</p><p>d. Devroye: $\epsilon \le \sqrt{\frac{1}{2N} (4\epsilon(1 + \epsilon) + \ln \frac{4m_{\mathcal{H}}(N^2)}{\delta})}$</p><p>e. Variant VC bound: $\epsilon \le \sqrt{\frac{16}{N}\ln\frac{2m_{\mathcal{H}}(N)}{\sqrt{\delta}}}$</p><p>代公式的问题：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a. (8/10000*ln((4*(2*10000)^50)/0.05))^(0.5) = 0.63217491520084</span><br><span class="line"></span><br><span class="line">b. ((2*ln(2*10000*10000^50))/10000)^0.5+(2/10000*ln(1/0.05))^0.5+1/10000 = 0.33130878596164</span><br><span class="line"></span><br><span class="line">c. (1/10000*(2*ε+ln(6*(20000)^50/0.05)))^0.5 当ε等于0.223左右的时候取等号,当ε大于0.223时候，上式已经不再成立，当小于0.223时候是成立的，所以bound在是0.223左右</span><br><span class="line"></span><br><span class="line">d. (1/20000*(4*ε*(1+ε)+ln(4*1000000^(50)/0.05)))^0.5 同上，bound在0.186左右</span><br><span class="line"></span><br><span class="line">e. (16/10000*ln(2*10000^50/0.5))^0.5 = 0.85967743993657</span><br></pre></td></tr></table></figure></p><p>答案为Devroye,选d.</p><p><strong>5. Continuing from Question 4, for small N, say N=5, which bound is the tightest (smallest)?</strong></p><p>答案与上面解答过程类似。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a. (8/5*ln((4*(2*5)^50)/0.05))^0.5 = 13.828161484991</span><br><span class="line"></span><br><span class="line">b. ((2*ln(2*5*5^50))/5)^0.5+(2/5*ln(1/0.05))^0.5+1/5 = 7.0487765641837</span><br><span class="line"></span><br><span class="line">c. 答案为5.0左右</span><br><span class="line"></span><br><span class="line">d. 答案为5.5左右</span><br><span class="line"></span><br><span class="line">e. (16/5*ln(2*5^50/0.5))^0.5 = 16.184752328814</span><br></pre></td></tr></table></figure></p><p>显然答案选Parrondo and Van den Broek.</p><p>In Questions 6­-11, you are asked to play with the growth function or VC-dimension of some hypothesis sets.</p><p><strong>6. What is the growth function $m_{\mathcal{H}}(N)$ of “positive-and-negative intervals on $\mathbb{R}$”? The hypothesis set $\mathcal{H}$ of “positive-and-negative intervals” contains the functions which are $+1$ within an interval $[\ell,r]$ and −1 elsewhere, as well as the functions which are −1 within an interval $[\ell,r]$ and +1 elsewhere.<br>For instance, the hypothesis $h_1(x)=sign(x(x−4))$ is a negative interval with -1 within $[0, 4]$ and +1 elsewhere, and hence belongs to $\mathcal{H}$. The hypothesis $h_2(x)=sign((x+1)(x)(x−1))$ contains two positive intervals in $[-1, 0]$ and $[1, \infty)$ and hence does not belong to $\mathcal{H}$.</strong></p><p>a. $N^2-N+2$</p><p>b. $N^2$</p><p>c. $N^2+1$</p><p>d. $N^2+N+2$</p><p>e. none of the other choices.</p><p>这个题目题意描述很长，但是看懂了并不难。实际上就是positive intervals的拓展，只不过原来是中间是正的，两边是负的,这时候情况与之前就不一样了。<br>之前，N个样本将这个直线划分成了N+1个区域，从中取两个，中间是正，外面是负，同时还包含一种全是负的情况，比如选的两个点在一个区域内，就会有全负的情况，因此结果是$C_{N+1}^2+1 =  frac{1}{2} N^2+ \frac{1}{2}N+1$;<br>而本题就要注意一些问题了，很直觉的想法是对上面的做法翻倍，但是实际上仔细想想，如果我们取到最边上的两个点，那么实际上就包含了全是正和全是负的结果，另一方面，只要我们取到了最边上的区域某个点，就会有重复的结果（与取另一端的端点是一样的），因此取到最边上的点应当只算一次。<br>所以我们要换个思路，一是两个点都不是端点区域的：$C_{N-1}^2$,<br>第二个是两个点有一个是端点区域的：$C_{N-1}^1 \times C_2^1 $,<br>最后一种情况是两个端点区域的，有两种情况，全正或者全负：2.<br>至于取相同区域的情况得到的结果是与最后一种情况一致的。<br>所以最后结果：$m_H(N) = N^2-N+2 $.</p><p>另一种讨巧的做法：当N = 3的时候，其他的答案都大于8，这是不可能发生的。</p><p><strong>7. Continuing from the previous problem, what is the VC-dimension of the hypothesis set of “positive-and-negative intervals on $\mathbb{R}$”?</strong></p><p>既然上面都得到成长函数了，很轻易可以得到结果，答案是3，当为N = 4时候，$N^2-N+2 = 14&lt;16$.</p><p><strong>8. What is the growth function $m_{\mathcal{H}}(N)$ of “positive donuts in $\mathbb{R}^2$”?</strong></p><p>The hypothesis set $\mathcal{H}$ of “positive donuts” contains hypotheses formed by two concentric circles centered at the origin. In particular, each hypothesis is +1 within a “donut” region of $a^2 \leq x_1^2+x_2^2 \leq b^2$ and −1 elsewhere. Without loss of generality, we assume $0 \lt a \lt b \lt \infty$.</p><p>a. $N+1$</p><p>b. $C_{N+1}^2+1$</p><p>c. $C_{N+1}^3+1$</p><p>d. none of the other choices.</p><p>e. $C_N^2+1$</p><p>这道题目是要在以原点为中心画两个圆，分布在环上的点为正，其余为负。看上去维度似乎变成了二维，实际上还是一维的：这个维度就是与原点的距离。如果与原点距离一致，它们的分类也是一样的。因此，我们简化一下这个问题，将与原点的距离画到一条线上，立马这个问题就成为一般的positive intervals问题了，答案也是一样的：$C_{N+2}^2+1$。</p><p><strong>9. Consider the “polynomial discriminant” hypothesis set of degree $D$ on $\mathbb{R}$, which is given by</strong></p><script type="math/tex; mode=display">\begin{eqnarray}\mathcal{H} = \left\{ h_{\bf{c}} \; \middle| \; h_{\bf{c}}(x) = {\rm{sign}}\left(\sum_{i=0}^D c_ix^i\right) \right\}\end{eqnarray}</script><p>What is the VC-dimension of such an $\mathcal{H}$?</p><p>这个不就是perceptron吗？答案是$D+1$.</p><p><strong>10.Consider the “simplified decision trees” hypothesis set on $\mathbb{R}^d$, which is given by</strong></p><script type="math/tex; mode=display">\begin{eqnarray}\mathcal{H}= \{h_{\mathbf{t},\mathbf{S}} \; | & \; h_{\mathbf{t},\mathbf{S}}(\mathbf{x}) = 2 [[\mathbf{v}\in S]] - 1,\text{ where} \; v_i = [[x_i>t_i]], & \\& \mathbf{S} \text{ a collection of vectors in } \{0,1\}^d,\mathbf{t} \in \mathbb{R}^d &\}\end{eqnarray}</script><p>That is, each hypothesis makes a prediction by first using the $d$ thresholds $t_i$ to locate $\mathbf{x}$ to be within one of the $2^d$ hyper-rectangular regions, and looking up $\mathbf{S}$ to decide whether the region should be +1 or −1.</p><p>What is the VC-dimension of the “simplified decision trees” hypothesis set?</p><p>a. $2^d$</p><p>b. $2^{d+1}-3$</p><p>c. $\infty$</p><p>d. none of the other choices.</p><p>e. $2^{d+1}$</p><p>这个题目看不大懂…</p><p><strong>11. Consider the “triangle waves’’ hypothesis set on $\mathbb{R}$, which is given by</strong></p><script type="math/tex; mode=display">\begin{eqnarray}\mathcal{H} = \{h_{\alpha} \; | & \; h_{\alpha}(x) = \text{sign}(| (\alpha x) \mbox{ mod } 4 - 2| - 1), \alpha \in \mathbb{R} \}\end{eqnarray}</script><p>Here $(z mod 4)$ is a number $z - 4k$ for some integer $k$ such that $z - 4k \in [0, 4)$. For instance, $(11.26 mod 4)$ is 3.26, and $(−11.26 mod 4)$ is 0.74. What is the VC-dimension of such an $\mathcal{H}$?</p><p>a. 1</p><p>b. 2</p><p>c. ∞</p><p>d. none of the other choices</p><p>e. 3</p><p>这个问题看上去很复杂，所以一步一步拆开来解决。<br>第一，这个点是分布在实数轴上的，所以我们要首先弄清楚轴上的那部分的点是+1，哪部分的点是-1.<br>如果是-1，则$|(\alpha x) mod 4 - 2| &lt; 1 $,可以推出来$(\alpha x) mod 4 \in (1,3)$,同理可以退出来如果是+1，则 $(\alpha x) mod 4 \in (0,1) \bigcup (3,4)$ ,根据题中负数取余数的定义，总结一下如下：</p><script type="math/tex; mode=display"> h_{\alpha}(x) = \left \{\begin{matrix}+1& \alpha x \in (-1+4k,1+4k) \\-1 & \alpha x \in (1+4k,3+4k)\end{matrix} \right.</script><p>对于N = 1和N = 2的时候，很容易可以知道各种情况都是可以shatter的。</p><p>（举个N=2的例子，如</p><p>$[0.6,0.7]—[+1,+1]; [0.6 \times \frac 9 6, 0.7 \times \frac 9 6 ]—[+1,-1];[0.6 \times \frac 29 6,0.7 \times \frac 29 6]—[-1,+1];[0.6 \times \frac 29 7,0.7 \times \frac 29 7]—[-1,-1]$）. </p><p>当N等于3的时候，也是可以被shatter。</p><p>实际上，取余的过程中有这么一个性质：$\alpha x mod 4 = [\alpha (x mod 4)] mod 4$，这意味着(假设有3个样本)，对于任何大小的$x_n$,我们都可以将它缩放到$[0,4)$的范围来进行处理。这个题目的答案是∞。但是如何证明我还不是很清楚。</p><p>In Questions 12-15, you are asked to verify some properties or bounds on the growth function and VC-dimension.</p><p><strong>12. Which of the following is an upper bounds of the growth function $m_\mathcal{H}(N)$ for $N \ge d_ \ge 2$?</strong></p><p>a. $m_H(⌊N/2⌋)$</p><p>b. $2^{d_{vc}}$</p><p>c. $ \min _{1 \leq i \leq N-1} 2^im_H(N-i)$</p><p>d. $\sqrt {N^{d_{vc}}}$</p><p>e. none of the other choices.</p><p>这个题目问的是成长函数。对于成长函数的界限，之前的博客已经有了以下的说明：</p><script type="math/tex; mode=display">B(N,k) \leq \sum _{i=0} ^{k-1} C_N^i</script><p>而上式中，$k = d+1$。<br>根据上式，我们可以很轻易的排除a,b两项。同时，如果举例计算，亦可以排除选项d。如，$B(6,3) = 22 ＞ \sqrt {6^2}$.</p><p>因此答案是c.至于对c的证明，我们可以从之前vc bound的表格里发现， </p><p>$B(N,d) = B(N-1,d-1)+B(N-1,d) \leq 2 \times B(N-1,d) \leq 4 \times B(N-2,d) \leq 2^i \times B(N-i,d)$，因此，任何 $2^im_H(N-i)$都是大于等于$m_H(N)$的，选择一个最小的即可。</p><p><strong>13. Which of the following is not a possible growth functions $m_{\mathcal{H}}(N)$for some hypothesis set?</strong></p><p>a. $2^N$</p><p>b. $2^{⌊ \sqrt {N} ⌋}$</p><p>c. 1</p><p>d. $N^2 -N +2$</p><p>e. none of the other choices.</p><p>答案是b. 首先，a,d的情况我们都遇到过，而c的情况也是很简单的，比如这个H对所有的样本都取正。至于b为什么错了，当N = 1的时候，$2^1 = 2$，而当N = 2的时候，$m_H(2) = 2$，<br>$m_H(3) =2$, $m_H(4) = 4$. 实际上是不可能出现成长函数呈现出这样的规律增长的，因为N个点中随意取N-1个出来，必然要满足之前的N-1个时候的所有要求（出现的情况与之前的N-1的各种情况一致，可以有重复，但是不能多也不能少），这保证了成长函数要么是严格单调增的，要么是不变的（我的理解）。</p><p><strong>14. For hypothesis sets $\mathcal{H}_1, \mathcal{H}_2, …, \mathcal{H}_K$ with finite, positive VC-dimensions d_(\mathcal{H}_k), some of the following bounds are correct and some are not.</strong></p><p>Which among the correct ones is the tightest bound on $d_(\bigcap_{k=1}^{K}!\mathcal{H}_k)$, the VC-dimension of the $\bf{intersection}$ of the sets?</p><p>(The VC-dimension of an empty set or a singleton set is taken as zero.)</p><p>这个题目是有K个H集合，每个集合都对应一个vc dimension，问题是这些集合的交集构成的集合的vc dimension的范围。</p><p>a. $ 0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k)$</p><p>b. $0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \min\{d_{vc}(H_k) \}_{k=1}^K $</p><p>c. $0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \max\{d_{vc}(H_k) \}_{k=1}^K $</p><p>d. $ \min\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \max\{d_{vc}(H_k) \}_{k=1}^K $</p><p>e. $ \min\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k) $</p><p>如果交集为空，那么vc dimension为0。同时，不管怎么说，H的大小不可能是比之前任何一个<br>$H_n$大，而且一定是之前任何一个集合的一部分。因此它的vc dimension也不会超过之前任何一个集合，所有答案很明显，是b.</p><p><strong>15. For hypothesis sets $\mathcal{H}_1, \mathcal{H}_2, …, \mathcal{H}_K$ with finite, positive VC-dimensions d_(\mathcal{H}_k), some of the following bounds are correct and some are not.</strong></p><p>Which among the correct ones is the tightest bound on $d_(\bigcup_{k=1}^{K}!\mathcal{H}_k)$, the VC-dimension of the $\bf{union}$ of the sets?</p><p>a.  $ 0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq K-1+\sum _{k=1} ^K d_{vc}(H_k)$</p><p>b. $ \min\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k) $</p><p>c. $ \max\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k) $</p><p>d. $ \max\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq K-1+\sum _{k=1} ^K d_{vc}(H_k) $</p><p>e. $0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k) $</p><p>这道题目与上一道刚好相反。首先，并集是包含所有的，因此它的vc dimension一定是大于最大的。所以就排除了a，b，d。然后，再c与d之间做选择.想象一个情况，$H_1$是将所有的点划分为正，$H_2$是将所有的点划分为负，$H_1+H_2$的vc dimension是1，但是各自的vc dimension为0.这样足以选出这个答案是d。如何证明？观察之前的那个表,可以举出更多的例子。但是如何得到这个具体的界限，需要更严格的数学证明。</p><p>For Questions 16-20, you will play with the decision stump algorithm.</p><p>16-20题目依然是编程问题。</p><p><strong>16. In class, we taught about the learning model of “positive and negative rays” (which is simply one-dimensional perceptron) for one-dimensional data. The model contains hypotheses of the form:</strong></p><script type="math/tex; mode=display">h_{s, \theta}(x) = s \cdot \mbox{sign}(x - \theta).</script><p>The model is frequently named the “decision stump’’ model and is one of the simplest learning models. As shown in class, for one-dimensional data, the VC dimension of the decision stump model is 2.</p><p>In fact, the decision stump model is one of the few models that we could easily minimize $E_{in}$ efficiently by enumerating all possible thresholds. In particular, for $N$ examples, there are at most $2N$ dichotomies (see page 22 of lecture 5 slides), and thus at most $2N$ different $E_{in}$ values. We can then easily choose the dichotomy that leads to the lowest $E_{in}$, where ties an be broken by randomly choosing among the lowest $E_{in}$ ones. The chosen dichotomy stands for a combination of some “spot” (range of $\theta$) and $s$, and commonly the median of the range is chosen as the $\theta$ that realizes the dichotomy.</p><p>In this problem, you are asked to implement such and algorithm and run your program on an artificial data set. First of all, start by generating a one-dimensional data by the procedure below:</p><p>(a) Generate $x$ by a uniform distribution in $[-1, 1]$.</p><p>(b) Generate $y$ by $f(x) = \tilde{s}(x)$+$noise$ where $ \tilde{s}(x) = sign(x)$ and the noise flips the result with $20%$ probability.</p><p>For any decision stump $h_{s, \theta}$ with $\theta \in [-1, 1]$, express $E_{out}(h_{s, \theta})$ as a function of $\theta$ and $s$.</p><p>a. $0.3+0.5s(|\theta| - 1)$</p><p>b. $0.3+0.5s(1 - |\theta|)$</p><p>c. $0.5+0.3s(|\theta| - 1)$</p><p>d. $0.5+0.3s(1 - |\theta|)$</p><p>e. none of the other choices.</p><p>虽然是编程题目，但是本道题目还没有涉及到代码编写，而是从理论分析这个问题。本题中数据生成是利用$sign(x)+noise$，其中noise出现的概率是20%。<br>我们可以知道，当$h_{s,\theta}(x)$在没有噪声的情况下，错误率是$\frac \theta 2$.</p><p>由第一题的分析可以知道，$E_{out} =  \frac {|\theta|} 2 \times (1 - 0.2) + (1 - \frac {|\theta|} 2) \times 0.2 = 0.3 |\theta| + 0.2$, 看了下似乎没有这个答案，这是因为我们没有考虑到符号的问题。如果考虑到符号，s是负的，那么原先的正确率反而变成错误率了, 即 $0.8 - 0.3 |\theta|$可以看到，答案选c。</p><p><strong>17. Generate a data set of size 20 by the procedure above and run the one-dimensional decision stump algorithm on the data set. Record $E_{in}$ and compute $E_{out}$ with the formula above. Repeat the experiment (including data generation, running the decision stump algorithm, and computing $E_{in}$ and $E_{out}$) 5,000 times. What is the average $E_{in}$? Please choose the closest option.</strong></p><p>a. 0.05</p><p>b. 0.15</p><p>c. 0.25</p><p>d. 0.35</p><p>e. 0.45</p><p>这道题目需要编程实现。首先，我们需要生成数据和噪音：<br>下面的代码生成20个数据，并用0.2的概率抽出来作为噪音。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sign</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">else</span> : <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateXY</span><span class="params">()</span>:</span></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span>  range(<span class="number">0</span>,<span class="number">20</span>):</span><br><span class="line">        x.append([random.random()*<span class="number">2</span><span class="number">-1</span>])</span><br><span class="line">    noise = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">20</span>):</span><br><span class="line">        ran = random.random()</span><br><span class="line">        <span class="comment">#print(ran)</span></span><br><span class="line">        <span class="keyword">if</span> ran &lt;= <span class="number">0.2</span>:</span><br><span class="line">            noise+=<span class="number">1</span></span><br><span class="line">            x[i].append(-sign(x[i][<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">else</span> :x[i].append(sign(x[i][<span class="number">0</span>]))</span><br><span class="line">    <span class="comment">#print("noise:",noise)</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>然后就是实现算法了。这个算法很简单，我们可以很轻易得枚举出来各种过程。同时为了简化算法，我没有实现s为负的场景，因为为负的场景最后大概率是选不到的。</p><p>首先，将随机数据排序，然后每次选择一个间隔，统计其之前与之后错误的分类个数。选择间隔的时候，首先选取d[i]，意味着现在选择的区域是(d[i-1],d[i])，将d[i]之前的作为-1，d[i]之后包括d[i]的作为+1，这样可以简化算法。值得注意的是i将会等于len(d)，因为间隔有len(d)+1个。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decision_stump</span><span class="params">(dataset)</span>:</span></span><br><span class="line"></span><br><span class="line">    sort_d = sorted(dataset)</span><br><span class="line">    min_pos = []</span><br><span class="line"></span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    min_err = len(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(dataset)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,i):</span><br><span class="line">            <span class="keyword">if</span> sort_d[k][<span class="number">1</span>]&gt;<span class="number">0</span>:</span><br><span class="line">                err+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(i,len(dataset)):</span><br><span class="line">            <span class="keyword">if</span> sort_d[k][<span class="number">1</span>]&lt;<span class="number">0</span>:</span><br><span class="line">                err+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> err &lt; min_err:</span><br><span class="line">            min_pos = []</span><br><span class="line">            min_pos.append(i)</span><br><span class="line">            min_err = err</span><br><span class="line">        <span class="keyword">elif</span> err == min_err:</span><br><span class="line">            min_pos.append(i)</span><br><span class="line">        err = <span class="number">0</span></span><br><span class="line"><span class="comment"># choose the lowest Ein randomly</span></span><br><span class="line">    choosen = int(len(min_pos)*random.random())</span><br><span class="line">    <span class="keyword">if</span> min_pos[choosen] &lt; len(sort_d):</span><br><span class="line">        <span class="keyword">return</span> [sort_d[min_pos[choosen]][<span class="number">0</span>],min_err]</span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> [(sort_d[min_pos[choosen]<span class="number">-1</span>][<span class="number">0</span>]+<span class="number">1</span>)/<span class="number">2</span>,min_err]</span><br></pre></td></tr></table></figure><p>结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">average Ein: 0.1713600000000006</span><br></pre></td></tr></table></figure></p><p>因此答案选b。</p><p><strong>18. Continuing from the previous question, what is the average E_{out}? Please choose the closest option.</strong></p><p>a. 0.05</p><p>b. 0.15</p><p>c. 0.25</p><p>d. 0.35</p><p>e. 0.45</p><p>对于Eout的计算，可以直接使用16中的公式带入。结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">average Eout: 0.25962811866336116</span><br></pre></td></tr></table></figure></p><p>因此答案选C.</p><p><strong>19. Decision stumps can also work for multi-dimensional data. In particular, each decision stump now deals with a specific dimension $i$, as shown below.</strong></p><script type="math/tex; mode=display">h_{s, i, \theta}(\mathbf{x}) = s \cdot \mbox{sign}(x_i - \theta).</script><p>Implement the following decision stump algorithm for multi-dimensional data:</p><p>a) for each dimension $i = 1, 2, \cdots, d$, find the best decision stump $h_{s, i, \theta}$ using the one-dimensional decision stump algorithm that you have just implemented.</p><p>b) return the “best of best” decision stump in terms of $E_{in}$. If there is a tie , please randomly choose among the lowest-$E_{in}$ ones.</p><p>The training data $\mathcal{D}_{train}$ is available at:</p><p><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw2_train.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw2_train.dat</a></p><p>The testing data $\mathcal{D}_{test}$ is available at:</p><p><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw2_test.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw2_test.dat</a></p><p>Run the algorithm on the $\mathcal{D}_{train}$. Report the $E_{\text{in}}$​ of the optimal decision stump returned by your program. Choose the closest option.</p><p>在本例中，是将之前的算法用到多维度的数据上，分两步：1.对每个维度的数据运用上面的算法选出最佳的$E_in$;2.在所有的维度中选择一个最好的出来。</p><p>这个对应到实际中可能会出现，比如某个维度是真正起作用的，而其余的特征的作用不大。</p><p>实际上用到的算法与之前的一致。但是需要注意的是，因为这次我们对真实的$\theta,s$值一无所知，因为不能忽略s为负的情况。改进算法的步骤很简单，因为s为负的情况出错的个数就是所有样本个数减去s为正的情况出错的个数。</p><p>改正后的算法：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decision_stump</span><span class="params">(dataset)</span>:</span></span><br><span class="line"></span><br><span class="line">    sort_d = sorted(dataset)</span><br><span class="line">    min_pos = []</span><br><span class="line"></span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line">    isNeg = <span class="keyword">False</span></span><br><span class="line">    min_err = len(dataset)</span><br><span class="line">    size = len(dataset)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(dataset)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,i):</span><br><span class="line">            <span class="keyword">if</span> sort_d[k][<span class="number">1</span>]&gt;<span class="number">0</span>:</span><br><span class="line">                err+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(i,len(dataset)):</span><br><span class="line">            <span class="keyword">if</span> sort_d[k][<span class="number">1</span>]&lt;<span class="number">0</span>:</span><br><span class="line">                err+=<span class="number">1</span></span><br><span class="line">        isNeg = <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">if</span> err &lt; min_err:</span><br><span class="line">            min_pos = []</span><br><span class="line">            min_pos.append([i,isNeg])</span><br><span class="line">            min_err = err</span><br><span class="line">        <span class="keyword">elif</span> err == min_err:</span><br><span class="line">            min_pos.append([i,isNeg])</span><br><span class="line">        isNeg = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">if</span> (size - err) &lt; min_err:</span><br><span class="line">            min_pos = []</span><br><span class="line">            min_pos.append([i,isNeg])</span><br><span class="line">            min_err = size - err</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> (size - err) == min_err:</span><br><span class="line">            min_pos.append([i,isNeg])</span><br><span class="line">        err = <span class="number">0</span></span><br><span class="line"><span class="comment"># choose the lowest Ein randomly</span></span><br><span class="line">    <span class="comment">#print(min_pos)</span></span><br><span class="line">    choosen = int(len(min_pos)*random.random())</span><br><span class="line">    <span class="keyword">if</span> min_pos[choosen][<span class="number">0</span>] &lt; len(sort_d):</span><br><span class="line">        <span class="keyword">return</span> [sort_d[min_pos[choosen][<span class="number">0</span>]][<span class="number">0</span>],min_err,min_pos[choosen][<span class="number">1</span>]]</span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> [(sort_d[min_pos[choosen][<span class="number">0</span>]<span class="number">-1</span>][<span class="number">0</span>]+<span class="number">1</span>)/<span class="number">2</span>,min_err,min_pos[choosen][<span class="number">1</span>]]</span><br></pre></td></tr></table></figure></p><p>我们增添了一个isNeg的变量，来代表s是否是-1.</p><p>最后multi算法就是在不同维度上运行该算法，挑出错误最小的维度与$\theta$。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiDDecision_stump</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    min_err_d = []</span><br><span class="line">    min_err = <span class="number">0x7fffffff</span></span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)):<span class="comment">#</span></span><br><span class="line">        temp = decision_stump(dataset[i])</span><br><span class="line">        err = temp[<span class="number">1</span>]</span><br><span class="line">        <span class="comment">#print(err)</span></span><br><span class="line">        <span class="keyword">if</span> err &lt; min_err:</span><br><span class="line">            min_err = err</span><br><span class="line">            min_err_d = []</span><br><span class="line">            min_err_d.append([temp[<span class="number">0</span>],i,min_err,temp[<span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> err == min_err:</span><br><span class="line">            min_err_d.append([temp[<span class="number">0</span>],i,min_err,temp[<span class="number">2</span>]])</span><br><span class="line">    choosen = int(random.random()*len(min_err_d))</span><br><span class="line">    <span class="keyword">return</span> min_err_d[choosen]</span><br></pre></td></tr></table></figure></p><p>这道题目用到的数据是课程提供的，因此写入读取数据的过程：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataFrom</span><span class="params">(filename)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">with</span> open (filename) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline()[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">while</span> line:</span><br><span class="line">            temp = line.split(<span class="string">' '</span>)</span><br><span class="line">            <span class="comment">#print(temp)</span></span><br><span class="line">            <span class="keyword">if</span> len(result) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">for</span> x_i <span class="keyword">in</span> range(len(temp)<span class="number">-1</span>):</span><br><span class="line">                    result.append([[float(temp[x_i]),float(temp[<span class="number">-1</span>])]])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> x_i <span class="keyword">in</span> range(len(temp) - <span class="number">1</span>):</span><br><span class="line">                    result[x_i].append([float(temp[x_i]),float(temp[<span class="number">-1</span>])])</span><br><span class="line">            line = f.readline()[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>最后得到结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dimension: 3</span><br><span class="line">theta: 1.774</span><br><span class="line">Ein: 0.25</span><br></pre></td></tr></table></figure></p><p><strong>20. Use the returned decision stump to predict the label of each example within $\mathcal{D}_{test}$. Report an estimate of $E_{\text{out}}$ by $E_{\text{test}}$. Please choose the closest option.</strong></p><p>使用题目给的数据来做测试，估计$E_{out}$，需要一个检测错误的函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkout</span><span class="params">(min_err_d,dataset)</span>:</span></span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> dataset[min_err_d[<span class="number">1</span>]]:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> sign(i[<span class="number">0</span>] - min_err_d[<span class="number">0</span>]) != sign(i[<span class="number">1</span>]):</span><br><span class="line">            err += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> min_err_d[<span class="number">3</span>] == <span class="keyword">True</span>:</span><br><span class="line">        err =  len(dataset[<span class="number">0</span>]) - err</span><br><span class="line">    <span class="keyword">return</span> err</span><br></pre></td></tr></table></figure></p><p>最后结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eout: 0.36</span><br></pre></td></tr></table></figure></p><p>p.s. 10，11，15题目留有疑问。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Noise and Error</title>
      <link href="/2018/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Noise-and-Error/"/>
      <url>/2018/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Noise-and-Error/</url>
      
        <content type="html"><![CDATA[<p>上次的博客介绍了VC bound，用的是二元分类来证明。实际上推广到其他的线性回归等问题，我们只需要修改一些VC bound里相关的定义，最终一样可以得到类似的结果。<br><a id="more"></a><br>在有noise的情况下，VC bound也是成立的，学习一样是可行的。</p><p>本篇博客少了对上面这些论点的证明，因为我也不会。</p><p>这里主要介绍的是以些error measure的方法。一方面，我们想找到一个实际上$E_{in}$最小的解是一个NP-hard问题，因此只能尽可能去找到较好的解;另一方面，对不同的应用情景，可以定义不同的$E_{in}(h)$。用不同的定义来衡量错误。</p><p>我们之前的衡量g表现时候有3个特征：</p><ol><li>out of sample（通过对未见过的数据的预测进行衡量）</li><li>point wise（逐点衡量）</li><li>classification（二元分类问题）</li></ol><p>接着上面，我们已经知道二元分类有一个衡量方法，如下:</p><p>$E_{out}(g) = \epsilon _{x~P}[g(x) \neq f(x)]$</p><p>实际上也就是统计预测错误的个数。</p><p>在以后的学习中我们还是会使用point wise这个策略，每个点每个点的来进行计算。我们将衡量每个点的错误的办法记为$err(y’,y)$，那么上述衡量办法就是$err(y’,y) = [y’ \neq y]$<br>另外一种衡量错误的方法：</p><p>$err(y’,y) = (y - y’)^2$</p><p>这个衡量错误的办法适用于线性回归，因为它得到的y’是实数，因此可以定义与真实值的距离来衡量错误。</p><p>还有很多别的定义，如$err(y’,y) = |y - y’|$.</p><p>对于不同的衡量错误的方法，得到的最佳的学习算法很可能是不一致的。</p><p>在实际情况中，即使是二元分类问题，我们也可能有不同的衡量错误算法，下面介绍加权分类。因为错误的情况有两种，假正和假负，它们对于实际应用造成的代价可能是不一致的。比如一间超市搞促销，对于预测为正的顾客认为是回头客，会给予打折活动。这时候假负例的代价是很大的，因为可能会损失回头客，再如果是CIA情报局的门禁系统，对于预测为工作人员的准许进入，假正的代价会非常大，因此我们可以写出下面样子的两个表格，代表不同错误的权重：</p><div class="table-container"><table><thead><tr><th style="text-align:center">R\P</th><th style="text-align:center">+1</th><th style="text-align:center">-1</th><th style="text-align:center"></th><th style="text-align:center">R\P</th><th style="text-align:center">+1</th><th style="text-align:center">-1</th></tr></thead><tbody><tr><td style="text-align:center">+1</td><td style="text-align:center">0</td><td style="text-align:center">1000</td><td style="text-align:center"></td><td style="text-align:center">+1</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">-1</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center"></td><td style="text-align:center">-1</td><td style="text-align:center">10000</td><td style="text-align:center">0</td></tr></tbody></table></div><p>因此，对于加权分类的错误衡量办法，可以写成：</p><script type="math/tex; mode=display">err(y',y) = \frac {(y + 1)(y - y')} 4 a_1 + \frac {(1-y)( y' - y)} 4 a_2</script><p>上式中，$a_1$是预测为假正的权重，$a_2$是预测为假负的权重.</p><p>我们需要将错误衡量方法加入学习算法，才能使得最终的结果让$E_{in}$尽量小.</p><p>举个例子，对于pocket，假如采用上面回头客的例子中的权重来进行约束，那么pocket算法中，假负的代价很高，当遇到假负的情况时候，等价于复制了1000个相同的点，每个点权重一致。这要求我们在实际写算法时候，不光对于该点的惩罚翻了1000倍，同时还要让这个点下次被选中的概率变大。其他算法中也是一样的，如果一个情况的错误代价很大，我们不光要对代价增加，也要尽可能地改正这个错误。</p><p>最后，要说明除此之外的一种情况。有一种数据是unbalanced data，这样的数据加上了权重，依然可能会给一个很烂的学习算法很低的错误评价，比如cia的例子中，我们有999 990个员工的样本，只有10个入侵者的样本，那么即使假正的权重提升到10000，对于一个总是预测正确的算法，错误衡量依然只有0.1，似乎还不错的评价，而这个算法甚至算不上一个学习算法。这说明评价算法还有别的方面需要考虑，如以后可能提到的查准率与查全率。</p><p>以上。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——VC bound</title>
      <link href="/2018/08/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94VC-bound/"/>
      <url>/2018/08/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94VC-bound/</url>
      
        <content type="html"><![CDATA[<p>上次的Hoeffding不等式那篇，证明了一个hypothesis集合是有限集合，那么学习是可行的。<br><a id="more"></a><br>如果定义$E_{in}$是资料上的错误率，$E_{out}$是整体的错误率，我们证明的结果，如果N足够大，那么很大概率上，$E_{in} \approx E_{out}$.我们只需要在有限的集合利用里学习算法选出一个$E_{in}$最低的，就可以实现学习，因为很大概率上它对整体分类后的错误率也是与$E_{in}$差不太多的。</p><p>先思考一个问题，H的大小影响的了什么？学习需要做的有两个：1. 保证$E_{in} \approx E_{out}$ 2.找到一个h使得$E_{in}很小$。<br>如果H集合过大，那么我们不容易保证第一个条件，但是如果集合过小，我们不一定能找到一个h使得它甚至在测试数据上有很好的表现。</p><p>上次博客留下来了一个问题：如果这个$H$集合是无限集合呢？例如之前实现的PLA算法。那我们怎么保证在无限的集合上，学习是可行的呢？</p><p>首先，我们来观察上次得到的hoeffding不等式：$P_{baddata} \leq 2te^{-2\epsilon ^2N}.如果其中t-&gt;$\lnfty$，那么这个不等式实际上是没有意义的，因为右边的值将会远大于1，但是说一个概率小于等于1那是废话。</p><p>仔细想想，那是因为我们的union bound太宽松了。它们实际上会有很多重叠的部分，比如对于某个hypothesis是bad data，对于另一个它可能也是。这就要求我们将这个union bound继续压缩。</p><p>利用2D的perceptron learning algorithm来举例，如果N = 1，也就是我们只有一个样本，那么它要么是正要么是负，虽然平面上有无数条线，但是似乎只有这么两个效果，也就是只有这么两类线，在这两类线上，它们的$E_{in}$是一致的。</p><p>同样的道理，如果平面上有两个点，我们利用平面上的直线最多也就只能分成4种情况,我们将每一种情况称为一个dichotomy。</p><p>当N为3的时候，在纸上我们可以画出，平面上可以有8种dichotomy，但是也会有意外，例如如果3个点拍成一条直线，那么“× ○ ×”的情况，我们似乎无法用一条直线分开了。</p><p>当N为4的时候，即使4个点是每一个点都是凸四边形的顶点，我们依然无法将所有的情况都表示出来，如下面这种情况：</p><p>× ○</p><p>○ ×</p><p>实际上，当N为4的时候，我们可以分出来的dichotomy共有14种。而所有的情况有$2^4=16$种，很明显可以看出dichotomy的数量是少于$2^N$。</p><p>我们将某个大小为N的dataset所有情况都可以用这个H做出来(dichotomy的数量为$2^N$)，成为被H shatter。</p><p>当N&gt;4的时候，这个dichotomy又有多少？现在我们很难找到2d perceptron其中这个规律。幸运的是最后我们也不需要关注它具体是多少。</p><p>在这里我们考虑几种不同的简单的H，来更加熟悉这个概念：</p><ol><li>Positive Ray</li></ol><p>样本为1维的点，这个hypothesis set是在直线上所有的非样本点，选取一个点，该点坐标之前的为positive，之后的为negative。容易看出来，当样本个数为N时候，最多可以有N+1个dichotomy（N个点将该轴分为N+1个部分，每个部分的点是一类）。</p><ol><li>Positive Intervals</li></ol><p>样本依然是1维的点，这个hypothesis set是选取一个范围，范围内的为positive，范围之外的为negative。当样本个数为N的时候，最多可以有$\frac {(N+1)N} {2}+1$个dichotomy（N个点将该轴分为N+1个部分，从N+1个部分中任两个取一个点即可，但是这样还缺一种，就是全是positive的情况，我们依然可以做到将这个情况，只需要将两次的点选在同一个部分即可）。</p><ol><li>Convex Sets</li></ol><p>样本是二维的点，并且是凸N边形的顶点。选取一个凸多边形的范围，使得多边形内部为positive，外部为negative。可以看到任何时候这个dataset都可以被H shatter，所以它的dichotomy个数是$2^N$.</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/SEKLYM%60EURGS%40%5D4F%247%5B347X.png" alt="1"></p><ol><li>1D perceptron（positive/negative ray）</li></ol><p>与1类似，除了最端点的两个部分，其他的分割之后都有个与之对立的dichotomy，而端点的部分得到的是全p或者全n，所有是$2(N+1-2)+2 = 2N$.</p><p>而这个2N，N+1等等，我们乘其为成长函数。假设我们希望用$m_H$来代替乘进去的那个集合的大小，用$m_H(N)$来表示成长函数，例如：对于positive ray来说，$m_H(N) = N+1$。</p><h2 id="Break-Point"><a href="#Break-Point" class="headerlink" title="Break Point"></a>Break Point</h2><p>我们引入一个新的定义，叫做Break Point，它表示第一个所有情况下都不能被shatter的样本个数。我们将break point简写为k，举个例子，positive ray的k = 2，因为$2+1!=2^2$，同样的道理，positive intervals的k = 3，1D perceptron的k = 3，convex sets的k不存在。</p><p>如果用2D perceptron为例，他的k = 4，但是我们很难得到它的成长函数。我们希望它的成长函数可以是一个多项式，这样随着N的增加，$E_{in}$与$E_{out}$还是会很大可能相差不多的。</p><p>找不到成长函数，另一个希望是可以找到成长函数的上限。比如，在k = 4的情况下，N个样本最多能产生几个dichotomy？我们将这个简写为B(N,k).<br>k = 4，意味着任意3个样本都不能被shatter。我们试图去填写下面这样的一个表格：</p><div class="table-container"><table><thead><tr><th>B(N,k)</th><th style="text-align:center">1</th><th style="text-align:center">2</th><th style="text-align:center">3</th><th style="text-align:center">4</th><th style="text-align:center">5</th><th style="text-align:center">…</th><th>N</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">…</td><td>2</td></tr><tr><td>2</td><td style="text-align:center">1</td><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">4</td><td style="text-align:center">4</td><td style="text-align:center">…</td><td>4</td></tr><tr><td>3</td><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center">7</td><td style="text-align:center">8</td><td style="text-align:center">8</td><td style="text-align:center">…</td><td>8</td></tr><tr><td>4</td><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">15</td><td style="text-align:center">16</td><td style="text-align:center">…</td><td>16</td></tr><tr><td>5</td><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">31</td><td style="text-align:center">…</td><td>32</td></tr></tbody></table></div><p>表格中的已经填写的部分我们很容易就知道了，如果N &lt; k，那么可以shatter，答案就是$2^N$，如果N = k，那么恰好不能shatter，所以最多就是$2^N-1$,接下来我们尝试一个简单的,N = 3,k = 2的情况。我们一个个列举所看到的情况，很容易发现最多最多，可以写出4个dichotomy，任意两个都没有被shatter,如下：</p><p>o o o</p><p>o o x</p><p>o x x</p><p>x o o </p><p>我们再添加任何一种，都会导致有两个样本被shatter。</p><p>将 4 填入表中后，我们发现了一个有趣的规律，在已经填好的数据里，任何一个$B(N,k) = B(N-1,k)+B(N-1,k-1)$，不知道这是否是个巧合？</p><p>利用程序$^{见p.s1.}$将B(4,3)的情况跑出来，发现B(4,3)=11:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">11</span><br><span class="line">[0, 0, 0, 0]</span><br><span class="line">[1, 0, 0, 0]</span><br><span class="line">[0, 1, 0, 0]</span><br><span class="line">[1, 1, 0, 0]</span><br><span class="line">[0, 0, 1, 0]</span><br><span class="line">[1, 0, 1, 0]</span><br><span class="line">[0, 1, 1, 0]</span><br><span class="line">[0, 0, 0, 1]</span><br><span class="line">[1, 0, 0, 1]</span><br><span class="line">[0, 1, 0, 1]</span><br><span class="line">[0, 0, 1, 1]</span><br></pre></td></tr></table></figure></p><p>我们将0标为negative，1标为positive，经过整理可以得到下面的样子：</p><p>2α</p><script type="math/tex; mode=display">\begin{Bmatrix}X & X & X & X \\X & X & X & O \\X & X & O & X \\X & X & O & O \\X & O & X & X \\X & O & X & O \\O & X & X & X \\O & X & X & O\end{Bmatrix}</script><p>β</p><script type="math/tex; mode=display">\begin{Bmatrix}O & O & X & X \\O & X & O & X \\X & O & O & X \end{Bmatrix}</script><p>首先，前2α中每一组种每个dichotomy前3个是一致的，因此只看前3列，$\alpha + \beta \leq B(3,3)$，再看前α组的第一行的前3个，它们每两个必然不能shatter，否则加上第四列的就会出现3个样本被shatter的情况，因此$\alpha \leq B(3,2)$.</p><p>总的来说共有$2\alpha + \beta$种，它是小于等于B(3,3)+B(3,2)的。推广到更大的N，这个也依然是成立的，我简单说明一下其中的道理：</p><p>B(N-1,k-1)的dichotomy每个后面都增加一个O或者X，那么个数会翻倍，而且可以shatter的样本个数加一，这就是B(N,k)的一部分，其余部分的前N-1个元素不会出现相同的情况，如果相同，则前N-1个元素与之前的2*B(N-1,k-1)个必然会有k-1个被shatter，加上最后的一列会有k个被shatter，这与前提是矛盾的，而且剩余的个数是小于$B(N-1,k) - B(N-1,k-1)$的，不然依然会与条件矛盾。</p><p>因此，我们可以填满这张表格了：</p><div class="table-container"><table><thead><tr><th>B(N,k)</th><th style="text-align:center">1</th><th style="text-align:center">2</th><th style="text-align:center">3</th><th style="text-align:center">4</th><th style="text-align:center">5</th><th style="text-align:center">…</th><th>N</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">…</td><td>2</td></tr><tr><td>2</td><td style="text-align:center">1</td><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">4</td><td style="text-align:center">4</td><td style="text-align:center">…</td><td>4</td></tr><tr><td>3</td><td style="text-align:center">1</td><td style="text-align:center">4</td><td style="text-align:center">7</td><td style="text-align:center">8</td><td style="text-align:center">8</td><td style="text-align:center">…</td><td>8</td></tr><tr><td>4</td><td style="text-align:center">1</td><td style="text-align:center">5</td><td style="text-align:center">11</td><td style="text-align:center">15</td><td style="text-align:center">16</td><td style="text-align:center">…</td><td>16</td></tr><tr><td>5</td><td style="text-align:center">1</td><td style="text-align:center">6</td><td style="text-align:center">16</td><td style="text-align:center">26</td><td style="text-align:center">31</td><td style="text-align:center">…</td><td>32</td></tr></tbody></table></div><p>那么B(N,k) = B(N-1,k-1) +B(N-1,k) ,利用上面的表格一路上去，我们可以使用数学归纳法证明下式成立：</p><script type="math/tex; mode=display">B(N,k) \leq \sum _{i=0} ^{k-1} C_N^i</script><p>实际上等号也是成立的，但是证明需要更加复杂的数学理论。</p><p>而$C_N^i$的上限是$N^i$，那么$B(N,k)$首项最高项就是$N^{k-1}$，这是一个好消息，因为它的增长速度不够快。所以$m_H(N)$我们可以使用$N^{k-1}$来代替了（当$N \leq 2,k \leq 3$时）。</p><p>但是它能否直接带入原来的不等式呢？还是有点问题，实际上，我们无法保证</p><script type="math/tex; mode=display">P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|>\epsilon] \leq 2 m_H(N) e^{-2\epsilon ^2N}</script><p>我们最终得到的是下面的样子：</p><script type="math/tex; mode=display">P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|>\epsilon] \leq 2 \cdot 2 m_H(2N) \cdot e^{-2 \cdot \frac 1 {16} \epsilon ^2 N}</script><p>严格的证明需要很高的数学技巧以及数学理论，但是可以从以下3个方向简单解释下原因：</p><h4 id="1-finite-E-in-and-infinite-E-out"><a href="#1-finite-E-in-and-infinite-E-out" class="headerlink" title="1. finite $E_{in}$ and infinite $E_{out}$"></a>1. finite $E_{in}$ and infinite $E_{out}$</h4><p>我们的这些证明都是在只考虑了$E_{in}$的基础上，在泛化的过程中是有问题的。首先，对于dataset，$E_{in}$的个数是有限的，因为只要有break point，我们一定可以根据N与k找到h种类的上限，但是$E_{out}$的个数是无限的。虽然同一类h它们的$E_{in}$可能一致，但是它们的$E_{out}$并不一致。</p><p>如何对付这个无限的$E_{out}$？我们可以再从总体种抽出一个数目为N的dataset，它用H得到的错误率记为$E’_{in}$，然后我们用$E_{in}$与$E’_{in}$来解决这个问题，因为同样，$E’_{in}的个数是有限的$。</p><p>从下图中可以看出来，当$|E_{in}-E_{out}| \geq \epsilon$时候，$|E_{in}-E’_{in}| \geq \epsilon$的概率大概为1/2，当然可能会更大。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/XU%5DTY%7DQ%24SSE4X%40B%24_A1ZORN.png" alt=""></p><p>不过实际上的其他情况下，$|E_{in}-E’_{in}| \geq \epsilon$也是有可能会发生的，因此</p><script type="math/tex; mode=display">\frac 1 2 P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)| > \epsilon] \leq P[∃h \ln H s.t. |E_{in}(h) - E'_{in}(h)| > \frac {\epsilon} 2]</script><p>为什么要对${\epsilon}$除以2，我也不清楚。$E_{out}$是无限的，如果$E_{out}$与$E_{in}$是一一对应的关系，那么不除以二上式也是成立的。也许因为是更严格的数学限制，但是不管怎么说经过复杂的数学证明（超出我的能力界限，交给统计学家与数学家吧），上式一定是成立的。</p><p>因此我们将无限的换成了有限的，这样离终点就进了一步。我们可以携程下面的样子：</p><p>$P[Baddata] \leq 2P[∃h \ln H s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$</p><h4 id="2-decompose-H-by-kind"><a href="#2-decompose-H-by-kind" class="headerlink" title="2. decompose H by kind"></a>2. decompose H by kind</h4><p>这一步，需要使用$m_H(N)$来处理上式的$∃h \ln H$，但是值得注意的是，因为我们后来又取了N个样本来做$E’_{in}$，因此所有的样本量是2N，需要替换为$m_H(2N)$,得到下面的结果：</p><p>$P[Baddata] \leq 2 m_H(2N) P[fixed h s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$</p><h4 id="3-hoeffding-without-replacement"><a href="#3-hoeffding-without-replacement" class="headerlink" title="3. hoeffding without replacement"></a>3. hoeffding without replacement</h4><p>第三个，就要用来处理$P[fixed h s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$了。实际上，我们可以将上式写成下面的样子：</p><script type="math/tex; mode=display">P[fixed h s.t. |E_{in}(h) - \frac {E'_{in}(h)+E_{in}(h)} 2 | > \frac {\epsilon} 4 ]</script><p>仔细观察，上面其实就是hoeffding不等式的一种，只不过这时候的bin不是无限大了，但是最后结果是一样的。（从2N个抽出N个，算出错误的比率，与实际上2N的错误的比率的差）（<font color="red">实际上我对这个解释是存有疑虑的，这个随机抽出2N个应该是从整体出发的，而不是从2N个中抽出来N个，算这个期望差，也许可以从数学上证明二者概率是一致的吧</font>）。</p><p>代入hoeffding不等式可以得到最终的结果：</p><script type="math/tex; mode=display">P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|>\epsilon] \leq 2 \cdot 2 m_H(2N) \cdot e^{-2 \cdot \frac 1 {16} \epsilon ^2 N}</script><p>这就是对怎么得到最终结果的简单的说明。严格的证明是非常复杂的。不过我们好歹似乎明白了那么一点点其中的道理。</p><h2 id="VC-bound"><a href="#VC-bound" class="headerlink" title="VC bound"></a>VC bound</h2><p>上面的简单证明得到的结果，叫做Vapnik Chervonenkis Bound，简称为VC bound。</p><p>引入一个新的定义，叫做VC dimension，它的定义与break point非常类似，VC dimension = k - 1，也就是最后一个可以在某种dataset下被shatter的dataset的大小。</p><p>现在我们尝试推算一下 perceptrons 的 VC dimension.</p><p>对于1维的来说很简单， 它的VC dimension 是 2.</p><p>对于2维的来说，由之前的也可以得到是 3.</p><p>那么对于d维的perceptron，我们可以猜测，它的vc dimension 难道是 d+1吗？</p><p>为了证明V(d) = d+1,我们需要证明两点：1. $V(d) \geq d+1$ 2. $ V(d) \leq d+1$.</p><p><strong>证明$V(d) \geq d+1$：</strong></p><p>首先，构造下面一个d+1*d+1的矩阵：</p><script type="math/tex; mode=display">\begin{bmatrix}1&0&0&0&0&...&0 \\1&1&0&0&0&...&0 \\1&0&1&0&0&...&0 \\...\\1&0&0&0&0&...&1\end{bmatrix}</script><p>上述矩阵每一行都是一个样本的，是d维的，不过会加上额外的$x_0$维度。<br>共有d+1个样本。</p><p>回想perceptron，$XW = Y$(在本例中),而上述矩阵是可逆的，则$W = YX_{-1}$，因此不管Y怎么变，都有W可以使得它成立，因此至少上面的这个dataset可以被H shatter，所有$V(d) \geq d+1$.</p><p><strong>证明$V(d) \leq d+1$：</strong></p><p>为了证明上式，我们要再加入一个样本，证明无论如何d+2个样本是不能被shatter的。</p><p>我们再上面的矩阵里再加一个非零的行向量$X_{d+2}$，那么由线性代数可以知道:</p><script type="math/tex; mode=display">X_{d+2} = \sum _{i = 1}^{d+1} a_iX_i</script><p>因此 $X_{d+2}W = \sum _{i = 1}^{d+1} a_iX_iW$.</p><p>则 y = $\{sign(a_1),sign(a_2),…sign(a_{d+1}) ,-1 \}$这种情况就一定是不能生成的($a_iX_iW$后每一项都是大于等于0的)。<br>所以d+2个样本是无法被shatter的.</p><p>如果前d+1个样本都不能被shatter，就更不用说d+2个可以被shatter了。</p><p>所以我们可以得到，V(d) = d+1.</p><p>VC dimension 实际上是自由度，一般来说，它是互不依赖的可以变动的参数个数（并不一定总是这样）。</p><h2 id="Interpreting-of-VC-dimension"><a href="#Interpreting-of-VC-dimension" class="headerlink" title="Interpreting of VC dimension"></a>Interpreting of VC dimension</h2><p>Hoeffding 告诉我们坏事情发生的概率，我们现在反推，好事情发生的概率，很简单如下：</p><p>$P[|E_{in}(g) - E_{out}(g)|&lt; \epsilon ] \geq 1 -  4(2N)^{d_{vc}}e^{- \frac 1 8 \epsilon ^2 N} $</p><p>如果将大于等于后复杂的那一部分（VC bound）列为$\delta$，那么经过推算可以得到：</p><script type="math/tex; mode=display">\epsilon = \sqrt {\frac 8 N \ln  {(\frac {4(2N)^{d_{vc}}} {\delta })}}</script><p>那么我们可以在$1 - \delta$的概率下获得保证$E_{out}$在这个范围内：</p><script type="math/tex; mode=display">\left [ E_{in}(g) - \sqrt {\frac 8 N \ln {(\frac {4(2N)^{d_{vc}}} {\delta })}}, E_{in}(g) + \sqrt {\frac 8 N \ln {(\frac {4(2N)^{d_{vc}}} {\delta })}} \right ]</script><p>我们比较重视右边的部分，也就是$E_{out}$最坏是多少。我们称$\sqrt {…}$为penalty for model complexity，记为${\Omega (N,H,\delta)}$.</p><p>一般来说，有个以下的关系图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/M%29P32DW%29EE9%7BWB%246A08T8%29X.png" alt=""></p><p>从上面可以看出来，如果样本个数一定而且保证很高的probability，一味增加维度（增加新的特征）可能会出现过拟合的情况，因为它增加了模型复杂度。这启发了我们在机器学习时候不一定非要增加过多的特征量，或者一味地去降低$E_{in}$，从而导致泛化能力不强。</p><p>此外，我们还需要注意一点，如果我们利用VC bound去求所需要的数据量，往往得到一个很大的值，但是实际上一般来说只要10$d_{vc}$就差不多足够了，这说明VC bound是很宽松的。因为我们一直取的都是上限，但是我们也很难在包容这么多分布的情况下找到一个更好的界限。</p><p>到这里，就说的差不多了，我们证明了如果有VC dimension，那么在N足够大的情况，可以取得不错的学习效果。同时也启发了以后我们在机器学习上的一些做法。</p><h2 id="p-s"><a href="#p-s" class="headerlink" title="p.s."></a>p.s.</h2><ol><li><p>用程序生成B(4,3)，我使用的是很简单的程序，但是应该可以证明这样生成的dichotomy个数就是最大的个数。程序如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">(result,l)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> in_a <span class="keyword">in</span> [[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]:</span><br><span class="line">        exist = [<span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">8</span>)]</span><br><span class="line">        size = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            temp = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> bit <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                temp+=(i[in_a[bit]]&lt;&lt;bit)</span><br><span class="line">            <span class="keyword">if</span> exist[temp] == <span class="number">0</span>:</span><br><span class="line">                exist[temp] = <span class="number">1</span></span><br><span class="line">                size+=<span class="number">1</span></span><br><span class="line">        temp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> bit <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            temp += (l[in_a[bit]] &lt;&lt; bit)</span><br><span class="line">        <span class="keyword">if</span> exist[temp] == <span class="number">0</span>:</span><br><span class="line">            exist[temp] = <span class="number">1</span></span><br><span class="line">            size += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> size == <span class="number">8</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">four_three</span><span class="params">()</span>:</span></span><br><span class="line">    l = []</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">16</span>):</span><br><span class="line">        temp = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">            temp.append((i&gt;&gt;j)&amp;<span class="number">1</span>)</span><br><span class="line">        l.append(temp)</span><br><span class="line"></span><br><span class="line">    result.append(l[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">16</span>):</span><br><span class="line">        <span class="keyword">if</span> check(result,l[i]):</span><br><span class="line">            result.append(l[i])</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    result = four_three()</span><br><span class="line">    print(len(result))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">        print(i)</span><br></pre></td></tr></table></figure></li><li><p>hoeffding不等式是无需知道数据分布情况的，也就是对于任何分布它都适用，这也是为何VC bound很宽松的一个原因。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）作业1</title>
      <link href="/2018/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A1/"/>
      <url>/2018/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A1/</url>
      
        <content type="html"><![CDATA[<p>总共20道题目。<a id="more"></a></p><p><strong>1. Which of the following problems are best suited for machine learning?</strong></p><p>(i) Classifying numbers into primes and non-primes</p><p>(ii) Detecting potential fraud in credit card charges</p><p>(iii) Determining the time it would take a falling object to hit the ground</p><p>(iv) Determining the optimal cycle for traffic lights in a busy intersection</p><p>(v) Determining the age at which a particular medical test is recommended</p><p>这个题目比较简单，其中1和3很明显不是机器学习问题，我们清楚质数与非质数的规则，也知道物体下落公式，不需要机器去学习，其他正确，答案是2，4，5.</p><p>For Questions 2­-5, identify the best type of learning that can be used to solve each task below.</p><p><strong>2. Play chess better by practicing different strategies and receive outcome as feedback.</strong></p><p>reinforcement learning———加强学习，因为需要不断加强，学习过程是连续的。</p><p><strong>3. Categorize books into groups without pre-defined topics.</strong></p><p>unsupervised learning————很明显是无监督学习。</p><p><strong>4. Recognize whether there is a face in the picture by a thousand face pictures and ten thousand non­face pictures.</strong></p><p>supervised learning————数据已经标好标签。</p><p><strong>5. Selectively schedule experiments on mice to quickly evaluate the potential of cancer medicines.</strong></p><p>active learning————实验的次数是有限的，可能无法做出海量次数的实验，因此需要根据少数实验结果（即部分样本有标签），这实际上是半监督学习的一种，当遇到机器无法决断的时候再去人工标签，也就是主动学习。</p><p>Question 6-8 are about Off-Training-Set error.</p><p>6.<img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/B%247SX%5BIV_SSX4LWNA%5BO7%7EM6.png" alt="6"></p><p>这个题目中样本$x_1,…x_n$为训练集，而其余L个为测试集。正确的分类是所有的都是+1，而我们得到的$g(x)$是样本中下标为奇数的是+1，也就是大概会错一半。具体错多少？<br>总体样本错的也就是⌊$\frac {N+L} 2​​$⌋，而除去训练集中会错的⌊$\frac {N} 2​​$⌋答案是第五个。</p><p><strong>7. We say that a target function $f$ can “generate” $\mathcal{D}$ in a noiseless setting if $f(x_n)=y_n$​ for all ($x_n$, $y_n$) $\in \mathcal{D}$.<br>For all possible f$ \colon \mathcal{X} \rightarrow \mathcal{Y}$, how many of them can generate $\mathcal{D}$ in a noiseless setting?</strong></p><p>这个题目意思容易让人曲解，实际上问的是外面测试集大小为L，那么有多少种可能的f，f满足D中的样本，但是对于测试集中是无所谓的，因此可能的f有$2^L$个。</p><p>8.<img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/22%24ZSJYPDBCLC0U%7EC7%7DP87Q.png" alt="8"><br>这个题目主要在考察的是NFL定理。如果所有可以generateD的f是等概率的，也就是对于测试集中样本的+1，-1是完全随机的，那么所有学习算法得到的误差期望都是一致的。所以选2.</p><p>For Questions 9-12, consider the bin model introduced in class. </p><p><strong>9. Consider a bin with infinitely many marbles, and let μ be the fraction of orange marbles in the bin, and ν is the fraction of orange marbles in a sample of 10 marbles. If μ=0.5, what is the probability of ν=μ?</strong></p><p>这是一道比较简单的概率题。u = 0.5，求选出10个出来有5个是橘色的概率。因为这个仓库箱子里弹珠的个数是无穷的，所以即使不放回，每次取出来依然近似于独立重复实验。则<br>$p = C_{10}^5 {\frac 1 2}^{10} \approx 0.246$.</p><p><strong>10. If μ=0.9, what is the probability of ν=μ?</strong></p><p>与上面类似：$p = C_{10}^9 {0.9}^9 \times 0.1 \approx 0.387$.</p><p><strong>11. If μ=0.9, what is the actual probability of ν≤0.1?</strong></p><p>这个问题就上面来说稍微复杂了一点，但是也不难。v≤0.1也就是10个中抽到了1个或者0个。<br>$p = C_{10}^9 {0.9}^1 \times 0.1^9 + C_{10}^{10} {0.1}^{10} = 9.1 \times 10^{-9}$.</p><p><strong>12. If μ=0.9, what is the bound given by Hoeffding’s Inequality for the probability of ν≤0.1?</strong></p><p>由题目可以知道$\epsilon$ = 0.8,带入公式可以得到概率上界为$2e^{-12.8} \approx 5.52 \times 10^{-6}$</p><p>Questions 13­-14 illustrate what happens with multiple bins using dice to indicate 6 bins. Please note that the dice is not meant to be thrown for random experiments in this problem. They are just used to bind the six faces together. The probability below only refers to drawing from the bag.</p><p><strong>13. Consider four kinds of dice in a bag, with the same (super large) quantity for each kind.</strong></p><p>A: all even numbers are colored orange, all odd numbers are colored green</p><p>B: all even numbers are colored green, all odd numbers are colored orange</p><p>C: all small (1~­3) are colored orange, all large numbers (4­~6) are colored green</p><p>D: all small (1­~3) are colored green, all large numbers (4~­6) are colored orange</p><p>If we pick 5 dice from the bag, what is the probability that we get 5 orange 1’s?</p><p>简单翻译下题目：袋子里有4种骰子，第一种2，4，6面为橘色，第二种1，3，5面为橘色，第三种1，2，3面为橘色，第四种4，5，6面为橘色。4种筛子比例相同，骰子数目很多。第一道题目问到，拿5个骰子出来，5个骰子第一面都是橘色的概率？</p><p>1面是橘色，我们可以将上面4类分成2类了，其中第二与第三合并，每次取出来1面为橘色的概率是0.5，所以5个都是的概率是$\frac 1 {32}$。</p><p><strong>14. If we pick 5 dice from the bag, what is the probability that we get “some number” that is purely orange?</strong></p><p>我们拿出5个骰子，至少有一面全部都是橘色的概率。</p><p>这个就是稍微复杂的一个问题。首先观察骰子种类，我们发现，只要第一种与第二种碰面，或者第三种与第四种碰面，那么就不可能有一面全都是橘色。所以我们要求的就是上面两种情况不发生的概率。</p><p>如果抽出的5个骰子，占了4种骰子种的3种或者4种，那么上面的情况至少会有一种会发生。<br>而取5次取出3种的情况有2 2 1与 3 1 1两种可能。</p><p>首先，从4种里选3种出来$C_4^3$,其次，考虑2 2 1的情况$C_5^2C_3^2$,而2 2 1又会有3种分布，因此2 2 1的所有可能情况是$3C_4^3C_5^2C_3^2 = 360$.</p><p>3 1 1与上述类似$3C_4^3C_5^3C_2^1 = 240$.</p><p>然后考虑从4种取4种的情况，只会有一种分布：1 1 1 2，可以得到$4C_5^2C_3^1C_2^1 = 240$.</p><p>最后我们就要考虑到从4种中取出来两种，而且恰好是第一种与第二种，或者第三种与第四种的概率。骰子有两种的次数分布有2种情况：1 4，2 3.</p><p>1 4: 2$C_5^4 = 10$</p><p>2 3: $2C_5^3 = 20$</p><p>考虑到第一种与第二种，第三种与第四种，因此结果还应乘2，最后结果是：60.</p><p>所以，所有不符合的情况共有240+240+60+360 = 900，因此这道题目最后结果是$1 - \frac {900} {4^5} = \frac {31} {256}$.</p><p>For Questions 15-20, you will play with PLA and pocket algorithm. </p><p>15-20为编程题目，需要自己写代码验证，然后得到结果。</p><p><strong>15.  First, we use an artificial data set to study PLA. The data set is in<br><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_15_train.dat" target="_blank" rel="noopener">data</a>.Each line of the data set contains one ($\mathbf{x}_n, y_n$) with $\mathbf{x}_n \in \mathbb{R}^4$. The first 4 numbers of the line contains the components of $\mathbf{x}_n$ orderly, the last number is $y_n$.<br>Please initialize your algorithm with $\mathbf{w} = 0$ and take $sign(0)$ as -1. Please always remember to add $x_0 = 1$ to each $\mathbf{x}_n​$.Implement a version of PLA by visiting examples in the naive cycle using the order of examples in the data set. Run the algorithm on the data set. What is the number of updates before the algorithm halts?</strong></p><p>a.&lt;10 updates</p><p>b.11 - 30 updates</p><p>c.31 - 50 updates</p><p>d.$\geq$ 201 updates</p><p>e.51 - 200 updates</p><p>这道题目只需要应用上次实现的PLA算法，需要额外做的是数据的读取。在数据读取时候我运用了正则表达式来进行分割，整个过程整合在一个叫做readDataFrom函数中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataFrom</span><span class="params">(filename)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    separator = re.compile(<span class="string">'\t|\b| |\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(filename,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline()</span><br><span class="line">        <span class="keyword">while</span> line:</span><br><span class="line">            temp = separator.split(line)[<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">            abc = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> temp]</span><br><span class="line">            result.append(abc)</span><br><span class="line">            line = f.readline()</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p><p>最后得到结果是修正了61次。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修正次数： 61</span><br></pre></td></tr></table></figure></p><p><strong>16. Implement a version of PLA by visiting examples in fixed, pre-determined random cycles throughout the algorithm. Run the algorithm on the data set. Please repeat your experiment for 2000 times, each with a different random seed. What is the average number of updates before the algorithm halts?</strong></p><p>a.&lt;10 updates</p><p>b.11 - 30 updates</p><p> c.31 - 50 updates</p><p>d.$\geq$ 201 updates</p><p>e.51 - 200 updates</p><p>这个版本需要对原来的pla算法进行简单的修改，每次寻找预测错误的样本时候采用随机的顺序去寻找。对于序列进行随机的办法实现方法很简单，也就是打乱序列，做法是与随机的坐标进行交换：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomIndex</span><span class="params">(n)</span>:</span></span><br><span class="line">    index = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,n)]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">swap</span><span class="params">(l,x,y)</span>:</span></span><br><span class="line">        l[x] = l[x]+l[y]</span><br><span class="line">        l[y] = l[x] - l[y]</span><br><span class="line">        l[x] = l[x] - l[y]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,n):</span><br><span class="line">        swap(index,i,int(random.random()*n))</span><br><span class="line">    <span class="keyword">return</span> index</span><br></pre></td></tr></table></figure></p><p>应用上面的函数生成随机打乱的序列，然后代替顺序查找，运行2000次平均修正次数如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修正次数： 61.3933</span><br></pre></td></tr></table></figure></p><p>**17. Implement a version of PLA by visiting examples in fixed, pre-determined random cycles throughout the algorithm, while changing the update rule to be </p><script type="math/tex; mode=display">\mathbf{w}_{t+1} \leftarrow \mathbf{w}_t +\eta y_{n(t)}\mathbf{x}_{n(t)}</script><p>with η=0.5. Note that your PLA in the previous Question corresponds to η=1. Please repeat your experiment for 2000 times, each with a different random seed. What is the average number of updates before the algorithm halts?**<br>a.&lt;10 updates</p><p>b.11 - 30 updates</p><p>c.31 - 50 updates</p><p>d.$\geq$ 201 updates</p><p>e.51 - 200 updates</p><p>只需要对上述算法进行简单改动即可.运行2000次后平均修正次数如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修正次数： 63.532</span><br></pre></td></tr></table></figure></p><p><strong>18. Next, we play with the pocket algorithm. Modify your PLA in Question 16 to visit examples purely randomly, and then add the “pocket” steps to the algorithm. We will use <a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_18_train.dat" target="_blank" rel="noopener">train</a> as the training data set $\mathcal{D}$, and <a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_18_test.dat" target="_blank" rel="noopener">test</a> as the test set for “verifying’’ the gg returned by your algorithm (see lecture 4 about verifying). The sets are of the same format as the previous one. Run the pocket algorithm with a total of 50 updates on $\mathcal{D}$ , and verify the performance of $\mathbf{w}_{POCKET}$ using the test set. Please repeat your experiment for 2000 times, each with a different random seed. What is the average error rate on the test set?</strong></p><p>a. &lt;0.2</p><p>b. 0.2 - 0.4</p><p>c. 0.4 - 0.6</p><p>d. $\geq$ 0.8</p><p>e. 0.6 - 0.8</p><p>这个题目需要实现pocket算法。pocket算法之前没有介绍，因为它和pla很像，只是pla算法的一个变形。因为我们无法保证数据一定是线性可分的，为此我们每次遇到错误更新后，与之前的w进行对比，如果错误率更低，再更新这个参数，同时pla算法选择错误的样本时候是随机顺序选择的，从之前的代码验证中我们也发现了随机对于减小修正次数来说是有好处的（但是生成随机序列同样也会带来额外开销）。</p><p>实现pocket算法只需要多加几行代码以及做少量改动，这里就不列出来了。值得注意的是需要添加一个新的函数，进行错误评估：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeER</span><span class="params">(para,datas)</span>:</span></span><br><span class="line">    size = len(datas)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> size &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    dms = len(datas[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> dms == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, size):</span><br><span class="line">        p = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, dms - <span class="number">1</span>):</span><br><span class="line">            p += para[x] * datas[i][x]</span><br><span class="line">        p += para[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> p &lt;= <span class="number">0</span> <span class="keyword">and</span> datas[i][<span class="number">-1</span>] &gt; <span class="number">0</span> <span class="keyword">or</span> p &gt; <span class="number">0</span> <span class="keyword">and</span> datas[i][<span class="number">-1</span>] &lt; <span class="number">0</span>:<span class="comment">#ignore </span></span><br><span class="line">            count=count+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count/size</span><br></pre></td></tr></table></figure></p><p>下面是运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">平均错误率： 0.12437000000000001</span><br></pre></td></tr></table></figure></p><p><strong>19. Modify your algorithm in Question 18 to return $\mathbf{w}_{50}$ (the PLA vector after 5050 updates) instead of $\hat{\mathbf{w}}$ (the pocket vector) after 50 updates.Run the modified algorithm on $\mathcal{D}$, and verify the performance using the test set.Please repeat your experiment for 2000 times, each with a different random seed. What is the average error rate on the test set?</strong></p><p>a. &lt;0.2</p><p>b. 0.2 - 0.4</p><p>c. 0.4 - 0.6</p><p>d. $\geq$ 0.8</p><p>e. 0.6 - 0.8</p><p>这个算法返回pla向量。运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">平均错误率： 0.3666599999999999</span><br></pre></td></tr></table></figure></p><p><strong>20. Modify your algorithm in Question 18 to run for 100 updates instead of 50, and verify the performance of \$mathbf{w}_{POCKET}$ ​using the test set. Please repeat your experiment for 2000 times, each with a different random seed. What is the average error rate on the test set?</strong></p><p>a. &lt;0.2</p><p>b. 0.2 - 0.4</p><p>c. 0.4 - 0.6</p><p>d. $\geq$ 0.8</p><p>e. 0.6 - 0.8</p><p>很简单的改动，运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">平均错误率： 0.10796000000000007</span><br></pre></td></tr></table></figure></p><h2 id="Note："><a href="#Note：" class="headerlink" title="Note："></a>Note：</h2><ol><li><p><em>刚开始对pocket算法的理解有误，以为wt的更新是每次都对pocket中的w为基准的，实际上它就是正常的pla算法运行的过程，仔细思考这样确实比原来的算法更快。第二，pocket算法中随机选取错误意味着每次都要随机打乱样本，这样可以获得更低的错误率。</em></p></li><li><p><em>python不支持i++,++i这种操作，但是，为何不报错…</em></p></li><li><p><em>list直接赋值只是对源对象进行了引用，同时有浅拷贝与深拷贝之分。这个狠狠地坑了我一把。</em></p></li><li><p>15，16，17题目前运行依然是60多次.答案是31到50。———<br>更新于8.8。 我忽略了cycle这个词，也就是找错误的过程应该从上次断掉的地方继续开始，更新后得到正确的结果。<br>受到影响的代码重新跑了一遍：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">15. 修正次数： 46</span><br><span class="line">16. 修正次数： 40.867</span><br><span class="line">17. 修正次数： 41.5105</span><br></pre></td></tr></table></figure></li></ol><p>代码上传至<a href="https://github.com/MyEvolution/PLA" target="_blank" rel="noopener">github</a>，修改了上次可视化的内容，不过只是修改了接口内容。</p><p>代码几乎没怎么写注释，这是需要改进的地方。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Hoeffding不等式</title>
      <link href="/2018/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Hoeffding%E4%B8%8D%E7%AD%89%E5%BC%8F/"/>
      <url>/2018/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Hoeffding%E4%B8%8D%E7%AD%89%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>这次用霍夫丁不等式来证明学习的可行性。首先要说明一个定理，叫做“No Free Lunch”定理。如果真是需要预测的值是完全随机的情况下，我们无论最后建立一个什么样的模型，误差期望都是一致的。这样学习似乎是不可行的。<a id="more"></a>但是实际上，事物都有自己的规律。我们可以套用霍夫丁不等式来说明，在某个验证集上这个模型的准确率是p，那么在总体上它预测的实际准确率很大可能与p是相差不大的（Probably Approximately Correct）。</p><p>Hoeffding不等式：$P[\nu  - \upsilon|&gt; \epsilon ] \leq 2 e^{-2\epsilon ^2N}$</p><p>其中$\nu$是我们测的期望，而$\upsilon$是真实期望，这是未知的，N是测试抽取的样本数量，而$\epsilon$是我们可以容忍的误差值，因此实际上也就是$\upsilon ∈ [\nu - \epsilon , \nu + \epsilon]$的概率是大于等于$2 e^{-2\epsilon ^2N}$的，也就是置信区间与置信度的关系。</p><p>因此霍夫丁不等式对独立随机变量的和与其期望值偏差的概率上限。</p><p>从另一个简单的例子来说：假如我们有一个罐子里装了红球和绿球，我们想要测的是红球的占比。每次取出N个球，则这N个球中红球占比为$\nu$，而总体红球占比为$\upsilon$，我们假设可以接受的误差范围为$\epsilon$，那么这几个量满足霍夫丁不等式。总体球中取出N个有m中不同的组合，而这些组合中红球占比误差很大的组合占了所有组合的比重是小于$2 e^{-2\epsilon ^2N}$的。而这些误差很大的样本组合就是所谓的Bad Data。因为从它测出来的值与实际值偏差很大。</p><p>从另一方面来讲，如果我们测试的数目足够多，依然很有可能选到错误样本。就像你我是天才的概率很小，但这个世界总会出现天才。用霍夫丁不等式来说，假如我们测试了t次，那么出现一次bad data 的概率是小于$2te^{-2\epsilon ^2N}$，为什么可以简单相加？如下：</p><p>假如一件事发生的概率是p，那么n次它至少发生一次的概率是$1-(1-p)^n$。</p><p> 令 $g(p) = 1- (1-p)^n - np, g’(p) = n(1-p)^{n-1} - n = n[(1-p)^{n-1} - 1];$<br> 令$g’(p) = 0$,则$p = 0;$<br> 当p$∈[0,1]$时候， $g’(p) \leq 0, g(0) = 0$,所以$g(p)\leq 0$;<br> 因此 $1- (1-p)^n \leq np$</p><p>上述是一个简单的证明，而实际上独立随机变量至少发生一件的概率是小于它们各自发生的概率之和的。在概率论中这相当于是个常识。</p><p>应用到机器学习当中，如果H是有限的，也就是我们可选假说个数是有限的，只要选取足够大的测试样本量（Hoeffding不等式中的N足够大），出现错误估计的概率依然是非常小的，该test dataset有很大的概率对每个假说都能正确评估它在总体样本上的性能，因此我们可以选择一个表现最好的来当做g，它对大多数样本都会使用，相比之下也就更接近f。</p><p>这就说明学习是可行的。</p><p>这里还有个问题：如果H的个数是无限的呢？</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Fibonacci数列——快速矩阵幂</title>
      <link href="/2018/08/01/Fibonacci%E6%95%B0%E5%88%97%E2%80%94%E2%80%94%E5%BF%AB%E9%80%9F%E7%9F%A9%E9%98%B5%E5%B9%82/"/>
      <url>/2018/08/01/Fibonacci%E6%95%B0%E5%88%97%E2%80%94%E2%80%94%E5%BF%AB%E9%80%9F%E7%9F%A9%E9%98%B5%E5%B9%82/</url>
      
        <content type="html"><![CDATA[<p>今天想起来之前一个oj题目，是求类似与斐波那契数列一个数列的第N位。那时候接触到一个算法叫快速矩阵幂。</p><p>在这里我就用斐波那契数列的列子来简单说明一下如何用快速矩阵幂来解决这个题目。<br><a id="more"></a></p><p>Fibonacci数列定义：$F(0) = 1, F(1) = 1, F(2) = 1, F(3) = 2, …… F(n) = F(n-1)+F(n-2)$</p><p>首先说明一下，因为斐波那契数列增长速度非常迅速，得到的数字可能过大，因此我们将结果对10000007（$10^7+7$）取余来进行对比。</p><h2 id="最天真的做法是用递归来解决："><a href="#最天真的做法是用递归来解决：" class="headerlink" title="最天真的做法是用递归来解决："></a>最天真的做法是用递归来解决：</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">fibNaive</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> (fibNaive(n<span class="number">-1</span>)%d+fibNaive(n<span class="number">-2</span>)%d)%d;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不用说了，算法第一步就会介绍这个反例，来说明递归效率不一定会高(他的算法的运行时间随n的增长类似与Fibonacci数列的增长)。实际上这个做法到n = 40的时候就已经可以让人等的有点急了。</p><h2 id="然后正常的做法是用简单的循环"><a href="#然后正常的做法是用简单的循环" class="headerlink" title="然后正常的做法是用简单的循环"></a>然后正常的做法是用简单的循环</h2><p>用两个数来代表之前的两个值，求出新值后继续依次更新前两个值，直到得到正确的结果：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">fibNormal</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>; </span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> last1 = <span class="number">0</span>,last2 = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> now;</span><br><span class="line">    n--;</span><br><span class="line">    <span class="keyword">while</span>(n--)</span><br><span class="line">    &#123;</span><br><span class="line">        now = (last1%d+last2%d)%d;</span><br><span class="line">        last1 = last2;</span><br><span class="line">        last2 = now;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> now;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个算法时间复杂度是$O(n)$。$O(n)$已经是一个很好的复杂度了，那还有没有办法继续加快这个过程？？</p><h2 id="快速矩阵幂"><a href="#快速矩阵幂" class="headerlink" title="快速矩阵幂"></a>快速矩阵幂</h2><p>观察斐波那契数列的生成过程，我们可以发现它们可以被写成下面的样子：</p><script type="math/tex; mode=display">F(N) = F(N-1) + F(N-2)F(N-1) = F(N-1)+0*F(N-2)</script><p>上面的式子可以写成矩阵形式：</p><script type="math/tex; mode=display">\left [\begin{matrix}F(N)\\F(N-1)\end{matrix}\right ] =\begin{bmatrix}1&1\\1&0\end{bmatrix}\begin{bmatrix}F(N-1)\\F(N-2)\end{bmatrix}</script><p>不断重复上面过程，往后继续展开，我们可以得到：</p><script type="math/tex; mode=display">\left [\begin{matrix}F(N)\\F(N-1)\end{matrix}\right ] ={\begin{bmatrix}1&1\\1&0\end{bmatrix}}^{n-1}\begin{bmatrix}F(1)\\F(0)\end{bmatrix}</script><p>因此我们可以把重点放到怎么来求中间这个矩阵的幂。而快速矩阵幂的思想也很简单，就类似与对于数字的幂的求法一致。比如：$X^9 = X^8 \cdot X$,而$X^8 = (X^4)^2 = ((X^2)^2)^2$，因此需要3+1次乘法就可以算出来8次幂，容易看出来快速矩阵幂的时间复杂度是$O(\log (n))$。<br>因此利用快速矩阵幂，可以将斐波那契数列的求法进一步加速。</p><p>至于如何实现就是细节问题了，需要注意的时候是乘法取余数的时候，两方都小于10000007,乘积依然可能会超过int的范围（10000007*10000007），导致出错，因此我在这里选择long long类型，这样可以保证结果的正确性。</p><p>实现分为几步1：定义矩阵乘法：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;&gt; Matrix;</span><br><span class="line"><span class="keyword">long</span> <span class="keyword">long</span> d = <span class="number">10000007</span>;</span><br><span class="line"><span class="function">Matrix <span class="title">m_mul</span><span class="params">(<span class="keyword">const</span> Matrix &amp;m,<span class="keyword">const</span> Matrix &amp;n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//check(m,n);</span></span><br><span class="line">    Matrix result = <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;&gt;(m.size(),<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;(n[<span class="number">0</span>].size()));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">long</span> <span class="keyword">long</span> i = <span class="number">0</span>;i!=m.size();++i)</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">long</span> <span class="keyword">long</span> j = <span class="number">0</span>;j!=n[<span class="number">0</span>].size();++j)</span><br><span class="line">    &#123;</span><br><span class="line">         <span class="keyword">long</span> <span class="keyword">long</span> temp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">long</span> <span class="keyword">long</span> k = <span class="number">0</span>;k!=n.size();++k )</span><br><span class="line">         temp = ((m[i][k]*n[k][j])%d + temp%d)%d;</span><br><span class="line">         result[i][j] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p><p>第二，定义help函数，专门对矩阵的幂为2的整数次幂来计算：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function">Matrix <span class="title">help</span><span class="params">(<span class="keyword">const</span> Matrix &amp; m,<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix result;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> m;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(n == <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> m_mul(m,m);</span><br><span class="line">    result = help(m,n/<span class="number">2</span>);</span><br><span class="line">     <span class="keyword">return</span> m_mul(result,result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>第三步，实际的quickMartrixPower函数，它实际上会将n次幂拆散为2的整数次幂之和，实际实现将n用二进制表示，如9 = (1001)$_b$。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Matrix <span class="title">quickMatrixPower</span><span class="params">(<span class="keyword">const</span> Matrix &amp;m,<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//check(m);</span></span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> np = <span class="number">1</span>;</span><br><span class="line">    Matrix result = <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;&gt; (m.size(),<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;(m.size()));</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">long</span> <span class="keyword">long</span> i = <span class="number">0</span>;i!=m.size();++i)</span><br><span class="line">    result[i][i] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(n!=<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(n&amp;<span class="number">1</span>)</span><br><span class="line">        result = m_mul(result,help(m,np));</span><br><span class="line">        n = n &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        np = np&lt;&lt;<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后用fib函数封装起来：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">fib</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">       &#123;</span><br><span class="line">           Matrix start = &#123;&#123;<span class="number">1</span>,<span class="number">1</span>&#125;,&#123;<span class="number">1</span>,<span class="number">0</span>&#125;&#125;;</span><br><span class="line">           Matrix m = quickMatrixPower(start,n<span class="number">-1</span>);</span><br><span class="line">           <span class="keyword">return</span> m[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后用main函数利用clock函数进行时间测试<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> n,result;</span><br><span class="line">    <span class="keyword">double</span> start,end;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;n)</span><br><span class="line">    &#123;</span><br><span class="line">    start = clock();</span><br><span class="line">    result = fib(n);</span><br><span class="line">    end = clock();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;result&lt;&lt;<span class="string">" "</span>&lt;&lt;end-start&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    start = clock();</span><br><span class="line">    result = fibNormal(n);</span><br><span class="line">    end = clock();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;result&lt;&lt;<span class="string">" "</span>&lt;&lt;end-start&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    start = clock();</span><br><span class="line">    <span class="keyword">if</span>(n&lt;<span class="number">45</span>)</span><br><span class="line">    &#123;</span><br><span class="line">    result = fibNaive(n);</span><br><span class="line">    end = clock();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;result&lt;&lt;<span class="string">" "</span>&lt;&lt;end-start&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>输出第一个为结果，第二个是运行的clock差值，结果如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入：<span class="number">40</span></span><br><span class="line"><span class="number">2334085</span> <span class="number">0</span></span><br><span class="line"><span class="number">2334085</span> <span class="number">0</span></span><br><span class="line"><span class="number">2334085</span> <span class="number">6956</span></span><br><span class="line">输入：<span class="number">1000000</span><span class="comment">//此时naive的算法已经无法求出来</span></span><br><span class="line"><span class="number">9640841</span> <span class="number">0</span></span><br><span class="line"><span class="number">9640841</span> <span class="number">19</span></span><br><span class="line">输入：<span class="number">100000000</span></span><br><span class="line"><span class="number">129680</span> <span class="number">0</span></span><br><span class="line"><span class="number">129680</span> <span class="number">3295</span></span><br></pre></td></tr></table></figure></p><p>可以看到快速矩阵幂算法在数据量很大的时候很牛逼。<br>不过，斐波那契数列还有个公式：</p><script type="math/tex; mode=display">F(n) = \frac{1}{\sqrt 5}{\left [ {\left ( \frac {1+\sqrt 5}{2} \right )}^n - {\left ( \frac {1-\sqrt 5}{2} \right )}^n  \right ]}</script><p>所以学计算机不如学数学啊！</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
            <tag> Matrix </tag>
            
            <tag> code </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——PLA算法实现与可视化</title>
      <link href="/2018/07/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94PLA%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
      <url>/2018/07/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94PLA%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>上次主要是证明了PLA算法的可行性，这次用来实现PLA算法，并且实现可视化。<br>这个算法的实现是比较简单的，比较难的部分在于要考虑可视化。<br><a id="more"></a><br>我选择python来实现这个算法，同时利用了matplotlib来进行图形的绘制。<br>为了可视化数据，我们需要的就不能是仅仅实现那么简单吗，而且还要考虑到可视化之后的清晰与美观。因此这部分的代码主要分成3个部分：</p><h2 id="随机生成数据"><a href="#随机生成数据" class="headerlink" title="随机生成数据"></a>随机生成数据</h2><p>数据的生成一定是要局限在某个范围内，为了简便我选择的数据特征量范围在0，20之间。而一维数据较为简单，高维数据画不出来，因此生成数据应该是二维或者三维的，以便于可视化。为了简便，我选择生成二维数据。<br>同时还要生成一组参数，作为$W_f$，也就是最初的规则，这里需要注意，随机生成的参数确定的分割线可能不会经过上述范围的数据，这样导致所有的样本都归为一类，这就失去了可视化的意义，因为生成参数时，我选择了在范围内随机生成两个点，用这两个点来确定分割线，再计算出对应的参数出来。</p><h2 id="PLA算法"><a href="#PLA算法" class="headerlink" title="PLA算法"></a>PLA算法</h2><p>pla算法没什么好说的，参数初始设为0，然后每次遇到一个坏点，就开始更正，直到没有坏点。我们需要保证传入的数据是线性可分的。</p><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>可视化使用matplotlib来实现，使用两种不同的标志（尽量区分颜色，如红x与绿o）来区分正负样本，在坐标轴上标出，并且用实线来绘制实际的规则，用虚线来绘制我们算法得到的规则。最后可以得到很明显的可视化效果。</p><h3 id="可视化结果"><a href="#可视化结果" class="headerlink" title="可视化结果"></a>可视化结果</h3><p>随机样本为20个：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%5BNJ07J%7E9%29%286ZV0%2846%28S%40%29LN.png" alt="20"><br>修正次数： 3209</p><p>随机样本为50个：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/NLYU%7EZSV%609S%29557%602RBG8%409.png" alt="50"></p><p>修正次数： 2268</p><p>随机样本为100个：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/71K%251Y%7B%7D3K1HMRY%5DR%60K%29%25E8.png" alt="100"></p><p>修正次数： 4540</p><p>从图中可以看到虽然红线不一定与蓝线重合，但是依然很好的分割了样本。实际上相重合是很困难的，样本越是多越更有可能相似，如下图，样本次数提高到1000，我们可以说推断的规则与原先的规则已经基本一致了。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EQPB1J%7B5LY%7B%5B4V%24%7BK0N6%29CU.png" alt="1000"></p><p>我们从这里看不到修正次数与样本个数之间的关系，因为本来他们关系就不够大，甚至一定程度上可以说是”运气”，但是算法终究会停止，由上一篇博客的证明也可知道，如果R与P的比值很小，那么就算数据再大，也可以很快的得到想要的规则。</p><p>下面是PLA实现的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pla</span><span class="params">(datas)</span>:</span></span><br><span class="line">    size = len(datas)</span><br><span class="line">    <span class="keyword">if</span> size&lt;=<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    err_i = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    dms = len(datas[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> dms == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    para = [<span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,dms)]</span><br><span class="line">    run_times = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line"></span><br><span class="line">        run_times+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, size):</span><br><span class="line">            p = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, dms - <span class="number">1</span>):</span><br><span class="line">                p += para[x] * datas[i][x]</span><br><span class="line">            p += para[<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">if</span> p &lt;= <span class="number">0</span> <span class="keyword">and</span> datas[i][<span class="number">-1</span>] &gt; <span class="number">0</span> <span class="keyword">or</span> p &gt;= <span class="number">0</span> <span class="keyword">and</span> datas[i][<span class="number">-1</span>] &lt; <span class="number">0</span>:<span class="comment">#ignore datas[i][-1] == 0</span></span><br><span class="line">                err_i = i;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">if</span> err_i != <span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, dms - <span class="number">1</span>):</span><br><span class="line">                para[x] += datas[err_i][<span class="number">-1</span>] * datas[err_i][x]  <span class="comment"># update the parameters</span></span><br><span class="line">            para[<span class="number">-1</span>] += datas[err_i][<span class="number">-1</span>]</span><br><span class="line">            err_i = <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">else</span>:<span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [para,run_times]</span><br></pre></td></tr></table></figure></p><p>全部python代码可以在<a href="https://github.com/MyEvolution/PLA" target="_blank" rel="noopener">PLA</a>找到。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> code </tag>
            
            <tag> machine learning </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>markdown+mathjax显示公式，苦逼的找bug过程 </title>
      <link href="/2018/07/29/markdown-mathjax%E6%98%BE%E7%A4%BA%E5%85%AC%E5%BC%8F%EF%BC%8C%E8%8B%A6%E9%80%BC%E7%9A%84%E6%89%BEbug%E8%BF%87%E7%A8%8B/"/>
      <url>/2018/07/29/markdown-mathjax%E6%98%BE%E7%A4%BA%E5%85%AC%E5%BC%8F%EF%BC%8C%E8%8B%A6%E9%80%BC%E7%9A%84%E6%89%BEbug%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>在记录自己学习过程中，难免会遇到公式，截图的办法不是长久之计。于是我给它加上了渲染公式的过程。</p><p>整个过程非常崎岖。<br><a id="more"></a></p><p>其实很简单，在普通的页面上引入一个js文件，就可以将latex代码渲染成公式。为了方便编写，我直接在文章中引入了这个js，在vs code上渲染是非常成功的。但是在博客上怎么弄也没法成功。百度的话有很多相关的博客来介绍怎么去做，主要是因为hexo的渲染器与mathjax中部分语法有冲突。我也天真的相信我的问题就是这些构成的，后来我发现即使是最简单的公式（没有下标）也无法渲染成功，此时我的blog里已经加了很多别的没用包了，也删除了很多可能有用的包，怎么设置也没办法。</p><p>昨晚就纠结了很久，今天没办法了重新装了下blog，先解决最简单公式显示的问题（直接打开next主题中的mathjax开关），成功了，然后我遇到的问题，才是别人遇到的那些问题。慢慢解决，后来发现还是有部分错误，有两处问题：</p><p>1.这次是latex与markdown的冲突：markdown中的*是斜体，因此尽量乘法不要使用它，可以使用{a \times b}（$a \times b$）来代替来代替 a*b,或者就是对*进行转义，或者直接省略。</p><p>2.在使用范式时||a||，似乎直接使用‘|’这个符号也会出错，总之有范式的地方的公式显示是很混乱的，可能也有冲突（在latex是可以直接使用这个符号的），因此使用{\Vert a \Vert}（${\Vert a \Vert}$）来代替。</p><p>最后，浏览器响应github page的速度不快，可能已经deploy了但是依然没有体现出更新的结果。</p><p>哎，折腾了一天，感觉收获远远不够花费的时间，不过我经常遇到这样的问题，找bug的能力还有待提高。</p><h2 id="P-S-Markdown与latex常用语法"><a href="#P-S-Markdown与latex常用语法" class="headerlink" title="P.S. Markdown与latex常用语法"></a>P.S. Markdown与latex常用语法</h2><h3 id="markdown语法"><a href="#markdown语法" class="headerlink" title="markdown语法"></a>markdown语法</h3><ul><li>标题：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 一号字体 #</span><br><span class="line">## 二号字体 ## </span><br><span class="line">### 三号字体 ###</span><br></pre></td></tr></table></figure><h1 id="一号字体"><a href="#一号字体" class="headerlink" title="一号字体"></a>一号字体</h1><h2 id="二号字体"><a href="#二号字体" class="headerlink" title="二号字体"></a>二号字体</h2><h3 id="三号字体"><a href="#三号字体" class="headerlink" title="三号字体"></a>三号字体</h3><ul><li>加粗：</li></ul><p>要加粗的文字左右分别用两个*号包起来</p><ul><li>斜体：</li></ul><p>要倾斜的文字左右分别用一个*号包起来</p><ul><li>斜体加粗：</li></ul><p>要倾斜和加粗的文字左右分别用三个*号包起来</p><ul><li>删除线：</li></ul><p>要加删除线的文字左右分别用两个~~号包起来</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">**这是加粗的文字**</span><br><span class="line">*这是倾斜的文字*`</span><br><span class="line">***这是斜体加粗的文字***</span><br><span class="line">~~这是加删除线的文字~~</span><br></pre></td></tr></table></figure><p><strong>这是加粗的文字</strong></p><p><em>这是倾斜的文字</em></p><p><strong><em>这是斜体加粗的文字</em></strong></p><p><del>这是加删除线的文字</del></p><ul><li>引用：</li></ul><p>在引用的文字前加&gt;即可</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; 引用的内容</span><br></pre></td></tr></table></figure><blockquote><p>引用的内容</p></blockquote><ul><li>分割线：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">***</span><br></pre></td></tr></table></figure></li></ul><hr><hr><ul><li>超链接：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[name](url)</span><br></pre></td></tr></table></figure><p><a href="https://www.google.com" target="_blank" rel="noopener">Google</a></p><ul><li>图片：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![name](imgurl)</span><br></pre></td></tr></table></figure><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_8234.PNG" alt="name"></p><ul><li>列表：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 列表内容</span><br><span class="line">+ 列表内容</span><br><span class="line">* 列表内容</span><br></pre></td></tr></table></figure><pre><code>注意：- + * 跟内容之间都要有一个空格</code></pre><ul><li>列表内容</li></ul><ul><li>列表内容</li></ul><ul><li><p>列表内容</p></li><li><p>表格：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">表头|表头|表头</span><br><span class="line">---|:--:|---:</span><br><span class="line">内容|内容2|内容</span><br><span class="line">内容|内容100|内容</span><br></pre></td></tr></table></figure><p>第二行分割表头和内容。<br>文字默认居左<br>-两边加：表示文字居中<br>-右边加：表示文字居右<br>注：原生的语法两边都要用 | 包起来。此处省略</p><div class="table-container"><table><thead><tr><th>表头</th><th style="text-align:center">表头</th><th style="text-align:right">表头</th></tr></thead><tbody><tr><td>内容</td><td style="text-align:center">内容2</td><td style="text-align:right">内容</td></tr><tr><td>内容</td><td style="text-align:center">内容100</td><td style="text-align:right">内容</td></tr></tbody></table></div><ul><li>代码：</li></ul><p><code>单行代码</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">多行代码</span><br></pre></td></tr></table></figure></p><p>vscode中前面加制表符自动为代码格式。<br>可以在标记后标记出代码语言，用来高亮：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"hello,world"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="Latex语法"><a href="#Latex语法" class="headerlink" title="Latex语法"></a>Latex语法</h3><ul><li>希腊字母：</li></ul><div class="table-container"><table><thead><tr><th>显示</th><th>命令</th><th>显示</th><th>命令</th></tr></thead><tbody><tr><td>α</td><td>\alpha</td><td>β</td><td>\beta</td></tr><tr><td>γ</td><td>\gamma</td><td>δ</td><td>\delta</td></tr><tr><td>ε</td><td>\epsilon</td><td>ζ</td><td>\zeta</td></tr><tr><td>η</td><td>\eta</td><td>θ</td><td>\theta</td></tr><tr><td>ι</td><td>\iota</td><td>κ</td><td>\kappa</td></tr><tr><td>λ</td><td>\lambda</td><td>μ</td><td>\mu</td></tr><tr><td>ν</td><td>\nu</td><td>ξ</td><td>\xi</td></tr><tr><td>π</td><td>\pi</td><td>ρ</td><td>\rho</td></tr><tr><td>σ</td><td>\sigma</td><td>τ</td><td>\tau</td></tr><tr><td>υ</td><td>\upsilon</td><td>φ</td><td>\phi</td></tr><tr><td>χ</td><td>\chi</td><td>ψ</td><td>\psi</td></tr><tr><td>ω</td><td>\omega</td><td></td></tr></tbody></table></div><p>命令首字母大写则为显示为大写。</p><ul><li>字母修饰：</li></ul><p>上标：^</p><p>下标：_</p><p>举例：C_n^2 呈现为 $C_n^2$</p><p>矢量：</p><p>\vec a呈现为 $\vec a$</p><p>\overrightarrow{xy}呈现为$\overrightarrow{xy}$</p><ul><li>分组:</li></ul><p>使用{}将具有相同等级的内容扩入其中，成组处理</p><p> 举例：10^{10}呈现为$10^{10}$，而10^10呈现为$10^10$</p><ul><li>括号：<br>小括号：()呈现为()<br>中括号：[]呈现为[]<br>尖括号：\langle,\rangle呈现为$\langle,\rangle$</li></ul><p>大括号为与分组符号{}相区别，使用转义字符\</p><p>使用\left(或\right)使符号大小与邻近的公式相适应；该语句适用于所有括号类型</p><p>(\frac{x}{y})呈现为$(\frac{x}{y})$</p><p>而\left(\frac{x}{y}\right)呈现为$\left(\frac{x}{y}\right)$</p><ul><li>求和：</li></ul><p>求和符号\sum显示为$∑$</p><p>举例:\sum_{i=0}^n 显示为 $\sum_{i=0}^n$</p><ul><li>极限：</li></ul><p>极限符号\lim显示为$lim$</p><p>举例:\lim_{x\to\infty} </p><p>$<br>\lim_{x\to\infty}<br>$</p><ul><li>积分：</li></ul><div class="table-container"><table><thead><tr><th>命令</th><th>显示</th></tr></thead><tbody><tr><td>\int</td><td>∫</td></tr><tr><td>\iint</td><td>∬</td></tr><tr><td>\iiint</td><td>∭</td></tr><tr><td>\iiiint</td><td>∬∬</td></tr><tr><td>\oint</td><td>∮</td></tr></tbody></table></div><p>举例：\int_0^\infty{fxdx} 显示为<script type="math/tex">\int_0^\infty{f(x)dx}</script></p><ul><li>分式：</li></ul><p>\frac{公式1}{公式2}显示为$\frac{公式1}{公式2}$</p><p>举例:\frac a b $\frac a b$</p><ul><li><p>根号：<br>\sqrt[x]{y}显示为$\sqrt[x]{y}$</p></li><li><p>常见函数：</p></li></ul><p>\函数名</p><p>举例:\sin x,\ln x,\log_n^2 5,\max(A,B,C)显示为</p><script type="math/tex; mode=display">\sin x,\ln x,\log_n^2,\max(A,B,C)</script><p>暂时写这么些，还有很多其他用法，需要平时的积累。</p>]]></content>
      
      
      <categories>
          
          <category> 博客建设 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> markdown </tag>
            
            <tag> LaTex </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——PLA</title>
      <link href="/2018/07/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94PLA/"/>
      <url>/2018/07/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94PLA/</url>
      
        <content type="html"><![CDATA[<p>对研究生要跟的导师还不确定，暑假打算学习点专业课与英语，也迟迟没有做好。我想不管哪个实验室应该都不会离开机器学习吧。因此开始看这方面的东西。</p><a id="more"></a><p>今天接触了一个算法叫<strong>PLA</strong>（Percetron Learning Algorithm）,用来做线性分类的算法。它应用的前提是样本集是线性可分的。用二维特征值的样本来举例子：</p><p><img src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=793659404,4189322929&amp;fm=27&amp;gp=0.jpg" alt="linear separable"></p><p>我们要的就是通过算法来找到这条线。对于二维的样本（特征分别为$x_1$,$x_2$）,则分类结果为-1，+1，分别表示为negative，positive（这与另一种常用的分类算法不一致）。思想就是每个特征对应一个参数，乘积之后如果大于某个阈值，则设定为分类结果为+1，小于则为-1。若为特征添加一个特征$ x_0 $恒等于一，则用向量化可以将分类过程写成如下形式：</p><script type="math/tex; mode=display">result(X) = sign(W{X^T})</script><p>其中W为特征的参数向量，我们使用$y$来表示样本真实类别。</p><p>整个算法的思想其实很简单，刚开始画出一条线，如果分错了，则往正确的方向旋转这条线。但是如何旋转这条线，旋转多少角度，还是很有意思的。一般的想法都是从图直观上来看，利用代价函数（cost function）来解决，不过对于这个简单的线性分类，用代价函数进行梯度下降还是相对来说计算量还是比较大的。这个算法让我觉得厉害的地方在于它向量化不光是为了提高计算效率，而是从向量的角度来考虑一步步向结果逼近的：遇到的分类错误有两种情况，如果$y$应该是正，但是$W{X^T}$得到的是负的，从向量角度来说，$W$与$X$的夹角太大，因此内积为负，我们要减小两个向量的角度，可以令$W=W+X$,相反，$y$应该是负，结果却为正，那么$W$与$X$的夹角太小，可以令$W=W-X$，这样就增大了夹角，从下图可以很直观的看出来这个道理：</p><p><img src="https://gss3.bdstatic.com/7Po3dSag_xI4khGkpoWK1HF6hhy/baike/c0%3Dbaike72%2C5%2C5%2C72%2C24/sign=71339aceab773912d02b8d339970ed7d/b3b7d0a20cf431ad4cdf9f4a4936acaf2edd98b0.jpg" alt="向量加减"></p><p>合并两种情况，则每次遇到被错误分类的样本$X_n$，我们对参数向量$W_t$进行如下更新（其中$t$表示修正的次数）：<script type="math/tex">W_{t+1} = W_t + y_nX_n</script><br>下面主要来证明一下，对于线性可分的样本来说，这个算法一定会停止，找到那条符合的参数向量$W_f$。我们可以知道：</p><script type="math/tex; mode=display">y_n{W_f}^TX_n >= _{min}[ y_nX_nW_f^T]>0</script><p>而</p><script type="math/tex; mode=display">W_{t+1}W_f^T = W_tW_f^t + y_nX_nW_f^T >= W_tW_f^T + _{min}[ y_nX_nW_f^T]</script><p>因此我们可以得到：</p><script type="math/tex; mode=display">W_{t+1}W_f^T >= W_tW_f^T >= W_0W_f^T +(t+1) *_{min}[ y_nX_nW_f^T]</script><p>因为我们每次找到一个出错点才进行修正，出错点为（$X_n,y_n$），可以知道$ y_nW_tX_n^T&lt;0 $，则：</p><script type="math/tex; mode=display">\Vert W_{t+1} \Vert ^2 = \Vert W_t \Vert ^2 + \Vert y_nX_n \Vert ^2+2y_nW_tX_n^T>= \Vert W_t \Vert ^2+_{max}[ \Vert X_n \Vert ^2]</script><p>因此我们可以得到：</p><script type="math/tex; mode=display"> \Vert W_{t+1} \Vert ^2 = \Vert W_t \Vert ^2 +  \Vert y_nX_n \Vert ^2+2 \times y_nW_tX_n^T>= \Vert W_0 \Vert ^2+ (t+1) \times _{max}[ \Vert X_n \Vert ^2]</script><p>最后，假设最开始$W_0=0$，通过正规化，我们可以算出$W_t$与$W_f$之间的角度是不断逼近的（角度重合时候也就得到了正确的参数，实际上角度相同后我们不在乎向量的模的大小，因为它不会影响$W_t^TX_n$的符号）：</p><script type="math/tex; mode=display">\frac{W_tW_f^T}{ \Vert W_t \Vert  \Vert W_f \Vert } >= \frac{t \times _{min}[y_nW_fX_n]}{\sqrt{t} \times _{max} \Vert X_n \Vert  \Vert W_f \Vert } = \sqrt{t} \frac q R</script><p>其中：$q = _{min}[y_nW_fX_n],R^2 = ( _{max} \Vert X_n \Vert  )^2$，而正规化后内积是小于等于1的（此时方向一致），可以得到$ t&lt;=\frac {R^2} {q^2} $，可以得到，最多经过$\frac {R^2} {q^2} $次修正即可得到正确结果。</p><p>到这里就证明结束了,以后会上传相关的代码。</p><p>可以看到虽然算法实现很简单，但其中的推理还是不容易的。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> classification </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2018/07/25/hello-world/"/>
      <url>/2018/07/25/hello-world/</url>
      
        <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;时间过的真快，转眼间从大学毕业已经一个月了。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这两个月的时间里，我一直是“社会人”，因此享受不到阿里云的学生优惠，作为一个穷人，我很果断地放弃了我的梦想：关掉了之前自己一步一步搭出来的博客。<br><a id="more"></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前的博客是用java一步一步堆出来，到了最后功能也比较完善了，虽然看的人不多（数量为zero），但是我每天也会习惯性的上去转转，有什么想说的也会写进去，慢慢成了一个习惯。最近十来天没了它，我有时候想记录点啥，也不知道往哪里去写，不过今天搭好了这个，却又不知道写什么了。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以这两天我想着重新弄一个，微博，csdn，空间等不会用的，别问我为什么，我也不知道，可能因为他们不够折腾吧😂。但是我现在也没钱买台服务器，毕竟就我一个人用，实在是有点浪费。早听说很多人用GitHub搭博客，于是我就来尝试下这个。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;搭得差不多之后，我也有点明白了它的原理：在github上，每个repo都可以有github page页面，它是一个静态页面，用来展现这个项目的一些东西。利用github搭建博客就是基于这个页面。先通过Hexo写好文章然后生成展示它的页面（包括文章的分类，检索等都已经本地生成结果）上传到自己的github上去，然后利用这个page就可以访问了。所以即使github page是静态页面，依然可以实现博客的搭建，这里面离不开Hexo的功劳，所有“动态”的业务在自己的电脑上已经完成了。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个做法还真是挺牛逼的。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;至于怎么搭建博客，网上一查一大堆，照着来就好，就不说了。因为不用自己写什么代码，相对来说还是很容易的。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，按照惯例说句： </p><h1 id="Hello-world"><a href="#Hello-world" class="headerlink" title="Hello,world!"></a>Hello,world!</h1>]]></content>
      
      
      <categories>
          
          <category> 灌水 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> casual note </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>

<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>图形学——光线追踪</title>
      <link href="/2019/03/13/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/"/>
      <url>/2019/03/13/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/</url>
      
        <content type="html"><![CDATA[<p>之前我们重视的是镜面反射和漫反射的效果，对于折射却提到很少。这意味着只能显示非透明的东西。想要显示比如透明的水晶球，还有更复杂的，比如镜面中的场景，就需要光线追踪。<br><a id="more"></a><br>Whitted模型是第一个光线追踪模型。Whitted是图形学大佬，只发表了19篇文章，就被评为了工程院院士。所以大佬的作品在质不在量。光线追踪算法可以实现其他算法很难达到的视觉效果，被广泛使用。</p><p>说光线追踪，首先要知道，人之所以能看到东西，是光线经过一系列反射折射等等最终摄入我们的眼睛。光线追踪的思路就是顺着这个原理倒回去。首先，计算机有个显示缓存区，是由空间中的像素组成的，人眼透过这些像素看到场景中的物品。对于每个像素$P$计算其颜色值。步骤如下：</p><ul><li>计算视点连接像素$P$中心的光线（Ray）延长后所碰到的第一个物品的交点</li><li>使用局部光照模型计算交点处的颜色值，到目前我们还只能看到投射的效果</li><li>沿交点处的反射和折射方向对光线进行追踪，比如反射，折射方向有别的物品，对这个物品继续利用局部光照模型等，则进行加权叠加，这样就能实现更逼真的反射和折射效果</li></ul><p>通过光线追踪，可以很容易地表现出来阴影，反射，折射等引人入胜的视觉效果。由于一个递归的过程，光线追踪适用于更复杂的物体表示方法。</p><p>简单原理图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking1.jpg" alt=""></p><p>效果图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking0.jpg" alt=""></p><h2 id="光线求交（Ray-Intersection）"><a href="#光线求交（Ray-Intersection）" class="headerlink" title="光线求交（Ray Intersection）"></a>光线求交（Ray Intersection）</h2><h3 id="光线的表示"><a href="#光线的表示" class="headerlink" title="光线的表示"></a>光线的表示</h3><p>光线由射线表示：</p><ul><li>$P(t) = R_0+t\cdot R_d$</li><li>$R_0 = (x_0,y_0,z_0)$为光线的源点;$R_d=(x_d,y_d,z_d)$表示光线的朝向，一般来说为单位向量</li><li>$t$表示光线到达的位置，在光线的正方向上$t\ge 0$</li></ul><h3 id="光线与平面求交"><a href="#光线与平面求交" class="headerlink" title="光线与平面求交"></a>光线与平面求交</h3><ul><li>平面的表示<ul><li>显示表示：$n_0,P_0$分别表示法向量和平面上一点</li><li>隐示表示：$Ax+By+Cz+D=0\\&amp;nP+D=0\end{aligned}$</li></ul></li><li><p>点到平面的距离：</p><ul><li>当$n$是单位法向量时，$P$到平面$H$的距离为$H(P)$</li></ul></li><li><p>根据平面和光线的方程得到方程组，求解即可：</p><script type="math/tex; mode=display">P(t) = R_0+t\cdot R_d\\n\cdot P(t) + D = 0</script><p>解得：$t = -(D+n\cdot R_0)/(n\cdot R_d)$，最后验算$t&gt;0$。</p></li></ul><h3 id="光线与三角形求交"><a href="#光线与三角形求交" class="headerlink" title="光线与三角形求交"></a>光线与三角形求交</h3><p>首先求与三角形平面交点，再检查交点是否在三角形内。三角形中的点有多种表示方法。</p><ul><li>重心坐标：</li></ul><p>三角形$P_0P_1P_2$内部一点$P$可以表示为：</p><pre><code>$$P = \alpha P_0 + \beta P_1 + \gamma P_2$$</code></pre><p>这里的$(\alpha,\beta,\gamma)$被称为重心坐标。满足$0\leq\alpha,\beta,\gamma \leq 1,\alpha+\beta+\gamma=1$。<br>重心坐标有很多应用，纹理映射，法向插值，颜色插值等等。</p><p>通过将三角形坐标带入方程组，得到点的重心坐标。这个都是很容易计算的。</p><script type="math/tex; mode=display">P = (1 - \beta - \gamma)P_0+\beta P_1 + \gamma P_2 = R_0+tR_d</script><p>也就是：</p><script type="math/tex; mode=display">\begin{pmatrix}R_d &P_0-P_1 & P_0-P_2 \end{pmatrix}\begin{pmatrix}t\\\beta\\\gamma\end{pmatrix} = P_0 - R_0</script><p>最后需要检查$t,\alpha,\beta,\gamma$的有效值。</p><h3 id="光线与多边形求交"><a href="#光线与多边形求交" class="headerlink" title="光线与多边形求交"></a>光线与多边形求交</h3><p>与多边形求交也非常重要。思路为求与多边形平面交点，再检查交点是否在多边形内。为了判断第二个，首先我们需要将平面和交点投影到XY，XZ或者YZ面，然后判断在这个平面上的关系。这时候需要使用交点检测算法，属于计算几何的范畴。交点检测算法的原理如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking2.jpg" alt=""></p><p>很简单，如果一个点是多边形的内点，那么从它射出去的一条射线，与多边形边的交点是奇数个。如果是外点，则交点为0或者为偶数个。但是这检测的过程中会有一些有歧义的地方，比如射线和边重叠了，或者射线和多边形顶点重叠了，需要进行额外的判断。</p><p>这个算法的一个改进是根据交点为原点来建立坐标系，而x的正半轴就是射出去的线的方向。这样很多事情会方便很多，但是本质上没有太大的区别。</p><p>另外一个算法是面积法，通过计算该点与各个边组成的三角形面积之和，如果等于多边形的面积，则在内部。但是这个还需要进行多边形的面积计算。</p><p>最后介绍一个叫弧长法。弧长法是最快的算法，不过是一步步简化的，最开始也需要大量计算。看下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking3.jpg" alt=""></p><p>我们会判断该点与各个边的夹角，这个夹角是按照一定方向过去的，如果夹角之和为$2\pi$，则为内点，如果最后和为0，则为外点。如果代数和为$\pi$，则点在多边形上。</p><p>仔细一看，这个方法也不算那么简单，因为计算夹角和计算面积可能区别不大。但是弧长法可以继续改进。我们将该点作为坐标系原点，各个象限内点的符号分别为：$(+,+),(-,+),(-,-),(+,-)$。如果某个顶点$P_i$的某个坐标为0，则符号为+，如果该顶点为$(0,0)$，则说明该顶点为被测点，则弧长变化为下表：</p><div class="table-container"><table><thead><tr><th>$(x_i,y_i)$</th><th>$(x_{i+1},y_{i+1})$</th><th>弧长变化</th><th>象限变化</th></tr></thead><tbody><tr><td>(+,+)</td><td>(+,+)</td><td>0</td><td>I-&gt;II</td></tr><tr><td>(+,+)</td><td>(-,+)</td><td>$\pi/2$</td><td>I-&gt;II</td></tr><tr><td>(+,+)</td><td>(-,-)</td><td>$\pi$</td><td>I-&gt;III</td></tr><tr><td>…</td><td>…</td><td>…</td><td>…</td></tr></tbody></table></div><p>下面的变化依照上面的规律。这是计算各个之间弧长（并不是真正的角度）的方法，另外一种方法通过计算:</p><script type="math/tex; mode=display">f = y_{i+1}x_i - x_{i+1}y_i</script><p>如果$f=0$，则边穿过坐标原点，如果$f&gt;0$，弧长代数和增加$\pi$，否则弧长代数和减少$\pi$。最后，得到弧长和为$2\pi$，则为内点。</p><p>弧长法好的地方在与它除了速度外还有鲁棒性。因为计算不能精确为0或者$2\pi$，只要近似，我们就能得到结果。</p><h3 id="光线与球面交点"><a href="#光线与球面交点" class="headerlink" title="光线与球面交点"></a>光线与球面交点</h3><p>之前的交点计算都是比较简单的，这次说说与球面的交点。球的隐式方程为：</p><script type="math/tex; mode=display">\Vert P(t) - P_c \Vert = r</script><p>最容易想到的方法，是根据方程组来解。联立球的坐标和射线坐标，我们可以得到一个一元二次方程组，从而得到两个解。这个方法的缺点是，需要解方程。而且，我们往往仅需要一个交点即可。下面介绍另一种几何方法。看下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking4.jpg" alt=""></p><ul><li>计算视点指向球心的向量为$l: l = P_c - R_0$。</li><li>判断视点是否位于球体内部，这个也非常简单，只要判断$l^2,r^2$的大小即可。如果视点位于球面上，需要考虑退化情况。</li><li>计算球心到光线所在直线的投影点（垂足）： $t_p = l\cdot R_d$，$t_p$也就是在$R_d$方向上的距离。如果$t_p&lt;0$，则光线与球面不相交。因为我们没法看到后面。</li><li>计算$d$，$d$很好算，如果$d^2 &gt; r^2$，不相交。</li><li>计算$t’$，为投影点到光线与球面的交点的距离，它也可以根据圆内的简单直角三角形利用勾股定理得到，得到$t’$后：<ul><li>如果光源在球体外部，$t = t_p - t’$</li><li>如果光源在球体内部，$t = t_p + t’$</li></ul></li></ul><p>由此就计算出来了$t$，从而得到交点。虽然上面的过程看着也比较复杂，但是只是简单的向量乘积，因此速度更快，而且鲁棒性更高。而解方程由于有较多除法，可能会遇到奇异解。</p><h3 id="光线与长方体交点"><a href="#光线与长方体交点" class="headerlink" title="光线与长方体交点"></a>光线与长方体交点</h3><p>求光线与长方体的交点是非常有必要的。因为在做光线追踪的时候，对于一个复杂的模型的所有三角面片进行求交点是非常麻烦的，最后求出来结果可能是根本没有交点。因此会需要一个预处理，来排除一定没有交点的情况。这时候常用的方法是用长方体做对物体做包围盒。如果光线与包围盒不相交，那么和模型也一定不相交。这个思想在图形学中是非常重要而且普遍应用的。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking5.jpg" alt=""></p><p>对于长方体的求交最直接的想法是向多边形求交那样，对于长方体的6个面进行判断，但是由于长方体的形状特殊，实际上有更简便的方法。首先，长方形有6个面，每两个面是互相平行的，平面方程：$Ax+By+Cz+d = 0$，也就是只有$d$有区别。这两个面一个是近平面，一个是远平面。我们求对每对平面（不是长方体的面，是长方体面所在平面）求$t_{max},t_{min}$,最后得到：</p><script type="math/tex; mode=display">t^{(1)}_{max},t^{(1)}_{min}, t^{(2)}_{max},t^{(2)}_{min},t^{(3)}_{max},t^{(3)}_{min}.</script><p>接着，我们对所有的最大值求最小值，对所有的最小值求最大值。得到：</p><script type="math/tex; mode=display">t_{max} = \min\{t^{(1)}_{max},t^{(2)}_{max},t^{(3)}_{max}\}\\t_{min} = \max\{t^{(1)}_{min},t^{(2)}_{min},t^{(3)}_{min}\}</script><p>如果$t_{max} \ge t_{min}$，则这两个就是光线与长方体的交点。对于这个算法的原理解释，我们可以在二维的情况下画图理解，这个思路是非常巧妙的，如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking6.jpg" alt=""></p><h2 id="计算阴影"><a href="#计算阴影" class="headerlink" title="计算阴影"></a>计算阴影</h2><p>在交点向着光源发出一条射线，如果有遮挡，那说明该点位于阴影区域。在计算阴影区域时，我们只需关注是否与物体相交，而不用关注哪个是最近交点。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>光线追踪算法从提出到现在，依然在广泛使用。而近些年在光线追踪方面的改进，也是主要用于加速求交等等。思考光线追踪的过程，从人眼出发，反向去找交点从而得到各个效果，是非常聪明的做法。</p><p>首先，我们初中就学过，在宏观世界里，光逆向之后可以回到原点。因此这个方法是符合常识的。第二个，如果我们从光源出发，那么一个光源应该射出多少条射线？光源理论上发出来无数条光线，而在计算机中，我们不能做到无数，只能均匀发出一系列光线，而这些光线最后能弹射到人眼中的只占了一小部分，既浪费了计算量，也无法保证每个像素都能被光线弹射到，这样使得效果也差，算是费力不讨好，如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking8.jpg" alt=""></p><p>而从视点出发，对每个像素进行反向追踪，计算量不算大，又能得到很好的效果。</p><p>要知道光线追踪算法是一个递归算法，那么这个递归如何停止。因为很有可能这个递归会一直走下去。这种情况下有两种做法，一是达到一定的层数后，自动结束递归，第二个是通过衰减系数。前面我们也知道，不管折射还是反射都是会损耗光的能量，如果这个光递归了很久衰减系数低到一定的阈值，我们就将其忽略，结束递归。这二者都能取到不错的效果。因为即使递归少了一辆层，看上去依然能得到很惊艳的光线追踪效果。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/light_tracking7.jpg" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> computer graphics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——光照模型</title>
      <link href="/2019/03/12/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2019/03/12/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>这次简单介绍一下几个著名的光照模型。<br><a id="more"></a><br>首先，我们要知道，我们能看到物体是因为物体反射的光进入了我们眼睛。光照模型是基于入射角反射角定理的。在物理上有一个更复杂一点的描述光的反射的函数，简称BRDF（双向反射分布函数）。因此这些光照模型，又被称为BRDF模型。</p><p>再介绍各个模型之前，我们再了解一些关于光学的定义。入射角反射角定理就不多说了，是中学知识。光有以下几个度量方法：</p><ul><li>立体角：<ul><li>衡量物体相对于某一视点P的视角大小：$dw = \frac{ds}{r^2}$，距离为弧面面积比上距离的平方</li><li>立体角最大为$4\pi$，也就是球面积比上半径的平方</li></ul></li><li>光通量：<br>  -光通量为单位时间内通过面元$ds$的光能量，记为$dF$</li><li>发光强度：<br>  -发光强度为单位立体角内的光通量，记为$I$</li></ul><p>我们知道能量守恒定理。在光反射的过程中也是一样的，光的能量等于被镜面反射的光的能量，漫反射的光能量，如果有折射还要加上折射掉的能量，以及被物体吸收等所有能量之和。</p><h3 id="Phong模型"><a href="#Phong模型" class="headerlink" title="Phong模型"></a>Phong模型</h3><p>Phong模型是最简单而且也是最常用的光照模型。它支持点光源和方向光源。Phong模型是局部光照模型，它将局部光照效果简单分解为下面三个部分：</p><ul><li>漫反射光效果</li><li>镜面反射光效果</li><li>环境光效果<script type="math/tex; mode=display">I_i = I_d + I_s + I_a.</script>如下图：</li></ul><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/brdf1.jpg" alt=""></p><p>L为入射光方向（图中方向画反），R为反射光，N为物体表面法向量，V是视点方向，H是L和V夹角的角平分线方向。</p><h4 id="漫反射光效果"><a href="#漫反射光效果" class="headerlink" title="漫反射光效果"></a>漫反射光效果</h4><ul><li>漫反射光的传播是各项同性的</li><li>漫反射光强度为：<script type="math/tex; mode=display">I_d = I_iK_d\times (L\cdot N)</script>上式中$K_d$为漫反射系数，具有3个分量，分别代表R，G，B三个通道的漫反射系数。可见，$K_d$与模型自身的色彩紧密相关。<h4 id="镜面反射效果"><a href="#镜面反射效果" class="headerlink" title="镜面反射效果"></a>镜面反射效果</h4></li><li>对于光滑的平面，根据反射定律，反射光往往集中在一个小的立体角内，这些反射光我们称之为镜面反射光。</li><li>镜面反射光的强度为：<script type="math/tex; mode=display">I_s = I_iK_s \times (R\cdot V)^n</script>上式中，$K_s$为镜面反射稀疏，与物体表面的光滑程度有关，而$n$是反射指数，$n$越大，高光区域越集中，这里的意思是，因为$R \cdot V$是小于等于1的，如果$n$越大，$(R\cdot V)^n$下降得越快，因此高光越集中。</li></ul><h4 id="环境光效果"><a href="#环境光效果" class="headerlink" title="环境光效果"></a>环境光效果</h4><p>环境光效果很简单，也就是除了镜面反射和漫反射的其他光总称为环境光。$I_a = I_iK_a$。</p><p>所以Phong模型非常简单，它简单将光分成这几类，计算量很小，而且保证了不错的效果。因此被广泛使用。</p><h4 id="法向插值"><a href="#法向插值" class="headerlink" title="法向插值"></a>法向插值</h4><p>当然，明暗处理（shading）除了光照模型这些，还需要考虑的是插值。因为物体表面几个细节并不规则圆滑，为了减轻这种效果，需要对面片进行插值。插值也有多种方法，在Phong之前采用的是颜色插值。而Phong采用了一种新颖的想法，对法向进行插值。得到面片上各个点（非顶点）的法向，这时候在进行光照处理，会使得整个模型显示更加平滑。很神奇的是，我们先通过顶点计算出面片法向，再通过面片法向计算出顶点法向，然后根据顶点法向对面片上各个点法向进行插值，它们在互相利用。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/brdf2.jpg" alt=""></p><h3 id="其他BRDF模型"><a href="#其他BRDF模型" class="headerlink" title="其他BRDF模型"></a>其他BRDF模型</h3><p>这里将除了Phong模型以为的模型归结为其他，是因为我的知识浅薄，对其他的模型理解的不够透彻，绝对不是因为他们不够重要。对于要求更高的场景Phong模型是肯定不够的。其他的模型一般有更好的效果，相应也更复杂一点。</p><p>一般来说，BRDF模型有物理模型和经验模型两个区别。其实这个分类也不是太绝对，因为即时是经验模型也是基于一些物理知识的。</p><p>经验模型一般是依照直觉来定一些规则，而物理模型是严格按照光学物理知识来建立模型。</p><h4 id="菲涅尔项"><a href="#菲涅尔项" class="headerlink" title="菲涅尔项"></a>菲涅尔项</h4><p>在物理模型中，会假如一个菲涅尔项，是基于一个物理的现象：单向反射性在擦地角附近增大。在一般物理模型中，入射光的反射量是由麦克斯韦电磁波方程组中的菲涅尔公式得到的，被称为菲涅尔项。菲涅尔项的定义比较复杂，如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/brdf4.jpg" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/brdf3.jpg" alt=""></p><p>比较著名的其他光照模型还有Cook-Torrance模型，Ward模型（各向异性，没有考虑菲涅尔项和衰减稀疏，更像是经验模型）。</p><p>除了物理模型和经验模型，还有一种是基于数据的，数据驱动模型。原理就是采集大量数据，获取光的规律。它一般需要很大的数据集，并且需要数据降维来压缩数据。</p><p>最后说一下对BRDF模型的度量，就是采集真实照片与模型投影来进行对比，原理很简单，但是设备还是非常贵重的。</p>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> computer graphics </tag>
            
            <tag> BRDF </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——颜色与网格</title>
      <link href="/2019/03/11/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94%E9%A2%9C%E8%89%B2%E4%B8%8E%E7%BD%91%E6%A0%BC/"/>
      <url>/2019/03/11/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94%E9%A2%9C%E8%89%B2%E4%B8%8E%E7%BD%91%E6%A0%BC/</url>
      
        <content type="html"><![CDATA[<p>这次介绍图形学的一些基本的东西，几种颜色空间以及三角网格模型。<br><a id="more"></a></p><h3 id="色彩"><a href="#色彩" class="headerlink" title="色彩"></a>色彩</h3><p>色彩是非常重要的。最常见的颜色空间为RGB通道（红绿蓝），这3种颜色是符合人眼视锥细胞等等原理的。不过RGB的缺点是无法表示所有的颜色。RGB是加色系统，白色是3通道都到最大值，黑色是3通道都为0值。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/RGB.png" alt=""></p><p>CMY是减色系统（青，品红和黄），三色都为最大值得到黑色，三色都为0值为最小值，主要用于印刷业。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/CMY.png" alt=""></p><p>HSV为色彩，饱和度，亮度三个指标，修图的人经常会用到。它最大的好处是更容易让人理解。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/HSV.png" alt=""></p><p>CIE-XYZ色彩空间可以表示所有的可见颜色。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_hexo/CIE_XYZ.png" style="width:50%"></p><p>我们最常用的还是RGB。</p><h3 id="三角网格"><a href="#三角网格" class="headerlink" title="三角网格"></a>三角网格</h3><p>三角网格（mesh）是表示三维模型的方法，大家肯定也经常听到。三角网格由顶点集合和面片集合组成。</p><p>顶点：$V={v_1,v_2,…,v_n}$</p><p>面片：$F={f_1,f_2,…,f_m}$</p><p>其中面片是由3个顶点组成的三角形：$f_1 = {v_a,v_b,v_c},v_a,v_b,v_c \in V$。</p><p>我们可以根据3个顶点坐标求出每个面片的法向量。法向量有两个方向，一般选取朝外的。连续可定向的三角网格整体，相邻三角面片一般要具备一致的法向量朝向。</p><p>除了面片法向量还有顶点法向量。顶点法向量通过周围的所有面片法向量加权叠加得到，有多种加权方法：</p><ol><li>算术平均</li><li>面积加权平均</li><li>角度加权平均</li></ol><p>网格模型的简单绘制，对于顶点有各个颜色值。而面片上各个点的颜色值通过顶点颜色值插值得到。同时加上光照模型，可以得到阴影反射等效果。这就是下一个要介绍的光照模型。</p>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> computer graphics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper——Large-Scale and Drift-Free Surface Reconstruction Using Online Subvolume Registration</title>
      <link href="/2019/03/09/Paper%E2%80%94%E2%80%94Large-Scale-and-Drift-Free-Surface-Reconstruction-Using-Online-Subvolume-Registration/"/>
      <url>/2019/03/09/Paper%E2%80%94%E2%80%94Large-Scale-and-Drift-Free-Surface-Reconstruction-Using-Online-Subvolume-Registration/</url>
      
        <content type="html"><![CDATA[<p>这次周末再读一篇文章，希望能从中得到一些启发，来做好现在的相关的工作。这篇文章为<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Fioraio_Large-Scale_and_Drift-Free_2015_CVPR_paper.pdf" target="_blank" rel="noopener">Large-Scale and Drift-Free Surface ReconstructionUsing Online Subvolume Registration</a>，是2015年CVPR的一篇文章。<br><a id="more"></a><br>关于TSDF，我们已经知道的很多了。在这篇文章中也是同样的。文章中，$\mathbf{u}$代表空间中的三维点，而$F(\mathbf{u})$代表该点的SDF值，$W(\mathbf{u})$表示的是SDF值的信心度量（可以理解为权重）。不同的地方是，文章中还定义了一个归一化梯度：</p><script type="math/tex; mode=display">\hat{\nabla}F(\mathbf{u}) \triangleq \frac{\nabla F(\mathbf{u})}{\Vert \nabla F(\mathbf{u}) \Vert}</script><p>当$F$是常数时，也就是梯度为0,返回一个未定义值。</p><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>为了进行depth fusion，每个voxel都被投影到二维平面中，并且和传感器获得的深度值对比：</p><script type="math/tex; mode=display">\Delta _z(\mathbf{u},t) = D_t(\pi (T^{-1}_t \cdot \mathbf{u})) - \zeta(T^{-1}_t\cdot \mathbf{u})</script><p>上式中，$\pi$是一个$\mathbb R^3 \rightarrow \mathbb R^2$的投影过程，也就是从三维到二维的转换，而$\zeta$提取了$z$坐标，也就是$\zeta(x,y,z) = z$。当$\Delta_z &gt; -\sigma$时候更新TSDF值，而$\sigma$指的是截断距离。新的TSDF$(F^{new},W^{new})$为：</p><script type="math/tex; mode=display">F^{new}(\mathbf{u}) = \frac{F(\mathbf{u})W(\mathbf{u})+ \min\left(1,\frac{\Delta_z(u,t)}{\sigma}\right)}{W(\mathbf{u})+1},\\W^{new}(\mathbf{u}) = W(\mathbf{u})+1</script><p>值得注意的是，这里依然保留的是截断距离，只不过用了另一种方法，选取和1比较的最小值。另外，对于权重的分配，有很多种方法，论文中采取的是最简单的，也就是平均分配，每次$W = W+1$。</p><p>这篇文章的模型是在KinectFusion的基础上进行的，而KinectFusion之所以不能很好的在large scale上应用，主要有两个原因，一是drift累积，二是global TSDF会需要较大的内存。</p><h3 id="Low-Drift局部模型"><a href="#Low-Drift局部模型" class="headerlink" title="Low-Drift局部模型"></a>Low-Drift局部模型</h3><p>这篇文章在解决Drift问题上，采取了submap的形式。在本文中，称为subvolume。每K帧会建立一个submap。这篇文章提出了一个比较有趣的方法，来做integrate，为了避免每一步都进行K次integrate，也就是对F，W的更新，每次得到新的帧时，它将该帧以及对应的位姿push进一个队列中（FIFO），同时将$t-K$帧pop出去，对TSDF volume进行腐蚀（erosion）：</p><script type="math/tex; mode=display">F^{new}(\mathbf{u}) = \frac{F(\mathbf{u})W(\mathbf{u})-\min\left(1,\frac{\Delta_z(u,t-K)}{\sigma}\right)}{W(\mathbf{u})-1},\\W^{new}(\mathbf{u}) = W(\mathbf{u})-1</script><p>当处理的帧数量少于K帧时，不会发生腐蚀。当到达K帧时，队列也满了，将volumen从GPU拷贝到主机中，作为一个新的subvolume，然后腐蚀操作开始。其实我是真的不知道这样做有什么吊用。。。或者我理解有误？总之，这不是关注的重点。</p><p>这一部分还包含了对有效Block的筛选，也是比较常规的做法，就不多说了。</p><p>本文中$K=50$。</p><h3 id="Subvolume注册"><a href="#Subvolume注册" class="headerlink" title="Subvolume注册"></a>Subvolume注册</h3><p>我比较想借鉴的是，如何将各个submap融合，因为每个submap在融合到global的情况下，需要进行optimize，会对每个submap求出位姿，或者说各个submap之间有相对的位姿，知道这个位姿后，如何对各个submap的TSDF进行transform？</p><p>在本文中，每K帧形成一个新的subvolume$(F_j,W_j)$，被存储在主机上，下面会将各个subvolume的位姿表示为$V_j$。尽管每个subvolume的局部位姿都很小，但是将它们直接简单收集起来会产生较大的drift和misalignment。本篇文章中通过全局优化各个subvolume的位姿来解决这个问题，当得到一个新的subvolume时，会通过一个创新的volume混合方案来进行非刚性变换。一个比较显著的点是，这个优化过程不需要相机tracking模块，因此它可以使得操作实时进行，并且在把新的subvolume放入一个共享缓存区，允许位姿优化作为一个并行运行的过程。</p><p>提出的优化过程是受到了ICP算法的启发。优化需要的cost function是这样得到的：</p><ol><li>对于每个subvolume，提取出zero-level的点的集合，并且得到它们的法向量</li><li>对于每个subvolume，考虑它的边界框，并且找到与其他subvolume之间的overlap</li><li>对于每个subvolume得到的点集，通过距离函数的梯度来找到与它有overlap的subvolume中的对应</li><li>每个有效的对应都会带来一个点到平面的距离约束，用来优化</li><li>如果有一个位姿超出约束，至少有一个位姿错误项被添加，来保证全局一致</li></ol><p>接着，通过最小化一个合适的cost function来优化subvolume的位姿。在添加subvolume时候，上一个创建的subvolume的位姿保持固定，来得到tracked相机的最终估计。相对应的，下一个subvolume也能很快根据之前的subvolume得到一个合适的位姿，在相机track成功的情况下。cost funtion会最小化直到收敛，当得到新的对应时，继续最小化。下面会详细介绍一下point matching和优化问题。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/subv3.png" alt=""></p><h4 id="The-Correspondence-Set"><a href="#The-Correspondence-Set" class="headerlink" title="The Correspondence Set"></a>The Correspondence Set</h4><p>给定subvolume$(F_j, W_j)$，以及zero-level点集：$\left\{ \mathbf p_i^{(j)} \right\}$以及计算的法向量$\mathbf{n_i^{(j)}} = \hat{\nabla}F_j\left(p_i^{(j)}\right)$。我们定义最小的边界框（bounding box）包围了它所有的有效voxel。接着，找到subvolume的子集$S^{(j)}$，它们之间有重叠的边界框。接着，对于每个点$\mathbf p_i^{(j)}$，我们遍历候选集，对于每个$k \in S^{(j)}$，计算插值距离函数以及它在$V_k^{-1} \cdot V_j \cdot\mathbf p_i^{(j)}$的梯度。如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/subv1.png" alt=""></p><p>一个点的match为下：</p><script type="math/tex; mode=display">\mathbf q_k^{ij} = V_k^{-1} \cdot V_j \cdot \mathbf p_i^{(j)} - F_k\left(V_k^{-1} \cdot V_j \cdot \mathbf p_i^{(j)}\right)\hat \nabla F_k\left(V_k^{-1}\cdot V_j \cdot  \mathbf p_i^{(j)} \right).</script><p>对于所有的subvolume中所有的采样点进行上面的过程，有点类似于ICP算法匹配的过程。我还不是很明白这里梯度那一项的作用，也许可以增加鲁棒。</p><h4 id="The-Opitimization-Problem"><a href="#The-Opitimization-Problem" class="headerlink" title="The Opitimization Problem"></a>The Opitimization Problem</h4><p>假设通过上面的过程，我们已经成功找到了对应。我们可以根据这些对应建立cost funstion。对于每个点对$\left( \mathbf p_i^{(j)},\mathbf q_k^{ji} \right)$，我们对$F_k$在$\mathbf q_k^{ji}$处的形状是没有保证的。我们已经估计了$F_j$中$p_i^{(j)}$处的法向量，因此我们可以得到一个点与平面之间的constraint：</p><script type="math/tex; mode=display">e_k^{ji} = \left(\mathbf p_i^{(j)} - V_j^{-1}\cdot V_k \cdot \mathbf q_k^{ji}\right)\cdot \mathbf n_i^{(j)}.</script><p>cost function的形式为：</p><script type="math/tex; mode=display">\arg \min_{V_1,...,V_N} \sum_j \sum_i \sum_k\Vert e_k^{ji} \Vert^2</script><p>在本文中，通过Ceres中的列文伯格-马夸尔特方法来优化。</p><p>在这个过程中，有可能会出现一些别的情况，比如subvolume $F_h$是空的，或者有很少的基数，使得约束不成立，或者得到很差的位姿估计，在这种情况下可以引入位姿之间的约束来增强相机追踪得到的估计。当这个位姿引用的两帧分别在两个subvolume上，如$Z_{h-1,h}$，则估计的错误项可以描述为下：</p><script type="math/tex; mode=display">e^{h-1,h} = \Phi\log (Z_{h-1,h} \cdot V_h^{-1} \cdot V_{h-1})</script><p>上式中$\log$将$SE(3)$转换到$\mathcal{se}(3)$，而$\Phi$是一个$6\cdot 6$的刚性矩阵。按照经验将$\Phi$设置为单位矩阵。</p><h3 id="融合Subvolume"><a href="#融合Subvolume" class="headerlink" title="融合Subvolume"></a>融合Subvolume</h3><p>对于融合Subvolume，文章中没有过多介绍。如何融到一个global volume中？</p><script type="math/tex; mode=display">F_G(\mathbf u)=\frac{\sum_j F_j(V_j^{-1}\cdot \mathbf u)W_j(V_j^{-1}\cdot \mathbf u)}{\sum_{j}W_j(V_j^{-1}\cdot \mathbf u)}.</script><p>这个过程并没有太多的不同。而困扰我的，当TSDF旋转之后，原来的体素乘以transform矩阵得到的位置不是一个体素的中心位置，这时候的sdf距离会有误差，在文章中并没有过多提到。也许即时直接旋转也不会有太多的不同。</p><p>文章中，如何融合global volume，是通过对一个全局的位置依次扫描，对每个位置$\mathbf u$进行上述的操作。这样的采样，如果subvolume分布比较广，会导致大量的无用计算。如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/subv2.png" alt=""></p><p>因此，它会根据有overlap的subvolume来进行：</p><script type="math/tex; mode=display">F_j(\mathbf u) = \frac{\sum_k F_k(V_k^{-1} \cdot V_j \cdot \mathbf u) W_k(V_k^{-1} \cdot V_j \cdot \mathbf u)}{\sum_kW_k(V_k^{-1}\cdot V_j \cdot \mathbf u)}.</script><p>上式中$k \in S^{(j)}$，也就是与subvolume j有重叠的subvolume的集合。</p><p>上述就是这个文章的主要内容。其实读完了我觉得没什么特别新颖的点。</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 3D reconstruction </tag>
            
            <tag> SLAM </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper——Real-time 3D Reconstruction at Scale using Voxel Hashing</title>
      <link href="/2019/03/04/Paper%E2%80%94%E2%80%94Real-time-3D-Reconstruction-at-Scale-using-Voxel-Hashing/"/>
      <url>/2019/03/04/Paper%E2%80%94%E2%80%94Real-time-3D-Reconstruction-at-Scale-using-Voxel-Hashing/</url>
      
        <content type="html"><![CDATA[<p>之前的两篇文章都使用了voxel hashing的策略，而实际上为了减少存储，一般不会将空间所有的voxel都记录下来，而是使用voxel hashing或者octree的方法。而这篇文章（<a href="http://www.graphics.stanford.edu/~niessner/papers/2013/4hashing/niessner2013hashing.pdf" target="_blank" rel="noopener">Real-time 3D Reconstruction at Scale using Voxel Hashing</a>）是最早使用voxel hashing的。它的引用量达到了390。鉴于不是深度学习等热门领域，实际上这个成绩已经相当不错了。<br><a id="more"></a><br>当然，这篇文章中使用的还是TSDF，对于TSDF我就不多介绍了。在之前的表示中，会存储每个voxel的TSDF值。但是既然使用了截断SDF值，意味着不在截断范围内的体素组成的空间是free space，也就是没有必要的部分，对表面的重建不会有太大的帮助。因此可以设计一个新的数据结构来开发有效体素的稀疏性。实际上在之前图形学领域中，已经有hashing算法提出用来进行2D/3D渲染阶段以及，在基于GPU的hashing中也提出了成熟的方法，极大减少了hash冲突的数量。</p><p>这篇文章提出的系统目标是建立一个实时系统，探索一种空间hashing的方案，来实现可伸缩（scalable）体积的重建。对于三维重建来说非常重要的是，因为要重建的目标几何形状是未知的，并且可能随着时间不断变化（指的是随着时间变化获取信息在增加，或者由于优化改变了之前的重建结果），所以提出的数据结构应该可以动态分配和更新，同时还要在不知道任何重建表面的先验信息的情况下最小化潜在的hash冲突。</p><p>这篇文章提出的数据结构有下面几个优点：</p><ul><li>可以高效压缩TSDF，并且不降低分辨率，不适用分层的数据结构</li><li>可以高效地融合新的TSDF到哈希表中</li><li>无需重新组织结构就可以删除和收集无用的voxel block</li><li>在主机和GPU之间轻量级的voxel block双向流，允许无限制的重建</li><li>可以使用标准的raycasting或者多边形操作高效提取等值面(isosurface)，用来进行渲染以及相机位姿估计</li></ul><h3 id="System-Pipeline"><a href="#System-Pipeline" class="headerlink" title="System Pipeline"></a>System Pipeline</h3><p>这个系统的Pipeline非常简单，如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/hashing.png" alt=""></p><p>这个系统最关键的部分是空间哈希的策略。将voxels组织成块（例如8×8×8），每个体素包含一个TSDF值，一个weight以及一个额外的颜色值（可选）。这个哈希表是unstructured，也就是不是根据空间位置顺序分配的，可能离得很近的block在哈希表的实际位置中距离很远。我们也不会按照空间位置来查找对应的block，而是根据一个能够极大减少冲突的hash映射。</p><p>当有新的深度图进来时，使用ICP算法对位姿进行估计（使用的是point-plane的ICP，来保证位姿估计是frame to model而不是frame to frame，从而减少了飘逸的情况），接着开始进行integration。首先根据相机视锥，对所有的voxel进行block的分配，然后对每一个voxel进行TSDF的计算。然后我们进行垃圾收集，找出所有voxel都在表面截断范围外的block，在hash表中删除。这个步骤保证了hash表的稀疏性。</p><p>在integration之后，根据进行raycast，从而得到表面。</p><h3 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h3><p>想象将无穷的空间分割均匀分割成一个个block，每个block又分成N（8×8×8）个voxel。voxel的结构如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Voxel</span>&#123;</span></span><br><span class="line">    <span class="keyword">float</span> sdf;</span><br><span class="line">    uchar colorRGB[<span class="number">3</span>];</span><br><span class="line">    uchar weight;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>hash表与一般的hash表区别不大，也就是根据世界坐标位置$(x,y,z)$通过哈希函数得到一个映射，找到block，从而找到voxel。hash函数如下：</p><script type="math/tex; mode=display">H(x,y,z) = (x\cdot p_1 \oplus y\cdot p_2 \oplus z \cdot p_3)mod n</script><p>为了减少冲突，$p_1,p_2,p_3$是大质数（73856093, 19349669, 83492791），n是hash表的大小。除了存储一个指针指向voxel block，每个哈希entry也包含了世界坐标，一个偏移量，用来存储冲突发生时，相对于计算的位置的偏移量。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">HashEntry</span>&#123;</span></span><br><span class="line">    <span class="keyword">short</span> position[<span class="number">3</span>];<span class="comment">//the coordinate of </span></span><br><span class="line">    <span class="keyword">short</span> offset;<span class="comment">//offset of the next hash entry that suppose to be in the same bucket</span></span><br><span class="line">    <span class="keyword">int</span> pointer;<span class="comment">//pointer to voxel block</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>整个哈希表结构如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/hashing1.png" alt=""></p><p>为了解决冲突，作者将hash entry指针指向一个bucket。bucket大小固定，通过顺序遍历bucket来找到对应的hash entry（比较position）。当bucket满了的时候，寻找临近的bucket来找到是否有空闲的位置，而这个bucket相对于原来的偏移量就是offset，被存储在链表上一个entry中。这是hash表的一个比较通用的实现方式。</p><p>下图为哈希表插入以及删除的一个过程：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/hashing2.png" alt=""></p><p>值得注意的是，为了实行链表这个操作，每个bucket最后一个entry只能放链表的表头，也就是本身就该分配到这个bucket的元素才能插入该bucket的最后一个位置。</p><p>在查找操作中，找到对应的bucket，然后遍历，如果到了结尾依然找不到，就顺着链表继续找，直到查找成功，或者遇到一个空位置，说明查找失败。</p><p>需要注意的是，在垃圾收集过程中，我们会用到遍历block中的voxel时候设定的weight最大值，或者sdf最小值。如果weight最大值小于0，或者最小sdf绝对值大于1（或者某个值），那么就将这个block看做invalid，最后被删除掉。</p><p>对于本篇文章的其他内容，基本算是老生常谈了。动态的truncation，用来补偿远距离深度的不确定性，根据ICP估计位姿，根据raycast，tri-linear interpolation来计算出表面。以及一些GPU和host的双向流，这目前还不是我关注的重点。</p><p>实际上，如果不用GPU，本篇文章的hashing scheme思想还是比较简单的。而现在这样的idea越来越少了，目前的reconstruction系统需要结合IMU，纹理贴图等等，变得越来越复杂庞大了。</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 3D reconstruction </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper——RLSD 3D Reconstruction with LCD</title>
      <link href="/2019/02/21/Paper%E2%80%94%E2%80%94RLSD-3D-Reconstruction-with-LCD/"/>
      <url>/2019/02/21/Paper%E2%80%94%E2%80%94RLSD-3D-Reconstruction-with-LCD/</url>
      
        <content type="html"><![CDATA[<p>这次介绍的论文是牛津大学的一篇文章，全文名为<a href="https://link.springer.com/chapter/10.1007/978-3-319-46484-8_30" target="_blank" rel="noopener">Real-time Large-Scale Dense 3D Reconstruction with Loop Closure</a>。这是一篇16年ECCV的文章，我主要希望借鉴的是文章中关于submap的一些做法和想法。</p><a id="more"></a><p>和之前一样，我们跳过abstract，introduction，related work以及实验evaluation的部分，主要介绍这个系统的pipeline和技术实现。RLSD使用的是Submap的方法来重建,与之前的FlashFusion有较大的不同。不过在重建上，它依然使用的是hashing voxel与TSDF fusion。</p><h3 id="融合深度图"><a href="#融合深度图" class="headerlink" title="融合深度图"></a>融合深度图</h3><p>融合深度图其实也就是TSDF过程。为了方便理解，我们就使用论文中的符号来讲解TSDF的过程。实际上这里的TSDF与之前的也没有什么不同，不过在这里再次详细说明一下。</p><p>我们把地图中的场景用TSDF来描述，而具体的值用一个函数$F(X)$来描述。其中$X$表示的是空间中的一个体素坐标，而$F(X)$则是一个三元组$(d,w,c)$,$d$表示sdf值，也就是$X$距离最近的表面的距离，$w$表示的是权重,$c$表示的是颜色，这个是可选的。当然，还有个截断范围$[-\mu,\mu]$，超出截断范围的，设$w=0$,$d,c$为未定义（或者为1）。在本文中，$8\times 8 \times 8$为一个block，有效的block（包含了在截距范围内的voxel）才会被分配。为了找到一个空间点$X$对应的block，我们需要使用一个hash映射。这与FlashFusion中并没有太大的不同。</p><p>Tracking这一步是基于ICP算法的。众所周知，ICP算法是3D点之间的配准，而对于点的对应基于的是投影数据的联系，这个联系可以通过特征点匹配等等来得到。我们记相机内参为$K$，$t$时刻的深度图为$D_t$（也就是相机坐标下的z值），这样可以得到一个从2D到3D的转换：</p><script type="math/tex; mode=display">p(x) = D_t(x)K^{-1}\begin{pmatrix}x\\1\end{pmatrix}.</script><p>上面式子不难理解，其实正是我们之前介绍过的内容。这里的$x$指的是像素坐标，二维，而$P(x)$也就是$x$对应的相机坐标。</p><p>在每个时刻$t$，我们想估计的是位姿$T_t = (R_t,t_t)$，其中$R_t$表示旋转，而$t_t$表示的是平移。作为额外的输入，我们需要知道的是一个2D对应的3D的地图$V_{t-1}(x)$，以及表面法向图$N_{t-1}(x)$，这些都可以从已知位姿$T_{t-1}$以及TSDF中得到，我们通过使得下面的代价函数最小化来计算$T_t$:</p><script type="math/tex; mode=display">\epsilon_{ICP} (T_t) = \sum_x \rho\left((T_t^{-1}P(x) - V_{t-1}(\overline P(x)))^T N_{t-1}(\overline P(x))\right)</script><p>上式中，$\rho$是一个鲁棒的错误范数（比如huber），而$\overline P(x) = \pi(KT_{t-1}T_t^{-1}P(x))$。上式看起来比较复杂，但是细心分解一下还是不难理解的。$\pi$表示从齐次到非齐次的转换，也就是取前两维，使得三维变为二维坐标。$\overline P(x)$求的是$x$对应的点在$t-1$时刻的相机下的2维投影位置。而$V_{t-1}(x)$得到了$t-1$时刻像素位置$x$对应的三维点坐标，这个坐标是世界坐标系下的坐标。因此，$T_t^{-1}P(x) - V_{t-1}(\overline P(x))$理论应该是为0的，也就是我们需要优化的部分。而乘上法向量的部分我就不是很明白了，不知道有什么优点。论文中通过列文伯格-马夸尔特法来求得极值点。</p><p>为了将深度$D_t$融合到TSDF中，对于空间点集$\{T_t^{-1}P(x)\}$以及在它们截断距离内的点，我们在Hash表中分配对应的voxel block，并且将它们设定为可见集合$\mathbb{V}$的一部分。然后我们对可见集合中所有的voxel进行下面的更新：</p><script type="math/tex; mode=display">d \leftarrow \frac{wd+d^*}{w+1},c\leftarrow \frac{wc + c^ *}{w+1}, w\leftarrow w+1,</script><p>上式中，$d^* = D_t(\pi(KT_tX)) - [T_tX]_{(z)}$，也就是一个空间点投影到像素位置后，用该位置的深度减去该空间点的z值，从而得到了该点到表面的距离。如果颜色也是可用的，那么$c^* = C_t(\pi (KT_tX))$，也就是简单的取了投影像素位置的颜色值。</p><p>对于当前时刻的$V,N$地图我们可以通过raycasting来获得。关于raycasting论文中介绍的不多，和<a href="https://wlsdzyzl.top/2019/01/25/3D-Reconstruction%E2%80%94%E2%80%94TSDF-volume-reconstruction/" target="_blank" rel="noopener">TSDF</a>中的差距也不大。</p><h3 id="Tracking准确率的评估"><a href="#Tracking准确率的评估" class="headerlink" title="Tracking准确率的评估"></a>Tracking准确率的评估</h3><p>这篇文章中一个创新的地方是利用SVM对tracking是否成功进行评估。大多数现有的系统对于tracking失败的问题都不会做特殊的处理，但是在本文中，知道tracking是否失败对于建立一个鲁棒的建图系统以及建立submap之间的constraint都非常关键。</p><p>一般来说对于tracking是否失败的检测，会手动设定一个阈值，然后根据tracking过程中得到的指标来判断。这有一些额外的要求，比如residual不应该比某个阈值更大。而在本篇文章中，作者训练一个分类器来分开tracking成功与tracking失败的情况。对于每个$\epsilon_{ICP}$的优化，衡量inlier的百分比，Hessian矩阵的行列式以及最后的residual。接着，使用一个$x^2$的kernel函数将这三个特征推展为20维的描述子。最后，使用SVM来进行tracking成功和tracking失败进行分类。这个训练过程是在7 scenes数据集上进行的，从而获得需要的参数。通过训练，分类器分类的正确率达到95%，如果不使用kernel，成功率会下降到92.4%。具体的训练细节在这里就不多说了，我们主要是关注这个paper中的思想。</p><h3 id="Submap的构造"><a href="#Submap的构造" class="headerlink" title="Submap的构造"></a>Submap的构造</h3><p>本篇paper和FlashFusion最大的不同是使用了submap，submap的好处是每个小图的维护比较精确，而全局的优化也可以简化成对于各个submap位姿的优化，而不是对于每个关键帧都进行优化。因此可以减少计算量，从而实现对large scale的重建。这里先了解一下submap的构建。</p><p>在之前的工作中，submap建立的策略有两种，一是每$k$帧建立一个submap，在这种情况下，submap增长的速度是和时间成正比的，而各个submap之间的相似度取决于相机移动的速度。比如如果相机移动过慢或者静止，多个submap的内容可能一样，另外一种是根据相机的移动来建立submap。这样如果相机不动，就不会建立新的submap。</p><p>本文中提出了一种新颖的策略：我们评估这个场景的可见度，并且当相机的视窗移开了之前submap的中心位置，就开始一个新的submap。</p><p>Voxel hashing的方法很适合这个策略。我们给场景中新的部分分配voxel block。此外，我们维持了一个可见块集合$\mathbb V$。因为之前分配的block更有可能在submap的附近，我们计算可见块$\mathbb V$中的一个比例$r_{vis}$。这个比例指的是block creation index小于某个阈值$B$的比例。这么想，新建的block的creation index是越来越大的，因此，如果新建的block越多，那么有较小的index的block占的比例$r_{vis}$就会变小。如果$r_{vis}&lt; \theta$，则说明相机的视窗移动过去了，我们就开始一个新的submap。而$\theta$与$B$的值决定了每个submap的大小。</p><h3 id="Submap之间的constraints"><a href="#Submap之间的constraints" class="headerlink" title="Submap之间的constraints"></a>Submap之间的constraints</h3><p>在之前的关于submap的论文中，一个基本观点是local submaps需要能够互相重叠。本篇文章和这些之前工作不同的地方在于，我们同时并行多个submap的建立，由于高效的voxel block hashing，这种并行是可以实时进行的。</p><p>当我们假设submap之间一个新的overlap时，我们会跑一个额外独立的进程来建图。在尽可能多的submap上tracking，在全局帧中，相机的轨迹应该是一样的。这就给了我们在这些submap之间的constraint。在时间$t$从submap $i$到submap $j$的转换为$T_{t,i,j}$，则：</p><script type="math/tex; mode=display">T_{t,i,j} = T_{t,j}^{-1}T_{t,i},</script><p>上式中$T_{t,j},T_{t,i}$分别是submap $i,j$中tracking得到的位姿。</p><p>当我们tracking成功的时候，我们得到最高品质的有效constraint:$T_{t,i,j}$。为了维持一致性，多个这样的constraint被累加到一起得到一个总体的估计$T_{i,j}$。我们认为$v(T)$是一个压缩的6维向量来代表位姿的转换$T$，计算：</p><script type="math/tex; mode=display">v(\hat T_{i,j}) = \sum_{t}w_t v(T_{t,i,j}) + wv(T_{i,j})\sum_{t} w_t + w,</script><p>上式中$w_t = \frac{\sqrt{2b\hat r - b^2}}{\hat r}, r = \max(\Vert v(T_{t,i,j} - v(\hat T_{i,j})) \Vert,b)$，$b$是outlier阈值，$w$是之前用于估计$T_{i,j}$的观测的数目。使用迭代的reweighted最小平方，我们不仅仅估计出$\hat T_{i,j}$，也计算出在新的constraint $T_{t,i,j}$的inliers。在论文的后面会介绍到，我们会停止tracking一个submap，并且丢弃新计算的$T_{t,i,j}$如果他们不是自洽的（self-consistent）或者它与之前的估计$T_{i,j}$不一致。</p><p>通过这种策略实际上计算量是非常小的。因为tracking是必须做的，因此$T_{t,i},T_{t,j}$就会直接得到，而$T{i,j}$等聚合计算也是很容易做到的。</p><h4 id="P-S"><a href="#P-S" class="headerlink" title="P.S."></a>P.S.</h4><p>这里的部分我看的不是很明白。应该就是将submap中多个constraint合起来优化，得到一个估计$\hat T_{i,j}$。但是$v(\hat T_{i,j})$我不是很明白这里的权重的分配。</p><h3 id="回环检测和重定位"><a href="#回环检测和重定位" class="headerlink" title="回环检测和重定位"></a>回环检测和重定位</h3><p>实际上就我来说，submap中比较难把握的部分就是回环检测了。如果不是基于关键帧的，你可能需要将所有的帧都进行相似度的度量。现在我们看看本篇论文中的回环检测。</p><p>本文中的回环检测是基于关键帧的。毕竟对所有的帧都进行回环检测是不现实的。在本篇文章中，tracking和mapping都是运行在GPU上的，而loop closure和重定位是运行在CPU上的，说明loop closure与重定位需要较少的计算量。</p><p>loop closure关键的部分在于图片的相似度衡量。本篇paper中输入只有深度图，因此对于相似度的度量不能在基于RGB图的特征匹配。它是这么做的：</p><p>对于每一个输入的深度图进行窗口采样，窗口大小为$40 \times 30$，并且用$\sigma = 2.5$进行高斯滤波，得到的结果为$\tilde D_t$。然后使用fern conservatory来计算该图片的简化编码。在我们的实现中，每个conservatory由$n_F=500$个ferns组成，每个fern计算$n_B = 4$个二项决策。每个二项决策都根据$\tilde D_t$中的像素根据阈值$\tilde D_t(x_i) &lt; v_i$来确定一个布尔值，这其中$x_i,v_i$在最开始是被随机选择的。连接一个fern中的二进制码$f_i=\{0,1\}$得到一个编码块$b_j = (f_1,…,f_{n_B})$。使用$\ne$操作来返回一个布尔值，通过这种方法得到一个高效的方法来计算非相似性：</p><script type="math/tex; mode=display">\text{BlockHD}(\tilde D_{t_1},\tilde D_{t_2}) = \frac{1}{n_F} \sum_{j}(b_j(\tilde D_{t_1}) \ne b_j(\tilde D_{t_1})).</script><p>我们对所有关键帧维护这样的编码，如果某个帧与所有关键帧的最小不相似分数大于某个阈值，将它看作一个新的关键帧。</p><p>这个过程其实就是计算相似度的过程，与FlashFusion的mild类似。这部分的内容讲得也不够清楚，不清楚这样度量相似度背后的原理。不过，有很多别的闭环检测的算法，因此如果不是使用这种，我们可以跳过这一部分。下图为submap以及回环检测前和回环检测后的对比。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/lcd.png" alt=""></p><h3 id="控制逻辑以及闭环验证"><a href="#控制逻辑以及闭环验证" class="headerlink" title="控制逻辑以及闭环验证"></a>控制逻辑以及闭环验证</h3><p>闭环检测过程仅仅返回关键帧的ID。它们可以很容易地联系到位姿以及submap的索引。</p><p>系统的构架图如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/pipe.png" alt=""></p><p>我们会一直维持一个active submaps的集合，当tracking和raycasting在所有的active submap中进行时，新的深度信息会被融合到一个主要submap。如果tracking失败了，我们就不融合这个信息，并且继续tracking这个过程。如果在任何一个submap都没有tracking成功，就丢掉。</p><p>当相机移开了主要submap的中心（由之前的submap的构造中定义的标准），我们就初始化一个新的submap。因为这个submap最开始是空的，所以需要融合深度信息用来进行raycasting和tracking。我们累积主要地图和新的地图之间的constraint，一旦得到了一个稳定的相对的位姿估计，有$N_{stable}$个inlier帧，则新的submap就初始化成功。</p><p>同时，闭环检测系统也在运行着。如果新进的帧对主要的场景我们有一个稳定的tracking结果，而且闭环检测结果建议插入一个关键帧，我们就更新关键帧的数据库。</p><p>另外，如果闭环检测在数据库中找到了一个相似的深度图，在之前的某个当前不活跃的submap中，我们初始化一个新的闭环attempt。意思是我们将该submap激活并且开始raycasting和tracking。因为我们试图在当前主要submap与该submap中track一序列帧，我们又能够在这两个submap之间建立constraint。我们还需要验证闭环检测，因此除了鲁棒地估计这两个submap之间的相对位姿constraint，还需要验证得到的位姿constraint的正确性。一旦我们得到了$N_{stable}$个inlier帧，就认为闭环检测成功，否则丢弃这个闭环检测，认为这并不是一个回环。</p><p>很明显，如果对于所有活跃的场景的tracking都失败了，我们不能建立相对位姿的constraint，而是需要重定位。在这种情况下，如果$N_{stable}$个tracking attemps成功了我们任务重定位成功，否则我们认为重定位失败。</p><p>在这个过程最后，我们维护一个active submap的集合，删除那些不再被track以及闭环检测和重定位失败的submap。如果有多个候选，我们通过检测submap的可见度限制来选择一个新的主要场景并且选择当前课件比例最大的submap作为主要submap。如果有新的场景或者闭环attempt成功验证了，我们会开启一个新的进程来进行图优化。图优化的结果不仅对整个过程非常重要，对之后的可视化也非常关键。</p><h3 id="submap图优化"><a href="#submap图优化" class="headerlink" title="submap图优化"></a>submap图优化</h3><p>上面在讨论的是我们获得一系列submap之间的constraint，可以用来优化每个submap在全局坐标下的位姿。如果没有回环，那么计算确切的submap位姿是无关紧要的，而这时候全局的位姿优化问题就产生了。</p><p>用$\tilde q(T)$来表示四元数的三个虚分量，表示欧几里得变换$T$的旋转部分。用$t(T)$来表示平移，用$v(T) = (\tilde q(T),t(T))^T$将旋转和平移连接起来。如果用$P_i$来表示submap $i$的位姿，而$T_{i,j}$表示的是两个submap的相对constraint，那么我们想最小化的代价函数为：</p><script type="math/tex; mode=display">\epsilon_{graph} = \sum_{i,j \in \mathbb T}\Vert v(P_iP_j^{-1}T_{i,j}) \Vert ^2</script><p>上式中，$\mathbb T$表示的所有的submap之间配对关系的总和。</p><p>上面的部分有点难以理解。我的理解是这样的：首先$T_{i,j}$是一个优化得到的submap之间的位姿转换，因为各个时刻的相同的帧在不同submap中的位姿应该是一致的，或者即使位姿不一致，它们应该也是存在一个刚性的转换。而由于噪声的存在，往往无法保证一致或者转换后一致，因此我们会从多个对应帧中找到这两个submap之间的相对位姿。</p><p>而$P_iP_j^{-1}T_{i,j}$得到的应该是一个没有平移没有旋转的转换矩阵，因此它的范数作为了优化变量。使用四元数这种表述方法是因为旋转矩阵没有转换的话是非零的，是一个单位矩阵，不便于作为代价函数。</p><p>通过上面的代价函数，我们可以得到各个submap的位姿$P$。</p><p>上述函数依然使用非线性优化来得到最小值。在本文中，为了方便计算，使用四元数来代表导数$\Delta \tilde q$。另外一个值得注意的点是海森矩阵$\Delta ^2 \epsilon _{graph}$或者他的估计是稀疏矩阵。对2到100个submap进行上述优化并没有显著的计算区别，建议使用稀疏和超节点矩阵因子分解方法。在实际中，这个优化仅仅偶尔会进行，而且它比较低的计算量使得它可以运行在后端的CPU线程上。</p><h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><p>对于submap的构建实际上有多种办法，一种是SLAM中常见的，他们只是局部建立位姿和稀疏特征点的submap，而不会分割TSDF场。通过上述的SLAM再根据全局的map来建立TSDF也是可以的，但是不会减少TSDF占用的内存。另外一种是对TSDF也进行分割，visualize的时候我们可以将部分TSDF放入外存，从而减少内存占用。</p><p>本篇文章中会对TSDF也进行分割，这时候对多个submap进行可视化就需要对各个submap的TSDF进行融合。</p><p>要明白，submap的图优化和局部submap的在线更新对于实时的可视化是非常重要的。将局部submap表示为TSDF的优点在于在呈现全局映射的时候可以动态的融合各个子映射。文章中定义了一个新的TSDF：</p><script type="math/tex; mode=display">\hat F(X) = \sum_{i}F_w(P_iX)F(P_iX).</script><p>上式中$P_i$为submap $i$的位姿，使用$F_w$来表示从$F$中取出来$w$项，也就是权重。可视化通过全局的TSDF，也就是$\hat F$来进行raycasting等等得到模型表面法向。</p><p>上面的内容就是论文的主要思路。还有一些不明白的地方可以查看原文，或者在实践中找到答案。</p><p>其实我比较疑惑的部分在于闭环检测时候，对于多个submap进行track。因为这时候序列是不同的了，因此它们的位姿也就不同，这时候又如何根据原来的帧的位姿求得$T_{i,j}$?</p><p>答：在submap中track得到的理论上是当前的位姿，因此在多个submap中track同一个帧一样得到的应该是相同的位姿。我之前理解错误了。注意track是得到位姿的过程。</p><h3 id="source-code"><a href="#source-code" class="headerlink" title="source code"></a>source code</h3><p>这篇论文有一个相关的项目，叫做<a href="https://github.com/victorprad/InfiniTAM/" target="_blank" rel="noopener">InfiniTAM</a>，可以点击阅读源码，了解详细的实现过程。</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 3D reconstruction </tag>
            
            <tag> SLAM </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper——Flashfusion</title>
      <link href="/2019/02/21/Paper%E2%80%94%E2%80%94Flashfusion/"/>
      <url>/2019/02/21/Paper%E2%80%94%E2%80%94Flashfusion/</url>
      
        <content type="html"><![CDATA[<p>对于论文的阅读是我的弱项，这是导致我学习过程总是恍恍惚惚一脸懵比的一个重要的原因。出来混总是要还的。大学时候的浪荡带来的后果现在就得到了体现。<br><a id="more"></a><br>今天记录一篇对于<a href="http://www.roboticsproceedings.org/rss14/p06.pdf" target="_blank" rel="noopener">FlashFusion</a>的阅读。这篇文章是我们实验室的学长发在RSS的论文，是关于实时三维重建的。 </p><p>FlashFusion是一个实时三维重建系统，能够在CPU上实现全局一致的稠密实时三维重建。对于文章的分析主要是对于系统构架以及具体实现的技术进行解读，因此我们跳过abstract，related work以及实验部分。</p><p>FlashFusion的系统构架图如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/flashfusion.png" alt=""></p><p>我们可以看到的是FlashFusion采取的是关键帧策略。它分为三个线程：tracking，optimization，以及meshing，分别对应了追踪，优化以及网格提取。FlashFusion之所以能实现上述效果，是因为它在回环检测，以及SLAM上都有不少的改进。</p><h3 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h3><p>FlashFusion中的SLAM部分被称为FastGO，或者GCSLAM。采取的是帧注册的策略。当捕获到新的帧时，使用<a href="https://arxiv.org/abs/1702.08780" target="_blank" rel="noopener">MILD</a>闭环检测与上一个关键帧进行相似度的度量，如果相似度过大，则当前帧被识别为一个新的关键帧。否则，被当作前一个关键帧对应的局部帧，并且在判断的过程中，根据ORB等特征点匹配，计算出从关键帧到当前帧的位姿变换，从而得到当前帧的位姿。</p><p>如果当前帧被识别为关键帧，则就会进行一次全局注册，对所有的关键帧的位姿进行一次优化，也就是进入了optimization线程，用于维持global consistency。为了说明这个优化过程，我们先来看看一对帧之间的代价函数：</p><script type="math/tex; mode=display">\begin{equation}E_{i,j}(T_{i,j}\vert T_{i,j} \in SE(3)) = \sum_{k=0}^{\vert C_{i,j} \vert - 1}\Vert p_i^k- T_{i,j}p_j^k \Vert^2\end{equation}</script><p>上式中，$T_{i,j}$是第i帧与第j帧之间的相对转换，$C_{i,j} = \{(p_i^k,p_j^k)\vert k = 0,1,…,\vert C_{i,j} \vert-1\}$是第i帧与第j帧之间的所有对应的特征点对的集合，由于有深度图，所以我们也就直接得到了特征点的相机坐标，通过转换后，属于一对的特征点坐标应当一致。因此上面的误差也算是重投影误差的一种吧。</p><p>而全局误差就是对所有的关键帧对应的局部帧上述误差的总和：</p><script type="math/tex; mode=display">E(\xi) = \sum_{i=0}^{N-1}\sum_{j \in \Phi(i)} E_{i,j} = \sum_{i=0}^{N-1}\sum_{j \in \Phi(i)}\sum_{k=0}^{\vert C_{i,j} \vert-1}\Vert p_i^k - T_{i,j}p_j^k\Vert^2</script><p>上式中，$\Phi(i)$指的是由mild选出来的最接近关键帧$F_i$的5个帧。如果对所有的帧都进行上述误差会使得计算量过大，使得CPU上的实现不够现实。</p><p>这5个帧是如何选出来的？实际上，当新的关键帧插入时候，会与之前所有的关键帧进行match，进而通过mild选出来5个相似度最高的关键帧，这也就意味着上述全局误差的贡献者全部为关键帧。</p><p>上述优化问题是比较好解决的，文章中使用的是高斯牛顿优化算法，根据之前的SLAM中<a href="https://wlsdzyzl.top/2018/11/14/SLAM%E2%80%94%E2%80%94%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/" target="_blank" rel="noopener">非线性优化</a>的章节，我们知道高斯牛顿优化需要的是：$J(x)^TJ(x)$与$J(x)^Tf(x)$。</p><p>我们将误差$E(\xi)$换一种写法：$E(\xi) = r(\xi)^Tr(\xi)$，其中$r(\xi) = [r_0^T ,r_1^T,…,r_{M-1}^T]$，$r_l = p_i^k - T_{i,j}p_j^k$，$M$就是特征点对的总和了。</p><p>则在本例中，我们要求的$\delta$，也就是每次迭代的增量为：</p><script type="math/tex; mode=display">\delta = -(J(\xi)^TJ(\xi))^{-1}J(\xi)^Tr(\xi),</script><p>这里和高斯牛顿中推导的方法是一致的。而雅科比矩阵的求解：</p><script type="math/tex; mode=display">J(\xi)^TJ(\xi) = \sum_{i=0}^{N-1}\sum_{j \in \Phi(i)}\sum_{k=0}^{\vert C_{i,j}\vert-1}(J_{i,j}^k)^TJ_{i,j}^k,\\J(\xi)^Tr(\xi) = \sum_{i=0}^{N-1}\sum_{j \in \Phi(i)}\sum_{k=0}^{\vert C_{i,j}\vert-1}(J_{i,j}^k)^Tr_l,</script><p>我们不会直接求$J(\xi)$，因为需要的是上面两个矩阵，而他们的求法甚至比直接求单独的雅科比矩阵更加容易。从<a href="http://www.luvision.net/img/FlashFusion/FastGO.pdf" target="_blank" rel="noopener">FastGO</a>中，我们可以更加详细地了解解决上面优化话题的快速算法。同时，为了提高鲁棒性，Flashfusion对于cost funstion选择了Huber norm，为了实现实时减少计算量，也不会对所有的frame pair进行计算，而是选取变化最大的10个frame pair。</p><p>这里有一个细节，在观看demo的时候，我们看到作者捂住了镜头，换到了之前扫描过的场景，而重建的视野也直接回到了之前扫描的场景。对于这个帧，插入的一定是新的关键帧，甚至有可能会tracking failed。而该帧的位姿，就是通过global optimization得到的。可以看到FlashFusion是非常强大的。</p><h3 id="TSDF-Fusion"><a href="#TSDF-Fusion" class="headerlink" title="TSDF Fusion"></a>TSDF Fusion</h3><p>关于TSDF的介绍，之前<a href="https://wlsdzyzl.top/2019/01/25/3D-Reconstruction%E2%80%94%E2%80%94TSDF-volume-reconstruction/" target="_blank" rel="noopener">TSDF</a>也提了，虽然没有涉及到具体的公式，但是还是能够有个大概的了解。下面我们用一些数学表达，介绍一下原本的TSDF的具体实现。</p><p>TSDF将空间分成若干个voxel，voxel的个数依赖于重建的分辨率，而TSDF值就是每个voxel中心距离最近的表面的距离。这个TSDF值如何得到？我们将体素根据当前的相机位姿，转换到相机坐标系下，然后投影到成像平面上。然后对于该投影坐标（二维），我们有一个对应的深度值，使用该深度值减去体素在相机坐标下的z值，我们就可以得到它到这个平面的距离。</p><script type="math/tex; mode=display">d^* = D_t(\pi(KT_tp)) - [T_tp]_z</script><p>上式中，$K$为相机内参，$T_t$为此刻的相机位姿，而p为体素，$\pi$表示从齐次到非齐次的转换，也就是取了前两维，我们通过$D_t$来表示取深度值，$[p]_z$表示z轴坐标。</p><p>为了截断，我们还需要用下面这样的截断函数：</p><script type="math/tex; mode=display">d = \left\{\begin{matrix}\frac{d^ *}{d_{\max}} & \frac{d^ *}{d_{\max}}<1\\1&\frac{d^*}{d_{\max}}\ge 1\end{matrix}\right.</script><p>其中，$d_{\max}$为截断值。</p><p>另外，TSDF fusion中一点是权重。因为对于不同的位姿得到的同一个voxel下的TSDF值是不同的，因此在integrate的时候需要有权重。在本篇文章中，对于sdf和权重的更新：</p><script type="math/tex; mode=display">sdf_n = \frac{sdf_0 * w_0 + sdf_i * w_i}{w_i + w_0}, w_n = w_i + w_0 .</script><p>其中$w_0$为原来的，$w_i$为新来的，$w_n$为融合之后的。</p><p>我们做的重建主要是表面重建，因此关注的就是靠近表面的体素。传统的TSDF fusion会对视锥内的每一个voxel都进行上述过程，从而获取它的截断距离。而为了节省空间，研究人员提出来了Hashing和Octree两种方法，本篇文章采用的是Hash的方法。对于Hashing，每$8\times 8\times 8$个体素被组建成一个chunk，每个chunk都通过哈希函数映射到一个位置，大大提高了检索速度。我们可以观察一般的tsdf fusion中有效块的占比：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/valid_chunk.png" alt=""></p><p>可以看到，视锥内只有一小部分的chunk包含了表面，也就是有效的TSDF值，而传统方法中对所有的voxel进行遍历得到TSDF，会浪费很多的时间和计算量。因此，FlashFusion采取了一种稀疏体素采样方法，选取有效块。对于每个chunk，计算它的8个定点的TSDF值，如果有一个定点的TSDF值（绝对值）小于某个阈值，那么将它作为有效的chunk。这背后的道理是，如果一个chunk中包含表面，它有很大的可能性至少某个面会经过这个面，有很大的可能性至少有一个顶点会投影到这个表面上，如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/corner.png" alt=""></p><p>假如分辨率为$r$，这个chunk的大小为$N^3$。如果一个voxel在表面的截断距离内，则：$\vert d_v \vert \le d_{\max}$。那么它的顶点应该会满足：</p><script type="math/tex; mode=display">\vert d_c \vert\leq \vert d_v \vert + \sqrt{2}N \times r < d_{\max}+\sqrt 2N \times r.</script><p>因此，如果所有的顶点都大于$d_{\max}+\sqrt 2N \times r$，那么这个chunk里几乎不可能包含表面了（这部分的内容和论文有区别，不清楚是不是论文的错误）。在实现中，论文将$8 \times 8 \times 8$个chunk再次归为一个Cube，现在Cube上进行稀疏采样，再在有效的Cube里进行chunk的采样。下面是采用稀疏采样的准确度和时间：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/ssv.png" alt=""></p><p>可以看到利用稀疏采样，我们可以选到98%的真正有效chunk，接着对有效的chunk进行遍历求得TSDF值，花费时间仅仅为全部体素遍历的2%。</p><p>对于有效chunk的选择仅仅应用在关键帧上，然后局部帧再被融合到对应的关键帧中。也就是，chunk的ID会被存储到对应的关键帧中，用于后面的de-integrated。对于颜色也是类似的，新的帧的颜色会给更多的权重。</p><h3 id="网格提取"><a href="#网格提取" class="headerlink" title="网格提取"></a>网格提取</h3><p>对于网格提取可以分成多边形生成与法向提取两个部分。如何从TSDF场到一个三维网格模型，别的paper中很多又叫做raycasting，这篇文章中提到了一个方法，叫做<a href="https://www.nvidia.com/object/gpu_gems_home.html" target="_blank" rel="noopener">ncrementalmarching  cubes  algorithm</a>(这是一本书)。这些算法的道理都是表面两侧体素的TSDF值符号不同，因此会使用线性插值来得到表面。插值过程如下：</p><script type="math/tex; mode=display">v = \frac{s_a \times v_b - s_b \times v_a}{s_a - s_b}</script><p>其中$s$为sdf值，而$v$代表了各个体素的坐标。你可能会奇怪，为什么sdf值和体素没有对应相乘，如果画一张图你就会理解：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/inter.jpg" alt=""></p><p>可以看到，实际上表面的点是更靠近sdf值小的，因此计算位置时候应该给sdf值小的较大的权重。</p><p>在本篇paper中，采取了动态阈值的方法，因为仅仅根据sdf值来判断是不合适的，因为如果出现比较bad的情况，比如观测的方向和表面接近平行，那么即使表面附近的voxel也有比较大的sdf值。所以基于chunk的策略，它为不同的chunk设定不同的阈值，当生成网格时，包含表面的voxel中最大的sdf被当作这个chunk的阈值。这样，当引入新的frame时，如果某个体素的sdf比这个阈值更大，就会被忽略。在这种策略下，每次meshing阶段，平均只需要增加10%的新的mesh，其他的mesh只是被更新了。通过这种方法，多边形生成的速度被加速了两倍。</p><p>法向提取的过程如下：</p><script type="math/tex; mode=display">n = \begin{bmatrix}\delta_x\\\delta_y\\\delta_z\end{bmatrix}=\begin{bmatrix}s_{i+1,j,k} - s_{i-1,j,k}\\s_{i,j+1,k} -s_{i,j-1,k}\\s_{i,j,k+1} - s_{i,j,k-1}\end{bmatrix},</script><p>上面的法向计算过程其实不难理解，是对该点的法向的粗略估计，需要6个临近的voxel（有效的）。在FlashFusion中，每个chunk中还维护了一个查找表，用来记录它相邻的chunk的地址，这样就避免了在多边形生成与法向提取中对总的查找表（chunkList）的查询。对于本文章中mesh的生成我了解得还不是太清楚，因为介绍的比较简单。不过这也不是我想了解的重点，因此暂时就先不深究了。</p><h3 id="Re-integrate"><a href="#Re-integrate" class="headerlink" title="Re-integrate"></a>Re-integrate</h3><p>reintegrate是只将关键帧对应的局部帧融合进去。对于每个关键帧，我们只融合它对应的前10个局部帧，因为如果局部帧过多，只能说明相机没有移动或者移动过慢，而这些局部帧大多提供了相似的信息，并不会有多大的贡献。因此选取前10个既保证了速度，又保证了效果。</p><p>上述就是FlashFusion的关键部分介绍。下面是一个FlashFusion重建的demo：</p><video id="video" controls preload="none"><source id="mp4" src="http://luvision.net/img/FlashFusion/demo_rss_TBSI.mp4" type="video/mp4"></video><p>关于mild闭环检测和GCSlam可以看下面两篇文章：</p><ul><li><a href="https://ieeexplore.ieee.org/iel7/8014303/8019290/08019479.pdf" target="_blank" rel="noopener">MILD: Multi-index hashing for appearance based loop closure detection</a></li><li><a href="http://www.luvision.net/FastGO" target="_blank" rel="noopener">Real-time Global Registration for Globally Consistent RGBD SLAM</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 3D reconstruction </tag>
            
            <tag> SLAM </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——回环检测</title>
      <link href="/2019/02/16/SLAM%E2%80%94%E2%80%94%E5%9B%9E%E7%8E%AF%E6%A3%80%E6%B5%8B/"/>
      <url>/2019/02/16/SLAM%E2%80%94%E2%80%94%E5%9B%9E%E7%8E%AF%E6%A3%80%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<p>回环检测（Loop Closure Detection）和之前谈到的前端和后端都不一样，但是一个完整的SLAM系统也不能离开回环检测。</p><a id="more"></a><p>回环检测，简单的来说，就是来看看现在扫描的场景之前有没有遇到过。因为即时有了前后端的存在，我们依然无法保证位姿与路标的完全正确性，由于噪声的存在，下一次你再次走到该地方的时候，得到的路标可能与上次的路标位置不同。这几乎是一定会发生的事情。这样，没有回环检测，就会导致建图出现差错，重影，从而也会影响到定位。下图展示了闭环检测前与闭环检测后的效果：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/loop_closure.png" alt=""></p><p>实际上对于回环检测也有很多的方法。有一种想法是基于里程计的几何关系，也就是我们知道运动到上次运动的地方了，然后进行闭环检测，来观察是否是上次运动的地点。不过这个想法有点本末倒置，因为由于误差的存在，我们往往无法知道是否运动到了之前运动地点的附近。相反，我们正是希望通过闭环检测来更加准确的建图和定位，因此这个方法无法在累积误差较大的时候工作。</p><p>另外一种是基于外观的，也是目前的闭环检测方法的主流。主要就是判断当前场景与之前运动过场景进行一个相似度的辨识。如果相似度很高，就可以找到之前运动的地点了。</p><p>对于闭环检测的判别，与其他分类，判断的问题一样，是有准确率和召回率两个判断依据的。准确率是通过这个闭环检测器检测出来的是相同地点中判断正确的比例，而召回率是所有相同地点有多少被检测出来了。在SLAM中，我们对准确率要求更高，因为如果不是相同地点我们却当成了相同地点，那会导致建图结果与实际运动情况差别非常大，而将相同地点判断为非相同地点，可能也就是出现少数重影，也可以通过别的回环或者其他方法消除这个inconsistency。</p><p>对于相似度的判别有很多，有一种办法是基于特征匹配的，比较容易理解。只要匹配个数超过一定值，我们就认为出现了闭环，或者定义匹配个数数量为相似度的度量。这个方法对于光照等变化比较敏感，因为可能光照不同，就会造成特征匹配不成功。</p><p>另外一种方法是词袋模型。这里我简单介绍一下词袋模型（Bag of Words）。词袋模型需要字典（dictionary）。简单来说，就是对扫描的场景中出现的属于某些东西做成一个分类，类似于字典。而对于扫描到的每一帧，建立一个词袋，来观察该帧里出现的属于字典中的东西。我们可以用0和1来表示某个“字”是否出现过，或者用大于1的数表示该帧里出现的次数，从而对于某个帧都能形成一个向量，再比较向量的相似性，从而比较图片的相似性。我们可以假象字典里有桌子，椅子等等，但是实际上字典的建立是一个聚类问题，比如使用k-means算法进行无监督学习来聚类，字典中的”字“比我们想象的更抽象，就是聚类的结果，一般来说就是一个个数字来标识类别。为了提高字典的查找速度，可能需要用多叉数来建立这个字典，也就是多层聚类等。</p><p>词袋模型是一个很好的闭环检测的方法。我们可能隐约感觉到了词袋模型很像语义分割。实际上目前神经网络的识别远远超过了词袋模型，因此越来越多的研究者将深度学习与闭环检测结合，达到更好的效果。</p><p>最后，实际上基于特征的闭环检测用的也很多，实验室的学长提出的<a href="https://arxiv.org/abs/1702.08780" target="_blank" rel="noopener">MILD: Multi-Index hashing for Loop closure Detection</a>是一种非常快速的闭环检测方法，可以用到实时的三维重建当中。</p><p>本篇文章只是简单的介绍了下什么是闭环检测，并没有涉及到具体的做法。而闭环检测有很多相关的论文，可以通过阅读它们来了解更先进的闭环检测方法。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——位姿图优化</title>
      <link href="/2019/02/16/SLAM%E2%80%94%E2%80%94%E4%BD%8D%E5%A7%BF%E5%9B%BE%E4%BC%98%E5%8C%96/"/>
      <url>/2019/02/16/SLAM%E2%80%94%E2%80%94%E4%BD%8D%E5%A7%BF%E5%9B%BE%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>SLAM中另外一个用到的最多的后端优化方法叫做位姿图（Pose Graph）优化。想象一下，对于路标的优化，可能进行几次之后就已经收敛了，这时候每次插入一个帧都再次进行一次BA仿佛有点用力过猛。而且实际中，路标的数量远远大于位姿数量，因此BA在大规模建图时，它的计算量可能会越来越大，使得实时计算变得困难。这里我们介绍的位姿图优化，就是省去了对路标的优化，仅仅调整位姿的一种做法。<br><a id="more"></a></p><p>我们将pose graph的优化转换成图的问题，那么图的节点就是一个个位姿，用$\xi_1,…,\xi_n$来表示，而边则是两个位姿之间相对运动的估计，这个估计可能来自与特征点法或者是直接法。比如$\xi_i,\xi_j$之间一个相对运动$\Delta \xi_{ij}$，则：</p><script type="math/tex; mode=display">\Delta \xi_{ij} = \xi_i^{-1}\circ \xi_j = \ln(\exp((-\xi_i)^{\hat{}}) \exp (\xi_j^{\hat{}}))^{\hat{}}</script><p>或者按照李群的写法：</p><script type="math/tex; mode=display">T_{ij} = T_{i}^{-1} T_j.</script><p>我们知道，实际中上式不会精确成立，因此我们需要设立最小二乘误差，然后讨论关于优化变量的导数。这里我们将上式的$T_{ij}$移到右侧，为了让其满足误差最小为0的设定，加上一个$\ln$:</p><script type="math/tex; mode=display">e_{ij} = \ln(T_{ij}^{-1}T_i^{-1}T_j)^{\hat{}} = \ln(\exp((-\xi_{ij})^{\hat{}})\exp((-\xi_{i})^{\hat{}})\exp(\xi_j^{\hat{}}))^{\hat {}}</script><p>值得注意的是这里的优化变量有两个：$\xi_i,\xi_j$，因此我们需要求$e_{ij}$关于这两个变量的导数。按照李代数的求导方式，给$\xi_i,\xi_j$各一个左扰动$\delta \xi_i,\delta \xi_j$，于是误差变为：</p><script type="math/tex; mode=display">\hat e_{ij} = \ln(T_{ij}^{-1}T_i^{-1}\exp((-\delta \xi_i)^{\hat{}})\exp(\delta\xi_j)^{\hat{}}T_j)^{\hat{}}</script><p>我们希望将扰动项移到左侧或者右侧，需要利用到一个伴随性质：</p><script type="math/tex; mode=display">\exp((Ad(T)\xi)^{\hat{}}) = T\exp(\xi^{\hat{}})T^{-1}.</script><p>稍加改变，得到：</p><script type="math/tex; mode=display">\exp(\xi^{\hat{}})T = T\exp((Ad(T^{-1})\xi)^{\hat{}}).</script><p>这说明通过引入一个伴随项，我们能够交换扰动项左右侧的$T$，利用它可以将扰动项移到最右，导出右乘形式的雅科比矩阵：</p><script type="math/tex; mode=display">\begin{aligned}\hat e_{ij} &=\ln\left (T_{ij}^{-1}T_i^{-1}\exp((-\delta\xi_i)^{\hat{}})\exp(\delta\xi_j^{\hat{}})T_j\right)^{\hat{}}\\&=\ln\left(T_{ij}^{-1}T_i^{-1}T_j \exp\left((-Ad(A_j^{-1})\delta\xi_i)^{\hat{}}\right)\exp\left((Ad(T_j^{-1})\delta \xi_j)^{\hat{}}\right)\right)\\&\approx \ln(T_{ij}^{-1}T_i^{-1}T_j[I - (Ad(T_j^{-1})\delta \xi_i)^{\hat{}} + (Ad(T_j^{-1})\delta\xi_j)^{\hat{}}])^{\hat{}}\\&\approx e_{ij}+\frac{\partial e_{ij}}{\partial \delta \xi_i}\delta \xi_i + \frac{\partial e_{ij}}{\partial \delta \xi_j}\delta \xi_j\end{aligned}</script><p>因此，按照李代数上的求导规则，我们求出了误差关于两个位姿的雅科比矩阵。关于$T_i$的：</p><script type="math/tex; mode=display">\frac{\partial e_{ij}}{\partial \delta \xi_i} = -\mathcal{J}_r^{-1}(e_{ij})Ad(T_j^{-1}).</script><p>关于$T_j$的：</p><script type="math/tex; mode=display">\frac{\partial e_{ij}}{\partial \delta \xi_i} = \mathcal{J}_r^{-1}(e_{ij})Ad(T_j^{-1}).</script><p>这部分的理解有点困难，可以回顾之前的<a href="https://wlsdzyzl.top/2018/11/09/SLAM%E2%80%94%E2%80%94%E6%9D%8E%E7%BE%A4%E5%92%8C%E6%9D%8E%E4%BB%A3%E6%95%B0/" target="_blank" rel="noopener">李群李代数</a>。之前也说过，由于李群（se(3)）上的雅科比矩阵形式过于复杂，我们通常取近似。如果误差接近于0，可以取近似：</p><script type="math/tex; mode=display">\mathcal{J}_r^{-1}(e_{ij}) \approx I + \frac 1 2 \begin{bmatrix}\phi _e ^{\hat{}} & \rho _e^{\hat{}}\\0 & \phi _e ^{\hat{}}\end{bmatrix}.</script><p>了解了雅科比计算之后，其余的部分就是普通的图优化了。记$\varepsilon$为所有边的集合，总体的目标函数为：</p><script type="math/tex; mode=display">\min_\xi \frac{1}{2} \sum_{i,j \in \varepsilon} e_{ij}^T\Sigma_{ij}^{-1}e_{ij}.</script><p>我们依然可以利用列文伯格或者高斯牛顿法来解决这个问题。</p><h3 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h3><p>伴随性质：</p><ul><li>SO(3)<script type="math/tex; mode=display">R \exp(p^{\hat{}})R^T = \exp((Rp)^{\hat{}}).</script></li><li>SE(3)<script type="math/tex; mode=display">T\exp(\xi^{\hat{}})T^{-1} = \exp((Ad(T)\xi)^{\hat{}}).</script>其中：<script type="math/tex; mode=display">Ad(T) = \begin{bmatrix}R & t^{\hat{}}R\\0 & R\end{bmatrix}.</script></li></ul>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>3D Reconstruction——TSDF volume reconstruction</title>
      <link href="/2019/01/25/3D-Reconstruction%E2%80%94%E2%80%94TSDF-volume-reconstruction/"/>
      <url>/2019/01/25/3D-Reconstruction%E2%80%94%E2%80%94TSDF-volume-reconstruction/</url>
      
        <content type="html"><![CDATA[<p>最近做的工作是三维重建的，需要解决的问题是submap中tsdf的re-integrate与de-ingegrate。现在先搞明白整个TSDF fusion是怎么回事。我们从一个简单的例子：从多张输入帧中重建出三维模型。<br><a id="more"></a></p><p>输入帧每一对由一张颜色图（RGB）与对应的深度图（depth）结合而成的。对于这个重建的过程必须要足够快，才能满足实时的要求。如下图，分别为输入的RGB与depth。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/tsdf1.png" width="49%"><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/tsdf2.png" width="49%"></p><p>整个系统的pipeline如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/tsdf7.png" alt=""></p><p>首先，输入一对frame，对于深度图，我们需要经过双边滤波来降噪，并且计算法向量，以进行ICP点云配准，最后结合color进行TSDF的integration，得到TSDF field，根据TSDF进行raycasting，从而获得重建表面。</p><p>这其中必须提到的是坐标系的转换。因为多个帧的相机坐标系是不一样的，但是我们要将他们重建在一起，需要转换到全局坐标系下，或者得到各个相机坐标系之间的相互转换，也就是要求得相机的位姿。对于相机坐标（针孔相机，pinhole camera）与世界坐标的模型，我们现在应该已经很熟悉了。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/tsdf3.png" alt=""></p><p>上述的图片展示了从世界坐标转换到相机坐标最后到像素投影坐标的过程。期间有一个gridPos的转换，这个是将空间分割成了大小相等的体素，这个步骤很简单一般只是对空间坐标的缩放保留精度问题。</p><h3 id="TSDF"><a href="#TSDF" class="headerlink" title="TSDF"></a>TSDF</h3><p>接下来就到了TSDF的介绍了。TSDF（Truncated Signed Distance Function）是截断符号距离函数的缩写，各个体素的截断符号距离组成了TSDF field。这个TSDF是如何计算的？</p><p>首先我们需要介绍什么是SDF值。一个体素的SDF值，是它到最近的表面的距离，如果它在表面前（也就是距离相机更近），它是正值，如果在表面后，则为负值。对于这个值的计算，我们首先将在视锥内的体素投影到像素坐标，然后用该像素坐标的深度值减去这个体素的实际z值。在相机运动的过程中，空间voxel的sdf值可能会更新的。</p><p>而TSDF就是规定了一个最远距离。因为我们知道，三维重建我们关注的是重建的表面，如果一个体素距离表面太远，它对表面重建不会有什么实际贡献。因此TSDF规定一个最远距离，如果距离比这个更大，它的TSDF值就是无效的，也就是用SDF值除以$d_{\max}$，只保留区间$[-1,1]$的值。下面这幅图形象地解释了什么是TSDF。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/tsdf5.png" alt=""></p><p>在相机运动的过程中，同一个voxel对应的color与depth值是不一样的，因此在integrate的时候对于不同的值我们需要加上权重，来表示它的可信赖程度。如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/tsdf4.png" alt=""></p><p>可以看到，入射角更小，则是比较好的情况，入射角越大，带来的结果也相对更不可靠，因为很明显它不应该是距离表面最近的距离。因此实际中的权重，应该给入射角小的相机位置采集到的帧率更大的权重。具体的实现，可以将voxel位置向量（相机坐标系下）与它的法向量相称，入射角小的时候，根据向量乘，我们知道它能得到更大的乘积结果。</p><h3 id="Adaptive-Raycasting"><a href="#Adaptive-Raycasting" class="headerlink" title="Adaptive Raycasting"></a>Adaptive Raycasting</h3><p>Raycasting是从TSDF场中恢复出表面的过程。我们可以这样想象，从一个地方射出一条线过去，如果它经过了表面，那么这个光线经过的体素的TSDF值一定有一个从正变负，或者从负变正（如果是实时重建，那么只有从正到负）的过程。这个射出的方向，就是相机坐标系z轴的。而正负交接点0点，我们称为zero-crossing，就是表面所在的voxel。我们要做的就是找到这个地方，当然有时候可能不会有哪个的体素大小直接是0,这时候就需要进行三线性插值（trilineal interpolation），找到逼近0的哪个地方。距离操作中，我们为了加速，可能会开始已一个比较大的步长，找到了zero-crossing，换成更小的步长，直到得到要求的精度，使得选取点的TSDF值尽量接近于0。得到这个点之后，再同样根据线性插值，写入color（实际中color可能是包含在TSDF场中的，以及权重）。</p><p>上面的算法没有包含光线和阴影的部分。</p><p>接下来的就是mesh生成与法向量的提取。这个就是另外的部分了，现在我们已经简单介绍了一般的实时三维重建的步骤，这里都是非常通俗的语言，没有包含任何公式。实际中的工程遵循上面的思想，还会遇到各种各样的实际问题。总之希望能有所帮助吧。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/tsdf6.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 三维重建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 3D reconstruction </tag>
            
            <tag> TSDF </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——后端（二）Bundle Adjustment</title>
      <link href="/2019/01/23/SLAM%E2%80%94%E2%80%94%E5%90%8E%E7%AB%AF%EF%BC%88%E4%BA%8C%EF%BC%89Bundle-Adjustment/"/>
      <url>/2019/01/23/SLAM%E2%80%94%E2%80%94%E5%90%8E%E7%AB%AF%EF%BC%88%E4%BA%8C%EF%BC%89Bundle-Adjustment/</url>
      
        <content type="html"><![CDATA[<p>Bundle Adjustment近些年在SLAM的研究中起到了非常重要的作用。Bundle Adjustment是将特征点与相机位姿一起作为优化变量，使得整体误差尽量变小。因为是非线性优化，不一定能找到全局最小值，因此对初始值的依赖比较大。另外，可以想象的到，BA需要计算的矩阵维度非常大，但是因为它特殊的结构，使得BA的计算简化了不少。<br><a id="more"></a></p><h3 id="投影模型与BA代价函数"><a href="#投影模型与BA代价函数" class="headerlink" title="投影模型与BA代价函数"></a>投影模型与BA代价函数</h3><p>之前我们曾经介绍过投影模型以及畸变，现在我们重新复习下一个世界坐标系下的点$p$投影到照片上的过程。</p><ol><li><p>将世界坐标系转换到相机坐标：</p><script type="math/tex; mode=display">P' = Rp+t = [X',Y',Z']^T</script></li><li><p>将$P’$投影到归一化平面，得到归一化坐标：</p><script type="math/tex; mode=display">P_c = [u_c,v_c,1]^T = [\frac{X'}{Z'},\frac{Y'}{Z'},1]</script></li><li><p>考虑径向畸变：</p><script type="math/tex; mode=display">\left\{ \begin{matrix} u'_c = u_c(1+k_1r_c^2 + k_2r_c^4)\\ v'_c = v_c(1+k_1r_c^2 + k_2r_c^4) \end{matrix}\right.</script></li><li><p>根据相机内参，得到像素坐标：</p><script type="math/tex; mode=display">\left\{ \begin{matrix}u_s = f_xu'_c + c_x\\v_s = f_yv'_c+c_y \end{matrix}\right.</script></li></ol><p>实际上，上面的一系列过程就是观测方程$z = h(x,y)$。具体地说，$x$指代的是此时相机的位姿，也就是$R,t$，对应的李代数为$\xi$。而$y$指的是路标，也就是三维点$p$，观测的数据是像素坐标$z = \triangleq [u_s,v_s]^T$。以最小二乘的角度考虑可以得到误差项：</p><script type="math/tex; mode=display">e = z - h(\xi,p).</script><p>把其他时刻的观测量也考虑进来，设$z_{ij}$为位姿$\xi_i$下对$p_j$的观测数据，则整体代价函数为：</p><script type="math/tex; mode=display">\frac{1}{2} \sum_{i=1}^m \sum_{j=1}^n \Vert e_{ij}\Vert^2 = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^n \Vert z_{ij} - h(\xi_i,p_j) \Vert^2.</script><p>求解上述问题，就相当于对位姿和路标同时做了调整，也就是所谓的Bundle Adjustment。</p><h3 id="BA求解"><a href="#BA求解" class="headerlink" title="BA求解"></a>BA求解</h3><p>很明显，BA问题不是一个简单的线性问题。我们把自变量定义为所有代优化的变量：</p><script type="math/tex; mode=display">x = [\xi_1,\xi_2,...,\xi_m,p_1,...,p_n]^T</script><p>假如$\Delta x$是整体自变量的增量，则：</p><script type="math/tex; mode=display">\frac{1}{2} \Vert f(x + \Delta x)\Vert^2 \approx \frac{1}{2} \sum_{i=1}^m\sum_{j=1}^n \Vert e_{ij}+F_{ij}\Delta \xi_{i}+E_{ij}\Delta p_j \Vert^2.</script><p>上式中$F_{ij},E_{ij}$分别为误差项对相机位姿与路标的偏导数。我们在之前的内容（<a href="https://wlsdzyzl.top/2019/01/18/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%B8%89%EF%BC%89PnP/" target="_blank" rel="noopener">PnP</a>）中也推导过它们的形式。现在，我们把相机位姿变量放在一起：</p><script type="math/tex; mode=display">x_c = [\xi_1,...,\xi_m]^T \in \mathbb{R}^{6m},</script><p>同理，把空间点变量也放在一起：</p><script type="math/tex; mode=display">x_p = [p_1,...,p_n]^T \in \mathbb{R}^{3n}</script><p>则增量误差可以写为：</p><script type="math/tex; mode=display">\frac{1}{2} \Vert f(x + \Delta x)\Vert^2 \approx \frac 1 2 \Vert e+F\Delta x_c E \Delta x_p \Vert^2</script><p>上式由很多小型二次项和变成了一个整体的二范数，因此这里的雅科比矩阵$E,F$也是对整体变量的导数，它将是一个很大的矩阵，是由不同的$F_{ij},E_{ij}$拼接起来的。当然，由之前的<a href="https://wlsdzyzl.top/2018/11/14/SLAM%E2%80%94%E2%80%94%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/" target="_blank" rel="noopener">非线性优化</a>，我们可以使用高斯牛顿或者列文伯格——马夸尔特法来进行找到极小值，但是无论使用哪个都会面对增量线性方程：</p><script type="math/tex; mode=display">H \Delta x = g</script><p>只不过在高斯牛顿中：</p><script type="math/tex; mode=display">H = J^TJ</script><p>列文伯格中：</p><script type="math/tex; mode=display">H = J^TJ+\lambda I</script><p>由于我们把变量归类成为了位姿和空间点两种，所以雅科比矩阵可以分块为：</p><script type="math/tex; mode=display">J = [F,E]</script><p>如果使用高斯牛顿法，则：</p><script type="math/tex; mode=display">H = J^TJ = \begin{bmatrix}F^TF & F^TE\\E^TF & E^TE\end{bmatrix}.</script><p>由于考虑了所有的优化变量，这个矩阵维度是非常大的。不过这里的$H$矩阵是有一定的特殊结构的，我们可以用它来加速求解过程。</p><h3 id="稀疏性和边缘化"><a href="#稀疏性和边缘化" class="headerlink" title="稀疏性和边缘化"></a>稀疏性和边缘化</h3><p>实际上，BA这个概念很早就提出了，不过当时研究者认为上述$H$矩阵太大，计算量是不可能完成的任务，直到近十年发现$H$矩阵的稀疏性可以加速求解。</p><p>首先，我们来考虑这个问题，就是cost function对变量$\xi_i,p_j$的雅科比矩阵，实际上只有$e_{ij}$与它有关，也就是：</p><script type="math/tex; mode=display">J_{ij}(x) = \left(0_{2\times 6},...,0_{2\times 6},\frac{\partial e_{ij}}{\partial \xi_i},...,0_{2\times 3},...,0_{2\times 3},...,\frac{\partial e_{ij}}{\partial p_j},0_{2\times 3},...,0_{2 \times 3}\right).</script><p>上式中$0_{2 \times 6}$表示$2\times 6$的零矩阵。该误差项对于相机姿态的偏导为$2\times 6$，对于路标点的偏导为$2 \times 3$（详情见<a href="https://wlsdzyzl.top/2019/01/18/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%B8%89%EF%BC%89PnP/" target="_blank" rel="noopener">PnP</a>）。实际上这个很符合直觉，因为别的地方的误差项与当前的位姿和路标是无关的。</p><p>假如$J_{ij}$只在$i,j$处有非零块，它对于$H$的贡献为$J_{ij}^TJ_{ij}$。不难理解这个$J_{ij}^TJ_{ij}$也只有4个非0块，分别位于$(i,i),(i,j),(j,i),(j,j)$。而对于$H$：</p><script type="math/tex; mode=display">H = \sum_{i,j}J_{ij}^TJ_{ij},</script><p>我们将$H$分块：</p><script type="math/tex; mode=display">H = \begin{bmatrix}H_{11}&H_{12}\\H_{21}&H_{22}\end{bmatrix}.</script><p>分块的依据是，$H_{11}$只和相机位姿有关，而$H_{22}$只和路标点有关。同时还有下面的事实成立：</p><ol><li>$H_{11}$是对角阵，只在$H_{ii}$处有非零块</li><li>$H_{22}$也是对角阵，只在$H_{jj}$处有非零块</li><li>对于$H_{12}$或者$H_{21}$，它们是稠密还是稀疏是不确定的。</li></ol><p>注意，上述对角阵针对的是分块矩阵，并不意味着是只有对角线元素非0。</p><p>这就显示了$H$矩阵的稀疏结构。一般情况下的$H$矩阵如图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/h1.jpg" alt=""></p><p>对于这种稀疏矩阵的求解，存在许多可以加速计算的方法，在这篇文章中会介绍一种叫做边缘化（marginalization）的方法。为了方便后面的说明，我们将矩阵分块为$B,E,E^T,C$四个块。如图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/h2.jpg" alt=""></p><p>因此，对应的线性方程组$H\Delta x = g$可以写成下面的形式：</p><script type="math/tex; mode=display">\begin{bmatrix}B&E\\E^T&C\end{bmatrix}\begin{bmatrix}\Delta x_c\\\Delta x_p\end{bmatrix} = \begin{bmatrix}v\\w\end{bmatrix}.</script><p>由于在实际中，往往路标的个数远远大于相机位姿的个数，因此实际中$C$的维度也比$B$要大很多。$B,C$都是对角矩阵，而$C$每个非零块维度为$3\times 3$。对角矩阵求逆难度远小于一般矩阵的难度，因此我们只需要对对角线矩阵块分别求逆即可。考虑到这个，我们对线性方程组进行高斯消元，目的是消去$E$：</p><script type="math/tex; mode=display">\begin{bmatrix}I&-EC^{-1}\\0&I\end{bmatrix}\begin{bmatrix}B&E\\E^T&C\end{bmatrix}\begin{bmatrix}\Delta x_c\\\Delta x_p\end{bmatrix} = \begin{bmatrix}I&-EC^{-1}\\0&I\end{bmatrix}\begin{bmatrix}v\\w\end{bmatrix}.</script><p>整理可得：</p><script type="math/tex; mode=display">\begin{bmatrix}B - EC^{-1}E^T & 0\\E^T & C\end{bmatrix}\begin{bmatrix}\Delta x_c\\\Delta x_p\end{bmatrix} = \begin{bmatrix}v - EC^{-1}W\\w\end{bmatrix}.</script><p>经过消元以后，方程第一行变成和$\Delta x_p$无关的项，拿出来可以得到：</p><script type="math/tex; mode=display">\begin{equation}[B-EC^{-1}E^T]\Delta x_c = v - EC^{-1}w.\end{equation}</script><p>通过上述方程求解得到$\Delta x_c$，代入原方程求解得到$\Delta x_p$。这个过程被称为Marginalization，或者Schur消元。它的优势在于利用了对角块矩阵的逆更好求，加速了求解过程。</p><p>至于方程$(1)$，它的求解没有什么特殊的办法。我们记此方程稀疏为$S$矩阵，它的维度和$B$一致。$S$矩阵的稀疏性是不规则的，它的物理意义为，如果在S矩阵非对角线上存在非零矩阵块，那么意味着该处对应的两个相机位姿有共同观测的路标。因此$S$矩阵的稀疏性主要与实际场景相关。以上就是对于$H$矩阵稀疏结构的应用。</p><p>从概率的角度来说，我们将对于$(\Delta x_c,\Delta x_p)$的求解转化成了先求$\Delta x_c$再求$\Delta x_p$，相当于做了条件概率的展开：</p><script type="math/tex; mode=display">P(x_c,x_p) = P(x_c)\cdot P(x_p\vert x_c).</script><p>因此相当于求了边缘分布，所以被称为边缘化。</p><h3 id="Robust-Kernel-function"><a href="#Robust-Kernel-function" class="headerlink" title="Robust Kernel function"></a>Robust Kernel function</h3><p>此外，我们在介绍一个鲁棒的核函数。因为我们在用二范数误差时候，假设的是特征点匹配都是正确的。而实际中，经常出现误匹配的现象。在优化时候，我们依然当成了正确的匹配，这时候为了满足这个错误项，就会朝着错误的方向去走了。其中一个原因是二范数的增长太快。因此研究者提出了一些比二范数增长更慢的核函数，用的最多的是Huber norm：</p><script type="math/tex; mode=display">H(e) = \left \{\begin{matrix}\frac 1 2 e^2 & \vert e\vert \leq \sigma\\\sigma(\vert e\vert - \frac{1}{2}\sigma) & \text{otherwise}\end{matrix} \right.</script><p>可以看到的是当误差大于某个阈值之后，函数增长变成了一次形式，同时还方便求导。相对于二范数度量，它有更好的鲁棒性。它的图像如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/huber.gif" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——后端（一）滤波器后端</title>
      <link href="/2019/01/23/SLAM%E2%80%94%E2%80%94%E5%90%8E%E7%AB%AF%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2019/01/23/SLAM%E2%80%94%E2%80%94%E5%90%8E%E7%AB%AF%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>虽然这篇文章的名字很简单：后端，但是它实际上是SLAM中非常重要的部分。因为在帧与帧的定位在局部来说还是比较准确，但是每次都会有一定的漂移（drift），而放到全局就会造成严重的全局不一致（inconsistence），可以说没有一个好的后端就无法实现好的定位与重建。</p><a id="more"></a><p>在SLAM中，对于后端的实现一般有两种，基于滤波（filter）的后端与基于全局优化（global opitimization）的后端。本次主要介绍基于滤波的后端。后端的需要解决的问题主要是从带噪声的数据估计内在状态。</p><p>最简单的，我们在实际中面对的问题有两种，一种是实时的数据，另外一种是已经采集好的数据，可以离线进行建图。最简单的办法，前一种一帧一帧处理，后一中可以做批量处理，分布称为渐进式和批量式。而滤波就是用来处理渐进式的方法。</p><ol><li>保持当前状态的估计，在加入新信息时，更新已有的估计</li><li>线性系统+高斯噪声=卡尔曼滤波</li><li>非线性系统+高斯噪声+线性近似=扩展卡尔曼滤波</li><li>非线性系统+非高斯噪声+非参数化=粒子滤波器</li><li>滑动窗口滤波以及多状态卡尔曼（MSCKF）</li></ol><p>我们知道SLAM的过程是用运动方程与观测方程描述的：</p><script type="math/tex; mode=display">\left\{    \begin{matrix}    x_k = f(x_{k-1},u_k) + w_k\\    z_{k,j} = h(y_j,x_k)+v_{k,j}    \end{matrix}\right. k=1,...,N,j=1,...,M</script><p>我们知道每个方程都受噪声影响，所以要把这里的位姿$x$和路标$y$看成服从某种概率分布的随机变量。因此我们的问题就变成了拥有运动数据$u$和观测数据$z$的时候，如何确定$x,y$的分布，以及得到新的数据的时候，他们的状态又该如何改变。一般来说，我们会假设状态量和噪声项都服从高斯分布——这意味着程序中只需要存储它们的均值和协方差矩阵。均值为最优估计，而协方差定义了它的不确定性。</p><p>我们假设$x_k$为$k$时刻的所有待估计变量的和，这意味着它包含了路标位置和位姿：</p><script type="math/tex; mode=display">x_k \triangleq \{x_k,y_1,...,y_m\}.</script><p>同时我们把k时刻的所有观测数据记为$z_k$，这时候新的方程就变成了：</p><script type="math/tex; mode=display">\left\{    \begin{matrix}    x_k = f(x_{k-1},u_k)+w_k\\    z_k = h(x_k)+v_k    \end{matrix}\right. k = 1,...,N.</script><p>现在考虑第k时刻的情况，我们希望用过去0到k-1时刻的状态来估计现在的状态分布：</p><script type="math/tex; mode=display">P(x_k\vert x_0,u_{1:k},z_{1:k})</script><p>下标$1:k$表示：从1到$k$时刻的所有数据。</p><p>按照贝叶斯法则，将$z_k$与$x_k$的位置交换，得到：</p><script type="math/tex; mode=display">P(x_k\vert x_0,u_{1:k},z_{1:k}) \propto P(z_k\vert x_k)P(x_k\vert x_0,u_{1:k},z_{1:k-1}).</script><p>右式中第一项为似然，第二项为先验。似然有观测方程给定（比如知道位置和位姿求空间点的投影像素位置），先验部分$x_k$是基于过去所有的状态估计得来的，至少它会收到$k-1$时刻的状态影响：</p><script type="math/tex; mode=display">P(x_k\vert x_0,u_{1:k},z_{1:k-1}) = \int \underbrace{P(x_k\vert x_{k-1},x_0,u_{1:k},z_{1:k-1})}_ {\alpha} \underbrace {P(x_{k-1}\vert x_0,u_{1:k},z_{1:k-1})}_ {\beta}dx_{k-1}</script><p>如果考虑之前更久的状态，就要对上面的式子继续展开。到这一步，处理就产生了两种办法，一是马尔可夫性质的假设，认为$k$时刻至于$k-1$时刻有关，这样我们就会得到扩展卡尔曼滤波（EKF）的处理方法;另外就是依然考虑$k$时刻的状态与之前所有时刻的状态都是相关的，这时候就得到非线性优化的优化框架。这一篇主要介绍卡尔曼滤波与EKF。</p><h3 id="线性系统与KF"><a href="#线性系统与KF" class="headerlink" title="线性系统与KF"></a>线性系统与KF</h3><p>如果我们假设了马尔可夫性，由于当前时刻只和上一个时刻有关，则$\alpha$简化为：</p><script type="math/tex; mode=display">\alpha = P(x_k\vert x_{k-1},x_0,u_{1:k},z_{1:k-1}) = P(x_k\vert x_{k-1}, u_k)</script><p>$beta$可以写为：</p><script type="math/tex; mode=display">\beta = P(x_{k-1}\vert x_0,u_{1:k},z_{1:k-1}) = P(x_{k-1}\vert x_0,u_{1:k-1},z_{1:k-1})</script><p>这是因为$u_k$，是$k-1$时刻之后的输入，它不会对过去的状态产生影响。我们可以看到，$\beta$实际上是$k-1$时刻的状态分布。因此我们在做的是如何把$k-1$时刻的状态分布推导到$k$时刻，因此整个程序实现中，我们需要维护的只有一个状态分布而已，并不断用它结合输入来得到下一个时刻的状态分布。如果我们假设噪声服从高斯分布，我们需要维护的只有均值和协方差即可。</p><p>现在首先假设我们的系统为线性高斯系统，也就是运动方程和观测方程可以由线性方程来描述：</p><script type="math/tex; mode=display">\left\{    \begin{matrix}    x_k = A_kx_{k-1} + u_k + w_k\\    z_k = C_kx_k + v_k    \end{matrix}\right . k = 1,...,N</script><p>并且假设所有的状态和噪声均满足高斯分布。假如这里的噪声满足零均值高斯分布，则：</p><script type="math/tex; mode=display">w_k \sim N(0,R), v_k \sim N(0,Q)</script><p>假设我们知道了$k-1$时刻的后验状态估计$\hat x_{k-1}$以及协方差$\hat P_{k-1}$，现在要根据$k$时刻的输入和观测数据，确定$x_k$的后验分布。为了区分先验和后验，我们在记号上规定有$\hat{}$的为后验，有$\overline{}$的为先验。</p><p>卡尔曼滤波器的第一步，通过运动方程确定$x_k$的先验分布。根据高斯分布的性质可以得到：</p><script type="math/tex; mode=display">P(x_k\vert x_0,u_{1:k},z_{1:k}) = N(A_k\hat x_{k-1} + u_k,A_k\hat P_{k-1}A_k^T + R)</script><p>这一步称为预测，它显示了如何从上一个时刻的状态根据输入信息推断当前时刻的状态分布。这个分布也就是先验，记：</p><script type="math/tex; mode=display">\overline x_k = A_k \hat x_{k-1} + u_k,\overline P_k = A_k \hat P_{k-1} A_k^T + R</script><p>而由观测方程，我们可以计算在某个状态下产生怎样的观测数据：</p><script type="math/tex; mode=display">P(z_k\vert x_k) = N(C_kx_k,Q).</script><p>为了得到后验概率，需要计算他们的乘积。假如结果为：$x_k \sim N(\hat x_k, \hat P_k)$，那么：</p><script type="math/tex; mode=display">N(\hat x_k, \hat P_k) = N(C_kx_k,Q)\cdot N(\overline x_k,\overline P_k)</script><p>由于都是高斯分布，我们可以先只关注指数部分：</p><script type="math/tex; mode=display">(x_k - \hat x_k)^T\hat P_k ^{-1} (x_k - \hat x_k) = (z_k - C_k x_k)^TQ^{-1}(z_k - C_kx_k) + (x_k - \overline x_k)^T\overline{P}_k^{-1} (x_k - \overline x_k)</script><p>为了求得左侧的$\hat x_k$与$\hat P_k$，我们先将两边展开,比较$x_k$的二次和一次系数。</p><ul><li><p>对于二次可以得到：</p><script type="math/tex; mode=display">\hat P_k^{-1} = C_k^TQ^{-1}C_k + \overline P_k^{-1}</script><p>该式给出了协方差的计算过程。对上式左右各乘$\hat P_k$，我们可以得到：</p><script type="math/tex; mode=display">I = \hat P_k C_k^T Q^{-1}C_k + \hat P_k \overline P_k ^{-1}</script><p>定义:$K = \hat P_k C_k^T Q^{-1}$，则得到：</p><script type="math/tex; mode=display">I = KC_k + \hat P_k \overline P_k^{-1}.</script><p>即：</p><script type="math/tex; mode=display">\hat P_k = (I - KC_k)\overline P_k.</script></li><li><p>比较一次项系数，有：</p><script type="math/tex; mode=display">-2\hat x_k^T \hat P_k^{-1}x_k = -2z_k^TQ^{-1}C_kx_k - 2\overline x_k^T \overline P_k^{-1}x_k.</script><p>取系数并转置后，可以得到：</p><script type="math/tex; mode=display">\hat P_k^{-1}\hat x_k = C_k^T Q^{-1}z_k + \overline P_k^{-1}\overline x_k.</script><p>对上式两侧乘以$\hat P_k$带入$K$的定义，可以得到：</p><script type="math/tex; mode=display">\begin{aligned}\hat x_k &= \hat P_k C_k^TQ^{-1}z_k + \hat P_k \overline P_k^{-1}\overline x_k\\&=Kz_k + (I-KC_k)\overline x _k \\&= \overline x_k + K(z_k - C_k\overline x_k)\end{aligned}</script></li></ul><p>因此我们得到了后验均值的表达。上面两个步骤可以称为<strong>预测</strong>与<strong>更新</strong>:</p><ol><li>预测：<script type="math/tex; mode=display">\overline x_k = A_k\hat x_{k-1} + u_k, \overline P_k = A_k\hat P_{k-1} A_k^T +R</script></li><li>更新：先计算$K$，又被称为卡尔曼增益：<script type="math/tex; mode=display">K = \overline P_k C_k^T (C_k\overline P_k C_k^T + Q_k)^{-1}.</script>计算后验概率的分布：<script type="math/tex; mode=display">\hat x_k = \overline x_k + K(z_k - C_k\overline x_k),\hat P_k = (I - KC_k)\overline P_k.</script></li></ol><p>于是到这里，我们就推到了卡尔曼滤波器的整个过程。实际上它有若干种推导方式，我们使用的是从概率角度出发的最大后验概率估计的形式。可以看到，在线性高斯系统中，卡尔曼滤波器构成了该系统中的最大后验概率估计，由于高斯分布经过线性变换后仍然为高斯分布，整个过程我们并没有进行任何的近似，因此可以说卡尔曼滤波器是线性系统的最优无偏估计。</p><h3 id="非线性系统和EKF"><a href="#非线性系统和EKF" class="headerlink" title="非线性系统和EKF"></a>非线性系统和EKF</h3><p>我们前面推导的是线性系统下的卡尔曼滤波器，而SLAM中运动方程与观测方程都散非线性函数。而一个高斯分布再进行非线性变换之后，就不一定是高斯分布了，因此在非线性系统中，我们需要取一定的近似，将一个非高斯分布近似乘为高斯分布。</p><p>如果我们希望把卡尔曼滤波器的结果拓展到非线性系统中，称为扩展卡尔曼滤波器（Extended Kalman Filter，EKF）。可以想到的做法是对观测方程与运动方程进行线性近似，也就是进行泰勒展开，保留一阶项,然后按照上面的线性系统来计算，也就是：</p><script type="math/tex; mode=display">x_k \approx f(\hat x_{k-1},u_k) + \frac{\partial f}{\partial x_{k-1}}\vert_{\hat x_{k-1}}(x_{k-1} - \hat x_{k-1}) + w_k.</script><p>记这里的偏导数为：</p><script type="math/tex; mode=display">\mathbf{F} = \frac{\partial f}{\partial x_{k-1}}\vert_{\hat x_{k-1}}.</script><p>同样的，对于观测方程：</p><script type="math/tex; mode=display">z_k \approx h(\overline x_k) + \frac{\partial h}{\partial x_k}\vert_{\overline x_k}(x_k - \overline x_k) + n_k.</script><p>记这里的偏导数：</p><script type="math/tex; mode=display">\mathbf{H} = \frac{\partial h}{\partial x_k}\vert_{\overline x_k}.</script><p>那么在预测步骤中，根据运动方程有：</p><script type="math/tex; mode=display">P(x_k\vert x_0,u_{1:k},z_{0:k-1}) = N(f(\hat x_{k-1},u_k),\mathbf F\hat P_{k-1}\mathbf F^T + R_k).</script><p>记先验和协方差均值为：</p><script type="math/tex; mode=display">\overline x_k = f(\hat x_{k-1},u_k), \overline P_k = \mathbf F\hat P_{k-1}\mathbf F^T + R_k.</script><p>考虑在观测中我们有：</p><script type="math/tex; mode=display">P(z_k \vert x_k) = N(h(\overline x_k) +\mathbf{H}(x_k - \overline x_k),Q_k).</script><p>根据最开始的贝叶斯展开式，这些接下来的推导与卡尔曼滤波器的内容都是非常相似的，因此就不在这里介绍中间步骤了，而直接介绍结果。我们同样会定义一个卡尔曼增益$K_k$:</p><script type="math/tex; mode=display">K_k = \overline P_k \mathbf H^T (\mathbf H\overline P_k \mathbf H^T + Q_k)^{-1}.</script><p>在卡尔曼增益的基础上，后验概率形式为：</p><script type="math/tex; mode=display">\hat x_k = \overline x_k + K_k(z_k - h(\overline x_k)), \hat P_k = (I - K_k \mathbf{H})\overline P_k.</script><p>因此，在SLAM这种非线性系统下，EKF给出了单次线性近似下的最大后验估计。</p><p>滤波器方法在较早的时候非常流行，而在现在的实际应用中，往往是渐进式与批量式集合的方法。如获取新的一帧后，不只是根据上一帧来优化，而是可以根据之前的所有帧来做这个处理。当然，实际中计算机算力有限，我们往往基于关键帧的策略来做这个事情。这就要用到下一次我们要说明的方法Bundle Adjustment。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——视觉里程计（五）光流法和直接法</title>
      <link href="/2019/01/21/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%BA%94%EF%BC%89%E5%85%89%E6%B5%81%E6%B3%95%E5%92%8C%E7%9B%B4%E6%8E%A5%E6%B3%95/"/>
      <url>/2019/01/21/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%BA%94%EF%BC%89%E5%85%89%E6%B5%81%E6%B3%95%E5%92%8C%E7%9B%B4%E6%8E%A5%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>特征点法是提取特征，根据稀疏特征点的对应点来计算相机的位姿变换。但是它是有比较明显的缺点的：1.特征点的提取比较耗时，限制了SLAM的运行速度，2. 特征点过于稀疏，可能会浪费很多有用信息 3. 我们在生活中总会遇到纹理特征缺失的情况，比如一面白墙，这时候我们找不到足够的特征点来得到相机的运动。所以我们来讨论另外的两种方法，叫做光流法和直接法。<br><a id="more"></a></p><h3 id="光流法"><a href="#光流法" class="headerlink" title="光流法"></a>光流法</h3><p>光流是一种描述像素随时间在图像之间运动的方法，随着时间的流逝，同一个像素会在图像中运动，而我们希望追踪它的运动过程。如果只计算部分像素的运动我们称为稀疏光流，计算所有像素的运动我们称为稠密光流。其中，稀疏光流以Lucas-Kanade光流为代表，可以在SLAM中用于追踪特征点的位置，因此我们主要了解以下LK光流。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/hdbb.jpg" alt=""></p><p>在LK光流中，我们认为来自相机的图像是随着时间变化的，而图像可以看成时间的函数：$I(t)$。那么在$t$时刻，位于$(x,y)$的像素它的灰度为：$I(x,y,t)$。现在考虑某个固定的空间点，它在t时刻的像素坐标为$(x,y)$。我们假设在相机运动中，同一个空间点的像素灰度是不变的，这个假设叫灰度不变假设。这个假设是一个强假设，因为实际中灰度一般都会变化。</p><p>现在假设在$t+dt$的时刻它的位置运动到了$(x+dx,y+dy)$，则我们可以得到：</p><script type="math/tex; mode=display">I(x,y,t) = I(x+dx, y+dy,t+dt)</script><p>如果对上式中右侧进行一介泰勒展开：</p><script type="math/tex; mode=display">I(x+dx,y+dy,t+dt) \approx I(x,y,t)+\frac{\partial I}{\partial x}dx + \frac{\partial I}{\partial y}dy + \frac{\partial I}{\partial t}dt</script><p>由此可以得到：</p><script type="math/tex; mode=display">\frac{\partial I}{\partial x}dx + \frac{\partial I}{\partial y}dy + \frac{\partial I}{\partial t}dt = 0.</script><p>对两侧同时除以$dt$，我们得到：</p><script type="math/tex; mode=display">\frac{\partial I}{\partial x}\frac{dx}{dt} + \frac{\partial I}{\partial y}\frac{dy}{dt} = -\frac{\partial I}{\partial t}.</script><p>其中$\frac{dx}{dt},\frac{dy}{dt}$为像素在$x,y$轴上的运动速度，把它们分别记为$u,v$。同时$\frac{\partial I }{\partial x},\frac{\partial I}{\partial y}$记为图像在$x,y$方向上的梯度，分布记为$I_x,I_y$。再把图像灰度对于时间的变化量记为$I_t$，则我们可以把上式写为：</p><script type="math/tex; mode=display">\begin{bmatrix}I_x&I_y\end{bmatrix}\begin{bmatrix}u\\v\end{bmatrix} = - I_t</script><p>我们想计算的是像素运动$u,v$，但上面的单个式子是无法计算出来的。因此需要额外的约束，在LK光流中，我们假设某个窗口内的像素具有相同的运动。现在考虑一个大小为$w\times w$的窗口，它还有$w^2$数量的像素。由于该窗口内像素具有同样的运动，因此方程个数为$w^2$个。记：</p><script type="math/tex; mode=display">A=\begin{bmatrix}[I_x,I_y]_1\\\vdots\\[I_x,I_y]_k\end{bmatrix},b=\begin{bmatrix}I_{t1}\\\vdots\\I_{tk}\end{bmatrix}</script><p>我们得到：</p><script type="math/tex; mode=display">A\begin{bmatrix}u\\v\end{bmatrix} =- b</script><p>对于这个超定方程，我们可以使用最小二乘解：</p><script type="math/tex; mode=display">\begin{bmatrix}u\\v\end{bmatrix}^* = -(A^TA)^{-1}A^Tb</script><p>在稀疏光流法中我们依然需要计算特征点，不过可以只计算关键点。通过对特征点的追踪来得到构成方程$u,v$。由于像素梯度仅在局部有效，所以如果一次迭代结果不够，我们会多迭代几次这个方程。在SLAM中，LK光流经常被用来追踪角点的运动。</p><p>在实践中，对于光流法对于角点的追踪效果最好，对于边缘与区块中的特征点效果较差，可能会追踪失败。</p><h3 id="直接法"><a href="#直接法" class="headerlink" title="直接法"></a>直接法</h3><p>对于直接法，它和光流法有一样的前提假设，即灰度不变。假如$p_1,p_2$分别是空间中同一个坐标点在两个不同位姿的相机下的投影坐标，我们现在想求的是这两个坐标之间的相对位姿，从$P_1$到$P_2$，则：</p><script type="math/tex; mode=display">p_1 = \begin{bmatrix}u_1\\v_1\\1\end{bmatrix} = \frac 1 {Z_1}KP,\\p_2 = \begin{bmatrix}u_2\\v_2\\1\end{bmatrix} = \frac 1 {Z_2}K(RP+t) = \frac{1}{Z_2}K(\exp(\xi ^{\hat{}})P)</script><p>上述坐标依然包含了齐次到非齐次的转换。通过上式，我们知道了$p_1,p_2$，不过直接法可以不用提取特征点，因此我们并不知道他们在图像上真正的对应关系，只得到了一个预测值。这时候，我们就需要使用灰度不变的假设了，将重投影误差转换成灰度之间的差异，叫做光度误差，也就是两个像素的亮度误差：</p><script type="math/tex; mode=display">e = I_1(p_1) - I_2(p_2)</script><p>当然我们对优化目标依然取二范数。</p><script type="math/tex; mode=display">\xi^* = \arg\min_{\xi} J(\xi) = \sum_{i=1}^n\Vert e \Vert^2</script><p>不过现在先关注$e$的导数。使用李代数上的扰动模型，则：</p><script type="math/tex; mode=display">\begin{aligned}e(\xi \oplus \delta \xi) &= I_1\left(\frac 1 {Z_1}KP\right) -I_2\left(\frac 1 {Z_2} K \exp(\delta \xi ^{\hat{}}) \exp(\xi ^{\hat{}})P\right) \\&\approx I_1\left(\frac 1 {Z_1} K P\right) - I_2\left(\frac{1}{Z_2}K(1+\delta\xi^{\hat{}})\exp(\xi^{\hat{}})P\right)\\&=I_1\left(\frac 1 {Z_1}KP\right) - I_2\left(\frac 1 {Z_2} K \exp (\xi^{\hat{}})P + \frac 1 {Z_2}K\delta\xi^{\hat{}}\exp(\xi^{\hat{}})P\right)\end{aligned}</script><p>记：</p><script type="math/tex; mode=display">q = \delta \xi ^{\hat{}} \exp(\xi^{\hat{}})P, u = \frac 1 {Z_2}Kq</script><p>这里的$q$为扰动分量在第二个相机坐标系下的坐标，$u$为它的像素坐标。利用一阶泰勒展开，可以得到：</p><script type="math/tex; mode=display">\begin{aligned}e(\xi \oplus \delta \xi) &= I_1\left(\frac 1 {Z_1}KP\right) - I_2\left(\frac 1 {Z_2} K \exp(\xi^{\hat{}})P + u \right)\\&\approx I_1\left(\frac{1}{Z_1}KP\right) - I_2\left(\frac{1}{Z_2}K\exp(\xi^{\hat{}})P \right) - \frac{\partial I_2}{\partial u}\frac{\partial u}{\partial q} \frac{\partial q}{\partial \xi}\delta\xi\\&= e(\xi) - \frac{\partial I_2}{\partial u}\frac{\partial u}{\partial q} \frac{\partial q}{\partial \xi}\delta\xi\end{aligned}</script><p>可以看到一阶导数由于链式法则分成了3层。而这3层都是比较容易计算的：</p><ol><li>$\frac{\partial I_2}{\partial u}$为$u$处的像素梯度</li><li>$\frac{\partial u}{\partial q}$为投影方程关于相机坐标系下的三维点的导数。即$q=[X,Y,Z]^T$，根据上一次PnP下的推导可以得到：<script type="math/tex; mode=display">\frac{\partial u}{\partial q} =\begin{bmatrix}\frac{\partial u}{\partial X}&\frac{\partial u}{\partial Y}&\frac{\partial u}{\partial Z}\\\frac{\partial v}{\partial X}&\frac{\partial v}{\partial Y}&\frac{\partial v}{\partial Z}\end{bmatrix} = \begin{bmatrix}\frac{f_x}{Z} & 0 & -\frac{f_xX}{Z^2}\\0&\frac{f_y}{Z}&-\frac{f_yY}{Z^2}\end{bmatrix}</script></li><li>$\frac{\partial q}{\partial \xi} = (q)^{\odot}$</li></ol><p>在实践中，由于后两项只和三维点$q$有关，与图像无关，因此常常将他们合并：</p><script type="math/tex; mode=display">\frac{\partial u}{\partial  \xi} = \begin{bmatrix}\frac{f_x}{Z'} & 0 & -\frac{f_xX'}{Z'^2} & -\frac{f_xX'Y'}{Z'^2} & f_x + \frac{f_xX^2}{Z'^2} & -\frac{f_xY'}{Z'}\\0 & \frac{f_y}{Z'} & -\frac{f_yY'}{Z'^2} &-f_y - \frac{f_yY'}{Z'^2} & \frac{f_yX'Y'}{Z'^2} & \frac{f_yX'}{Z'}\end{bmatrix}</script><p>这个矩阵在之前的pnp中也出现过。因此：</p><script type="math/tex; mode=display">J =\lim_{\delta\xi \rightarrow 0}\frac{e(\xi \oplus \delta \xi)-e(\xi) }{\delta \xi}= -\frac{\partial I_2}{\partial u}\frac{\partial u}{\partial \xi}</script><p>这就是直接法的雅科比矩阵。</p><p>不过直接法有明显的优点，但也有明显的缺点。由于图像的非凸性，直接法往往找到的是极小值。单个像素没有区分度，因此我们计算的是像素块。最重要的是灰度不变是很强的假设，这意味着直接法只有在特定的条件下才能有比较好的效果。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——视觉里程计（四）ICP</title>
      <link href="/2019/01/20/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E5%9B%9B%EF%BC%89ICP/"/>
      <url>/2019/01/20/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E5%9B%9B%EF%BC%89ICP/</url>
      
        <content type="html"><![CDATA[<p>3D到3D之间的位姿匹配，我们要用到的方法就是ICP算法了。<br><a id="more"></a><br>ICP算法在之前的博客有过介绍，如果你还不了解什么是ICP算法，请点击<a href="https://wlsdzyzl.top/2019/01/17/ICP%E2%80%94%E2%80%94%E8%BF%AD%E4%BB%A3%E6%9C%80%E8%BF%91%E7%82%B9/" target="_blank" rel="noopener">ICP——迭代最近点</a>。</p><p>与上面介绍的ICP不同的是，最纯粹的ICP算法，是在不知道匹配点的情况下，怎么将两个点云配准，并且求出旋转矩阵。不过在SLAM中，如之前说的3D到2D，我们由于PnP已经能够求得3D点的坐标，或者根据特征点匹配，得到匹配点的坐标，同时又通过RGB-D得到了两个相机坐标下的点云。这时候，我们对点的匹配情况一般是已知的。</p><p>因此SLAM下的ICP算法非常简单，它也无需迭代，只需要构建最小二乘问题，最后用SVD分解得到$R$与$t$即可。</p><p>而另外，我们可以使用非线性解法来解ICP问题，同样也就是利用优化器来解决。为了使用优化器，我们需要用到李群李代数，才能求得梯度，从而不断迭代求解。因此，在非线性条件下，我们的问题描述变成了：</p><script type="math/tex; mode=display">\xi^*=\underset{\xi}{\arg\min}\frac{1}{2}\sum_{i=1}^{n}||P_i-K\exp(\xi^{\hat{}})P_i^{'}||_2^2</script><p>为了使用非线性优化，与之前的BA问题一样，我们需要找到误差对优化变量的雅科比矩阵。在这个题目中，这个问题变得很简单，我们已经知道：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial (TP)}{\partial \delta \xi} &= \lim_{\delta \xi \rightarrow 0} \frac{\begin{bmatrix}\delta \phi^{\hat{}}(RP+t) + \delta P\\0\end{bmatrix}}{\delta \xi}\\&= \begin{bmatrix}I&-(RP+t)^{\hat{}}\\0&0\end{bmatrix}\\&\triangleq (TP)^{\odot}\end{aligned}</script><p>因此可以得到：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial \delta \xi} = -(\exp(\xi^{\hat{}})P_i^{'})^{\odot}</script><p>根据上面的雅科比矩阵我们可以找到梯度，从而走向极小值。如果ICP已知匹配点，如果能找到极小值，那么它一定是全局最优值。因此对于ICP无需初始化，这是ICP算法的一个优点。</p><p>知道上面的问题，我们将其放入ceres或者g2o等库中优化即可。</p><p>在这个ICP问题中，我们已经知道了点的配对情况，因此没有必要迭代求解，而ICP算法的研究者更重视的是在匹配情况位置的情况下的配准。在实际的操作中，我们可能会结合多种方法一起使用以求得最佳的位姿。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> icp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——视觉里程计（三）PnP</title>
      <link href="/2019/01/18/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%B8%89%EF%BC%89PnP/"/>
      <url>/2019/01/18/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%B8%89%EF%BC%89PnP/</url>
      
        <content type="html"><![CDATA[<p>上篇文章的内容是关于对极几何约束的，它主要是用来解决2d-2d的情况，也就是我们只有两张不同角度的投影求空间点。现在假如我们已经知道了空间点的位置，接下来要的问题是3d-2d，这个时候我们可以用的方法是PnP来估计位姿。</p><a id="more"></a><p>因为PnP需要有3D点的位置，因此对于双目相机或者是RGB-D相机，我们可以一开始就使用PnP来求得位姿，而对于单目相机，必须需要使用对极约束得到第一组对点的空间估计，才能在后面使用PnP。这个叫做单目相机的初始化。</p><p>PnP问题有很多解法，如直接线性变换，只需要3对点的P3P等等，还可以使用Bundle Adjustment。</p><h3 id="直接线性变换"><a href="#直接线性变换" class="headerlink" title="直接线性变换"></a>直接线性变换</h3><p>现在假设一个空间点$P$，它的齐次坐标为$P=(X,Y,Z,1)^T$。而在图像中，它被投影到特征点$x = (u,v,1)^T$，这时候相机的位姿$R,t$都是未知的，是我们需要估计的量。我们定义增广矩阵$T = [R|t]$为一个$3\times 4$的矩阵，它包含了旋转与平移的信息，则：</p><script type="math/tex; mode=display">s\begin{pmatrix}u\\v\\1\end{pmatrix} = K \left(\begin{array}{c|c}R&t\end{array}\right) P =  \left(\begin{array}{ccc|c}t_1&t_2&t_3&t_4\\t_5&t_6&t_7&t_8\\t_9&t_{10}&t_{11}&t_{12}\end{array}\right)\begin{pmatrix}X\\Y\\Z\\1\end{pmatrix}</script><p>在这里，$s$为相机坐标下的Z值，也就是$s=t_9X+t_{10}Y+t_{11}Z+t_{12}$。由于$K$是个常数，我们为了简化问题将它忽略掉了。展开上面的式子，消去s，我们可以得到：</p><script type="math/tex; mode=display">u = \frac{t_1X+t_2Y+t_3Z+t_4}{t_9X+t_{10}Y+t_{11}Z+t_{12}}, v = \frac{t_5X+t_9Y+t_7Z+t_8}{t_9X+t_{10}Y+t_{11}Z+t_{12}}</script><p>我们定义$T$的行向量分别为$\mathbf{t}_1,\mathbf{t}_2,\mathbf{t}_3$，则：</p><script type="math/tex; mode=display">\mathbf{t}_1 P = u \mathbf{t}_3P, \mathbf{t}_2 P = v \mathbf{t}_3P</script><p>因此我们可以看到的是每对点提供了两个线性约束。假设一共有N个点，则我们可以列出下面的线性方程组：</p><script type="math/tex; mode=display">\begin{pmatrix}P_1^T &0& -u_1P_1^T\\0&P_1^T&-v_1P_1^T\\\vdots&\vdots&\vdots\\P_N^T &0& -u_NP_N^T\\0&P_N^T&-v_NP_N^T\end{pmatrix}\begin{pmatrix}\mathbf{t}_1^T & \mathbf{t}_2^T & \mathbf{t}_3^T\end{pmatrix} = 0</script><p>由于$\mathbf{t}$维度为12维，因此最少通过6对匹配点就可以解得这个方程。这种方法称为直接线性变换。当然，如果匹配点数过多，可以使用最小二乘，SVD等解超定方程。</p><p>在这个求解中，我们直接将T矩阵看成12个未知数，而忽略他们的联系。因此求出的解不一定满足旋转矩阵的约束。因此对于求得的旋转矩阵R，我们需要对他进行一个最好的近似，可以用QR分解完成。</p><h3 id="P3P"><a href="#P3P" class="headerlink" title="P3P"></a>P3P</h3><p>我们上面说$\mathbf{t}$的维度为12，但是我们知道实际上旋转和平移各只有3个自由度，总共也就只有6个自由度。因此实际上使用的点对应该更少。而P3P就只需要3对点来估计位姿。不过值得注意的是P3P并不会直接得到位姿，而是得到了各个点在相机坐标系下的坐标。然后通过下一次要说的3D-3D来求位姿。为什么要这样？因为3D-3D下对位姿的估计是非常简单的。</p><p>现在假设我们输入了3个3d点的世界坐标以及图像上的2d投影坐标，希望求的是它们在当前相机位姿下的相机坐标，从而求得位姿变换。如图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/pnp.png" alt=""></p><p>另外一种做法是输入了点的在上一个相机位置的相机坐标，以及当前图像上的2D投影坐标，这时候求得的就是当前相机位姿相对于上一个相机位姿的位姿变换。二者本质是一样的。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/pnp2.png" alt=""></p><p>P3P求解是从余弦定理开始的。观察最开始的图，我们可以得到：</p><script type="math/tex; mode=display">OA^2 + OB^2 - 2\cdot OA \cdot OB \cdot\cos\langle a,b\rangle = AB^2\\OA^2 + OC^2 - 2\cdot OA \cdot OC \cdot \cos \langle a,c \rangle = AC^2\\OB^2 + OC^2 - 2\cdot OB \cdot OC \cdot \cos \langle b,c \rangle = BC^2</script><p>对上述式子两侧同时除以$OC^2$，并且令：</p><script type="math/tex; mode=display">y = \frac{OB}{OC},x = \frac{OA}{OC}</script><p>则我们得到：</p><script type="math/tex; mode=display">x^2 + y^2 - 2xy\cos\langle a,b \rangle = \frac{AB^2}{OC^2}\\x^2 + 1 - 2x\cos \langle a,c \rangle = \frac{AC^2}{OC^2}\\y^2 + 1 - 2y \cos \langle b,c\rangle = \frac{BC^2}{OC^2}</script><p>令：</p><script type="math/tex; mode=display">u = \frac{AB^2}{OC^2},v = frac{BC^2}{AB^2}, w = \frac{AC^2}{AB^2}</script><p>则我们可以得到：</p><script type="math/tex; mode=display">x^2 + y^2 - 2xy\cos\langle a,b \rangle = u\\x^2 + 1 - 2x\cos \langle a,c \rangle = vu\\y^2 + 1 - 2y \cos \langle b,c\rangle = wu</script><p>将第一个式子带入后面两个，得到：</p><script type="math/tex; mode=display">(1 - w)x^2 - w y^2 - 2x\cos \langle a,c\rangle + 2wxy\cos\langle a,b\rangle + 1 = 0\\(1 - v)y^2 - v x^2-2y\cos\langle b,c \rangle + 2vxy\cos\langle a,b \rangle+1 = 0</script><p>上面的式子中，我们知道的：</p><script type="math/tex; mode=display">w,v,\cos \langle a,c\rangle,\cos \langle b,c\rangle,\cos\langle a,b\rangle,</script><p>因为剩余的未知量只剩两个，因此我们可以求得$x,y$。不过这个方程为二元二次方程，求解较为复杂，需要使用吴消元法。最后求出来的有四组解。为了得到正确的解，我们还需要一个额外的点来检验，选取重投影误差最小的点。</p><p>现在知道了$x,y$的值，我们可以进一步解方程，求得$OA,OB,OC$的值。为了求得坐标，我们只需要将$a$的坐标$(u,v,1)$归一化后得到向量，乘以$OA$的长度即可。这个利用了经过原点的一条直线上的点在各个坐标轴的投影三角形相似的原理。</p><h3 id="Bundle-Adjustment"><a href="#Bundle-Adjustment" class="headerlink" title="Bundle Adjustment"></a>Bundle Adjustment</h3><p>PnP问题同样也能使用万金油式的Bundle Adjustment（BA）来解决。为了使用Bundle Adjustment，我们需要把PnP问题构建成一个定义于李代数上得非线性最小二乘问题。之前说的方法，我们都是先求相机位姿再求得空间点，或者先求空间点，从而得到相机位姿。而在BA问题中，我们可以将它们都看成优化变量，放在一起优化。这是非常通用得求解方式，实际上BA在后端做全局优化的时候使用得更多。不过目前我们就讨论Bundle Adjustment如何被用来解决PnP问题。</p><p>在PnP问题中，BA主要是一个最小化重投影误差（reprojection errpr）的过程。考虑n各三维空间点$P$以及其投影$p$，我们希望计算的是相机的位姿$R,t$，它们的李代数表达为$\xi$。假设某空间点坐标为$P_i = [X_i,Y_i,Z_i]^T$，其像素坐标为$p_i = [u_i,v_i]^T$。我们知道像素位置与空间点位置的关系如下：</p><script type="math/tex; mode=display">s_i\begin{bmatrix}u_i\\v_i\\1\end{bmatrix} = K \exp(\xi ^{\hat{}})\begin{bmatrix}X_i\\Y_i\\Z_i\\1\end{bmatrix}</script><p>即:</p><script type="math/tex; mode=display">s_ip_i = K\exp(\xi ^{\hat{}})P_i</script><p>当然，上述过程中包含了齐次坐标到非齐次坐标的转换。现实世界中，我们采集到的数据往往存在着噪声，因此我们要把误差求和，并使其最小化，也就是最理想的位姿为：</p><script type="math/tex; mode=display">\xi ^* = \arg\min_{\xi} \frac{1}{2}\sum_{i=1}^n \left\Vert p_i - \frac 1 {s_i}K\exp(\xi^{\hat{}})P_i \right\Vert^2</script><p>如果我们观察上式，$ \frac 1 {s_i}K\exp(\xi^{\hat{}})P_i$可以说是$P_i$的重投影，所以这个误差被称为重投影误差。如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/pnp3.png" alt=""></p><p>因为这个重投影误差要考虑很多的点，因此最后到每个相机的重投影误差可能都不会精确为0。使用齐次坐标的话，误差的维度是3维，但是最后一维我们设定为1，因此不应该考虑它的误差项。因此我们一般在优化时候使用非齐次坐标，因此误差项维二维。最小二乘法的优化问题我们之前讨论过了，可以使用高斯牛顿法。列文伯格——马夸尔特法等进行求解。不过，我们首先要求的是每个误差项关于优化变量的导数，求导数的过程其实也是线性化的过程：</p><script type="math/tex; mode=display">e(x + \Delta x) \approx e(x) + J\Delta X</script><p>假如$e$为误差项，它的维度为2维，而$x$为相机位姿（李代数）为6维，这时候的雅可比矩阵$J$为$2\times 6$的矩阵。现在我们来推导$J$的形式。下面的推导需要用到之前关于<a href="https://wlsdzyzl.top/2018/11/09/SLAM%E2%80%94%E2%80%94%E6%9D%8E%E7%BE%A4%E5%92%8C%E6%9D%8E%E4%BB%A3%E6%95%B0/" target="_blank" rel="noopener">李群李代数</a>的讲解。</p><p>假如，我们假设相机坐标系下的坐标为$P’$，则：</p><script type="math/tex; mode=display">P' = (\exp(\xi^{\hat{}})P) = [X',Y',Z']^T</script><p>则它的投影为：</p><script type="math/tex; mode=display">su' = KP'</script><p>展开得到：</p><script type="math/tex; mode=display">\begin{bmatrix}su'\\sv'\\s\end{bmatrix} = \begin{bmatrix}f_x & 0 & c_x\\0 & f_y & c_y\\0&0&1\end{bmatrix}\begin{bmatrix}X'\\Y'\\Z'\\\end{bmatrix}</script><p>消去$s = Z’$，我们可以得到：</p><script type="math/tex; mode=display">u' = f_x \frac{X'}{Z'} + c_x, v' = f_y \frac{Y'}{Z'} + c_y, p' = [u',v']^T</script><p>实际上上面的内容就是对于针孔相机模型的回顾。而这个$u’,v’$正是重投影得到的，误差就是它和实际像素坐标的值，即$e(x) = (p - p’)$。接下来，我们来求$J$。这里我们使用左乘扰动模型。根据求导的链式法则：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial \xi} = \lim_{\delta\xi \rightarrow 0} \frac{e(\delta \xi \oplus \xi) - e(\xi)}{\delta \xi} = \frac{\partial e}{\partial P'}\frac{\partial P'}{\partial \xi}</script><p>在这里$\oplus$指的是对$\xi$左乘扰动模型的操作。因为左乘扰动模型是在李群上进行的，在李代数上的形式会比单纯的相加更复杂一点。</p><p>我们很容易得到的是$\frac{\partial e}{\partial P’}$：</p><script type="math/tex; mode=display">\begin{equation}\frac{\partial e}{\partial P'} = - \begin{bmatrix}\frac{\partial u'}{X'_i} & \frac{\partial u'}{Y'_i} & \frac{\partial u'}{Z'_i}\\\frac{\partial v'}{X'_i} & \frac{\partial v'}{Y'_i} & \frac{\partial v'}{Z'_i}      \end{bmatrix}\end{equation}</script><p>而在之前的推导中，我们知道：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial (TP)}{\partial \xi} &= \lim_{\delta \xi \rightarrow 0} \frac{\begin{bmatrix}\delta \phi^{\hat{}}(RP+t) + \delta P\\0\end{bmatrix}}{\delta \xi}\\&= \begin{bmatrix}I&-(RP+t)^{\hat{}}\\0&0\end{bmatrix}\\&\triangleq (TP)^{\bigodot}\\&=\begin{bmatrix}I&-(P')^{\hat{}}\\0&0\end{bmatrix}\end{aligned}</script><p>而$P’ = TP$，如果只取前3维，从而我们可以得到：</p><script type="math/tex; mode=display">\begin{equation}\frac{\partial P'}{\partial \xi} = [I,-{P'}^{\hat{}}]\end{equation}</script><p>将$(1),(2)$相乘可以得到：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial \xi} = -\begin{bmatrix}\frac{f_x}{Z'} & 0 & -\frac{f_xX'}{Z'^2} & -\frac{f_xX'Y'}{Z'^2} & f_x + \frac{f_xX^2}{Z'^2} & -\frac{f_xY'}{Z'}\\0 & \frac{f_y}{Z'} & -\frac{f_yY'}{Z'^2} &-f_y - \frac{f_yY'}{Z'^2} & \frac{f_yX'Y'}{Z'^2} & \frac{f_yX'}{Z'}\end{bmatrix}</script><p>这个之前有负号，是因为我们对$e$的定义是观测值减去预测值，而观测值是常数。如果对于se(3)的定义是旋转在前，平移在后，只要将前3列与后3列对调即可。由此我们得到了一阶雅可比矩阵。</p><p>此外，除了对相机位姿的优化，就像我们最开始说的，我们可以对空间点的位置也进行优化。所以需要求的是误差关于$P$的导数。这个导数相对来说会简单很多：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial P} = \frac{\partial e}{\partial P'}\frac{\partial P'}{\partial P}</script><p>第一项已经知道了。至于第二项，按照定义：$P’ = RP+t$，因此这个导数为$R$。因此：</p><script type="math/tex; mode=display">\frac{\partial e}{\partial P} =-\begin{bmatrix}\frac{f_x}{Z'} & 0 & -\frac{f_xX'}{Z'^2}\\0 & \frac{f_y}{Z'} & -\frac{f_yY'}{Z'^2}\end{bmatrix}R</script><p>这两个雅可比矩阵（分别是误差关于位姿的和关于空间点位置的）非常重要，是Bundle Adjustment的关键。</p><p>我在思考的问题是，为什么一定要建出来一个中间变量$P’$，如果直接对$P,\xi$求导，则得到的结果是用$\xi,P,K$表示的导数，理论上也能带我们走向极小值。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ICP——迭代最近点</title>
      <link href="/2019/01/17/ICP%E2%80%94%E2%80%94%E8%BF%AD%E4%BB%A3%E6%9C%80%E8%BF%91%E7%82%B9/"/>
      <url>/2019/01/17/ICP%E2%80%94%E2%80%94%E8%BF%AD%E4%BB%A3%E6%9C%80%E8%BF%91%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p>ICP（iterative closest point）最广泛的应用应该就是点云的配准了。它的提出也是为了解决这个问题。</p><a id="more"></a><p>假设我们有两个点云，它们应该是一一配对的（或者说在SLAM中两个场景有较大的overlap），但是我们并不知道点的配对关系。现在我们希望根据这两个点云的位置求到相机的位姿变化，也就是旋转矩阵$R$与平移$t$。</p><p>假设这两个点云分别为$p,p’$，那么我们知道$p = Rp’ + t $。想要求得$R,t$，首先要做的是配对关系。而ICP非常简单，它选取距离最近（一般来说为欧几里得距离）的点作为配对的点。因此，现在我们有了两组配对点：</p><script type="math/tex; mode=display">P = \{p_1,p_2,...,p_n\}, P' = \{p'_1,p'_2,...,p'_n\}</script><p>我们希望做的是最小化下面这个代价：</p><script type="math/tex; mode=display">J = \sum_{i=1}^n\Vert p'_i - (Rp_i+t)\Vert^2</script><p>如何解这其中的$R$和$t$？比较容易想到的就是最小二乘法，下面我们推导介绍一下利用SVD来解决这个最小二乘问题。</p><p>首先定义点云的质心为：</p><script type="math/tex; mode=display"> p = \frac 1 n \sum_{i=1}^np_i, p' = \frac{1}{n} \sum_{i=1}^np'_i</script><p>则:</p><script type="math/tex; mode=display">\begin{aligned}\sum_{i=1}^n\Vert p'_i - (Rp_i + t) \Vert^2 &= \sum_{i=1}^n\Vert p'_i- Rp_i - t - p' + Rp + p' - Rp \Vert^2\\&=\sum_{i=1}^n\Vert (p'_i-p'-R(p_i-p)) + (p'-Rp - t) \Vert^2\\&= \sum_{i=1}^n(\Vert p'_i-p'-R(p_i-p)\Vert^2 + \Vert p'-Rp - t \Vert^2 + 2(p'_i-p'-R(p_i-p))^T(p'-Rp - t))\end{aligned}</script><p>值得注意的是：$p’_i-p’-R(p_i-p)$在求和之后为0，这是由质心的定义决定的。</p><p>因此原来的问题就简化为：</p><script type="math/tex; mode=display">\min_{R,t} J = \sum_{i=1}^n(\Vert p'_i-p'-R(p_i-p)\Vert^2 + \Vert p'-Rp - t \Vert^2</script><p>观察之后，我们发现第一个式子只和旋转有关，第二个式子和旋转平移都有关，不过另一方面它只和质心相关。如果我们求得了$R$，简单的令第二个式子为0就可以求得对应的$t$。所以现在ICP的算法表述如下：</p><p>令$q_i,q’_i$为原来点的去质心坐标：</p><script type="math/tex; mode=display">q_i = p_i - p,q'_i = p'_i - p'</script><p>计算最佳的$R$:</p><script type="math/tex; mode=display">R^* = \arg\min_R \sum_{i=1}^n\Vert q'_i - Rq_i\Vert^2</script><p>最后，根据$R^*$计算$t$:</p><script type="math/tex; mode=display">t^* = p' - R^{*}p</script><p>因此求得$R$之后，$t$是非常容易得到的。</p><script type="math/tex; mode=display">\sum_{i=1}^n\Vert q'_i-Rq_i\Vert^2 = \sum_{i=1}^n( {q'}_i^Tq'_i + q_i^TR^TRq_i - 2{q'}_i^TRq_i)</script><p>第一项与$R$无关，而$R^TR=I$，因此第二项也无所谓。我们重点要做的是$\min_R \sum_{i=1}^n -{q’}_i^TRq_i$。</p><script type="math/tex; mode=display">\sum_{i=1}^n -{q'}_i^TRq_i = \sum_{i=1}^n -\text{tr}(Rq_i{q'}_ i^T) = -\text{tr}\left(R\sum_{i=1}^nq_i{q'}_i^T\right)</script><p>计算这个$R$可以使用SVD来解决。</p><p>定义$W = \sum_{i=1}^n q’_iq_i^T$，根据SVD得到：</p><script type="math/tex; mode=display">W = U\Sigma V^T</script><p>则$R^* = UV^T$。如果$\text{rank}(W)=3$，则$R$是唯一最优解。具体的证明比较复杂。这就求得了从$p$到$p’$的旋转，有了旋转矩阵，平移就非常容易得到了。</p><p>至于迭代的过程，就是我们根据求得的$R,t$进行转换后，重复上述的步骤。</p><p>最早的关于ICP的论文为<a href="http://www-evasion.inrialpes.fr/people/Franck.Hetroy/Teaching/ProjetsImage/2007/Bib/besl_mckay-pami1992.pdf" target="_blank" rel="noopener">A Method for Registration of 3-D Shapes</a>。</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
            <tag> SLAM </tag>
            
            <tag> icp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RANSAC——随机采样一致</title>
      <link href="/2019/01/17/RANSAC%E2%80%94%E2%80%94%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7%E4%B8%80%E8%87%B4/"/>
      <url>/2019/01/17/RANSAC%E2%80%94%E2%80%94%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7%E4%B8%80%E8%87%B4/</url>
      
        <content type="html"><![CDATA[<p>RANSAC（RANdom SAmple Consensus），随机采样一致，是一个比较简单，但是在SLAM，图像陪准中用得很多的算法。当然，在这里我们专注于算法的本身，至于它在其他的地方的应用要结合具体情况分析。<br><a id="more"></a></p><p>假如现在有一组采样得到的点，是由一条直线生成的。但是由于噪声的存在，它变得很乱。现在我们希望恢复这条直线。如果噪声比较小，或者是高斯噪声，我们使用最小二乘法（线性回归）就可以得到最佳的那条线，它们都用了least squares作为要优化的目标（可以看<a href="https://wlsdzyzl.top/2018/10/16/Learning-From-Data%E2%80%94%E2%80%94Softmax-Regression/" target="_blank" rel="noopener">数据学习第一篇</a>）。但是噪声比较大，而且我们也不知道噪声生成的规律，那么这个问题使用线性回归可能就得不到我们想要的那条线，因为此时least squares用作cost function不合适了。比如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/ransac1.jpg" alt=""></p><p>我们可以很轻易的看出来这个线应该是什么样子，但是使用线性回归却得到了错误的结果。</p><p>RANSAC算法的思想非常简单，它认为，有更多的样本符合这个假设，这个假设就是正确的。但是如何让最多的样本符合这个假设应该是一个NP-hard的问题，正如PLA中，如何分类使得错误的个数最小。</p><p>RANSAC算法是这么做的，随机采取一定的点来确定这个模型，正如本例中，两个点就可以确定一条直线。当然，实际上我们不会只采两个点，而是采一组，用这一组点利用线性回归或者最小二乘法得到模型，然后定义一个distance的threhold，对于小于threhold的确定为局内点（inlier），对于大于的定为局外点（outlier）。根据inlier的个数来觉得这个模型的好坏，并且重新计算这个模型。</p><p>不断迭代上面的过程，进行随机采样，如果可以得到更好的模型，就用它来替换最好的模型，如果不行，就将其淘汰，算法过程如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/ransac2.jpg" alt=""></p><p>可以看到的是，我们不能保证RANSAC收敛，因此会一般执行一定的步骤，得到最后的结果。在很大概率下，Ransac是可以得到不错的结果。实际上它的思想和Pocket PLA是非常相近的。</p><p>下面我们提一下Ransac在图像特征匹配中如何剔除误匹配。我们根据随机选取几组匹配点可以计算出一个位姿，也就是利用八点算法，或者五点算法。要知道一般来说误匹配的个数是相对正确的来说比较小的，因此理论上大部分的匹配点都应该满足这个位姿。接着我们看匹配点有多少是符合这个匹配的。不断迭代上面的过程，最后可以选取一个相对之前的多次迭代采样来说最正确的位姿，剔除掉不符合这个位姿的匹配点即可。在SLAM中的对于位姿的估计也是相似的做法。</p><p>paper：<a href="http://www.dtic.mil/dtic/tr/fulltext/u2/a460585.pdf" target="_blank" rel="noopener">Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
            <tag> SLAM </tag>
            
            <tag> ransac </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——最大熵原理与最小鉴别信息原理</title>
      <link href="/2019/01/10/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E6%9C%80%E5%A4%A7%E7%86%B5%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9C%80%E5%B0%8F%E9%89%B4%E5%88%AB%E4%BF%A1%E6%81%AF%E5%8E%9F%E7%90%86/"/>
      <url>/2019/01/10/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E6%9C%80%E5%A4%A7%E7%86%B5%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9C%80%E5%B0%8F%E9%89%B4%E5%88%AB%E4%BF%A1%E6%81%AF%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>这一节是信息论的最后一节（当然对于这门学科，这些东西只是冰山一角）。我们聊一聊信息论在压缩啊编码之外的一些作用。<br><a id="more"></a></p><p>假如我们现在面临的是一个传感器网络定位问题，我们希望能够得到传感器网络的节点的位置，但是由于没有一个定位系统，我们只能依靠传感器两两之间的测距信息来估计这个位置。假如有n个结点，而我们的测距信息可能远远达不到结点的个数，这个问题就成为了一个欠定问题。</p><p>另外一个问题，比如GPS全球定位原理。对一个点的定位我们需要确定的是4个变量(x,y,z,t)，而天上的卫星个数可能对于4个，使得约束过多，而卫星测距存在噪声，因此可能这些约束并没有一个共同的解，因此这个问题是一个超定问题。对于超定问题实际上是优化问题，可以使用最小二乘法等等方法来解决。</p><h3 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h3><p>面对欠定问题时，方程的可行解对于一个，使得问题变成了一个估计问题，究竟取哪个解才能是最佳的估计。而E.T.Jayne在1957提出的最大熵原理告诉我们，在所有满足约束的解中，能够使得随机变量的熵达到最大，是最佳解。其实本质上是统计方法。</p><p>最大熵原理问题表述如下：</p><p>设有某一离散随机变量$X$，其概率分布$p(x)$未知，已知其与若干函数的期望：</p><script type="math/tex; mode=display">\sum_{x \in \mathcal{X}} p(x)f_m(x) = C_m,\text{where }m = 1,...,M</script><p>求最佳估计$\hat p(x)$</p><p>按照最大熵原理求解该问题，可以表述为下面这样的约束优化问题：</p><ul><li>取概率分布的熵为目标函数$H(X) = -\sum_{x \in \mathcal{X}} p(x)\log p(x)$.</li><li>约束条件：<script type="math/tex; mode=display">\sum_{x}p(x)=1\\\sum_{x}p(x)f_m(x) = C_m,m=1,2,...,M</script></li><li>求：$ \hat p(x) = \arg\max _{p(x)} H(X)$</li></ul><p>运气很好的是，这个解也是有固定形式的。欠定约束下最大熵分布满足</p><script type="math/tex; mode=display">\hat p(x) = \exp\left[-\lambda_0 - \sum_{m=1}^M \lambda_m f_m(x) \right]</script><p>的形式，式中$\lambda_0,…,\lambda_m$的取值使得$\hat p(x)$满足约束条件。</p><p>这是一个典型的利用拉格朗日乘子方法求解约束极值的问题。</p><h4 id="连续随机变量"><a href="#连续随机变量" class="headerlink" title="连续随机变量"></a>连续随机变量</h4><p>将离散随机变量推广到连续随机变量，这个问题并没有变得复杂。最大熵原理依然成立，只是将离散熵变成了微分熵。</p><p>在连续随机变量的条件下:</p><script type="math/tex; mode=display">p(x)\ge 0\text{ and }p(x)=0 \text{ when }x \in S\\\int_s p(x)dx = 1\\\int_s p(x)f_m(x)dx = C_m,m=1,...,M</script><p>最大熵原理告诉我们：满足约束条件且使微分熵达到最大值的分布为：</p><script type="math/tex; mode=display">\hat p(x) = \exp\left[\lambda_0 + \sum_{m=1}^M \lambda_mf_m(x)\right].</script><h3 id="最小鉴别信息原理"><a href="#最小鉴别信息原理" class="headerlink" title="最小鉴别信息原理"></a>最小鉴别信息原理</h3><p>最大熵原理给出的是在没有任何先验信息前提下求解欠定问题的一种方法。如果存在一个先验的分布，如何求解最合理的分布？这时候我们需要用到最小鉴别信息原理。鉴别信息是度量两个分布之间差异的指标，而鉴别信息最小化指的是，在满足约束前提下，给出的分布距离先验分布最小，也就是鉴别信息最小。</p><p>最小鉴别信息院里的问题描述如下：</p><p>某随机变量$X$，概率分布$q(x)$未知，已知其先验概率密度$p(x)$以及若干函数的期望</p><script type="math/tex; mode=display">\int_s q(x)f_m(x)dx = C_m,m=1,2,...,M</script><p>求在上述条件下对$q(x)$的最佳估计。</p><p>按照最小鉴别信息原理，上述问题的求解可以表述为以下受限优化问题。</p><ul><li>取先验分布与目标分布之间的鉴别信息作为目标函数：<script type="math/tex; mode=display">D(q\Vert p) = \int_s q(x)\log\frac{q(x)}{p(x)}dx</script></li><li>约束条件：<script type="math/tex; mode=display">\int_s q(x)dx = 1\\\int_s q(x)f_m(x)dx = C_m,m=1,...,M</script>则解为：$\hat q(x) =\arg\min_{q(x)}D(q\Vert p)$。</li></ul><h3 id="二者之间联系"><a href="#二者之间联系" class="headerlink" title="二者之间联系"></a>二者之间联系</h3><p>实际上最大熵原理和最小鉴别信息原理之间联系非常密切。最大熵原理是最小鉴别信息原理的一个特例，而最小鉴别信息原理是最大熵原理的推广。在离散情形下，设先验概率等概：$p(x) = \frac 1 K$，那么二者就是一致的。</p><p>证明如下：</p><script type="math/tex; mode=display">\begin{aligned}D(q\Vert p) &= D(q\Vert \frac 1 K)\\&= \sum_{x \in \mathcal{X} }q(x)\log Kq(x)\\&= -H(X) + \log K\end{aligned}</script><p>因此此时让$D(q \Vert p)$最小就是让$H(X)$最大。</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><ul><li>$S=[0,\infty],EX = \mu$ 最大熵分布为指数分布</li><li>$S=[-\infty,\infty],EX = \mu$，最大熵分布为方差无穷大的高斯分布</li><li>$S=[-\infty,\infty],EX = \mu, E(X-\mu)^2 = \sigma^2$，最大熵分布为方差为$\sigma^2$的高斯分布 </li></ul>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——视觉里程计（二）对极几何</title>
      <link href="/2019/01/09/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%BA%8C%EF%BC%89%E5%AF%B9%E6%9E%81%E5%87%A0%E4%BD%95/"/>
      <url>/2019/01/09/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%BA%8C%EF%BC%89%E5%AF%B9%E6%9E%81%E5%87%A0%E4%BD%95/</url>
      
        <content type="html"><![CDATA[<p>上次介绍了特征，现在我们已经得到了特征匹配后的点对，现在我们需要用这些东西来估计相机运动。由于相机原理不同，估计的方法也不同。现在我们考虑的是单目相机，使用的方法为对极几何。<br><a id="more"></a></p><h3 id="对极约束"><a href="#对极约束" class="headerlink" title="对极约束"></a>对极约束</h3><p>如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/djjh1.png" alt=""></p><p>我们希望求得是两帧图像$I_1,I_2$之间的运动，设第一帧到第二帧的旋转为$R$，平移为$t$向量，两个相机的位置分别为$O_1,O_2$。假如$p_1,p_2$为一对匹配正确的特征点，那么他们是同一个空间点$P$在两个平面上的投影。$O_1p_1$与$O_2p_2$会相交于点$p$。这时候点$Q_1,Q_2,P$三个点可以确定一个平面，称为极平面（epipolar plane）。$O_1O_2$连线与像平面$I_1,I_2$的交点$e_1,e_2$为极点（epipoles），$O_1O_2$为基线（baseline）。</p><p>我们可以看到，如果只看第一帧$I_1$，射线$O_1p_1$上是任何一点都是这个像素点可能对应的空间位置，而$e_2p_2$是这个射线则是对应的可能的投影位置。因此，只有通过正确的特征匹配才能保证这个$p$点的确定位置，否则的话我们需要在这个极线上搜索。</p><p>现在我们从代数角度来看一下这其中的几何关系。假设在第一帧的相机坐标系下，P的坐标为：</p><script type="math/tex; mode=display">P_1 = [X_1,Y_1,Z_1]^T, P_2 = [X_2,Y_2,Z_2]^T</script><p>上式中：</p><script type="math/tex; mode=display">P_2 = RP_1 + t</script><p>根据之前介绍的针孔相机模型，我们可以得到两个像素点$p_1,p_2$的位置:</p><script type="math/tex; mode=display">p_1 = \frac 1 {Z_1}KP_1, p_2 = \frac 1 {Z_2 }KP_2 = \frac{1}{Z_2}(RP_1+t).</script><p>这里$K$为相机内参矩阵。现在取$x_1 = K^{-1}p_1, x_2 = K^{-1}p_2$，则$x_1,x_2$分别为在空间的归一化坐标，即：</p><script type="math/tex; mode=display">x_1 = [\frac{X_1}{Z_1},\frac{Y_1}{Z_1},1],x_2 = [\frac{X_2}{Z_2},\frac{Y_2}{Z_2},1]</script><p>我们知道：</p><script type="math/tex; mode=display">P_2 = RP_1 + t</script><p>则：</p><script type="math/tex; mode=display">Z_2x_2 = RZ_1 x_1 + t</script><p>在上式两侧左乘$t^{\hat {}}$，得到：</p><script type="math/tex; mode=display">Z_2t^{\hat{}} x_2 = Z_1t^{\hat{}} Rx_1</script><p>如果再将两侧左乘$x_2^T$：</p><script type="math/tex; mode=display">Z_2x_2^T t^{\hat{}} x_2 =Z_1 x_2^T t^{\hat{}} R x_1</script><p>由于$t^{\hat{}} x_2$与$t,x_2$都是垂直的，因此得到：</p><script type="math/tex; mode=display">Z_1x_2^T t^{\hat{}} R x_1 = 0.</script><p>即：</p><script type="math/tex; mode=display">x_2^T t^{\hat{}} R x_1 = 0.</script><p>重新代回$p_1,p_2$，得到：</p><script type="math/tex; mode=display">p_2^T(K^{-1})^Tt^{\hat{}}RK^{-1}p_1 = 0</script><p>上式就是对极约束。对极约束中包含了平移和旋转，我们把中间部分记为两个矩阵：基础矩阵（Fundamental Matrix）F与本质矩阵（Essential Matrix）E，据说可以进一步简化对极约束：</p><script type="math/tex; mode=display">x_2^T E x_1 = p_2^T F p_1 = 0</script><p>上式中：$E = t^{\hat{}}R,F = (K^{-1})^T E K^{-1}$。</p><p>对极约束简洁地给出了两个匹配点的空间位置关系，于是相机位姿的估计问题变成了下面两步：</p><ol><li>根据配对点像素求出E或者F</li><li>根据E或者F求出R和t。</li></ol><p>由于E和F只相差一个相机内参，而内参一般来说是已知的。实践中往往使用形式更简单的E。</p><h3 id="本质矩阵E"><a href="#本质矩阵E" class="headerlink" title="本质矩阵E"></a>本质矩阵E</h3><p>根据定义$E= t^{\hat{}}R$，它是一个$3\times 3$矩阵，有9个元素。它有下面几个性质：</p><ul><li>本质矩阵是由对极约束定义的，由于对极约束是等式为0的约束，因此对$E$乘以任意非0常数，对极约束依然满足，这说明$E$在不同尺度下是等价的。</li><li>根据定义可以证明，$E$的奇异值必定是$[\sigma,\sigma,0]^T$的形式，这是本质矩阵的内在性质。</li><li>由于$R$和$t$各有3个自由度，故$t^{\hat{}}R$共有6个自由度，而由于尺度等价性，$E$实际上有5个自由度。</li><li>E的秩为2</li></ul><p>由于$E$的自由度有5个，可以用5个匹配点就可以求出$E$，但是$E$的内在性质是一种非线性性质，在求解时候会带来麻烦。可以只考虑它的制度等价性，使用8对点来估计$E$，这就是8点算法。它只使用了$E$的线性性质，因此求解更加容易。通常来说，我们匹配点的个数不会少于8个。</p><h4 id="8点算法"><a href="#8点算法" class="headerlink" title="8点算法"></a>8点算法</h4><p>考虑到一对匹配点，它们的归一化坐标分别为$x_1 = [u_1,v_1,1]^T,x_2 = [u_2,v_2,1]^T$。根据对极约束有：</p><script type="math/tex; mode=display">\begin{pmatrix}u_1&v_1&1\end{pmatrix}\begin{pmatrix}e_1&e_2&e_3\\e_4&e_5&e_6\\e_7&e_8&e_9\end{pmatrix}\begin{pmatrix}u_2\\v_2\\1\end{pmatrix}</script><p>我们把矩阵$E$展开写成向量形式：</p><script type="math/tex; mode=display">e = [e_1,e_2,e_3,e_4,e_5,e_6,e_7,e_8,e_9]^T</script><p>那么对极约束可以写成与$e$有关的线性形式：</p><script type="math/tex; mode=display">[u_1u_2,u_1v_2,u_1,v_1u_2,v_1v_2,v_1,u_2,v_2,1]\cdot e = 0</script><p>同理，对其他的7对点也有这样类似的形式，于是我们就有一个线性方程组：</p><script type="math/tex; mode=display">\begin{pmatrix}u^1_1u^1_2&u^1_1v^1_2&u^1_1&v^1_1u^1_2&v^1_1v^1_2&v^1_1&u^1_2&v^1_2&1\\u^2_1u^2_2&u^2_1v^2_2&u^2_1&v^2_1u^2_2&v^2_1v^2_2&v^2_1&u^2_2&v^2_2&1\\\vdots&\vdots&\vdots&\vdots&\vdots&\vdots&\vdots&\vdots&\vdots\\u^8_1u^8_2&u^8_1v^8_2&u^8_1&v^8_1u^8_2&v^8_1v^8_2&v^8_1&u^8_2&v^8_2&1\end{pmatrix}\begin{pmatrix}e_1\\e_2\\e_3\\e_4\\e_5\\e_6\\e_7\\e_8\\e_9\end{pmatrix} = 0</script><p>如果这个系数矩阵是满秩的（秩为8），那么它的<font color="red">零空间维数为1,也就是e构成一条线，这和$e$的尺度等价性是一致的</font>（不明白这段话在说什么）。总之如果是满秩的，我们可以通过上面的方程组解出$e$的值。它们和e共同构成了一组9维空间的基。</p><p>有了e的值，我们就得到了本质矩阵$E$。接下来的问题是如何根据$E$求得$R,t(E = t^{\hat {}}R)$。</p><p>这时候我们需要用到奇异值分解（SVD）。假如：</p><script type="math/tex; mode=display">E = U\Sigma V^T,</script><p>由于$E$的内在性质，我们知道$\Sigma = \text{diag}(\sigma,\sigma,0)$。在SVD中，对于任何一个$E$，存在有两个可能的$t,R$与他们对应：</p><script type="math/tex; mode=display">t^{\hat{}}_1 = UR_Z(\frac{\pi}{2})\Sigma U^T, R_1 = UR_Z^T(\frac{\pi}{2})V^T\\t^{\hat{}}_2 = UR_Z(-\frac{\pi}{2})\Sigma U^T, R_2 = UR_Z^T(-\frac{\pi}{2})V^T</script><p>上式中$R_Z(\frac{\pi}{2})$表示沿Z轴旋转90度得到的旋转矩阵。为什么要这样算？首先我们知道，得到的$t^{\hat{}}$必须得是一个反对称矩阵，同时得到的$R$要是一个旋转矩阵，因此这说明求解$R,t$时候是有约束的。而$R_Z(\frac{\pi}{2})$得到的解则是满足上面的条件的。同时由于$-E$与$E$是等价的，因此对$t$取负号,也是有一样的结果。所以就会得到4个解。想看更多的内容，可以查看wiki：<a href="https://en.wikipedia.org/wiki/Essential_matrix#Determining_R_and_t_from_E" target="_blank" rel="noopener">determine R and t</a>。下图形象得展示了分解本质矩阵得到的4个解：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/djjh3.jpg" alt=""></p><p>可以从上图看出只有第一个是正确的，它的深度都是正值，因此排除其他3个解并不算困难。</p><p>由于$E$的内在性质，还有一种算法是五点算法，不过这个做法会更加复杂。由于我们每次匹配的个数一般都会成百上千，因此他们的区别不是很大。对于五点算法有兴趣的可以看着篇论文：<a href="http://www.ee.oulu.fi/research/imag/courses/Sturm/nister04.pdf" target="_blank" rel="noopener">五点算法</a>。</p><p>最后还有一个问题，根据线性方程组解得的$E$可能不满足$E$的性质，因为现实世界总是充满噪声的。这时候在做SVD时，我们会刻意将$\Sigma$矩阵调整成上面的样子，如$\Sigma=\text{diag}(\sigma_1,\sigma_2,\sigma_3)$，设$\sigma_1&gt;\sigma_2&gt;\sigma_3$，那么我们取：</p><script type="math/tex; mode=display">E = U\text{diag}(\frac{\sigma_1+\sigma_2}{2},\frac{\sigma_1+\sigma_2}{2},0)V^T.</script><p>其实更简单的做法是取$\Sigma = (1,1,0)$，由于$E$具有出度等价性，这样做也是没什么错误的。</p><h3 id="单应矩阵（Homography-Matrix）"><a href="#单应矩阵（Homography-Matrix）" class="headerlink" title="单应矩阵（Homography Matrix）"></a>单应矩阵（Homography Matrix）</h3><p>除了基本矩阵与本质矩阵，还有一个单应矩阵$H$需要我们注意。若场景中的特征点都落在同一平面上，则可以通过单应性来进行运动估计。</p><p>单应矩阵通常描述处于共同平面上的一些点在两张图像之间的变换关系。考虑在图像$I_1,I_2$有一对匹配好的特征点$p_1$和$p_2$。这些特征点落在平面$P$上，设这个平面满足：</p><script type="math/tex; mode=display">n^TP + d = 0.</script><p>稍加整理可以得到：</p><script type="math/tex; mode=display">-\frac{n^TP}{d} = 1</script><p>我们知道：</p><script type="math/tex; mode=display">\begin{aligned}p_2 &= \frac{1}{Z_2}K(RP+t)\\&= \frac{1}{Z_2}K(RP + t \cdot\left(-\frac{n^TP}{d})\right )\\&= \frac{1}{Z_2}K\left(R - \frac{tn^T}{d}\right)P\\&=\frac{Z_1}{Z_2}K\left(R - \frac{tn^T}{d}\right)K^{-1}p_1\\&= \frac{Z_1}{Z_2}Hp_1\end{aligned}</script><p>当然，这个$\frac{Z_1}{Z_2}$我们也是不知道的。我们可以忽略它到$H$矩阵求解中。简单得到$p_2 = Hp_2$<br>于是，我们得到了一个直接描述图像坐标$p_1,p_2$的变换$H$。它的定义与旋转，平移以及平面的参数有关。与基础矩阵$F$类似，单应矩阵$H$也是一个$3\times 3$的矩阵。根据匹配点，我们可以得到：</p><script type="math/tex; mode=display">\begin{pmatrix}u_2\\v_2\\1\end{pmatrix}=\begin{pmatrix}h_1&h_2&h_3\\h_4&h_5&h_6\\h_7&h_8&h_9\end{pmatrix}\begin{pmatrix}u_1\\v_1\\1\end{pmatrix}</script><p>对上式右侧侧展开后，一般我们是无法得到准确地等于1的，因此将第三项变为1,得到：</p><script type="math/tex; mode=display">u_2 = \frac{h_1u_1 +h_2v_1 + h_3}{h_7u_1+h_8v_1+h_9}\\v_2 = \frac{h_4u_1+h_5v_1+h_6}{h_7u_1+h_8v_1+h_9}</script><p>实际中我们会对$h_9$进行归一化，整理可以得到：</p><script type="math/tex; mode=display">h_1u_1 +h_2v_1+h_3-h_7u_1u_2-h_8v_1v_2 = u_2\\h_4u_1+h_5v_1+h_6-h_7u_1v_2-h_8v_1v_2 = v_2</script><p>这样一组匹配点对就可以构造出来两项约束，而$H$的自由度为8,我们可以通过4对匹配特征点算出（不能有3点共线的情况）。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/djjh2.jpg" alt=""></p><p>下面的做法把$H$矩阵看成向量，通过解该向量的线性方程来恢复$H$，又称直接线性变换法。求出单应矩阵以后需要进行分解才能得到对应的旋转矩阵$R$与平移矩阵$t$。分解的方法包括数值法与解析法。单应矩阵的分解同样得到四组解，依照深度信息可以排除两组，剩下的两组需要用先验信息来完成。如，如果场景平面与相机平面平行，法向来的理论值为$\mathbf{1}^T$。</p><h3 id="三角测量"><a href="#三角测量" class="headerlink" title="三角测量"></a>三角测量</h3><p>我们可以根据$R,t$来得到深度信息。首先，由之前的定义可以得到：</p><script type="math/tex; mode=display">Z_1x_1 = Z_2Rx_2 +t</script><p>上式左侧乘以$x_1^{\hat{}}$，得到：</p><script type="math/tex; mode=display">Z_1x_1^{\hat{}} = Z_2x_1^{\hat{}}Rx_2 +x_1^{\hat{}}t = 0</script><p>因此我们可以解出来$Z_2$与$Z_1$。当然由于尺度不确定性，这个求得只是三维坐标的相对位置。我们并无法得知它们真实的距离。</p><h3 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h3><ul><li><p>为什么需要单应矩阵？当特征点共面或者相机发生纯旋转或者平移的时候，基础矩阵的自由度下降，此时继续使用8点算法，对于的自由度主要由噪声决定，这就出现了退化。为了避免这种现象，通常会估计基础矩阵$F$和单应矩阵$H$，选择重投误差较小的哪个作为最终的运动估计矩阵。</p></li><li><p>单目相机具有尺度不确定性，我们求解出来的值并不能确定它的单位是多少，进行同比例的放大缩小结果都是一样的。同时，它需要进行初始化，再初始化时，不能进行纯旋转，如果平移为0,则无法根据8点算法来求解出旋转。之后的求解可以使用3D-2D来计算相机运动。</p></li><li><p>在使用8点算法时候，由于噪声存在，往往构成超定问题。这是很可以通过最小二乘法来优化（SVD可以用来解最小二乘问题），当然误匹配情况下，也可以使用RANSAC来解决这个问题，实际上后者用得更多一点。</p></li><li><p>在使用3角测量时，由于像素的不确定性（可以认为是相机分辨率不够对定位的误差），会造成深度的不确定性。想要增大深度估计的精度，我们需要增加相机分辨率，但这样会导致计算量以及需要的内存过大，或者是增加平移的距离。而平移距离加大会导致外观变化较大，使得特征提取和匹配变得困难。因此这就导致了三角化的矛盾：平移过小，深度精度不够，平移过大，匹配失败。如下图：</p></li></ul><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/djjh4.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> computer vision </tag>
            
            <tag> geometry </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——信息速率失真函数与熵压缩编码（二）</title>
      <link href="/2019/01/09/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E6%81%AF%E9%80%9F%E7%8E%87%E5%A4%B1%E7%9C%9F%E5%87%BD%E6%95%B0%E4%B8%8E%E7%86%B5%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
      <url>/2019/01/09/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E6%81%AF%E9%80%9F%E7%8E%87%E5%A4%B1%E7%9C%9F%E5%87%BD%E6%95%B0%E4%B8%8E%E7%86%B5%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>之前说到,我们直觉构造的1比特下高斯信源的传输与理论上的失真还有点差距，需要进行分组才能得到最优。下面，我们用失真联合典型序列来证明，同时证明率失真定理。<br><a id="more"></a><br>率失真定理的核心是我们要证明$R(D) = R^{(I)}(D)$。</p><h3 id="率失真定理的converse"><a href="#率失真定理的converse" class="headerlink" title="率失真定理的converse"></a>率失真定理的converse</h3><p>与之前不同的是，我们首先来证明定理的逆。我们需要说明这样一件事：</p><p>对于服从分布$P(x)$的随机变量$X$和失真度量$d(x,\hat x)$，以及任意满足失真小于$D$的率失真编码$(2^{nR},n)$来说，$R \ge R^{(I)}(D)$。</p><p>如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rate_distort2.jpg" alt=""></p><p>我们证明的是可行域是如图所示的。</p><script type="math/tex; mode=display">\begin{aligned}nR &\ge H(\hat X^n)\\&\ge H(\hat X^n) - H(\hat X^n|X^n)\\&= I(\hat X^n,X^n)\\&= H(X^n)-H(X^n|\hat X^n)\\&= \sum_{i=1}^n H(X_i) - \sum_{i=1}^n H(X_i|\hat X^n,X_1,...,X_{i-1})\\&\ge \sum (H(X_i) - H(X_i|\hat X_i))\\& = \sum I(X_i;\hat X_i)\\& \ge \sum R^{(I)}(E[d(X_i,\hat X_i)]) \\&= n\sum \frac 1 n R^{(I)}(E[d(X_i, \hat X_i)])\\&\ge nR^{(I)}(\frac 1 n \sum E[d(X_i,\hat X_i)])\\&= nR^{(I)}(D)\end{aligned}</script><p>因此我们证明了任何一个率失真编码得到的率失真函数都不可能比信息论上的率失真函数来得更小。</p><h3 id="率失真编码的存在性"><a href="#率失真编码的存在性" class="headerlink" title="率失真编码的存在性"></a>率失真编码的存在性</h3><p>对于存在性的证明，是依照这样的想法进行的：</p><ul><li>设$X_1,X_2,…,X_n$是服从$p(x)$的独立同分布随机变量</li></ul><ul><li>设$d(x,\hat x)$为有界的失真度量</li><li>对于任何$D$，有$R \ge R^{(I)}(D)$</li><li>现在我们要证明的是，存在一组率失真编码，他们的码率都是$R$，而失真渐进达到$D$</li></ul><p>这个过程与信道编码定理是很类似的，不同的是多了一个失真的约束。因此我们首先定义”失真”典型序列。</p><h4 id="失真典型序列"><a href="#失真典型序列" class="headerlink" title="失真典型序列"></a>失真典型序列</h4><p>设$p(x,\hat x)$和$d(x,\hat x)$分别是$X\times \hat X$上的联合概率分布和失真度量。对于任意$\epsilon&gt;0$，若一个序列对$(x^n,\hat x^n)$满足以下条件，就被称为失真$\epsilon$-典型序列。</p><script type="math/tex; mode=display">\left.\begin{matrix}\lvert -\frac 1 n \log p(x^n) - H(X)  \rvert < \epsilon\\\lvert -\frac 1 n \log p(\hat x^n) - H(\hat X)  \rvert < \epsilon\\\lvert -\frac 1 n \log p(x^n,\hat x^n) - H(X,\hat X)  \rvert < \epsilon\\\lvert d(x^n,\hat x^n) - E[d(X,\hat X)] \rvert < \epsilon\end{matrix}\right \}联合典型序列</script><p>前三个条件实际上就是联合典型序列的定义。实际上这个定义就是联合典型序列的拓展，失真联合典型序列一定是联合典型序列。</p><p>有了上面的定义，有这样一条引理：设$(X_i,\hat X_i)$是服从联合概率分布$p(x,\hat x)$的独立同分布随机变量，当$n\rightarrow \infty$时，$Pr(A_{d,\epsilon}^(n)) \rightarrow 1$。</p><p>证明如下：</p><p>按照大数定理，前三个不等式的左侧都散以概率1收敛到期望值0的，而对于最后一个条件，我们有：</p><script type="math/tex; mode=display">d(x^n,\hat x^n) = \frac 1 n \sum_{i=1}^n d(x_i,\hat x_i)</script><p>根据大数定律，上式也会收敛到失真度量的统计平均。因此，最后一个条件也依概率1收敛到0。因此这个命题是成立的。</p><h4 id="证明思路"><a href="#证明思路" class="headerlink" title="证明思路"></a>证明思路</h4><p>与之前的香农第二定理一样，这里我们依然要用到随机生成的码本。</p><ul><li>随机生成一个码本$C$，含有$2^{nR}$个序列$\hat X ^n \sim \prod _{i=1}^n p(\hat x_i)$</li><li>将上述随机生成的$2^{nR}$个码进行编号$w \in {1,2,…,2^{nR}}$，因此我们可以确定的是这个信道的传输码率是$R$。</li><li>构造编码映射：<blockquote><p>若$(X^n,\hat X^n(W)) \in A_{d,\epsilon}^{(n)}$，则编码映射$X^n \rightarrow w$；若满足以上条件的$w$多于1，则取最小的$w$，否则，取$w = 1$。</p></blockquote></li><li>构造解码映射：取恢复点为$\hat X^n (w)$</li><li>我们需要证明它的失真渐进等于$D$</li></ul><p>这个信道的输入只有$2^{nR}$种字符，因此它的码率一定是$n$。</p><p>这个信道如图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rate_distort1.jpg" alt=""></p><p>传输过程会有两种情况：</p><ol><li><p>$\exists w$, s.t. $(x^n,\hat X^n(w)) \in A_{d,\epsilon}^{(n)}$，则$d(x^n,\hat X^n(w)) &lt; D+\epsilon$</p></li><li><p>不存在上述$w$，那么这时候$d(x^n,\hat X^n(w)) &lt; d_{max}$</p></li></ol><p>因此得到：</p><script type="math/tex; mode=display">E[d(X^n,\hat X^n(X^n))] \leq (1-P_e)(D+\epsilon) + P_e \cdot d_{max}\leq D + \epsilon +P_e \cdot d_{max}</script><p>为了证明，我们再引入两个数学引理：</p><ul><li>对于所有$(x^n,\hat x ^n) \in A_{d,\epsilon}^{(n)}$，<script type="math/tex; mode=display">p(\hat x^n) \ge p(\hat x^n| x^n) 2 ^{-n(I(X;\hat X)+3\epsilon)}</script></li><li>对于$0\leq x,y\leq 1,n&gt;0$,<script type="math/tex; mode=display">(1 - xy)^n \leq 1 -x + e^{-yn}</script></li></ul><p>再引入一个标记函数：</p><script type="math/tex; mode=display">k(x^n,\hat x^n) = \left \{    \begin{matrix}    1 & (x^n,\hat x^n )\in A_{d,\epsilon}^{(n)}\\    0 & \text{otherwise}     \end{matrix}\right.</script><p>则：</p><script type="math/tex; mode=display">\begin{aligned}P_e &= \sum_{x^n}p(x^n)[1-\sum_{\hat x^n} p(\hat x ^n)k(x^n,\hat x^n)]^{2^{nR}}\\&\leq  \sum_{x^n}p(x^n)[1-2^{-n(I(X;\hat X) + 3\epsilon)} \sum_{\hat x^n}p(\hat x^n|x^n)k(x^n,\hat x^n)]^{2^{nR}}\\&\leq \sum_{x^n}p(x^n)[1-p(\hat x^n|x^n)k(x^n,\hat x^n) + \exp(-2^{-n(I(X;\hat X) + 3\epsilon)} 2^{nR})]\\&\leq 1- \sum_{x^n\hat x^n}p(x^n)p(\hat x^n|x^n)k(x^n,\hat x^n) + \exp(-2^{n(R - I(X;\hat X) - 3\epsilon)})\end{aligned}</script><p>为了让上式趋于0,我们需要让$R \ge I(X;\hat X)$。而上式实际上就是$R \ge R^{(I)}(D)$。因此我们证明了，只要$R \ge R^{(I)}(D)$，失真是可以无限渐进逼近于$D$的。</p><p>最后，形象化的解释如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rate_distort3.jpg" alt=""></p><p>实际上推导到现在，我们也能够感觉到实际上信道编码定理和率失真定理之间是有一定的对偶关系的。在信道编码时候，由于信道噪声的存在，使得一个个$X^n$空间的点胀成了超球，而这个容量C就是最多能容纳多少个球。在率失真的情况下，由于失真$D$，我们想要求的是最少可以有多少个球可以覆盖信源。但是球的半径由于平均失真限制住，不能无限大。而这两个过程，正是对互信息的最大化和最小化。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——信息速率失真函数与熵压缩编码（一）</title>
      <link href="/2019/01/08/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E6%81%AF%E9%80%9F%E7%8E%87%E5%A4%B1%E7%9C%9F%E5%87%BD%E6%95%B0%E4%B8%8E%E7%86%B5%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2019/01/08/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E6%81%AF%E9%80%9F%E7%8E%87%E5%A4%B1%E7%9C%9F%E5%87%BD%E6%95%B0%E4%B8%8E%E7%86%B5%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>之前我们研究的问题，冗余度压缩编码以及信道编码（增加信息冗余度，以对抗信道中的传输错误），目的都是对信息进行可靠无差错的传输，信息熵没有变化，也就是是保熵的。之后的内容，我们不再保证信息传输是无差错的。<br><a id="more"></a></p><p>在实际中，很多情况下我们是没有必要把信息的所有内容都保留下来的。比如看视频的时候，有高清标清的选择，对应于不同的网络情况。同样的还有图片的有损压缩等等。</p><h3 id="连续随机变量的量化"><a href="#连续随机变量的量化" class="headerlink" title="连续随机变量的量化"></a>连续随机变量的量化</h3><p>考察随机变量$X \sim N(0,\sigma^2)$，如果对该随机变量进行无失真编码是不可能的，假如我们需要用$R$比特来表示$X$。所以被表示的结果$\hat X$相对于原来的$X$一定是有失真的。而这个失真如何度量呢？最简单的方法是采用平方误差度量最小化：</p><script type="math/tex; mode=display">E(x - \hat X(x))^2 = \int_{-\infty}^{\infty} (x - \hat X(x))^2 p(x)dx.</script><p>现在假设$R=1$，比较显然的是该符号应该代表X的正负。为了最小化误差，恢复值应该为其代表区域的条件平均：</p><script type="math/tex; mode=display">\hat X(x) = \left \{\begin{matrix}\sqrt{\frac{2}{\pi}}\sigma &\hat x = 1(x\ge 0)\\-\sqrt{\frac{2}{\pi}}\sigma & \hat x=0(x < 0)\end{matrix}\right .</script><p>这个值是如何求得的？<br>首先我们要理解上面话的意思，最小化误差，其实也就是X的期望。对于整个分布来说，$X$的期望当然是0，现在我们只看左侧，希望能得到左侧的条件分布X的期望是多少。</p><script type="math/tex; mode=display">\begin{aligned}E(X) &= \int_{-\infty}^0 xf(x)dx\\&=\int_{-\infty}^0 2\sigma^2\cdot\frac{1}{\sigma \sqrt{2\pi}}exp(-\frac{x^2}{2\sigma^2})  f(x) d\frac{x^2}{2\sigma^2}\\&= -\frac{2\sigma}{\sqrt{2\pi}} exp (-\frac{x^2}{2\sigma^2})|_{-\infty}^{0}\\&=-\frac{2\sigma}{\sqrt{2\pi}} = -\sqrt{\frac{2}{\pi}}\sigma\end{aligned}</script><p>如果$R &gt; 1$，又如何划分量化区间？如何选取这个$2^R$个$\hat X(x)$的取值？这个问题就没有上面那么简单了。</p><p>针对随机变量的最优（最小失真）量化准则：</p><ul><li>如果给定了一组$\hat X(x)$，那么将随机变量$x$映射到最近的$\hat X(x)$可以最小化量化失真。由这种映射形成的划分称为Voronoi（Dirichlet）划分。</li><li>$\hat X(x)$的选取可以最小化对应趋于中的条件预期失真。</li></ul><h3 id="率失真理论的基本概念"><a href="#率失真理论的基本概念" class="headerlink" title="率失真理论的基本概念"></a>率失真理论的基本概念</h3><p>失真度量（失真函数）是这样一个映射：</p><script type="math/tex; mode=display">d:X \times \hat X \rightarrow R^{+}</script><p>它将源字母-恢复字母对映射到一个非负的实数，来代表失真多少。当原始字母集与映射的字母集是离散的，可以用一个矩阵来表示失真的大小，而在连续的情况下，这就是一个函数。失真函数永远都是非负的，因为我们没有办法说一个失真是负的。如果失真是有限的，则函数为有界函数。</p><p>下面举两个失真度量的例子：</p><ul><li>离散对称信源，信道输入输出及失真函数为：<script type="math/tex; mode=display">X = {x_1,...,x_k}\\\hat X = { x_1 ,...,\ x_k}\\d(x_i,x_j) = \left \{\begin{matrix}0 & i=j\\1 & i \ne j\end{matrix} \right.</script></li></ul><p>当恢复符号与发送符号对应时，失真不存在，不对应时，失真为1。这个失真被称为汉明失真。汉明距离在ORB特征匹配中是非常有用的。该失真矩阵为：</p><script type="math/tex; mode=display">[d] = \begin{bmatrix}0&1&\cdots&1\\1&0&\cdots&1\\\vdots&\vdots&\ddots&\vdots\\1&1&\cdots&0\end{bmatrix}</script><ul><li>连续信源，平方失真度量：$d(x,\hat x) = (x - \hat x)^2$<br>在语音编码中，常用的失真度量为：Itakura-Saito距离。而在图像处理中，目前还没有统一的失真度量，常用的还是平方失真度量。</li></ul><p>因此，失真度量的选择要与实际结合。</p><h4 id="平均失真"><a href="#平均失真" class="headerlink" title="平均失真"></a>平均失真</h4><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_1331.PNG" alt=""></p><p>失真函数在输入输出联合空间中取统计平均为</p><script type="math/tex; mode=display">D \triangleq \sum_{x_i,\hat x_j} p(x_i)q(\hat x_j | x_i)d(x_i,\hat x_j) \triangleq E[d(X,\hat X)]</script><p>在给定信源分布与转移概率分布时，上式为信道传输失真总体的平均度量。</p><p>现在我们想做的事情如下图，$X$经过信道之后，得到$\hat X$，我们希望$I(X;\hat X)$尽可能小，以此来压缩比特的传输。当然，这个互信息是不能为0的，那一切就失去了意义。压缩下有个前提，就是对失真函数的约束。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_1332.PNG" alt=""></p><h4 id="率失真函数"><a href="#率失真函数" class="headerlink" title="率失真函数"></a>率失真函数</h4><p>针对信源$X$和失真度量$d(x,\hat x)$，信息的率失真函数$R^{(I)}(D)$定义为：</p><script type="math/tex; mode=display">R^{(I)}(D) = \min_{q(\hat x|x):\sum_{x,\hat x} p(x)q(\hat x|x )d(x,\hat x) \leq D} I(X;\hat X)</script><p>这就是信息论意义下的率失真函数的定义，而$R$的上标$(I)$标识了这一点。</p><p>注：我们无法操作信源，能做的是最小化针对所有可能的条件分布$q(\hat x | x)$，并且使得联合分布满足要求的失真约束。这个函数求得的最小值，并不一定是可操作得到的，只是数学上的一个最小值。</p><h4 id="率失真编码"><a href="#率失真编码" class="headerlink" title="率失真编码"></a>率失真编码</h4><p>率失真编码$(2^{nR},n)$包括一个编码函数</p><script type="math/tex; mode=display">f_n:X^n \rightarrow \{1,2,...,2^{nR}\}</script><p>一个解码函数：</p><script type="math/tex; mode=display">g_n:\{1,2,...,2^{nR}\} \rightarrow X^n</script><p>以及一个与$(2^{nR},n)$相关的失真：</p><script type="math/tex; mode=display">E[d(X^n,g_n(f_n(X^n)))] = \sum_{x^n} p(x^n)d(x^n,g_n(f_n(x^n)))</script><p>注：</p><ul><li>$g_n(1),g_n(2),…,g_n(2^{nR})$构成了一个码本，以$\hat X^n(1),…,\hat X^n(2^{nR})$表示</li></ul><ul><li>$f^{-1}_n(1),…,f^{-1}_n(2^{nR})$，也就是f的反函数为对应的量化区间。</li></ul><h4 id="率失真区域"><a href="#率失真区域" class="headerlink" title="率失真区域"></a>率失真区域</h4><p>如果存在一组率失真编码$(2^{nR},n)$，使得$\lim_{n \rightarrow \infty} E[d(X^n,g_n(f_n(X^n)))] \leq D$，则称率失真对$(R,D)$是可达的。</p><p>信源的率失真区域是对所有可行率失真对$(R,D)$的闭包。</p><p>给定失真度量约束$D$，率失真函数$R(D)$是速率$R$跑遍率失真区域获得的下确界。</p><p>这个率失真函数是实际可以实现的。而香农告诉我们（香农第三定理），这两个率失真函数的值是相等的。</p><h4 id="率失真定理（香农第三定理）"><a href="#率失真定理（香农第三定理）" class="headerlink" title="率失真定理（香农第三定理）"></a>率失真定理（香农第三定理）</h4><p>给定具有独立同分布$p(x)$的信源X和有界的失真度量$d(x,\hat x)$，率失真函数等于信息的率失真函数，即：</p><script type="math/tex; mode=display">R(D) = R^{(I)}(D) = \min_{q(\hat x|x):\sum_{x,\hat x} p(x)q(\hat x|x )d(x,\hat x) \leq D} I(X;\hat X)</script><p>是在失真约束$D$下可以获得的最小信息传输速率。</p><h3 id="R-I-D-的性质"><a href="#R-I-D-的性质" class="headerlink" title="$R^{(I)}(D)$的性质"></a>$R^{(I)}(D)$的性质</h3><p>直接思维中$R(D)$的形式：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_1333.PNG" alt=""></p><h4 id="单调减函数"><a href="#单调减函数" class="headerlink" title="单调减函数"></a>单调减函数</h4><p>$R^{(1)}(D)$是非增函数。这个不难理解，证明如下：</p><p>如果$D_2 \ge D_1$，则：</p><script type="math/tex; mode=display">{q(\hat x| x), E[d(x,\hat x)] \leq D_1} \subset {q(\hat x| x), E[d(x,\hat x)] \leq D_2}</script><p>由于在子集上取得的最小值不可能比全集更小，因此可以得到：</p><script type="math/tex; mode=display">\min\{I(X;\hat X):E[d(x,hat x)] \leq D_2\} \leq \min\{I(X;\hat X):E[d(x,hat x)] \leq D_1\}</script><p>从而得到：$R(D_2) \leq R(D_1)$。</p><h4 id="定义域"><a href="#定义域" class="headerlink" title="定义域"></a>定义域</h4><p>$R^{(I)}(D)$的定义域是$(D_{min},\infty)$，且存在$D_{max}$，当$D \ge D_{max}$时，$R^{(I)}(D) = 0$。</p><p>这个在直觉上也是很好理解的。平均失真D是非负实函数$d(x,\hat x)$的期望，下限为0，则允许失真D的下限也为0，对应于不允许失真的情况。</p><p>当信源$p(x)$给定时，失真取决于转移矩阵$q(\hat x|x)$的取值。因此$D$是有一个最小值的。</p><p>如果允许失真大到一定值，错得太离谱，可以不用传输了，这时候就得到$R^{(I)}(D)=0$。</p><p>下面是一个关于$D_{min}$的例子：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_1334.PNG" alt=""></p><h4 id="下凸性质"><a href="#下凸性质" class="headerlink" title="下凸性质"></a>下凸性质</h4><p>$R(D)$是$D$的下凸函数。下面是一个简单的证明：</p><p>由于输入分布$p(x)$已知，所以输入与输出的互信息仅与转移概率矩阵$Q=q(\hat x|x)$决定，记为$I(Q)$。设$Q_1$是达到$R(D_1)$时的转移概率矩阵，$Q_2$是达到$R(D_2)$的转移概率矩阵。定义$Q$是达到$R(D)$的转移概率矩阵，$D = \lambda_1D_1 + \lambda_2D_2$。</p><p>注意到：$I(Q_1) = R(D_1)$，$E[d(x,\hat x)] \leq D_1$，同理得到：$I(Q_2) = R(D_2)$，$E[d(x,\hat x)] \leq D_2$。</p><p>在转移概率矩阵Q下，编码器的平均失真为：</p><script type="math/tex; mode=display">E[d(x,\hat x)]|_Q = \lambda_1 E[d(x,\hat x)]|_{Q_1} + \lambda_2 E[d(x,\hat x)] |_{Q_2} \leq \lambda_1 D_1 + \lambda_2 D_2 = D.</script><p>因此，$Q$在可行区域中，$R(D) \leq I(Q)$。而互信息相对于转移概率矩阵Q是下凸函数，因此：</p><script type="math/tex; mode=display">R(D)\leq I(Q) \leq \lambda_1 I(Q_1) + \lambda_2 I(Q_2) = \lambda_1 R(D_1) + \lambda_2 R(D_2)</script><p>由上面的性质，我们可以大约得到$R(D)$的图像：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_1336.PNG" alt=""></p><h3 id="率失真函数的计算"><a href="#率失真函数的计算" class="headerlink" title="率失真函数的计算"></a>率失真函数的计算</h3><h4 id="伯努利信源的率失真函数"><a href="#伯努利信源的率失真函数" class="headerlink" title="伯努利信源的率失真函数"></a>伯努利信源的率失真函数</h4><p>下面是一个伯努利分布$X\sim Bern(p)$的信源的传输。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/int3.png" alt=""></p><p>我们希望求的是：</p><script type="math/tex; mode=display">R(D) = \min_{q(\hat x|x):\sum_{x,\hat x} p(x)q(\hat x|x )d(x,\hat x) \leq D} I(X;\hat X)</script><p>但是我们并不用按照拉格朗日等那样一般的数学方法去求得这个最小值。我们可以缩放这个$I(\hat X;X)$，最后再证明这个等号是可以取得的。</p><script type="math/tex; mode=display">\begin{aligned}I(X;\hat X) &= H(X) - H(X|\hat X)\\&= H(p) - H(X \oplus \hat X |\hat X  )\\&\ge H(p) - H(X \oplus \hat X) \\&= H(p) - H(P_e)\\& = H(p) - H(D)\end{aligned}\\\text{where }D \leq \frac 1 2</script><p>我们可以构造这样的信道，最后得到这个等号是可以取到的。如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rate_distortion1.png" alt=""></p><p>在汉明失真度量下，伯努利信源的率失真函数为：</p><script type="math/tex; mode=display">R(D) = \left \{\begin{matrix}H(p) - H(D),&0\leq D\leq \min\{p,1-p\}\\0, & D> \min\{p,1-p\}\end{matrix}\right.</script><p>函数图像如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rate_distortion2.png" alt=""></p><h4 id="连续高斯信源的率失真函数"><a href="#连续高斯信源的率失真函数" class="headerlink" title="连续高斯信源的率失真函数"></a>连续高斯信源的率失真函数</h4><p>在均方失真度量下，高斯信源的率失真函数是：</p><script type="math/tex; mode=display">R(D) = \left \{\begin{matrix}\frac 1 2 \log \frac{\sigma^2}{D},&0\leq D\leq \min\{p,1-p\}\\0, & D> \min\{p,1-p\}\end{matrix}\right.</script><p>图像如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rate_distortion4.png" alt=""></p><p>这个证明过程和上面的伯努利情况是相似的：</p><script type="math/tex; mode=display">\begin{aligned}I(X;\hat X) &= h(X) - h(X|\hat X)\\&= \frac{1}{2} \log 2\pi e \sigma^2 - h(X - \hat X|\hat X)\\& \ge \frac{1}{2} \log 2\pi e \sigma^2 - h(X - \hat X)\\& \ge \frac{1}{2} \log 2\pi e \sigma^2 -h(N(0,E(X - \hat X)^2))\\& \ge \frac{1}{2} \log 2\pi e \sigma^2 -\frac 1 2 \log 2 \pi e D\\&= \frac 1 2 \log \frac{\sigma^2}{D}\end{aligned}</script><p>为了取到这个等号，我们构造的反向信道如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rate_distortion3.png" alt=""></p><p>注：</p><ul><li>可以将$R(D)$写成$D(R) = \sigma^2 2^{-2R}$</li><li>每比特失真为$0.25\sigma^2$</li><li>不等式关系：<font color="red">若$X_1,X_2$独立，$I(X_1,X_2;Y) \ge I(X_1;Y)+I(X_2;Y)$</font>(Why?)</li></ul><p>之前我们使用1bit量化标准高斯分布的连续随机变量时，量化误差为：$\frac{\pi - 2}{\pi}\sigma^2 = 0.363\sigma^2$，也就是我们直觉中的最小和理论还有一定的差距。</p><p>恢复点：</p><script type="math/tex; mode=display">\hat X(x) = \left \{\begin{matrix}\sqrt{\frac{2}{\pi}}\sigma &\hat x = 1(x\ge 0)\\-\sqrt{\frac{2}{\pi}}\sigma & \hat x=0(x < 0)\end{matrix}\right .</script><p>平均失真为：</p><script type="math/tex; mode=display">D = \int_{-\infty}^{\infty}(x - \hat X(x))^2p(x)dx = \frac{\pi - 2}{\pi}\sigma^2</script><p>这是为什么呢？之后我们会证明，这个最优值要在考虑足够的分组长度的情况下才能实现。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——信道及其容量（二）</title>
      <link href="/2019/01/02/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E9%81%93%E5%8F%8A%E5%85%B6%E5%AE%B9%E9%87%8F%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
      <url>/2019/01/02/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E9%81%93%E5%8F%8A%E5%85%B6%E5%AE%B9%E9%87%8F%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>到目前为止，我们都只算出来了信道容量，没有讲过怎么编码能得到这些容量。接下来要做的就是说明，所有上面算出来的容量，都是可以实现的。<br><a id="more"></a></p><p>一个信道如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/capa2.png" alt=""></p><h2 id="信道编码"><a href="#信道编码" class="headerlink" title="信道编码"></a>信道编码</h2><p>这里我们先回忆一下之前的混乱打字机。之前说过，世界上任何一个数字信道，都可以直接或者间接地看作是混乱打字机模型。</p><p>对于信道$\{X,q(y|x),Y\}$的信道编码包含以下要素：</p><ul><li>输入符号集合$\{1,2,…,M\}$</li><li>编码函数$X^n$:$\{1,2,…,M\} \rightarrow X^n$，该函数为每一个输入符号产生了相应的信道编码码字$X^n(1),X^n(2),…,X^n(M)$，这些码字构成的集合称为“码本”。</li><li>解码函数$g$:$Y^n \rightarrow \{1,2,…,M\}$，该函数为一个确定性判决函数，将每一个可能的接受向量映射到一个输入符号。</li></ul><p>意思也就是，对于符号个数为$M$的符号集，我们把它映射到一个长度为n的序列上,分n次传输。</p><h3 id="信道编码的码率"><a href="#信道编码的码率" class="headerlink" title="信道编码的码率"></a>信道编码的码率</h3><p>$(M,n)$码的码率Ｒ定义为：</p><script type="math/tex; mode=display">R = \frac{\log M}{n} ,</script><p>单位为比特/传输。这是信道码的每个码字母所能携带的最大的信息量。</p><p>如何理解？对于输入集合如果取等概分布，则它的信息量为$\log M$，这时候呢，$n$次传输才能传达这么多的信息量，所以每个传输的量就是$\frac{\log M}{n} = R$，则$M = 2^{nR}$。称这样的码为$(2^{nR},n)$码。</p><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><p><strong>重复码</strong>，输入字母数$M = 2$:$\{0,1\}$，重复n次，这个码率为$1/n$。</p><p>直观来说，如果字符个数为$M$个，我们需要编码长度为$log M$就够了，这时候就可以保证码率为1。那为什么要进行这么复杂的定义？因为我们需要知道信道的传输是有噪声的。因此往往码率是要小于1，也就是n个长度本可以表示更大的字符集，但是我们选择它，增加码的冗余度，来降低错误率。比如下面的例子。</p><p><strong>二进制奇偶校验码</strong>，输入字母数$M = 2^{n-1}:{x_1,x_2,…,x_{n-1}}$，信道编码方案为$C = x_1,x_2,…,x_{n-1}x_{\text{parity}}$，其中$x_{\text{parity}}$用于辨识码字中$1$的个数为奇数还是偶数，这个码率为：$\frac{n-1}{n}$。</p><h3 id="信道编码的错误概率"><a href="#信道编码的错误概率" class="headerlink" title="信道编码的错误概率"></a>信道编码的错误概率</h3><p>输入为符号$i$时的条件错误概率为：</p><script type="math/tex; mode=display">\begin{aligned}\lambda_i &= Pr\{g(Y^n) \ne i \vert X^n = x^n(i)\}\\&= \sum_{y^n} q(y^n\vert x^n(i))I(g(y^n) \ne i)\end{aligned}</script><p>其中$I(\cdot)$为指示函数。</p><p>$(M,n)$码的最大错误概率为：</p><script type="math/tex; mode=display">\lambda^{(n)} = \max_{i \in 1,2,...M} \lambda_i</script><p>$(M,n)$码的算术平均错误概率为：</p><script type="math/tex; mode=display">P_e^{(n)} = \frac{1}{M} \sum_{i=1}^M\lambda_i</script><p>我们称一个码率$R$是可达的，若存在一个信道编码$(\lceil 2^{nR}\rceil,n )$，其最大差错概率在$n\rightarrow \infty$时趋于0。可以看出来可达要求无差错，而且是渐进的。</p><p>这时候我们得到信道容量的另外一个定义：一个信道的容量是该信道上所有可达码率的上确界，即$C = \text{sup }R$，这意味着$C$一定对应着一种信道编码方案。</p><h3 id="经验主义式的设计"><a href="#经验主义式的设计" class="headerlink" title="经验主义式的设计"></a>经验主义式的设计</h3><p>在信道传输中如何减少差错？由香农公式：</p><script type="math/tex; mode=display">C_T(\beta) = WT \log(1+\frac{P_S}{N_0W})</script><p>可以得到，提高抗干扰能力的方法如下：</p><ol><li>增加功率(提高信噪比)</li><li>加大带宽(信号变化剧烈)</li><li>延长时间(降低速率)</li></ol><p>$C = max_{p(x),功率约束}\{I(X;Y)\}$</p><p>而降低重复速率，实际上就是重复，增加冗余。</p><h3 id="重复码"><a href="#重复码" class="headerlink" title="重复码"></a>重复码</h3><p>最直观的纠错方法就是：重复，增加冗余。</p><ul><li>编码１：将每个输入元重复三次<ul><li>纠正任一位上的错误</li><li>设码字记为$(c_8,c_7,…,c_0)$</li><li>由编码方法可知，信道无误时：<script type="math/tex; mode=display">c_8 = c_7 = c_6\\c_5 = c_4 = c_3\\c_2 = c_1 = c_0</script></li><li>解码时，若$c_8 = c_6 \ne c_7$，则判定$c_7$位出错，采用简单多数法进行判定</li><li>依据是：连续出现两个错误的概率远远小于出现一个错误的概率</li></ul></li></ul><p>如下图，如果我们将上述编码放进二进制对称信道，则想要得到无差错编码。误码率的大小是重复$2n+1$次，而至少出现了$n+1$次错误。为了让误码率取0,$n \rightarrow 0$，此时码率也趋近于0，这不是一个好消息。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/int3.png" alt=""></p><p>但是，是否对于信息的无差错传输，就意味着码率为0呢？答案是否定的。</p><p>现在我们考虑BSC信道，$W= \{1,2,…,2^k\}$,如下：</p><script type="math/tex; mode=display">W=\{1,2,...,2^k\} \rightarrow \text{Encoder} \rightarrow X^n \rightarrow\text{BSC(p)} \rightarrow Y^n \rightarrow \text{Decoder} \rightarrow W</script><p>我们可以得到：</p><script type="math/tex; mode=display">\begin{aligned}nC &\ge nI(X;Y)\\&\ge I(X^n;Y^n)\\&\ge I(W,\hat W)\\&=H(W) - H(W\vert \hat W)\\&\ge k - k H(P_e)\end{aligned}</script><p>上式中最后一步是由Fano不等式得到的（<font color="red">不知道怎么得到，实际上我只能得到的是：$\ge k - (H(P_e)+kP_e)$</font>）。</p><p>则：<script type="math/tex">k \leq  \frac{nC}{1 - H(P_e)}</script></p><p>而由于BSC信道的容量可以得到：$C = 1 - H(P)$，所以我们得到一个R的上界：</p><script type="math/tex; mode=display">R = \frac{k}{n} \ge \frac{1 - H(P)}{1 - H(P_e)}</script><p>通过变形，我们可以得到：</p><script type="math/tex; mode=display">H(P_e) \ge 1 - \frac C R \rightarrow P_e \ge H^{-1}\left(1 - \frac C R\right)</script><p>这意味着，如果想要让$P_e\leq 0$，则$R \leq C$，如果$R &gt; C$，则$H(P_e)&gt;0$，所以我们一定可以得到$P_e&gt;0$，不可能进行可靠通信。</p><p>那么无差错传输的情况下，码率最大能有多少？先给你看一个preview，很直白的内容，不过它被证明确实是正确的：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/capa3.jpg" alt=""></p><p>想象信道将信源映射到一个球体里，而对每个输入符号也对应一个球。而这个球的体积就意味着噪声带来的体积，而大球中能容纳多少小球，正是这个信道编码在无错的情况下可以映射的符号数M。因为这个球的维度是n维的，我们可以得到：</p><script type="math/tex; mode=display">M = \frac{\left[\sqrt{P_S +P_N}\right]^n}{\left[\sqrt{P_N}\right]^n} = (1 + \frac{P_S}{P_N})^{\frac n 2}</script><p>由上式，可以计算得出：</p><script type="math/tex; mode=display">R = \frac 1 2 \log (1 + \frac{P_S}{P_N})</script><p>而这个值，正好与连续无记忆加性高斯噪声信道的容量一致。</p><p>当然，这个只是preview，不是严格的证明过程。下面对这个证明进行稍微严谨地推导，说明大多数噪声信道都有这样地特性。</p><p>为了证明这个东西，我们需要介绍一些别的定义。之前证明信源无失真压缩定理地时候，用到了典型序列，而这次我们在典型序列地基础上，重新介绍一个新的内容。</p><h3 id="证明香农第二定理"><a href="#证明香农第二定理" class="headerlink" title="证明香农第二定理"></a>证明香农第二定理</h3><h4 id="联合典型序列"><a href="#联合典型序列" class="headerlink" title="联合典型序列"></a>联合典型序列</h4><p>设$(X^n,Y^n)$是长为$n$的随机序列对，其概率分布满足</p><script type="math/tex; mode=display">p(x^n,y^n) = \prod_{i=1}^n p(x_i,y_i)</script><p>若$(X^n,Y^n)$满足以下条件，则称其为联合典型序列：</p><ul><li>$\lvert -\frac 1 n \log p(x^n) - H(X) \rvert &lt; \epsilon$</li><li>$\lvert -\frac 1 n \log p(y^n) - H(Y) \rvert &lt; \epsilon$</li><li>$\lvert -\frac 1 n \log p(x^n,y^n) - H(X,Y)\rvert &lt; \epsilon$<br>联合典型序列构成的集合为$A_\epsilon^{(n)}$。</li></ul><p>联合典型序列与之前典型序列定义是有很大地相似性：<a href="https://wlsdzyzl.top/2018/11/02/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Lossless-Encoding/" target="_blank" rel="noopener">信息论——Lossless-Encoding</a>。我们首先要看看联合典型序列的性质，才能用它来证明。</p><h4 id="联合渐进等同分割定理（Joint-AEP）"><a href="#联合渐进等同分割定理（Joint-AEP）" class="headerlink" title="联合渐进等同分割定理（Joint AEP）"></a>联合渐进等同分割定理（Joint AEP）</h4><p>设$(X^n,Y^n)$是长度为$n$的随机序列对，其分布满足：</p><script type="math/tex; mode=display">p(x^n,y^n) = \prod_{i=1}^n p(x_i,y_i)</script><p>则以下性质成立：</p><ul><li>当$n \rightarrow \infty$时，$Pr((X^n,Y^n) \in A_\epsilon ^{(n)}) \rightarrow 1$</li><li>$(1 - \epsilon)2^{n(H(X,Y) - \epsilon)} \leq \vert A_\epsilon ^{(n)} \vert\leq 2^{n(H(X,Y)+\epsilon)}$</li><li>设$(\tilde{X^n},\tilde{Y^n})\sim p(x^n)p(y^n) $,即$\tilde{X^n},\tilde{Y^n}$统计独立，且具有与$p(x^n,y^n)$一致的边缘分布，则：<script type="math/tex; mode=display">Pr\left((\tilde{X^n},\tilde{Y^n}) \in A_\epsilon ^{(n)}\right) \leq 2^{-n(I(X;Y) - 3\epsilon)}</script>若$n$足够大，则：<script type="math/tex; mode=display">Pr\left((\tilde{X^n},\tilde{Y^n}) \in A_\epsilon ^{(n)}\right) \ge (1 - \epsilon)2^{-n(I(X;Y) + 3\epsilon)}</script></li></ul><p>前两点都比较好理解，第三点中，$(\tilde{X^n},\tilde{Y^n})$是由$(X^n,Y^n)$的边缘分布依照$X^n,Y^n$独立形成的另一个联合分布，而这个分布属于典型序列的概率约等于$2^{-nI(X;Y)}$。</p><p>在这里我们证明以下第三条的前半部分：</p><script type="math/tex; mode=display">\tilde{X^n},\tilde{Y^n}\text{ are independent. }\tilde{X^n}\sim P_X(x^n),\tilde{Y^n}\sim P_Y(y^n)\\\begin{aligned}Pr\{(\tilde{X^n},\tilde{Y^n}) \in A_\epsilon^{(n)} \} &= \sum_{(\tilde{x^n},\tilde{y^n}) \in A_\epsilon^{(n)}} P(x^n)P(y^n)\\&\leq 2^{b(H(X,Y) + \epsilon)}\cdot 2^{-n(H(X) - \epsilon)} \cdot 2^{-n(H(Y) - \epsilon)}\\&= 2^{-n(I(X;Y) - 3\epsilon)}\end{aligned}</script><p>下图可以帮助我们更好地理解这些性质：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/capa4.png" alt=""></p><ul><li>联合分布中，大约有$2^{nH(X)}$个典型X序列和$2^{nH(Y)}$个典型Y序列</li><li>其组合共有$2^{nH(X) + nH(Y)}$个，但是其中联合典型的只有$2^{nH(X,Y)}$个</li><li>随机选择而出现联合典型序列的概率为$2^{-nI(X;Y)}$</li></ul><p>现在来看一下联合典型序列的另一个解释：</p><ul><li>对于典型输入序列$x^n$，存在大约$2^{nH(Y|X)}$个可能的输出，且它们等概</li><li>所有可能的典型输出序列大约有$2^{nH(Y)}$个，这些序列被分成若干个不相交的子集</li><li>子集个数为$2^{n(H(Y) - H(Y|X))} = 2^{nI(X;Y)}$，表示信道可以无错误传递的最大字母序列个数</li></ul><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/capa1.png" alt=""></p><p>对于定理的证明包含两部分，一是可达性，也就是这个容量是可达的，第二个就是证明不可能达到比这个容量更好的速率。</p><h4 id="可达性的证明"><a href="#可达性的证明" class="headerlink" title="可达性的证明"></a>可达性的证明</h4><p>可达性的证明也就是我们可以找到一个编码函数和解码函数，使得信道带到容量C，而且是无差错地传输。</p><script type="math/tex; mode=display">W \in [1:2^{nR}] \rightarrow X^n \sim P_X(x) \rightarrow q(y|X)\rightarrow Y^n\rightarrow \hat W</script><p>很反直觉的是，香农给我们编码方法是随机编码。这个随机编码指的是生成码字的过程为随机的：</p><script type="math/tex; mode=display">\text{Random Code:}\\\ell =\begin{pmatrix}x^n(1)\\x^n(2)\\\vdots\\x^n(2^{nR})\end{pmatrix}</script><p>其中$x^n(k)$是独立同分布的生成的，分布为$P_X(x^n(k)) = \prod_{i=1}^n P_X(x_i(k))$</p><p>于是我们得到了码本，信源发送$x^n(k)$，而解码器收到$y^n$，一个长度为n的序列。</p><p>解码过程：如果解码器端找到唯一的$(x^n(\hat k), y^n) \in A_{\epsilon}^{(n)}$，则解码得到$\hat k$。也就是$y^n$和一个唯一的$\hat k$对应的编码序列$x^n(\hat k)$属于联合典型序列，则解码为$\hat k$，否则解码出错。</p><p>现在我们分析一下出错概率。假设1为被传输的符号，而$y^n$为对应的输出。那么$x^n(1)$与$y^n$为联合典型序列的概率非常高。而另外一个i对应的$x^n(i)$与$y^n$为联合典型序列的概率就没有那么高了。实际上这个概率和联合典型序列性质的第三条是一致的。$x^n(i),y^n$有很大的概率是边缘典型序列，而随意两个边缘典型序列组合为联合典型序列的概率，正是</p><script type="math/tex; mode=display">Pr\left((\tilde{X^n},\tilde{Y^n}) \in A_\epsilon ^{(n)}\right) \approx 2^{-nI(X;Y)}.</script><p>出错的类型有两种。</p><ol><li>传的是1,而没有联合典型，</li><li>传的是1,有多个和它是联合典型。</li></ol><script type="math/tex; mode=display">\begin{aligned}P(E) &= P(E_1\cup E_2)\\&\leq P(E_1)+P(E_2)\\&\leq \epsilon + \sum_{i=2}^{2nR}2^{-n(I(X;Y) - 3\epsilon)}\\&\leq \epsilon + 2^{3n\epsilon}2^{-n(I(X;Y) - R)}\end{aligned}</script><p>我们希望$P(E) \rightarrow 0$，而第一项是可以任意小的，我们真正在意的是想要$I(X;Y)-R &gt;0$。如果我们把生出随机码本的$P_X(x)$固定到$P^*_X(x)$，则$I(X;Y) = C$，于是只要$R&lt;C$即可。</p><p>这个证明并不严谨，但是给我们提供了一个很重要的思维脉络。我们证明了$R &lt; C$的情况下，可以实现无差错传输。</p><p>下面要说明的是定理的逆的证明。</p><h4 id="converse证明"><a href="#converse证明" class="headerlink" title="converse证明"></a>converse证明</h4><script type="math/tex; mode=display">\begin{aligned}nR &= H(W)\\&= H(W|\hat W) + I(W;\hat W)\\&= I(W;\hat W)\\&\leq I(X^n(W);Y^n)\\&= H(Y^n) - H(Y^n|X^n)\\&\leq \sum_{i} H(Y_i) - \sum_{i}H(Y_i|X_i)\\&= \sum_{i} I(X_i;Y_i)\\&\leq nC\end{aligned}</script><p>由此我们证明了，要想实现无差错的传输，那么$R\leq C$是一定成立的。由此香农第二定理的证明就结束了。和无差错编码一样，随机编码在现实中由于码本巨大也是难以实现的。不过在信息论提出的60年中，人类一次次提出新的编码，像香农界不断逼近。看着这些进步，感觉自己的信息论虽然没什么用到过，但是也没有白学。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——DQN</title>
      <link href="/2019/01/02/Learning-From-Data%E2%80%94%E2%80%94DQN/"/>
      <url>/2019/01/02/Learning-From-Data%E2%80%94%E2%80%94DQN/</url>
      
        <content type="html"><![CDATA[<p>之前的博客讲了<a href="https://myevolution.github.io/2018/12/28/Learning-From-Data%E2%80%94%E2%80%94Reinforcement-Learning/" target="_blank" rel="noopener">reinforcement learning</a>，但是上节课讲得更多的像是理论层面的东西，实际操作起来还是一脸懵逼。这次介绍一个非常有名的DQN（Deep Q-network），是神经网络和Q-learning结合起来的一个算法。并且在最后，我们会用它做一个有趣的事情。<br><a id="more"></a></p><h2 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h2><p>之前我们其实提到了一下Q-learning，最重要的就是动作价值函数Q。它接受两个参数：state，以及action。在Q-learning中，我们会维护一个Q-table。然后根据Q-table来决定下一步的动作怎么选择。</p><p>之前的文章中，比较复杂的地方是在一个状态选择一个动作之后，下一个状态是什么还是不确定的，现在我们可以简化这个值，也就是每个状态做一个动作之后得到的下一个状态一定是确定的。这样，问题就会得到简化。</p><script type="math/tex; mode=display">Q(s,a) = R(s,a)+\gamma \cdot \max_{\tilde{a}}\{Q(\tilde{s},\tilde{a})\}</script><p>当然，即使是不确定的，学习的道理也是一样的。只不过更复杂了，我们需要去计算期望值。</p><p>我们可以看一个简单的例子来理解Q-learning。这个例子来自于<a href="http://mnemstudio.org/path-finding-q-learning-tutorial.htm" target="_blank" rel="noopener">q-learning</a>。</p><p>假如现在有这样的一个房间：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dqn2.gif" alt=""></p><p>模型化之后长这个样子：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dpn4.gif" alt=""></p><p>这时候，我们可以得到一个R-table，他表示的是每个状态取每个动作之后的奖励是多少，这是我们不可控制的部分。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dqn5.gif" alt=""></p><p>同时我们需要维护的就是Q-table。我们不知道Q-table到底该长什么样子。因此最开始全部初始化为0。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dqn6.gif" alt=""></p><p>现在我们来尝试更新这个Q-table，Q-learning的学习过程如下：</p><p>随机选择一个状态s，假如我们在状态1，查找R表，发现可以走的是3和5。我们选择$Q(1,x)$比较大的，如果一样则随机选。如果采取状态5，那么根据算法的过程：</p><script type="math/tex; mode=display">\begin{aligned}Q(1,5) &=R(1,5)+\max\{Q(5,1),Q(5,4),Q(5,5)\}\\&=100+ \max\{0,0,0\}\\&= 100\end{aligned}</script><p>好了，更新Q-table中，$Q(1,5)$为100。</p><p>好了这样一个episode就结束了，我们继续这个过程，最后可以得到这个Q-table长成了这个样子：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dqn7.gif" alt=""></p><p>如果对他们进行normalize，得到：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dqn8.gif" alt=""></p><p>通过查找最大的价值，我们来决定下一步怎么走。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dqn9.gif" alt=""></p><p>当然，上面的例子太简单了，仔细思考的话，我们会发现一些问题。这个Q表是慢慢更新的。有时候，一个Q表的我们按照最大值，就会永远选择那个最大的，可能实际上它并不是最大的。这可能造成Q-table永远得不到更新。实际上，Q-learning的步骤比上面的更复杂一些，如下：</p><blockquote><p>Initialize Q-table abitrarily</p><p>Repeat (for each episode):</p><p>Initialize $s$</p><p>Repeat (for each step of episode):</p><ul><li>Choose $a$ from $s$ using policy derived from Q(e.g. $\epsilon$-greedy)</li><li>Take action $a$, observe $r$, $s’$</li><li>$Q(s,a):= Q(s,a)+\alpha[r+\gamma \max Q(s’,a’) - Q(s,a)]$</li><li>$s := s’$</li></ul><p>until $s$ is terminal</p></blockquote><p>这里，$\alpha$为学习率，$\gamma$为折扣因子。这些一般都是经验值。Q表可以看作是agent的记忆，如果$\alpha$更小，我们更依赖于当前表的值，否则我们更倾向于更新的值。而$\gamma$则是我们是否有长远眼光的一个度量。</p><p>其次$\epsilon$-greedy也是为了解决上面的问题提出来的，以$\epsilon$的概率来进行贪婪搜索（选最大的），而$1-\epsilon$的概率来进行开发。</p><p>在使用贪婪的时候，Q-learning实际上就是在选择最大让奖励最大的action，而且它更新的是Q值，因此实际上Q-learning实际上是值迭代的一种。</p><p>Q-learning还是挺强大的，但是之前我们提到了维度诅咒，如果这个维度过大，维护这个表的负担将是不可想象的。因此就有了很多别的方法来计算这个Q值，之前提到了有线性的，特征映射的线性，以及使用神经网络。当然神经网络的效果是好于其他两个的，这就是Deep Q-Network。</p><h2 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a>Sarsa</h2><p>在介绍Deep Q-Network之前，我们再提一个简单的强化学习算法，叫Sarsa，它和Q-learning算法非常相似。</p><blockquote><p>Initialize Q-table abitrarily</p><p>Repeat (for each episode):</p><p>Initialize $s$</p><p>Choose $a$ from $s$ using policy derived from Q(e.g. $\epsilon$-greedy)</p><p>Repeat (for each step of episode):</p><ul><li>Take action $a$, observe $r$, $s’$</li><li>Choose $a’$ from $s’$ using policy derived from Q(e.g. $\epsilon$-greedy)</li><li>$Q(s,a):= Q(s,a)+\alpha[r+\gamma Q(s’,a’) - Q(s,a)]$</li><li>$s := s’,a := a’$</li></ul><p>until $s$ is terminal</p></blockquote><p>它和Q-learning的区别在于，Q-learning选择了最大的$Q(s’,a’)$，更新Q表以后，下一步并不一定会做$a’$的动作，而sarsa多了一个选择$a’$的步骤,它选的不一定是最大值，并且在下一步一定执行这个动作。</p><p>可以看到的sarsa是在线学习，它的探索一定要自己去做，而Q-learning是离线学习，它可以使用别人的经验。而实际上，sarsa也有一些别的扩展算法，如sarsa($\lambda$)等，在这里就不细谈了。</p><h2 id="Deep-Q-Network"><a href="#Deep-Q-Network" class="headerlink" title="Deep Q-Network"></a>Deep Q-Network</h2><p>接下来就到了Deep Q-Network的内容了。之前提到了，Q-learning的问题在于，如果高维度连续的情况下，维护一个Q-table是不现实的。一个比较好的做法是把Q表的更新问题变成一个函数拟合的问题。比如输入状态$s$，动作$a$，再加上一个额外的参数$\theta$，用来得到$Q’(s,a)$。</p><script type="math/tex; mode=display">Q(s,a;\theta) \approx Q'(s,a)</script><p>而神经网络又可以自动提取复杂特征，所以用它来做这个事情是最合适不过了。</p><p>但是首先遇到的一个问题，神经网络需要标签，也就是$y$值，这个$y$值怎么得到呢？</p><p>上一篇博客提到了，使用物理法则，或者是模拟器等等,来创造这样的样本,产生经验元组，以供神经网络来训练。我们假设得到的目标样本为$Q_{\text{target}}$，则神经网络的Loss-function为：</p><script type="math/tex; mode=display">L(\theta) = \mathbb{E}[Q_{\text{target}} - Q(s,a,\theta)^2]</script><p>根据Q-learning得到：</p><script type="math/tex; mode=display">Q_{\text{target}} = r + \gamma\max_{a'}Q(s',a',\theta)</script><p>此外，在神经网络与Q-learning的结合中，还诞生了一些新的概念，如经验池（experience replay）,以及目标网络。</p><h3 id="experience-replay"><a href="#experience-replay" class="headerlink" title="experience replay"></a>experience replay</h3><blockquote><p>经验池的功能主要是解决相关性及非静态分布问题。具体做法是把每个时间步agent与环境交互得到的转移样本$(s_t,a_t,r_t,s_{t+1})$储存到回放记忆单元，要训练时就随机拿出一些（minibatch）来训练。</p></blockquote><p>在我看来经验池就是存储之前得到的样本。毕竟现在reward也不是之前可以用一张表就能描述的了。</p><h3 id="TargetNet"><a href="#TargetNet" class="headerlink" title="TargetNet"></a>TargetNet</h3><p>后来提出来的改进中，有专门一个网络，用来生成目标Q值。也许你会想说，你怎么知道这个得到的目标就一定是正确的呢？实际上，即使在原来的Q-learning中，Q表也是慢慢更新的。每一次迭代并不一定得到就是正确的值，你用来更新使用的是之前的非正确值，但是多次episode之后，这个值就趋于了稳定，收敛到正确的值，这里也是一样的。是一个互相督促的过程，先用目标网络产生目标值，让神经网络去不断逼近这个目标值，然后用再用神经网络替换目标网络，生成样本，不断这么重复。为什么这样可以？我也不是很清楚这背后的数学关系。</p><p>下面是Deep Q-Network的算法：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dqn1.png" alt=""></p><p>你可以查看这篇paper来了解关于DQN的更多信息：<br><a href="https://www.nature.com/articles/nature14236" target="_blank" rel="noopener">Human-level control through deep reinforcement learning</a></p><p>最后，我们来实现一下上一篇强化学习博客中提到的cartpole。</p><p>cartpole算是python库gym中的一个小项目，除了这个，它还有很多别的小游戏可以去尝试。</p><p>我们要做的是让小车尽量保持平衡。而状态是个四维向量$(x,\theta,\dot x \dot \theta)$,动作只有两种，向左或者向右。</p><p>整个想法和Q-learning是非常相似的。我们怎么选择下一个动作？这个依然要用到$\epsilon$-greedy，以$\epsilon$的概率输入状态，以得到各个动作的Q值（action-value funtion），然后选取最大的Q值对应的动作作为下一个输入；另外就是随机探索了。</p><p>如果小杆子到了，说明游戏结束，这时候得到的直接就是reward，而不会有下一个状态，如果没有倒，则状态转到下一个。当然，这些经历（state,action,next_state,reward,done）都要放到经验池里，然后我们根据经验池的数据来训练神经网络。</p><p>什么时候训练网络是一个经验值。在这里我们假设time%10=0的时候来训练，也就是进行了10的整数倍次数动作之后。什么时候更换目标网络也是一个经验值。</p><p>然后我们要面临的是学习的问题。我们通过上面的式子得到y，$\theta$表示的是MainNet，而$\hat \theta$表示是TargetNet，通过他们来得到y值，并用MSE loss以及Adam优化器来完成对参数的更新。需要注意的是机器学习中好的参数非常重要，如果出现错误了首先想到算法是不是写错了，接下来就要考虑调参的问题。</p><p>在这个实验中，我们对$\epsilon$的值也会进行控制，想法是越往后就让它有越大的可能进行贪心选择。</p><p>其实这个算法的实现并不算难，但是需要掌握一定的pytorch相关的知识，在这方面我还是比较薄弱的。实际上这个实验是数据学习课程的一个作业。而学长已经编好了大部分的框架，只需要我们实现网络的建立，网络学习过程以及动作的选择。因此大大简化了任务。下面是我的实现。采用4×80×80×2的网络，激活函数为ReLU。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Nov 29 13:05:14 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: xtw+wlsdzyzl</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line">torch.set_default_dtype(torch.float64)</span><br><span class="line">EPISODES = <span class="number">1000</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">some api you may use:</span></span><br><span class="line"><span class="string">    torch.from_numpy()</span></span><br><span class="line"><span class="string">    torch.view()</span></span><br><span class="line"><span class="string">    torch.max()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">net</span><span class="params">(nn.Module)</span>:</span>         <span class="comment"># build your net </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, state_size, action_size)</span>:</span></span><br><span class="line">        super(net, self).__init__()</span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        your code</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.fc1 = nn.Linear(state_size,<span class="number">60</span>)</span><br><span class="line">        self.fc1.weight.data.normal_(<span class="number">0.0</span>,<span class="number">0.1</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">60</span>,<span class="number">60</span>)</span><br><span class="line">        self.fc2.weight.data.normal_(<span class="number">0.0</span>,<span class="number">0.1</span>)</span><br><span class="line">        self.out = nn.Linear(<span class="number">60</span>,action_size)</span><br><span class="line">        self.out.weight.data.normal_(<span class="number">0.0</span>,<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        your code</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = nn.functional.relu(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = nn.functional.relu(x)</span><br><span class="line">        <span class="keyword">return</span> self.out(x)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DQNAgent</span>:</span>         <span class="comment"># bulid DQNagent</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, state_size, action_size, q_model, t_model)</span>:</span></span><br><span class="line">        self.state_size = state_size            </span><br><span class="line">        self.action_size = action_size</span><br><span class="line">        self.memory = deque(maxlen=<span class="number">2000</span>)</span><br><span class="line">        self.gamma = <span class="number">0.95</span>    <span class="comment"># discount rate</span></span><br><span class="line">        self.epsilon = <span class="number">1.0</span>  <span class="comment"># exploration rate</span></span><br><span class="line">        self.epsilon_min = <span class="number">0.001</span></span><br><span class="line">        self.epsilon_decay = <span class="number">0.995</span></span><br><span class="line">        self.q_model = q_model        <span class="comment"># model</span></span><br><span class="line">        self.t_model = t_model</span><br><span class="line">        self.criterion = nn.MSELoss() <span class="comment"># define loss</span></span><br><span class="line">        self.optimiser = optim.Adam(self.q_model.parameters(),lr = <span class="number">0.001</span>) <span class="comment">#define optimiser</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remember</span><span class="params">(self, state, action, reward, next_state, done)</span>:</span>     <span class="comment"># save memory</span></span><br><span class="line">        self.memory.append((state, action, reward, next_state, done))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">act</span><span class="params">(self, state)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        your code</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; self.epsilon:</span><br><span class="line">            <span class="keyword">if</span> random.random()&lt;<span class="number">0.5</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># argmax Q</span></span><br><span class="line">            action_value =  self.q_model.forward(torch.from_numpy(state))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> int(torch.argmax(action_value))</span><br><span class="line">        <span class="comment"># returns action</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">replay</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        minibatch = random.sample(self.memory, batch_size)</span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        your codes,</span></span><br><span class="line"><span class="string">        use data from memory to train you q_model</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">for</span> state,action,reward,next_state,done <span class="keyword">in</span> minibatch:</span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                yj = reward</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                yj = reward + self.gamma*torch.max(self.t_model.forward(torch.from_numpy(next_state)))</span><br><span class="line">            loss = self.criterion(yj,self.q_model.forward(torch.from_numpy(state))[action])</span><br><span class="line">            self.optimiser.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            self.optimiser.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.epsilon &gt; self.epsilon_min:   <span class="comment"># epsilon decay after each training</span></span><br><span class="line">            self.epsilon *= self.epsilon_decay</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_t</span><span class="params">(self)</span>:</span>    <span class="comment"># update t_model weights</span></span><br><span class="line">        torch.save(self.q_model.state_dict(), <span class="string">'params.pkl'</span>)</span><br><span class="line">        self.t_model.load_state_dict(torch.load(<span class="string">'params.pkl'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    env = gym.make(<span class="string">'CartPole-v1'</span>)</span><br><span class="line">    state_size = env.observation_space.shape[<span class="number">0</span>]</span><br><span class="line">    action_size = env.action_space.n</span><br><span class="line">    q_model = net(state_size, action_size)   <span class="comment"># generate nets and DQNagent model</span></span><br><span class="line">    t_model = net(state_size, action_size)</span><br><span class="line">    agent = DQNAgent(state_size, action_size, q_model, t_model)</span><br><span class="line">    done = <span class="keyword">False</span></span><br><span class="line">    replace_target_iter =  <span class="number">25</span>    </span><br><span class="line">    batch_size = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(EPISODES):</span><br><span class="line">        state = env.reset()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> e % replace_target_iter == <span class="number">0</span>:  <span class="comment"># update t_model weights</span></span><br><span class="line">            agent.update_t()</span><br><span class="line">        <span class="keyword">for</span> time <span class="keyword">in</span> range(<span class="number">481</span>):</span><br><span class="line">            env.render()      <span class="comment"># show the amination</span></span><br><span class="line">            action = agent.act(state)     <span class="comment"># chose action</span></span><br><span class="line">            next_state, reward, done, _ = env.step(action) <span class="comment"># Interact with Environment</span></span><br><span class="line">            reward = reward <span class="keyword">if</span> <span class="keyword">not</span> done <span class="keyword">else</span> <span class="number">-10</span>  <span class="comment"># get -10 reward if fail</span></span><br><span class="line">            </span><br><span class="line">            agent.remember(state, action, reward, next_state, done) <span class="comment"># save memory</span></span><br><span class="line">            state = next_state</span><br><span class="line">            <span class="keyword">if</span> done:                </span><br><span class="line">                print(<span class="string">"episode: &#123;&#125;/&#123;&#125;, score: &#123;&#125;, e: &#123;:.2&#125;"</span></span><br><span class="line">                      .format(e, EPISODES, time, agent.epsilon))</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> len(agent.memory) &gt; batch_size <span class="keyword">and</span> time % <span class="number">10</span> == <span class="number">0</span>: <span class="comment"># train q_model</span></span><br><span class="line">                agent.replay(batch_size)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> reinforcement learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Introduction of Deep Learning</title>
      <link href="/2019/01/01/Learning-From-Data%E2%80%94%E2%80%94Introduction-of-Deep-Learning/"/>
      <url>/2019/01/01/Learning-From-Data%E2%80%94%E2%80%94Introduction-of-Deep-Learning/</url>
      
        <content type="html"><![CDATA[<p>上节课是数据学习的最后一个课程，做了一个简单的深度学习的介绍。<br><a id="more"></a></p><p>不用我说大家也都知道，深度学习是当今最流行的机器学习算法了，甚至它成为了一门独立的学科，因为它真的非常强大。深度学习是从神经网络开始的。</p><p>神经网络：可微模型+可微损失</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl1.png" alt=""></p><p>简单的来说，在神经网络基础上go deep，就是深度学习了。</p><h2 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h2><h3 id="overfitting"><a href="#overfitting" class="headerlink" title="overfitting"></a>overfitting</h3><p>神经网络虽然能很好的拟合各个函数，但是它同样面临着挑战.那就是过拟合的问题。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl2.png" alt=""></p><p>之前的机器学习系列的博客也多次提到过拟合的问题。一个模型不是越强大就越好的，因为我们无法避免噪声的存在。如果为了迎合样本，最后产生了很奇怪的东西，那可能并不是我们想要的结果。如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl3.png" alt=""></p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl4.png" alt=""></p><h3 id="Vanishing-gradient-problem"><a href="#Vanishing-gradient-problem" class="headerlink" title="Vanishing gradient problem"></a>Vanishing gradient problem</h3><p>我们知道，神经网络需要激活函数。最容易想到的是sigmod函数，但是当x很大时候，它面临着很严重的梯度消失问题，使得结果可能无法收敛。使用什么样的激活函数也是深度学习需要面临的挑战。</p><p>Activation functions：</p><ul><li>Sigmoid</li><li>tanh</li><li>Relu</li><li>…</li></ul><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>另外的问题，就是选取什么样的优化。梯度下降是不显示的，因为神经网络往往有非常大的计算量。</p><p>Optimizers:</p><ul><li>SGD (Stochastic gradient descent)</li><li>Adam</li><li>Adamax</li><li>RMSprop</li><li>Adadelta</li><li>Nadam</li><li>…</li></ul><h3 id="Computation"><a href="#Computation" class="headerlink" title="Computation"></a>Computation</h3><p>计算量过大也是深度学习面临的问题。一般来说要跑神经网络，往往需要GPU，TPU等等。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl5.png" alt=""></p><h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><p>还有就是获取数据的问题。深度学习的训练往往需要大量的数据。数据获取，数据标注也是很大的问题。</p><h2 id="Representation"><a href="#Representation" class="headerlink" title="Representation"></a>Representation</h2><p>尽管神经网络有很大的挑战，但是它依然是一个非常强大的工具。以神经网络为基础，诞生了很多非常有名的网络模型，它们共同组成了深度学习。下面是深度学习的几个有名的代表：</p><h3 id="卷积神经网络（Convolutional-Neural-Network）"><a href="#卷积神经网络（Convolutional-Neural-Network）" class="headerlink" title="卷积神经网络（Convolutional Neural Network）"></a>卷积神经网络（Convolutional Neural Network）</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl6.png" alt=""></p><h3 id="RNN-Recurrent-Neural-Network"><a href="#RNN-Recurrent-Neural-Network" class="headerlink" title="RNN(Recurrent Neural Network)"></a>RNN(Recurrent Neural Network)</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl7.png" alt=""></p><h3 id="LSTM-Long-Short-Term-Memory-Module"><a href="#LSTM-Long-Short-Term-Memory-Module" class="headerlink" title="LSTM(Long-Short Term Memory Module)"></a>LSTM(Long-Short Term Memory Module)</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl8.png" alt=""></p><h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl9.png" alt=""></p><h3 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl10.png" alt=""></p><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>也许我们还没有注意到，但是深度学习现在已经应用到生活的各个地方了。</p><h3 id="NPL-word2vec"><a href="#NPL-word2vec" class="headerlink" title="NPL:word2vec"></a>NPL:word2vec</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl11.png" alt=""></p><h3 id="Image-Caption-Generator"><a href="#Image-Caption-Generator" class="headerlink" title="Image Caption Generator"></a>Image Caption Generator</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl12.png" alt=""></p><h3 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl13.png" alt=""></p><h3 id="GANs-Generative-Adversarial-Networks"><a href="#GANs-Generative-Adversarial-Networks" class="headerlink" title="GANs (Generative Adversarial Networks)"></a>GANs (Generative Adversarial Networks)</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl14.png" alt=""></p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl15.png" alt=""></p><h2 id="Opening-the-blackbox"><a href="#Opening-the-blackbox" class="headerlink" title="Opening the blackbox"></a>Opening the blackbox</h2><p>虽然神经网络功能非常强大，但是一直到现在，我们依然无法在数学上解释它为何这么强大。因此，神经网络对于我们来说一直像是一个黑盒子。我们希望可以打开一点这个黑盒子，窥视一下它背后的机理。之前有篇博客曾经提到这方面过，也就是<a href="https://wlsdzyzl.top/2018/12/05/Learning-From-Data%E2%80%94%E2%80%94derive-something-from-Softmax/" target="_blank" rel="noopener">derive something from Softmax</a>。这是黄绍伦老师的相关研究成果。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl16.png" alt=""></p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/dl17.png" alt=""></p><p>从那篇文章以及这些图片，我们可以对神经网络为何这么强大有一些直观的了解，并且部分明白了其背后的道理。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Reinforcement Learning</title>
      <link href="/2018/12/28/Learning-From-Data%E2%80%94%E2%80%94Reinforcement-Learning/"/>
      <url>/2018/12/28/Learning-From-Data%E2%80%94%E2%80%94Reinforcement-Learning/</url>
      
        <content type="html"><![CDATA[<p>这周数据学习的内容是关于强化学习（Reinforcement Learning）的。不过课上睡着了，而且由于信息论时间太赶一直没有空看这节课的内容。<br><a id="more"></a><br>强化学习现在是非常流行的一个机器学习方法，当然它和其他的算法不一样，你用了这个就是这个，而强化学习更像是一种学习方式，也就是一直在线学习。AlphaGo赢了围棋冠军，OpenAI赢了Dota冠军，以及自动驾驶汽车飞机等都有它的身影。</p><h2 id="什么是强化学习？"><a href="#什么是强化学习？" class="headerlink" title="什么是强化学习？"></a>什么是强化学习？</h2><p>强化学习有点像是玩游戏的过程，实际上强化学习应用最多的地方也正是游戏。他属于无监督学习，但是又是根据奖励来决定下一个动作，怎么知道奖励？就是走到头。有点类似于有“长远的眼光”。这个长远的眼光可以说是经验，是通过一次次训练得到的，类似于你的人生可以来无数回，你会怎么做这件事。可能经过多次碰壁以后，我终于活成了一个成功人士。每次人生）训练周期）称为episode。</p><p>首先要知道对于序列决策问题，我们很难找到明确的监督策略来决定结果的好坏。在强化学习中，学习的过程是通过代理完成的。强化学习定义了一个奖励函数（reward function）和environment，而代理（agent）要做的就是最大化累计的奖励。如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rf1.png" alt=""></p><h3 id="Markov-Decision-Process"><a href="#Markov-Decision-Process" class="headerlink" title="Markov Decision Process"></a>Markov Decision Process</h3><p>我们首先学习一下马尔可夫决策过程。一个马尔可夫决策过程可以看作是一个五元组：$(S,A,\{P_{sn}\},\gamma,R)$，其中：</p><ul><li>$S$是一个状态集合（环境）</li><li>$A$是一个动作集合</li><li>$P_{sa}$是状态转移概率</li><li>$R$:$S\times A \rightarrow \mathbb{R}$，是一个奖励函数</li><li>$\gamma \in [0,1)$，为折扣因子（discount factor）</li></ul><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rf2.png" alt=""></p><p>这幅图中,$S=\{S_0,S_1,S_2\};A=\{a_0,a_1\};R(s_1,a_0)=5,R(s_2,a_1) = -1$，而它的$P_{sa}$如下表：</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">$S_0$</th><th style="text-align:center">$S_1$</th><th style="text-align:center">$S_2$</th></tr></thead><tbody><tr><td style="text-align:center">$S_0,a_0$</td><td style="text-align:center">0.5</td><td style="text-align:center">0</td><td style="text-align:center">0.5</td></tr><tr><td style="text-align:center">$S_0,a_1$</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">$S_1,a_0$</td><td style="text-align:center">0.7</td><td style="text-align:center">0.1</td><td style="text-align:center">0.2</td></tr><tr><td style="text-align:center">$S_1,a_1$</td><td style="text-align:center">0</td><td style="text-align:center">0.95</td><td style="text-align:center">0.05</td></tr><tr><td style="text-align:center">$S_2,a_0$</td><td style="text-align:center">0.4</td><td style="text-align:center">0.6</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">$S_2,a_1$</td><td style="text-align:center">0.3</td><td style="text-align:center">0.3</td><td style="text-align:center">0.4</td></tr></tbody></table></div><p>现在考虑一个状态序列$S_0,S_1,…$以及对应的采取的动作$a_0,a_1,…,$</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rf3.png" alt=""></p><p>则这个序列的总共的奖励为：</p><script type="math/tex; mode=display">R(s_0,a_0) + \gamma R(s_1,a_1)+\gamma^2 R(s_2,a_2)+...</script><p>我们把问题想得简单一点，假设这个reward只和状态有关，则总的奖励为：</p><script type="math/tex; mode=display">R(s_0)+\gamma R(s_1) + \gamma^2 R(s_2)+...</script><p>未来第$t$步的奖励会被打$\gamma ^t$的折扣。这说明离当前这个状态越远权重越小，这意味着我们把下一步的奖励看得最重要，接下来是下下一步的奖励，依次减少。</p><h3 id="Policy-amp-Value-functions"><a href="#Policy-amp-Value-functions" class="headerlink" title="Policy &amp; Value functions"></a>Policy &amp; Value functions</h3><p>强化学习的目标就是：选择action，使得总的奖励期望最大：</p><script type="math/tex; mode=display">\mathbb{E}[R(s_0)+\gamma R(s_1) + \gamma^2 R(s_2)+...]</script><ul><li>一个策略（policy）是任意一个函数$\pi$:$S \rightarrow A$.</li><li>而该策略$\pi$对应的值函数（value function）为在从状态$s$开始，根据$\pi$来执行动作的条件下，总的奖励的期望值，也就是：<script type="math/tex; mode=display">V^\pi(s) = \mathbb{E}[R(s_0)+\gamma R(s_1) +\gamma^2 R(s_2) +...\vert s_0 = s,\pi]</script></li></ul><p>给定$\pi$，值函数（value function）满足Bellman等式：</p><script type="math/tex; mode=display">V^\pi(s)=R(s)+\gamma\sum_{s' \in S}P_{s\pi(s)}(s')V^\pi(s')</script><p>所以，这实际上是一个递归的过程，本次状态的值函数，是由下一个可能的状态值决定的。而下一个可能的状态值又和你的策略相关。为了方便理解，我们再定义一个函数，为动作-值函数Q。它接受两个输入：当前的状态$s$和当前状态采取的动作$a$：</p><script type="math/tex; mode=display">Q(s,a) = R(s)+\gamma\sum_{s' \in S}P_{sa}(s')V^\pi(s')</script><p>我们可以维护这一张关于Q值的表，这就是传说中的Q-learning。</p><h3 id="Optimal-value-and-policy"><a href="#Optimal-value-and-policy" class="headerlink" title="Optimal value and policy"></a>Optimal value and policy</h3><p>我们定义最优的值函数为：</p><script type="math/tex; mode=display">V^* (s) = \max_{\pi}V^\pi(s) = R(s)+\max_{a \in A}\gamma\sum_{s' \in S}P_{sa}(s')V^*(s')</script><p>最优的策略$\pi^*:S\rightarrow A$为实现了最优值函数的策略：</p><script type="math/tex; mode=display">\pi^*(s) = \arg\max_{a \in A}\sum_{s'\in S}P_{sa}(s')V^ *(s')</script><p>对于每一个状态$s$以及每一个策略$\pi$,</p><script type="math/tex; mode=display">V^*(s) = V^{\pi *} \ge V^\pi(s)</script><p>可以看到的是Q-learning是在维护一张表，而我们这里提到的和Q-learning非常相似，不过policy选的是最佳的动作，可以说Q-learning是实现这个目标学习的一种方法。</p><h3 id="求解有限状态MDP下的最佳的value或者policy"><a href="#求解有限状态MDP下的最佳的value或者policy" class="headerlink" title="求解有限状态MDP下的最佳的value或者policy"></a>求解有限状态MDP下的最佳的value或者policy</h3><p>实际上，我们可以看到只要解决了value和policy中一个，我们就能得到最佳的结果，因为实际上最佳策略也就是实现了最佳值的策略而已。因此这个解决过程就有两个方法。前提是，状态集合是有限的。</p><h4 id="value-iteration"><a href="#value-iteration" class="headerlink" title="value iteration"></a>value iteration</h4><p>假设MDP有有限的状态集合和动作空间，则值迭代如下：</p><blockquote><p>1.For each state $s$ , initialize $V (s) := 0$</p><p>2.Repeat until convergence {</p><p>Update </p><script type="math/tex; mode=display">V (s) := R(s) + \max_{a\in A} \gamma \sum_{s' \in S} P_{sa} (s')V(s')</script><p>for every state s</p><p>}</p></blockquote><p>在这里有两个办法来更新$V(s)$：</p><ul><li>同步更新（Synchronous update）:<blockquote><p>Set $V_0(s):= V(s)$ for all states $s \in S$</p><p>For each $s \in S$:</p><script type="math/tex; mode=display">V(s):= R(s) + \max_{a \in A} \gamma \sum_{s' \in S} P_{sa}(s') V_0(s')</script></blockquote></li><li>非同步更新（Asynchronous update）：<blockquote><p>For each $s \in S$:</p><script type="math/tex; mode=display">V(s):= R(s) + \max_{a \in A} \gamma \sum_{s' \in S} P_{sa}(s') V(s')</script></blockquote></li></ul><h4 id="policy-iteration"><a href="#policy-iteration" class="headerlink" title="policy iteration"></a>policy iteration</h4><blockquote><p>1.Initialize $\pi$ randomly</p><p>2.Repeat until convergence{</p><p>   a. Let $V:=V^\pi$</p><p>   b. For each state $s$,</p><script type="math/tex; mode=display">\pi(s):= \arg\max_{a \in A}\sum_{s' \in S}P_{sa} V(s')</script><p>}</p></blockquote><p>其中步骤a可以通过求解Bellman等式来完成（一个$\vert S\vert$集合的线性方程组）。</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>值迭代和策略迭代都可以最终收敛到最佳的$\pi^*$和$V^*$.</p><ul><li>策略迭代对于小的MDP更加高效，可以更快速地收敛</li><li>值迭代对于更大的状态空间来说更实用</li></ul><h2 id="Learning-a-model-for-finite-state-MDP"><a href="#Learning-a-model-for-finite-state-MDP" class="headerlink" title="Learning a model for finite-state MDP"></a>Learning a model for finite-state MDP</h2><p>如果奖励函数$R(s)$和转移概率$P_{sa}$是未知的。如何从数据中估计他们？</p><h3 id="Experience-from-MDP"><a href="#Experience-from-MDP" class="headerlink" title="Experience from MDP"></a>Experience from MDP</h3><p>给定政策$\pi$如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">$S$</th><th style="text-align:center">$\pi(s)$</th></tr></thead><tbody><tr><td style="text-align:center">$s_0$</td><td style="text-align:center">$a_0$</td></tr><tr><td style="text-align:center">$s_1$</td><td style="text-align:center">$a_1$</td></tr><tr><td style="text-align:center">$s_2$</td><td style="text-align:center">$a_0$</td></tr></tbody></table></div><p>在这个环境下重复地执行策略$\pi$:</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rf4.png" alt=""></p><h3 id="Estimate-model-from-experience"><a href="#Estimate-model-from-experience" class="headerlink" title="Estimate model from experience"></a>Estimate model from experience</h3><h4 id="Estimate-P-sa"><a href="#Estimate-P-sa" class="headerlink" title="Estimate $P_{sa}$"></a>Estimate $P_{sa}$</h4><p>对状态转移概率的最大似然估计为：</p><script type="math/tex; mode=display">P_{sa}(s') = P(s'|s,a)=\frac{\#\{s \rightarrow a \rightarrow s'\}}{\#\{s \rightarrow a \rightarrow \cdot\}}</script><p>如果$\#\{s \rightarrow a \rightarrow \cdot\}=0$，那么设$P_{sa}(s’) = \frac{1}{\vert S\vert}$.</p><h4 id="Estimate-R-s"><a href="#Estimate-R-s" class="headerlink" title="Estimate $R(s)$"></a>Estimate $R(s)$</h4><p>我们定义$R(s)^{(t)}$为第t次试验中状态s的瞬时奖励，则：</p><script type="math/tex; mode=display">R(s) = \mathbb{E}[R(s)^{(t)}] = \frac{1}{m}\sum_{t=1}^mR(s)^{(t)}</script><h3 id="Algorithm-MDP-model-learning"><a href="#Algorithm-MDP-model-learning" class="headerlink" title="Algorithm: MDP model learning"></a>Algorithm: MDP model learning</h3><blockquote><p>1.Initialize $\pi$ randomly , $V (s) := 0$ for all $s$</p><p>2.Repeat until convergence {</p><p>a.Execute $\pi$ for $m$ trails</p><p>b.Update $P_{sa}$ and $R$ using the accumulated experience</p><p>c.$V:=$ValueIteration$(P_{sa},R,V)$</p><p>d.Update $\pi$ greedily with respect to $V$:</p><script type="math/tex; mode=display">\pi(s)= \arg\max_{a\in A}\sum_{s'\in S}P_{sa}(s')V(s')</script></blockquote><p><strong>ValueIteration($P_{sa},R,V_0$)</strong></p><blockquote><p>1.Initialize $V = V_0$</p><p>2.Repeat until convergence{</p><p>Update </p><script type="math/tex; mode=display">V(s):=R(s)+\max_{a\in A}\gamma\sum_{s'\in S}P_{sa}(s')V(s')</script><p>for every state s</p><p>}</p></blockquote><h2 id="Continuous-state-MDPs"><a href="#Continuous-state-MDPs" class="headerlink" title="Continuous state MDPs"></a>Continuous state MDPs</h2><p>最后我们提一下连续的MDP，一个MDP的状态集合可能是无穷大的：</p><ul><li>A car’s state:$(x,y,\theta,\dot x,\dot y,\dot \theta)$</li><li>A helicopter’s state:$(x,y,z,\phi,\theta,\psi,\dot x,\dot y,\dot z,\dot \phi,\dot \theta,\dot \psi)$</li></ul><p>下面看一个有趣的例子：1D 倒立摆（Inverted Pendulum），目标是平衡车上的栏杆，如图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rf5.png" alt=""></p><ul><li>状态代表：$(x,\theta,\dot x, \dot\theta)$</li><li>动作：作用在车上的力$F$</li><li>奖励：每次这个栏杆是直立的时候+1</li></ul><p>由于维度的“诅咒”，一般来说离散化只能在一维两维的情况下保持不错的效果。</p><p>如何直接估计$V$而不用离散化？</p><p>主要的想法：</p><ul><li>获取MDP的模型或模拟器，可用于产生经验元组:$\langle s,a,s’,r \rangle$</li><li>现在有来自状态空间S的样本$s^{(1)},…,s^{(m)}$，使用模型来估计他们的最佳期望奖励总和，也就是：<script type="math/tex; mode=display">y^{(1)} \approx V(s^{(1)}),y^{(2)} \approx V(s^{(2)}),...</script></li><li>使用监督学习从$\left(s^{(1)},y^{(1)}\right),\left(s^{(2)},y^{(2)}\right),…$来近似$V$,让其作为一个状态$s$的函数，例如：<script type="math/tex; mode=display">V(s)=\theta^T\phi(s)</script><h3 id="Obtaining-a-simulator"><a href="#Obtaining-a-simulator" class="headerlink" title="Obtaining a simulator"></a>Obtaining a simulator</h3>模拟器是一个黑盒子，在给定状态$s_t$和动作$a_t$的情况下来产生下一个状态$s_{t+1}$。</li></ul><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rf6.png" alt=""></p><p>一般来说有下面几种策略：</p><ul><li>使用物理法则，也就是倒立摆的运动方程：<script type="math/tex; mode=display">(M+m)\ddot{x}+b\dot{x} +ml\ddot \theta \cos(theta) - ml\dot \theta ^2\sin(\theta) = F\\(l+ml^2)\ddot\theta+mgl\sin(\theta) = -ml\ddot x\cos(\theta)</script></li><li>使用现成的仿真软件</li><li>游戏模拟器<h3 id="Obtaining-a-model"><a href="#Obtaining-a-model" class="headerlink" title="Obtaining a model"></a>Obtaining a model</h3>在MDP中我们重复地执行动作，执行m次试验，每个试验进行了T次。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rf7.png" alt=""></li></ul><p>通过选择$\theta^*$来学习一个预测模型$s_{t+1}=h_\theta\left(\begin{bmatrix}s_t\\a_t\end{bmatrix}\right)$，而：</p><script type="math/tex; mode=display">\theta^* = \arg\min_\theta\sum_{i=0}^m\sum_{t=0}^{T-1}\left\Verts_{t+1}^{(i)} - h_\theta \left(\begin{bmatrix}s_t\\a_t\end{bmatrix}\right)\right\Vert^2</script><p>比较流行的预测模型有：</p><ul><li>线性模型：$h_\theta = As_t+Ba_t$</li><li>带有特征映射的线性模型：$h_\theta = A\phi_s(s_t) + B\phi_a(a_t)$</li><li>神经网络</li></ul><p>应用模型：</p><ul><li>决策模型（Deterministic Model）：$s_{t+1} = h_\theta \left(\begin{bmatrix}s_t\\a_t\end{bmatrix}\right)$</li><li>随机模型（Stochastic Model）：$s_{t+1} = h_\theta \left(\begin{bmatrix}s_t\\a_t\end{bmatrix}\right)+\epsilon _t,\epsilon_t\sim \mathcal N (0,\Sigma)$</li></ul><h3 id="Value-function-approximation"><a href="#Value-function-approximation" class="headerlink" title="Value function approximation"></a>Value function approximation</h3><p>如何直接近似$V$而不使用离散化？</p><p>主要的想法：</p><ul><li>获得一个MDP的模型或者模拟器</li></ul><ul><li>现在有来自状态空间S的样本$s^{(1)},…,s^{(m)}$，使用模型来估计他们的最佳期望奖励总和，也就是：<script type="math/tex; mode=display">y^{(1)} \approx V(s^{(1)}),y^{(2)} \approx V(s^{(2)}),...</script></li><li>使用监督学习从$\left(s^{(1)},y^{(1)}\right),\left(s^{(2)},y^{(2)}\right),…$来近似$V$,让其作为一个状态$s$的函数，例如：<script type="math/tex; mode=display">V(s)=\theta^T\phi(s)</script></li></ul><p>对于有限状态的MDP中，值函数的更新如下：</p><script type="math/tex; mode=display">V(s) := R(s)+\gamma \max_{a \in A}\sum_{s' \in S}P_{sa}(s')V(s')</script><p>而对于连续状态的值函数如下：</p><script type="math/tex; mode=display">\begin{aligned}V(s) &:= R(s)+\gamma \max_{a \in A}\int_{s'}P_{sa}(s')V(s')ds'\\&:=R(s)+\gamma\max_{a\in A}\mathbb{E}_{s'\sim P_{sa}}[V(s')]\end{aligned}</script><p>对于每个状态，我们使用有限的样本（来自$P_{sa}$）计算$y^{(i)}$来估计$R(s)+\gamma\max_{a\in A}\mathbb{E}_{s’\sim P_{sa}}[V(s’)]$.</p><h4 id="Algorithm-Fitted-value-iteration-Stochastic-Model"><a href="#Algorithm-Fitted-value-iteration-Stochastic-Model" class="headerlink" title="Algorithm: Fitted value iteration(Stochastic Model)"></a>Algorithm: Fitted value iteration(Stochastic Model)</h4><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/rf8.png" alt=""></p><h3 id="Computing-the-optimal-policy"><a href="#Computing-the-optimal-policy" class="headerlink" title="Computing the optimal policy"></a>Computing the optimal policy</h3><p>在得到值函数的估计之后，对应的策略为：</p><script type="math/tex; mode=display">\pi (s) = \arg\max_{a}\mathbb{E}_{s'\sim P_{sa}}[V(s')]</script><p>根据经验来估计最优策略：</p><blockquote><p>For each action $a$:</p><ol><li>Sample $s’_1,…,s’_k \sim P_{s,a}$ using a model</li><li>Compute $Q(a) = \frac 1 k \sum_{j=1}^k R(s)+\gamma V(s’_j)$,$\pi(s) = \arg\max_aQ(a)$</li></ol></blockquote><p>除了线性回归，其他的学习算法也可以用来估计$V(s)$.</p><p>参考：<br><a href="http://cs229.stanford.edu/notes/cs229-notes12.pdf" target="_blank" rel="noopener">Reinforcement Learning and Control</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> reinforcement learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数学——Unbiased Estimation</title>
      <link href="/2018/12/20/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Unbiased-Estimation/"/>
      <url>/2018/12/20/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Unbiased-Estimation/</url>
      
        <content type="html"><![CDATA[<p>在很久之前学习概率论的时候呢，有这么一个比较奇怪的地方，方差的无偏估计：</p><script type="math/tex; mode=display">\sigma^2 = \frac{1}{n-1}\sum_{i=1}^n(X_i - \overline X)^2</script><p>$\overline X = \frac 1 n X_i$，这里无偏估计是$\frac{1}{n-1}$总感觉有点反直觉。这篇文章就是想介绍一下无偏估计，以及这个$(n-1)$是从何而来的。<br><a id="more"></a><br>无偏估计的定义是这样：如果$\hat t$是$t$的一个无偏估计，那么$E[\hat t] =t $.其实从通俗意义上来理解，就是以$\hat t$有偏差，但是这个偏差是以$t$为中心的。可以想象一个打靶的过程，你实际打的地方就是你瞄准的地方的无偏估计，前提是你可能打上打左打右打下等等。如果你瞄准的就不是靶心，那么你打的地方就不是靶心的无偏估计了。</p><p>现在来说明一些比较简单的无偏估计，它是我们推导的前提。</p><p>假如$X_1,X_2,…,X_n$是对X的独立随机采样，那么,$\mu$是X的均值，$\sigma^2$是X的方差。</p><script type="math/tex; mode=display">\begin{equation}E[X_i] = \mu\end{equation}</script><script type="math/tex; mode=display">\begin{equation}E[\overline X] = \mu\end{equation}</script><p>上式中<script type="math/tex">\overline X = \frac{1}{n} \sum_{i=1}^n X_i</script>.</p><script type="math/tex; mode=display">\begin{equation}E[\frac 1 n \sum_{i=1}^n (X_i - \mu)^2] = \sigma^2\end{equation}</script><p>上面的式子前两个都不难理解，我们可以证明一下(3)：</p><script type="math/tex; mode=display">\begin{aligned}E[\frac 1 n \sum_{i=1}^n (X_i - \mu)^2] &= \frac{1}{n}\sum_{i=1}^nE[(X_i - \mu)^2]\\&= \frac{1}{n}\sum_{i=1}^n E[X_i^2 - 2X_i\mu + \mu^2]\\&= \frac{1}{n}\sum_{i=1}^n E[X^2 - 2X\mu + \mu^2]\\ &=  \frac{1}{n}\sum_{i=1}^n E[(X - \mu)^2]\\&= E[(X - \mu)^2] =\sigma^2\end{aligned}</script><p>但是实际中，我们也往往无法得到$\mu$的值。想象一下，如果需要统计全世界人的平均身高，你要统计60亿人的身高才能得到精确的$\mu$，如果有个人死掉了，有个人出生了，$\mu$又变了。实际中根本不会这么做。我们一般会根据$\overline X$来估计$\mu$。因此对于方差的估计也是用$\overline X$来完成的。这时候就出现了诡异的式子了：</p><script type="math/tex; mode=display">\begin{equation}E[\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline X)^2] = \sigma^2\end{equation}</script><p>也就是说，$S^2 =\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline X)^2 $才是$\sigma^2$的无偏估计。</p><p>为什么？</p><p>先给大家一个直观的理解。首先，我们知道$\sum_{i=1}^n (X_i - y)^2$这个式子，在$y = \overline X$时候取得最大值。如果你不知道这个，很好证明，之前数据学习一篇文章中也提到过<a href="https://wlsdzyzl.top/2018/11/19/Learning-From-Data%E2%80%94%E2%80%94K-Means-Clustering/" target="_blank" rel="noopener">k-means clustering</a>.</p><p>但是，我们得到的$\overline X $与$\mu$多少是有些偏差的，这意味着：</p><script type="math/tex; mode=display">\sum_{i=1}^n (X_i - \overline X)^2 \leq \sum_{i=1}^n (X_i - \mu)^2</script><p>也就是，我们如果这样估计：</p><script type="math/tex; mode=display">\frac{1}{n} \sum_{i=1}^n (X_i - \overline X)^2</script><p>结果是偏小的。</p><p>但是具体要增加多少才能达到无偏估计呢？下面开始推导：</p><script type="math/tex; mode=display">\begin{aligned}E[\sum_{i=1}^n (X_i - \overline X)^2] &=E[\sum_{i=1}^n(X_i - \mu -(\overline X - \mu))^2]\\&=  E[\sum_{i=1}^n ((X_i - \mu)^2 - 2(X_i - \mu)(\overline X - \mu) +  (\overline X - \mu)^2)]\\&= E[\sum_{i=1}^n (X_i - \mu)^2 - 2(\overline X - \mu)\sum_{i=1}^n(X_i - \mu) + n(\overline X - \mu)^2 ]\\&= E[\sum_{i=1}^n (X_i - \mu)^2 - 2(\overline X - \mu)(n\overline X - n\mu) + n(\overline X - \mu)^2 ]\\&= E[\sum_{i=1}^n (X_i - \mu)^2 - n(\overline X - \mu)^2 ]\\&= n\sigma^2 - nE[(\overline X - \mu)^2 ]\end{aligned}</script><p>现在我们想要弄明白的是：$E[(\overline X - \mu)^2 ] = ?$</p><script type="math/tex; mode=display">\begin{aligned}E[(\overline X - \mu)^2 ] &= E[(\frac 1 n \sum_{i=1}^n X_i - \mu)^2]\\&= E[(\frac 1 n (\sum_{i=1}^n X_i - n\mu))^2]\\&=E[\frac{1} {n^2} (\sum_{i=1}^n (X_i - \mu))^2]\\&= \frac{1}{n^2}E[\sum_{i=1}^n (X_i-\mu)^2 - 2\sum_{i\ne j}(X_i - \mu)(X_j - \mu)]\\&= \frac{1}{n^2}(E[\sum_{i=1}^n (X_i-\mu)^2] - 2\sum_{i\ne j}E[(X_i - \mu)(X_j - \mu)])\\&=  \frac{1}{n^2}(E[\sum_{i=1}^n (X_i-\mu)^2] - 2\sum_{i\ne j}E[(X_i - \mu)]E[(X_j - \mu)])\\&= \frac{1}{n^2}(E[\sum_{i=1}^n (X_i-\mu)^2])\\&= \frac 1 n \sigma^2\end{aligned}</script><p>上式中倒数第一步由(3)式得到，倒数第三步是因为我们采样是独立的。</p><p>所以我们得到：</p><script type="math/tex; mode=display">E[\sum_{i=1}^n (X_i - \overline X)^2]  = (n-1)\sigma^2</script><p>这也就证明了，对于方差的无偏估计是$S^2$，其中：</p><script type="math/tex; mode=display">S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline X)^2</script><p>下面我们将这个拓展到多维度变量的协方差矩阵。多维度变量$X \in \mathbb{R}^n$协方差矩阵的定义为：</p><script type="math/tex; mode=display">Cov(X) \triangleq E[(X-\mu)(X-\mu)^T]</script><p>现在假设有m个采样，而这些采样的平均值为$\hat \mu$.</p><p>现在我们证明$\hat C$为$\Sigma = Cov(X)$的无偏估计。其中：</p><script type="math/tex; mode=display">\hat C = \frac{1}{m-1}E[\sum_{i=1}^m(X_i - \hat \mu)(X_i - \hat \mu)^T].</script><p>实际上证明是大同小异的，幸运的是矩阵的多数运算都和标量非常相似。</p><script type="math/tex; mode=display">\begin{aligned}E[\hat C]&= \frac{1}{m-1}E[\sum_{i=1}^m(X_i - \hat \mu)(X_i - \hat \mu)^T]\\&=\frac{1}{m-1}\sum_{i=1}^mE[(X_i - \hat \mu)(X_i - \hat \mu)^T]\\&=\frac{1}{m-1}\sum_{i=1}^mE[(X_i - \mu + \mu - \hat \mu)(X_i - \mu + \mu - \hat \mu)^T]\\&= \frac{1}{m-1}\sum_{i=1}^m E[(X_i - \mu)(X_i - \mu)^T + 2 (X_i - \mu)(\mu - \hat \mu)^T + (\mu - \hat \mu)(\mu - \hat \mu)^T]\\&= \frac{1}{m-1}\left(\sum_{i=1}^m E[(X_i - \mu)(X_i - \mu)^T] + \sum_{i=1}^m E[2 (X_i - \mu)(\mu - \hat \mu)^T + (\mu - \hat \mu)(\mu - \hat \mu)^T]\right)\\&= \frac{1}{m-1} (m\Sigma + E[\sum_{i=1}^m 2(X_i - \mu)(\mu - \hat \mu)^T + m(\mu - \hat \mu)(\mu - \hat \mu)^T])\\&= \frac{1}{m-1} (m\Sigma + E[2m(\hat\mu - \mu)(\mu - \hat \mu)^T + m(\mu - \hat \mu)(\mu - \hat \mu)^T])\\&= \frac{1}{m-1}(m \Sigma - mE[(\hat \mu - \mu)(\hat \mu - \mu)^T])\\\end{aligned}</script><p>而其中：</p><script type="math/tex; mode=display">\begin{aligned}E[(\hat \mu - \mu)(\hat \mu - \mu)^T] &= E[(\frac{1}{m}\sum_{i=1}^m X_i - \mu)(\frac{1}{m}\sum_{i=1}^mX_i - \mu)^T]\\&= \frac{1}{m^2}E[(\sum_{i=1}^m(X_i - \mu))(\sum_{i=1}^m(X_i - \mu))^T]\\&=\frac{1}{m^2} E[\sum_{i=1}^m (X_i - \mu)(X_i - \mu)^T + 2\sum_{i\ne j}(X_i - \mu)(X_j - \mu )]\\&=\frac{1}{m^2}(m\Sigma + 2\sum_{i\ne j} E[X_i - \mu] E[X_j-\mu])\\&=\frac{1}{m^2}(m\Sigma + 0)\\&= \frac{1}{m}\Sigma\end{aligned}</script><p>所以我们得到：</p><script type="math/tex; mode=display">E[\hat C] = \frac{1}{m-1}(m-1)\Sigma = \Sigma.</script>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mathematics </tag>
            
            <tag> probility theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Mixture of Gaussians &amp; EM</title>
      <link href="/2018/12/17/Learning-From-Data%E2%80%94%E2%80%94Mixture-of-Gaussians-EM/"/>
      <url>/2018/12/17/Learning-From-Data%E2%80%94%E2%80%94Mixture-of-Gaussians-EM/</url>
      
        <content type="html"><![CDATA[<p>这一周的内容是关于EM算法的，同时介绍了EM算法在混合高斯模型（Mixture of Gaussians）上的情况以及在因子分析上的用途。<br><a id="more"></a><br>首先介绍一下，什么是混合模型。</p><h2 id="Mixture-modes"><a href="#Mixture-modes" class="headerlink" title="Mixture modes"></a>Mixture modes</h2><p>一个混合模型假设数据是通过下面的过程生成的：</p><ul><li>样本$z^{(i)} \in {1,…,k}$并且$z^{(i)}\sim Multinomial(\phi)$:<script type="math/tex">p(z^{(i)} = j) = \phi_j \text{ for all }j</script></li><li>样本可以观测的量$x^{(i)}$是符合某些分布$p(z^{(i)},x^{(i)})$:<script type="math/tex">p(z^{(i)},x^{(i)}) = p(z^{(i)})p(x^{(i)}\vert z^{(i)})</script></li></ul><p>例如：非监督学习的手写识别是一个10个伯努利分布的混合模型，财务收益估计采用两个高斯混合模型，正态模型和危机时间分布。</p><p>而高斯混合模型为：</p><script type="math/tex; mode=display">z^{(i)}\sim Multinomial(\phi)\\x^{(i)} \sim \mathcal{N}(\mu_j,\Sigma_j)</script><p>现在我们面临的问题是如何学习得到$\phi_j,\mu_j,\Sigma_j$？</p><p>这要分成两种情况来讨论：</p><ul><li><p>$z^{(j)}$是已知的，那么这个问题变成了一个监督学习的问题。解决的办法我们之前也学到过，实际上就是<a href="https://wlsdzyzl.top/2018/10/29/Learning-From-Data%E2%80%94%E2%80%94Generative-Learning-Algorithm/" target="_blank" rel="noopener">generative learning algorithm</a>的一种，不过它实际上是二次判别分析的例子，比上面的博客的内容更稍微进了一步，可以看<a href="https://wlsdzyzl.top/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Covariance-Matrix-Derivation/" target="_blank" rel="noopener">Covariance Matrix Derivation</a>了解详情。在这个情况下：</p><script type="math/tex; mode=display">\phi_j = \frac{1}{m} \sum_{i=1}^m \mathbf{1}\{z^{(i)} = j\}, \mu_j = \frac{\sum_{i=1}^m \mathbf{1}\{z^{(i)}=j\}x^{(i)}}{\sum_{i=1}^m\mathbf{1}\{z^{(i)} = j\}}</script><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\Sigma_j = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=j\}(x^{(i)} - \mu_{j}) (x^{(i)} - \mu_{j})^T}{\sum_{i=1}^m \mathbf{1}\{y_i=j\}}\end{aligned}\end{equation*}</script></li><li><p>$z^{(j)}$是未知的，这时候则是属于非监督学习的范畴。我们使用期望最大化(expectation mamximization),也就是EM算法。</p></li></ul><h2 id="Expectation-Maximization"><a href="#Expectation-Maximization" class="headerlink" title="Expectation Maximization"></a>Expectation Maximization</h2><p>EM算法是一个迭代求解最大似然估计的算法。求解最大似然估计我们已经遇到多次，与其他不同的地方在于，它估计的模型依赖于潜在的变量(latent variables)，这些变量是无法观察的。</p><p>首先，我们和往常一样，求数据的log-likelihood：</p><script type="math/tex; mode=display">I(\theta) = \sum_{i=1}^m\log p(x;\theta) = \sum_{i=1}^m\log\sum_z p(x,z;\theta)</script><p>我们先来看看EM算法的步骤，然后再证明它的正确性：</p><blockquote><p>Initialize θ</p><p>Repeat untill convergence {</p><p>(E - step ) For each i , set</p><p>$Q_i(z^{(i)} ):= p(z^{(i)} |x^{(i)} ; θ) \leftarrow $ Posterior distribution $z|x$ under $θ$</p><p>(M - step ) Set</p><script type="math/tex; mode=display">\begin{equation} \theta = \arg\max_{\theta} \sum_i \sum_{z^{(i)}}Q_i(z^{(i)})\log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\end{equation}</script><p>$\leftarrow$ Update parameter θ<br>}</p></blockquote><h3 id="Proof-of-Correctness"><a href="#Proof-of-Correctness" class="headerlink" title="Proof of Correctness"></a>Proof of Correctness</h3><p>我们将会证明(1)等价于$\arg\max_\theta I(\theta)$，也就是等式(1)是$I(\theta)$的一个很紧下界。我们也将会证明这个算法最终会收敛。<br>定义：</p><script type="math/tex; mode=display">J(Q,\theta) = \sum_j \sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}</script><p>第一步：<br>我们要说明，$J(Q,\theta)$是$I(\theta)$的一个下界，而且当$Q_i(z^{(i)}) = p(z^{(i)}\vert x^{(i)};\theta)$时，这个下界是tight bound.</p><h4 id="Jensen’s-Inequality"><a href="#Jensen’s-Inequality" class="headerlink" title="Jensen’s Inequality"></a>Jensen’s Inequality</h4><p>首先需要回顾一下Jensen不等式。如果$f$是一个convex函数，若$X$为随机变量，则：</p><script type="math/tex; mode=display">\mathbf{E}[f(X)] \ge f(\mathbf{E}[X])</script><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EM1.png" alt=""></p><p>注意：</p><ul><li>如果f(x)为concave函数，则$\mathbf{E}[f(X)] \leq f(\mathbf{E}[X])$.</li><li>如果f(x)为线性函数，则$\mathbf{E}[f(X)] = f(\mathbf{E}[X])$.</li></ul><p>我们知道$\log$是一个concave函数，实际上，我们可以将$J(Q,\theta)$写为：</p><script type="math/tex; mode=display">\begin{aligned}J(Q,\theta) &= \sum_j \sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\\&= \sum_j \mathbb{E}_Q[log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}] \\&\leq \sum_j \log \mathbb{E}[\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}]\\&= \sum_j \log \sum_{z^{(i)}}Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\\&= \sum_j\log \sum_{z^{(i)}} p(x^{(i)},z^{(i)};\theta)\\&= I(\theta)\end{aligned}</script><p>如何证明是一个tight bound?</p><p>继续查看上面的Jensen不等式，想要这个不等式变得更紧一点，一个容易想到的策略是让$f$变为一个常量。因此在这里，最简单的做法就是让$\log$后的内容与$z^{(i)}无关$：</p><script type="math/tex; mode=display">\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} = C</script><p>简单取$C=1$，我们得到：</p><script type="math/tex; mode=display">Q_i(z^{(i)}) = p(x^{(i)},z^{(i)};\theta)</script><p>但是，因为$Q$是一个分布，因此我们必须要让$\sum_{z^{(i)}}Q_i(z^{(i)}) = 1$。所以$Q$的取值就比较容易求得了：</p><script type="math/tex; mode=display">\begin{aligned}Q_i(z^{(i)}) &= \frac{p(x^{(i)},z^{(i)};\theta)}{\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta)}\\&= \frac{p(x^{(i)},z^{(i)};\theta)}{p(x^{(i)});\theta}\\&= p(z^{(i)}\vert x^{(i)};\theta)\end{aligned}</script><p>因此，上面的推导同时也就证明了当$Q_i(z^{(i)}) = p(z^{(i)}\vert x^{(i)};\theta)$时，$J(Q,\theta)$是一个tight lower bound（取到了等号）。到这里，我们完成了E-step。</p><p>第二步，证明收敛。<br>EM算法会单调增加log-likelihood，也就是，如果$\theta^{(t)}$作为第ｔ次迭代的参数值，则：</p><script type="math/tex; mode=display">I(\theta^{(t)})\leq I(\theta^{(t+1)}),</script><script type="math/tex; mode=display">Q_i^{(t)}(z^{(i)}) = p(z^{(i)}\vert x^{(i)};\theta^{(t)})</script><p>这个证明和$Q$的取值息息相关。首先，从之前的推导，我们已经知道了：</p><script type="math/tex; mode=display">I(\theta ^{(t)}) = \sum_j \sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\theta^{(t)})}{Q_i(z^{(i)})}</script><p>观察M-step，既然$\theta^{(t+1)}$是让上式取得最大值得到的$\theta$，那么可以得到：</p><script type="math/tex; mode=display">\begin{aligned}I(\theta ^{(t+1)}) &\ge \sum_j \sum_{z^{(i)}}Q_i^{(t)}(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\theta^{(t+1)})}{Q_i(z^{(i)})}\\&\ge \sum_j \sum_{z^{(i)}}Q_i^{(t)}(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\theta^{(t)})}{Q_i(z^{(i)})}\\&= I(\theta^{(t)})\end{aligned}</script><p>第一步简单地由Jensen不等式得到（对于任何分布$Q$都是成立的）。由此我们便证明了这个算法最终会收敛。</p><h3 id="EM-for-Mixture-of-Gaussians"><a href="#EM-for-Mixture-of-Gaussians" class="headerlink" title="EM for Mixture of Gaussians"></a>EM for Mixture of Gaussians</h3><p>现在我们来说明以下高斯混合模型下的EM算法。算法步骤如下：</p><blockquote><p>Repeat until convergence{</p><p>(E - step ) For each i, j , set</p><p>$w^{(i)}_j:=p(z^{(i)} = j\vert x^{(i)};\phi,\mu,\Sigma)$</p><p>(M - step ) Update parameters : assume $\phi_j = \mathbb{E}[w_j]$</p><script type="math/tex; mode=display">\phi_j = \frac 1 m \sum_{i=1}^m w_j^{(i)};\\\mu_j = \frac{\sum_{i=1}^m w_j^{(i)}x^{(i)}}{\sum_{i=1}^mw_j^{(i)}};\\\Sigma_j = \frac{\sum_{i=1}^mw_j^{(i)}(x^{(i)} - \mu_j)(x^{(i)} - \mu_j)^T}{\sum_{i=1}^mw_j^{(i)}}</script><p>}</p></blockquote><p>下图是一个利用混合高斯模型EM算法的例子：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EM2.png" alt=""></p><p>同时在这里我们可以看一下EM算法与Llyod’s k-means算法的比较：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EM3.png" alt=""></p><p>可以看到，混合高斯模型可以看作是k-means聚类问题的一个“软”版本。</p><h2 id="Factor-Analysis"><a href="#Factor-Analysis" class="headerlink" title="Factor Analysis"></a>Factor Analysis</h2><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EM4.png" alt=""></p><p>Figure: Self-ratings on 32 Personality Traits</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EM5.png" alt=""></p><p>Figure: Pairwise correlation plot of 32 variables from 240 participants</p><h3 id="Factor-Analysis-Terminology"><a href="#Factor-Analysis-Terminology" class="headerlink" title="Factor Analysis Terminology"></a>Factor Analysis Terminology</h3><p>首先介绍几个因子分析中的术语。</p><p><strong>observed randam variables</strong> $x \in \mathbb{R}^n$</p><script type="math/tex; mode=display">x = \mu + Λz+\epsilon</script><p><strong>factor</strong> $z \in \mathbb{R}^{k}$ is the hidden (latent) construct that “causes” the observed variables.</p><p><strong>factor loading</strong>  $ Λ \in \mathbb{R}^{n\times k}$: the degree to which variable $x_i$ is “caused” by the factors.</p><p>$\mu,\epsilon \in \mathbb{R}^n$ are the mean and error vectors.</p><p>这一些解释我认为用中文翻译的有点别扭，所以就写成了英文。</p><p>下面是一个factor loading  Λ的例子：</p><p>Table: Matrix of factor loading Λ for personality test data</p><div class="table-container"><table><thead><tr><th style="text-align:center">variable</th><th style="text-align:center">factor1</th><th style="text-align:center">factor2</th><th style="text-align:center">factor3</th><th style="text-align:center">factor4 </th></tr></thead><tbody><tr><td style="text-align:center">distant</td><td style="text-align:center">0.59</td><td style="text-align:center">0.27</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">talkative</td><td style="text-align:center">-0.50</td><td style="text-align:center">-0.51</td><td style="text-align:center">0</td><td style="text-align:center">0.27</td></tr><tr><td style="text-align:center">careless</td><td style="text-align:center">0.46</td><td style="text-align:center">-0.47</td><td style="text-align:center">0.11</td><td style="text-align:center">0.14</td></tr><tr><td style="text-align:center">hardworking</td><td style="text-align:center">-0.46</td><td style="text-align:center">0.33</td><td style="text-align:center">-0.14</td><td style="text-align:center">0.35    </td></tr><tr><td style="text-align:center">kind</td><td style="text-align:center">-0.488</td><td style="text-align:center">0.222</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td><td style="text-align:center">…</td></tr></tbody></table></div><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EM6.png" alt=""></p><p>Figure: Visualize loading of the ﬁrst two factors</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EM7.png" alt=""></p><p>Figure: Visualize loading of the ﬁrst two factors, rotated to align with axes</p><p>实际上因子分析也是一个混合模型，这里有可观察的变量：$x\in \mathbb R ^n$，以及潜在变量$z \in \mathbb{R}^k$，$(k &lt; n)$.</p><p>因子分析模型定义了一个联合分布$p(x,z)$:</p><script type="math/tex; mode=display">z \sim  \mathcal N(0,I)\\\epsilon \sim  \mathcal N (0,\Psi)\\x = \mu + \wedge z + \epsilon</script><p>其中$\Psi \in \mathbb{R}^{n \times n}$ 是一个对角矩阵，$\epsilon,\mu \in \mathbb R ^n$,并且互相独立, $\wedge \in \mathbb R ^{n \times k}$。</p><p>给定了$x^{(1)},…,x^{(m)}$，如何得到参数$\mu,\wedge,\Psi$？</p><h3 id="EM-for-factor-analysis"><a href="#EM-for-factor-analysis" class="headerlink" title="EM for factor analysis"></a>EM for factor analysis</h3><p>应该比较容易看出这个问题是可以用EM来解决的。下面写出迭代步骤：</p><blockquote><p>Initialize µ,Λ,Ψ</p><p>Repeat untill convergence {</p><p>(E-step)  For each i , set </p><script type="math/tex; mode=display">Q_i(z^{(i)}):= p(z^{(i)}\vert x^{(i)};\mu,\wedge,\Psi),</script><p>z is a continuous variable </p><p>(M-step) Set</p><script type="math/tex; mode=display">\begin{equation} \mu,\wedge,\Psi:= \arg\max_{\mu,\wedge,\Psi} \sum_{i=1}^m\int_{z^{(i)}}Q_i(z^{(i)}) \log \frac{p(x^{(i)},z^{(i)};\mu,\wedge,\Psi)}{Q_i(z^{(i)})}dz^{(i)}\end{equation}</script></blockquote><p>首先，我们需要把$p(z^{(i)}\vert x^{(i)}),p(z^{(i)},x^{(i)})$写成模型参数的形式。</p><p>我们的随机变量$\begin{bmatrix}z\\x\end{bmatrix} \sim  \mathcal N (\mu_{zx},\Sigma)$，其中：</p><script type="math/tex; mode=display">\mu_{xz} = \begin{bmatrix}0\\\mu\end{bmatrix},\Sigma = \begin{bmatrix}I&\wedge^T\\\wedge&\wedge\wedge^T+\Psi\end{bmatrix}</script><p>我们知道 $\mathbb{E}[z] = 0$,因为$ z \sim  \mathcal N(0,I)$。同时我们也可以得到：</p><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}[x]&=\mathbb{E}[\mu+\wedge z+\epsilon]\\&=\mu+\wedge\mathbb E [z]+\mathbb{E}[\epsilon]\\&=\mu\end{aligned}</script><p>所以可以得到：</p><script type="math/tex; mode=display">\mu_{xz} = \begin{bmatrix}0\\\mu\end{bmatrix}</script><p>如果想要得到$\Sigma$，需要比较长的推导。如果不在乎的过程的话可以直接跳过。</p><h4 id="Sigma-’s-derivation"><a href="#Sigma-’s-derivation" class="headerlink" title="$\Sigma$’s derivation"></a>$\Sigma$’s derivation</h4><p>为了得到$\Sigma$，我们需要计算$\Sigma_{zz} = \mathbb{E}[(z − \mathbb{E}[z])(z − \mathbb{E}[z])^T]$($\Sigma$的左上角)，$\Sigma_{zx} = \mathbb{E}[(z − \mathbb{E}[z])(x − \mathbb{E}[x])^T]$($\Sigma$的右上角)以及$ \Sigma{xx} = \mathbb{E}[(x − \mathbb{E}[x])(x − \mathbb{E}[x])^T] $(右下角)。</p><p>首先，因为$z \sim  \mathcal N(0,I)$，我们可以轻易得到：$\Sigma_{zz} = Cov(z) = I$。此外：</p><script type="math/tex; mode=display">\begin{aligned} \mathbb{E}[(z − \mathbb{E}[z])(x − \mathbb{E}[x])^T] &= \mathbb{E}[z(\mu+\wedge z + \epsilon - \mu)^T]\\&= \mathbb{E}[zz^T]\wedge^T +  \mathbb{E}[z\epsilon^T]\\&=\wedge^T\end{aligned}</script><p>在最后一步中，我们利用了$ \mathbb{E}[zz^T] = Cov(z)$，因为z是zero-mean，以及$ \mathbb{E}[z\epsilon^T] =  \mathbb{E}[z] \mathbb{E}[\epsilon] = 0$，因为他们是独立的。最后:</p><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}[(x − \mathbb{E}[x])(x − \mathbb{E}[x])^T] &= \mathbb{E}[(\mu+\wedge z + \epsilon - \mu)(\mu+\wedge z + \epsilon - \mu)^T]\\&= \mathbb{E}[\wedge z z^T\wedge^T + \epsilon z^T \wedge^T + \wedge^T z \epsilon^T + \epsilon\epsilon^T]\\&=\wedge \mathbb{E}[zz^T]\wedge^T + \mathbb{E}[\epsilon\epsilon^T]\\&= \wedge\wedge^T+\Psi\end{aligned}</script><p>最后我们就得到了：</p><script type="math/tex; mode=display">\Sigma = \begin{bmatrix}I&\wedge^T\\\wedge&\wedge\wedge^T+\Psi\end{bmatrix}</script><h4 id="E-step"><a href="#E-step" class="headerlink" title="E-step"></a>E-step</h4><p>E-step不难理解，因为后验分布：<script type="math/tex">z^{(i)}\vert x^{(i)} \sim \mathcal N \left( \mu_{z^{(i)}\vert x^{(i)}},\Sigma_{z^{(i)}\vert x^{(i)}}\right)</script>，根据EM算法可以得到：</p><script type="math/tex; mode=display">\mu_{z^{(i)}\vert x^{(i)}} = \wedge^T(\wedge\wedge^T + \Psi)^{-1}(x^{(i)}-\mu)\\\Sigma_{z^{(i)}\vert x^{(i)}} = I - \wedge^T(\wedge\wedge^T + \Psi)^{-1}\wedge\\Q_i(z^{(i)}) = \frac{1}{(2\pi)^{k/2}\vert \Sigma_{z^{(i)}\vert x^{(i)}}\vert^{1/2}}\exp\left(-\frac{1}{2}(z^{(i)} - \mu_{z^{(i)}\vert x^{(i)}})^T\Sigma^{-1}_{z^{(i)}\vert x^{(i)}}(z^{(i)} - \mu_{z^{(i)}\vert x^{(i)}})\right)</script><h4 id="M-step"><a href="#M-step" class="headerlink" title="M-step"></a>M-step</h4><script type="math/tex; mode=display">\begin{equation} \arg\max_{\mu,\wedge,\Psi} \sum_{i=1}^m\int_{z^{(i)}}Q_i(z^{(i)}) \log \frac{p(x^{(i)},z^{(i)};\mu,\wedge,\Psi)}{Q_i(z^{(i)})}dz^{(i)}\end{equation}</script><p>我们可以知道：</p><script type="math/tex; mode=display">\int_{z^{(i)}}Q_i(z^{(i)}) \log \frac{p(x^{(i)},z^{(i)};\mu,\wedge,\Psi)}{Q_i(z^{(i)})}dz^{(i)} \\=\mathbb{E}_{z\sim Q_i}[\log p(x^{(i)}|z^{(i)};\mu,\wedge,\Psi) + \log p(z^{(i)})−\log Q_i(z^{(i)})]</script><p>所以(3)也就等价于：</p><script type="math/tex; mode=display">\begin{equation}\arg\max_{\mu,\wedge,\Psi} \sum_{i=1}^m\mathbb{E}_{z\sim Q_i}[\log p(x^{(i)}|z^{(i)};\mu,\wedge,\Psi) + \log p(z^{(i)})−\log Q_i(z^{(i)})]\end{equation}</script><p>因为$x =\mu + \wedge z + \epsilon,\epsilon \sim  \mathcal N (0,\Psi)$，我们可以得到：</p><script type="math/tex; mode=display">x^{(i)}\vert z^{(i)} \sim \mathcal N (\mu+\wedge z,\Psi)</script><p>即：</p><script type="math/tex; mode=display">p(x^{(i)}|z^{(i)};\mu,\wedge,\Psi)\\=\frac{1}{(2\pi)^{n/2}\vert \Psi\vert^{1/2} }\exp\left(-\frac{1}{2}(x^{(i)} - \mu-\wedge z^{(i)})^T\Psi^{-1}(x^{(i)} - \mu-\wedge z^{(i)})\right)</script><p>我们通过$\mu,\wedge,\Psi$来最大化(4)。</p><h3 id="与混合高斯模型的对比"><a href="#与混合高斯模型的对比" class="headerlink" title="与混合高斯模型的对比"></a>与混合高斯模型的对比</h3><ul><li>混合高斯模型假设有足够的数据和相对较少的随机变量，也就是当$n\approx m$或者$n &gt; m$，$\Sigma$是奇异矩阵。</li><li>而因子分析在$n &gt; m$的时候通过允许模型误差来处理。</li></ul><h3 id="与PCA的关系"><a href="#与PCA的关系" class="headerlink" title="与PCA的关系"></a>与PCA的关系</h3><ul><li>他们都能找到低纬度潜在的子空间。</li><li>PCA可以用来做数据压缩，或者去除冗余数据，它减少了可以观察的数据间的联系。</li><li>因子分析适合来做数据勘探，来找到观测数据中的独立，共同因子。</li><li>因子分析允许噪声具有任意的对角协方差矩阵，而PCA假设噪声是球形的。</li></ul><p>总之，这节课上的还是很懵逼的。</p><p>参考资料：<br><a href="http://cs229.stanford.edu/notes/cs229-notes8.pdf" target="_blank" rel="noopener">EM algorithm</a>，<a href="http://cs229.stanford.edu/notes/cs229-notes9.pdf" target="_blank" rel="noopener">factor analysis</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> mathematics </tag>
            
            <tag> unsupervised learning </tag>
            
            <tag> factor analysis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——视觉里程计（一）feature</title>
      <link href="/2018/12/16/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%B8%80%EF%BC%89feature/"/>
      <url>/2018/12/16/SLAM%E2%80%94%E2%80%94%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%EF%BC%88%E4%B8%80%EF%BC%89feature/</url>
      
        <content type="html"><![CDATA[<p>从现在开始下面两篇文章来介绍SLAM中的视觉里程计（Visual Odometry）。这个是我们正式进入SLAM工程的第一步，而之前介绍的更多的是一些基础理论。视觉里程计完成的事情是视觉里程计VO的目标是根据拍摄的图像估计相机的位姿。目前主要有两个方法，我们这一篇介绍的是特征点法。<br><a id="more"></a><br>首先，我们之前提到了路标。SLAM中是根据路标的位置变化来估计自身的运动的。路标是三维空间中固定不变的点，应该有这么几个特征：</p><ul><li>数量充足，以实现良好的定位</li><li>具有较好的区分性，以实现数据关联<br>而图像的特征点可以比较好的满足上面的特点，可以通过特征点来作为SLAM中的路标。</li></ul><h2 id="特征点"><a href="#特征点" class="headerlink" title="特征点"></a>特征点</h2><p><strong>特征点</strong>是图像当中比较具有代表性的部分。<br>我们想象一下，我们识别一个物体的时候，即使旋转了，或者光照不同，尺度变化，我们还是能认出。这一点上，人眼真的是太强了。如图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%E7%9C%9F%E9%A6%99.gif" alt=""></p><p>即使糊成这样，我们依然能喊出来，诶呀真香。</p><p>而一种好的特征点，希望能做到上面几点，当然那是非常困难的。它应该有下面几个特征：</p><ul><li>可重复性，也就是，换个视角来看它应该还是原来的样子。</li><li>可区分性，可区分意味着不同的特征点看起来不一样，这样我们才能辨别不同场景。</li><li>高效，这个作为特征点并不是必要的，但是为了实时SLAM的运行，我们必须把它纳入，而且它是非常重要的。<br>特征点一般由两部分组成：<strong>关键点</strong>和<strong>描述子</strong>（descriptor）。其中关键点包含了这个点的位置，大小，方向评分等信息，但是只靠关键点不足以区分各个特征点，而描述子描述了特征点周围的像素的一些信息。</li></ul><p>一般来说特征点的选的部分都是角点或者边缘部分，因为它们有比较大的区分性，而区块点的区分性就比较差了，这个是符合我们的直觉的。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/orb5.png" alt=""></p><p>有一些比较有名的特征点，FAST，ORB，SIFT，SURF等等。一般来说，我们在SLAM中要兼顾特征点在各个条件下的性能（比如光照不同，旋转等情况下依然能得到基本一样的特征点，主要是靠描述子来实现），以及提取速度，这使得在SLAM中我们用的最多的是ORB特征点，我们可以在OpenCV feature2d模块中找到。下面对各个特征点做一个简单的介绍，同时会相对详细地介绍一下ORB特征点。</p><h3 id="Fast特征点"><a href="#Fast特征点" class="headerlink" title="Fast特征点"></a>Fast特征点</h3><p>首先介绍一下Fast特征点。Fast特征点是非常简单的一种特征点，它的提取速度也非常快。它的思路非常简单：若某像素与其周围邻域内足够多的像素点相差较大，则该像素可能是角点。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/orb4.png" alt=""></p><p>如上图，以一个像素p为中心，fast检测周围半径为3的圆上的16个像素点，在它的周围，如果有连续12个像素点与中心像素点的差都超过阈值，则它判断它是一个角点，这个方法是Fast12，其他的还有fast9等等，都只是个数不同而已。</p><p>为了提高效率，还有一个步骤，比如要超过12个像素点，那么首先检测p1,p5,p9,p13这几个像素点，如果有3个超过阈值，它才有可能是一个角点，当作候选点。相当于是一个预处理，这样可以大大提高提取的速度。</p><p>当然，通过这样的方法得到的特征点可能会在某个局部区域非常密集，因此我们需要进行极大值抑制。具体做法为：计算特征点出的FAST得分值（即score值，也即s值，定义为（16个点与中心差值的绝对值总和），判断以特征点p为中心的一个邻域（如3x3或5x5）内，若有多个特征点，则判断每个特征点的s值，若p是邻域所有特征点中响应值最大的，则保留；否则，抑制。若邻域内只有一个特征点（角点），则保留。</p><p>Fast特征点是非常直白的，它甚至没有描述子。而有意思的是它的提出（2006年）却没有SIFT等比较复杂的特征点那么早。</p><h3 id="ORB特征点"><a href="#ORB特征点" class="headerlink" title="ORB特征点"></a>ORB特征点</h3><p>Fast特征点虽然快，但是它并没有描述子，这样距离我们的应用还是有差距，因为它是没有办法匹配(match)的，仅仅靠关键点我们无法互相区分各个特征点。</p><p>ORB特征点是Fast特征点和BREIF特征描述子的改进，是Oriented Fast，它增加了描述子，具有局部旋转不变性。因为BREIF是二进制描述子，它的提取速度依然是非常迅速的。</p><p>除此之外，Fast特征点的数量往往很大而且不确定，我们一般希望对图像提取固定数量的特征点。假如我们需要提取N个角点，则ORB中可以对各个角点进行Harris响应值，然后选前N个具有最大响应值的角点。</p><p>下面稍微介绍一下ORB中对于Fast方向性和尺度方面的弱点的改进。</p><p>对于尺度方面，Fast由于计算的只是像素亮度的差异，有时候远处像角点的地方，离近了就不是角点了。尺度不变性由构建图像金字塔，并在金字塔的每一层上检测角点来实现。金字塔是对图像进行不同层次的降采样，以获得不同的分辨率。</p><p>对于方向性，是由灰度质心法实现的。我们知道一般来说，一个有质量的物体有个质心，那么图片呢？在图片中，我们把每个像素的灰度值当作“质量”来确定质心。</p><p>灰度质心法操作如下：</p><ol><li>在小的图像块B中，图像块的矩为：<script type="math/tex; mode=display">m_{pq} = \sum_{x,y \in B} x^py^qI(x,y)</script>上式中，$x,y$分别为坐标值，而$I(x,y)$为$(x,y)$的灰度值。</li><li>通过矩可以找到图像的质心：<script type="math/tex; mode=display">C = (\frac{m_{10}}{m_{00}},\frac{m_{01}}{m_{00}})</script></li><li>连接图像0点$O$和质心$C$，得到一个方向向量$OC$，则特征点的方向可以定义为：<script type="math/tex; mode=display">\theta = \arctan (\frac{m_{01}}{m_{10}})</script></li></ol><p>通过这个方法，Fast角点就有了尺度和旋转的描述，从而提升了它描述不同图像时候的鲁棒性。这种改进成为Oriented FAST。</p><p>此外,ORB特征点的另一个改进是对BREIF描述子的改进。</p><p>BREIF描述子是一种二进制描述子，其描述向量由许多个0和1组成，这里0和1编码了关键点附近两个像素（$p,q$）的大小关系：如果$p&gt;q$则为1，否则为0。如果我们取了127对这样的点，就得到了128维的二进制向量。p,q的选取一般会按照某个概率分布随机选取，速度很快。</p><p>原始的BREIF不具有旋转不变性。但是由于Oriented Fast有了方向，可以利用方向信息，计算旋转之后的“steer BRIEF”特征，使得ORB的描述子具有比较好的旋转不变性。</p><h3 id="特征匹配"><a href="#特征匹配" class="headerlink" title="特征匹配"></a>特征匹配</h3><p>特征匹配可以说是SLAM中至关重要的一步，因为SLAM中的路标，在不同帧之间的位置，就是通过特征匹配完成的。如果特征匹配的好，可以大大减少后续姿态估计，优化等操作的负担。然而，由于图像中重复纹理等等原因，误匹配的情况一直得不到非常好的解决，仅仅利用局部特征解决误匹配是非常困难的。</p><p>不过对于一般的图像，我们还是可以通过一些办法消除一些错误的匹配。到后面我们可以知道，其实我们只需要较少的几个特征点就能得到比较好的效果，因此尽管很多消除误匹配的算法会使得很多正确的匹配也被剔除了，但是依然是够用的。</p><p>匹配的办法有多种，最简单的是暴力匹配，就是与另一幅图的特征点一个个对比，来得到相似度最高的那个特征点。一般这个相似度差了多少，我们用距离来衡量，距离越远相似度越低。距离的定义可以有多种，如果是浮点数，我们可以求欧式距离，对于ORB的二进制描述子，我们用Hamming距离来衡量，而汉明距离实际上就是二进制码中不同位数的个数。</p><p>当特征点数量很大的时候，暴力匹配的速度变得很慢。这时候，可以使用FLANN（快速近似最近邻算法库）来实现匹配。这些算法已经非常成熟，可以去翻看相关论文来了解它具体的内容。</p><h3 id="实践：特征提取和特征匹配"><a href="#实践：特征提取和特征匹配" class="headerlink" title="实践：特征提取和特征匹配"></a>实践：特征提取和特征匹配</h3><p>下面有一个利用OpenCV提取ORB特征值并且进行匹配的程序，来总结这么一段关于ORB的内容。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/features2d/features2d.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(argc!=<span class="number">3</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Usage:feature_extraction img1 img2"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//Load Image</span></span><br><span class="line">    Mat img1 = imread(argv[<span class="number">1</span>]);</span><br><span class="line">    Mat img2 = imread(argv[<span class="number">2</span>]);</span><br><span class="line">    <span class="comment">//store keypoint</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;KeyPoint&gt; kp1,kp2;</span><br><span class="line">    <span class="comment">//store descriptors</span></span><br><span class="line">    Mat descriptors1, descriptors2;</span><br><span class="line">    Ptr&lt;ORB&gt; orb = ORB::create(<span class="number">500</span>,<span class="number">1.2f</span>,<span class="number">8</span>,<span class="number">31</span>,<span class="number">0</span>,<span class="number">2</span>,ORB::HARRIS_SCORE,<span class="number">31</span>,<span class="number">20</span>);</span><br><span class="line">    <span class="comment">//get keypoints</span></span><br><span class="line">    orb-&gt;detect(img1,kp1);</span><br><span class="line">    orb-&gt;detect(img2,kp2);</span><br><span class="line">    <span class="comment">//compute the descriptors</span></span><br><span class="line">    orb-&gt;compute(img1,kp1,descriptors1);</span><br><span class="line">    orb-&gt;compute(img2,kp2,descriptors2);</span><br><span class="line">    Mat outimg1,outimg2;</span><br><span class="line">    <span class="comment">//highlight keypoint on the image </span></span><br><span class="line">    drawKeypoints(img1,kp1,outimg1,Scalar::all(<span class="number">-1</span>),DrawMatchesFlags::DEFAULT);</span><br><span class="line">    drawKeypoints(img2,kp2,outimg2,Scalar::all(<span class="number">-1</span>),DrawMatchesFlags::DEFAULT);</span><br><span class="line">    imshow(<span class="string">"img1"</span>,outimg1);</span><br><span class="line">    imshow(<span class="string">"img2"</span>,outimg2);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//use Hamming distance to match </span></span><br><span class="line">    <span class="built_in">vector</span>&lt;DMatch&gt; matches;</span><br><span class="line">    <span class="function">BFMatcher <span class="title">matcher</span><span class="params">(NORM_HAMMING)</span></span>;<span class="comment">//maybe the dist have been normalized</span></span><br><span class="line">    matcher.match(descriptors1,descriptors2,matches);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//filter the wrong match(the distance is larger than double min distance)</span></span><br><span class="line">    <span class="comment">//An empirical handling</span></span><br><span class="line">    <span class="keyword">double</span> mindist = <span class="number">1000000</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i!=matches.size();i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">double</span> dist = matches[i].distance;</span><br><span class="line">        <span class="keyword">if</span>(dist &lt; mindist) mindist = dist;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"min dist: "</span>&lt;&lt;mindist&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">if</span>(mindist &lt; <span class="number">20</span>) mindist = <span class="number">20</span>;</span><br><span class="line">    <span class="built_in">vector</span>&lt;DMatch&gt; good_matches;</span><br><span class="line">    <span class="keyword">for</span>( <span class="keyword">int</span> i = <span class="number">0</span>;i!=matches.size();++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(matches[i].distance &lt;= <span class="number">2</span>*mindist)</span><br><span class="line">            good_matches.push_back(matches[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//show the match</span></span><br><span class="line">    Mat img_match,img_good_match;</span><br><span class="line">    drawMatches(img1,kp1,img2,kp2,matches,img_match);</span><br><span class="line">    drawMatches(img1,kp1,img2,kp2,good_matches,img_good_match);</span><br><span class="line">    imshow(<span class="string">"All the matches"</span>,img_match);</span><br><span class="line">    imshow(<span class="string">"Good matches"</span>,img_good_match);</span><br><span class="line">    waitKey(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>对应的CMakeLists.txt:<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.2</span>)</span><br><span class="line"><span class="keyword">project</span>(feature_extraction)</span><br><span class="line"><span class="keyword">find_package</span>(OpenCV REQUIRED)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;OpenCV_INCLUDE_DIRS&#125;</span> )</span><br><span class="line"><span class="keyword">ADD_EXECUTABLE</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> feature_extraction.cpp)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> <span class="variable">$&#123;OpenCV_LIBS&#125;</span>)</span><br></pre></td></tr></table></figure></p><p>这个代码中剔除错误匹配的用的剔除掉大于2倍最小距离的特征点，这更多是一个经验上的做法。此外还有RANSAC（随机采样一致）等算法，以及二者结合等等，可能得到更好的剔除效果。我曾经写过一个SIFT提取和匹配的算法，在剔除中用到了ransac算法，是一个VS工程：<a href="https://github.com/MyEvolution/feature_match_sift" target="_blank" rel="noopener">feature_match_sift</a>。有兴趣的可以看一下，其实我也忘得差不多了。</p><p>最后的结果：</p><ul><li>特征提取<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/orb1.png" alt=""></li><li>特征匹配<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/orb2.png" alt=""></li><li>过滤后的特征匹配<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/orb3.png" alt=""></li></ul>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> feature </tag>
            
            <tag> computer vision </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Hypothesis Testing</title>
      <link href="/2018/12/11/Learning-From-Data%E2%80%94%E2%80%94Hypothesis-Testing/"/>
      <url>/2018/12/11/Learning-From-Data%E2%80%94%E2%80%94Hypothesis-Testing/</url>
      
        <content type="html"><![CDATA[<p>上周讲的内容，和之前一样，从无到有推出来一堆东西。老师在白板上写Statistical Learning, Hypothesis Testing，当然是有关系的，但是这届课讲得内容应该只是上述二者的一小部分。比较神奇的是，最后竟然推到了VC Divergence。Amazing!<br><a id="more"></a></p><h2 id="Binary-Hypothesis-Testing"><a href="#Binary-Hypothesis-Testing" class="headerlink" title="Binary Hypothesis Testing"></a>Binary Hypothesis Testing</h2><p>假设$Y = \{0,1\}$，数据是以$P(X|Y=0)$或者$P(X|Y=1)$生成（iid）出来。</p><p>定义下面的表示：</p><script type="math/tex; mode=display">P_X(X) = P(X|Y=0),Q_X(X) = P(X|Y=1)</script><p>我们观察的是一个数据序列$X=\{x_1,x_2,…,x_n\} \in X^n$，长度为n的序列，判断它是以哪个hypothesis生成的($H_0$或者$H_1$).其中：</p><script type="math/tex; mode=display">H_0: X~iid,P_X(X) = P(X|Y=0),P_0 = P(Y=0);\\H_1: X~iid,Q_X(X) = P(X|Y=1),P_1 = P(Y=1).</script><p>上式中，$P_０,P_1$为先验分布(<a href="https://en.wikipedia.org/wiki/Prior_probability" target="_blank" rel="noopener">Prior Distribution</a>)。</p><p>要做到这件事，我们需要做的就是最小化做出错误决定（decision error probability）的概率。</p><p>如何做出决定其实不难理解，由下面的式子：</p><script type="math/tex; mode=display">P[H_0|(x_1,...,x_n)]  > P[H_1|(x_1,...,x_n)] \rightarrow H_0;\\P[H_0|(x_1,...,x_n)]  < P[H_1|(x_1,...,x_n)] \rightarrow H_1.\\</script><p>不过这个想要从数据中计算出这个值并不容易，而想要计算出$P[(x_1,…,x_n)|H_0]$是很容易的。还好我们有贝叶斯公式（Bayes’s Rule）:</p><script type="math/tex; mode=display">P[H_0|(x_1,...,x_n)] = \frac{P_X(x_1)...P_X(x_n)P_0}{P(x_1,...,x_n)}</script><p>同理我们可以得到：</p><script type="math/tex; mode=display">P[H_1|(x_1,...,x_n)] = \frac{Q_X(x_1)...Q_X(x_n)P_1}{P(x_1,...,x_n)}</script><p>根据这个来决定哪个Hypothesis，称为MAP Decision Rule。最后我们整理一下得到：</p><script type="math/tex; mode=display">\frac{P_X(x_1)}{Q_X(x_1)}...\frac{P_X(x_n)}{Q_X(x_n)} > \frac{P_1}{P_0} \rightarrow H_0;\\\frac{P_X(x_1)}{Q_X(x_1)}...\frac{P_X(x_n)}{Q_X(x_n)} < \frac{P_1}{P_0} \rightarrow H_1.</script><p>为了简化，我把上面两行写成一行，大于或者小于写成$?$.</p><p>学习机器学习到现在，对于上面的式子第一个反应当然是加$\log$，得到log-likelihood function：</p><script type="math/tex; mode=display">\sum_{i=1}^n \log \frac{P_X(x_i)}{Q_X(x_i)} ? \log \frac{P_1}{P_0}</script><p>这时候我们得到一个minimal <a href="https://en.wikipedia.org/wiki/Sufficient_statistic" target="_blank" rel="noopener">sufficient statistic</a>.</p><p>所以在已知$P_X(X),Q_X(X),P_0,P_1$的情况下，这个问题是很好解决的。</p><h2 id="M-Hypothesis-Testing"><a href="#M-Hypothesis-Testing" class="headerlink" title="M-Hypothesis Testing"></a>M-Hypothesis Testing</h2><p>我们将上面的２元情况拓展到$M$元，实际上这个结果并没有什么改变。</p><p>现在假设$Y = \{1,…,M\}$，我们有下面的Hypothesis:</p><div class="table-container"><table><thead><tr><th style="text-align:center">Hypothesis</th><th style="text-align:center">x</th><th style="text-align:center">$P_{X\vert Y}(X\vert Y=?)$</th><th style="text-align:center">$P(Y=?)$</th></tr></thead><tbody><tr><td style="text-align:center">$H_1$</td><td style="text-align:center">$x\sim  iid$</td><td style="text-align:center">$P_1(X)$</td><td style="text-align:center">$ P_1$</td></tr><tr><td style="text-align:center">$\vdots$</td><td style="text-align:center">$\vdots$</td><td style="text-align:center">$\vdots$</td><td style="text-align:center">$\vdots$</td></tr><tr><td style="text-align:center">$H_M$</td><td style="text-align:center">$x\sim  iid$</td><td style="text-align:center">$P_M(X)$</td><td style="text-align:center">$ P_M$</td></tr></tbody></table></div><p>计算$P[H_i|(x_1,…,x_n)]$，而实际上：</p><script type="math/tex; mode=display">P[H_i|(x_1,...,x_n)] = \frac{P_i(x_i)...P_i(x_n)P(Y=i)}{P(x_1...x_n)}</script><p>接下来的步骤和之前一样，注意在做决定的时候选择的策略一样有OVA,OVO两种。上面介绍的这种算是OVA。</p><h2 id="Error-Probability-Of-Optimal-Decision"><a href="#Error-Probability-Of-Optimal-Decision" class="headerlink" title="Error Probability Of Optimal Decision"></a>Error Probability Of Optimal Decision</h2><p>就二元的情况来说，发生的错误可能有两种：</p><ul><li>Type 1: $H_0$是对的，选择了$H_1$</li><li>Type 2: $H_1$是对的，选择了$H_0$</li></ul><p>这两种不同类型的错误在不同的场景下有不同的名字。</p><p>为什么会选错？实际上选错是因为，它是由$H_0$生成的，但是它却更像$H_1$生成的，也就是经验分布是$Q_x(X)$，而实际分布是$P_X(X)$。因此出现错误Type 1的概率为：</p><script type="math/tex; mode=display">P(\text{empirical distribution of }(x_1,...,x_n)\text{ is }Q_x|{x_1,...,x_n}\sim P_x)</script><p>如何计算上面的概率？我们考虑的是当$n$非常大的时候比较理想的情况。这时候，如果Hypothesis 0是正确的，假如$X$有ｋ个取值分布为1到k，定义$q_i = Q_X(i)$，则序列中出现i的个数的期望值为$nq_i$，而Hypothesis 1滋生出这样序列的概率为：</p><script type="math/tex; mode=display">P = \prod_{i=1}^kP_x^{nq_i}(i) = e^{\sum_{i=1}^k nq_i \log P_x(i)}</script><p>一共又有多少种这样可能的序列？答案是：</p><script type="math/tex; mode=display">\begin{align}C_n^{nq_1}C_{n-nq_1}^{nq_2}...C_{n-nq_1-...-nq_{k-1}}^{nq_k}&= \frac{n!}{(nq_1)!...(nq_k)!}\\&\approx \underbrace{\frac{\sqrt{2\pi n}}{\prod_{i=1}^k \sqrt{2\pi n q_i}} }_{\alpha}\cdot \underbrace{\frac{n^n}{(nq_1)^{nq_1}...(nq_k)^{nq_k}}}_{\beta}\end{align}</script><p>从(1)到(2)，是使用了<a href="https://en.wikipedia.org/wiki/Stirling%27s_approximation" target="_blank" rel="noopener">Stirling’s Formula</a>:</p><script type="math/tex; mode=display">n! \approx \sqrt{2\pi n} (\frac{n}{e})^n.</script><p>在(2)中，由于$\alpha$与$\beta$相比之下几乎是可以忽略的，因此我们专注于后者：</p><script type="math/tex; mode=display">\begin{aligned}\beta &= \frac{n^n}{(nq_1)^{nq_1}...(nq_k)^{nq_k}}\\&= \frac{1}{q_1^{nq_1}...q_k^{nq_k}}\\&= \exp(-\sum_{i=1}^k nq_i\log q_i)\\&= e^{nH(Q)}\end{aligned}</script><p>非常神奇，一个熵出现了。</p><p>因此我们可以得到：</p><script type="math/tex; mode=display">\begin{aligned}&P(\text{empirical distribution of }(x_1,...,x_n)\text{ is }Q_x|{x_1,...,x_n}\sim P_x)\\&= \beta \times P\\&= \exp(-\sum_{i=1}^k nq_i\log q_i) \cdot \exp(\sum_{i=1}^k nq_i \log P_x(i))\\&= \exp(-n\sum_{i=1}^k q_i\log q_i + n\sum_{i=1}^k q_i \log P_x(i))\\&= \exp(-n\sum_{i=1}^k q_i\log \frac{q_i}{P_x(i)})\\&= \exp(-n D(Q_x\Vert P_x))\end{aligned}</script><p>KL-Divergence出现了！这个就是Chernoff Stein Lemma:<br>给定错误2$\leq \alpha$，则错误1~$ \exp(-n D(Q_x\Vert P_x))$. 实际的数学推导是非常复杂的，这里只是大概给个直观的解释。详细请参考：<br><a href="https://www.icg.isy.liu.se/courses/infotheory/lect7-3.pdf" target="_blank" rel="noopener">Chernoff-Stein Lemma</a></p><p>这更像是一节信息论的课。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LFD class </tag>
            
            <tag> statistical learning </tag>
            
            <tag> hypothesis testing </tag>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数学——KKT condition</title>
      <link href="/2018/12/07/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94KKT-condition/"/>
      <url>/2018/12/07/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94KKT-condition/</url>
      
        <content type="html"><![CDATA[<p>实际上，之前的文章中已经多次提到了KKT条件，比如机器学习中<a href="https://wlsdzyzl.top/2018/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Dual-Support-Vector-Machine/" target="_blank" rel="noopener">SVM</a>，以及信息论中<a href="https://wlsdzyzl.top/2018/11/27/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E9%81%93%E5%8F%8A%E5%85%B6%E5%AE%B9%E9%87%8F/" target="_blank" rel="noopener">信道容量</a>.但是都是具体问题下的kkt条件。这次来概括说明下，纯数学中的kkt条件。<br><a id="more"></a><br>要说KKT条件，是离不开lagrange multiplier，也就是拉格朗日乘数法。这是在求约束极值下一个非常重要的方法，可以参考：<a href="https://wlsdzyzl.top/2018/10/09/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Lagrange-Multiplier/" target="_blank" rel="noopener">lagrange multiplier</a>。</p><p>那么什么是KKT条件呢？</p><p>对于目标函数$f:\mathbb{R}^n \rightarrow \mathbb{R}$，约束函数$g_i: \mathbb{R}^n \rightarrow \mathbb{R}$,$h_j: \mathbb{R}^n \rightarrow \mathbb{R}$,如果他们在点$x^*$都是连续可微的，且$x^*$是一个局部最优解,那么需要满足下面几个条件：</p><ul><li>stationary<ul><li>for maximizing $f(x):\nabla f(x^*) = \sum_{i=1}^m\mu_i\nabla g_i(x^*)+ \sum_{j=1}^n\lambda_i\nabla h_j(x^*)$</li><li>for minimizing $f(x):-\nabla f(x^*) = \sum_{i=1}^m\mu_i\nabla g_i(x^*)+ \sum_{j=1}^n\lambda_i\nabla h_j(x^*)$</li></ul></li><li>primal feasibility<ul><li>$g_i(x^ *) \leq 0$, for $i=1,…,m$</li><li>$h_j(x^ *) = 0$, for $j=1,…,n$</li></ul></li><li>Dual feasibility<ul><li>$\mu_i &gt; 0$, for $i=1,…,m$</li></ul></li><li>complementary slackness<ul><li>$\mu_ig_i(x^*)=0$, for $i=1,…,m$.</li></ul></li></ul><p>这几个条件就是KKT条件。如果$m=0$，可以看到的就是高数中的条件极值问题，也就是约束为$h_i(x)=0$.</p><p>这几个条件是怎么得到的？什么道理？实际上之前的SVM中说明了。假如我们要minimize，那么约束条件可以转化为dual problem：</p><script type="math/tex; mode=display">\min_{\mu_i,\mu_i \ge 0} (\max (f(x)+\sum_{i=1}^m \mu_i g_i(x) + \sum_{j=1}^n \lambda_j h_j(x) ))</script><p>为了让上面的式子和有约束的情况下一样，我们需要保证$\mu_i \ge 0$,因为我们需要让上式满足这个约束$g_i(x) \ge 0$。加入有$x_{\theta},g_i(x_{\theta})&gt;0$,那么在$\max$这一步会将它放至无限大，导致$min$的时候它一定不会被选到。所以$\mu_i \ge 0$是dual feasibility，而primal feasibility也很好理解，也就是那些约束。</p><p>至于complementary slackness, 也是很好理解的。如果解上式，$g_i(x)&lt;0$最终会得到$u_i=0$，因此得到$\mu_ig_i(x^*)=0$.</p><p>而stationary也就是对对偶问题两侧求导并得0得到的条件。</p><p>在凸函数上，满足KKT条件是就是最优解，也就是充要条件，否则只是最优解的必要条件。</p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mathematics </tag>
            
            <tag> KKT </tag>
            
            <tag> Convex optimization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Multivariate ACE</title>
      <link href="/2018/12/05/Learning-From-Data%E2%80%94%E2%80%94Multi-Dimensional-ACE/"/>
      <url>/2018/12/05/Learning-From-Data%E2%80%94%E2%80%94Multi-Dimensional-ACE/</url>
      
        <content type="html"><![CDATA[<p>上节课除了说了softmax与HGR，还介绍了ACE算法的拓展：多变量下的ACE。<br><a id="more"></a><br>之前的ACE是从两个变量$X,Y$之间的信息推导出来的，而这次要拓展到d个变量。可以看到的是，这时候我们没有把哪个变量当作标签了，因此这是非监督学习。实际上我认为之前的ACE也可以说是非监督学习。分析到信息论层面非监督学习和监督学习联系到一起了，它们之间的界限变得比较模糊了。</p><p>现在，有ｄ个离散变量：$X_1,X_2,…,X_d$.类似于之前，我们要做的是：</p><script type="math/tex; mode=display">\max \mathbb{E}[\sum_{ i \ne j} f_i(X_i) f_j(X_j)]\\s.t. \mathbb{E}[f_i(X_i)] = 0, \mathbb{E}[f_i^2(X_i)] = 1</script><p>这时候的$\mathbb{E}[f_i(X_i) f_j(X_j)] = \Psi_i^T B_{ij} \Phi_j$.这里的$B_{ij}$表示的是一个矩阵：</p><script type="math/tex; mode=display">B_{ij,x_i,x_j}  \frac{p_{X_iX)j}(x_i,x_j)}{\sqrt{p_{X_i}(x_i)p_{X_j}(x_j)}},B_{|X_j| \times |X_i|},B_{ij,|X_i| \times |X_j|}.</script><p>而定义$B$矩阵为：</p><script type="math/tex; mode=display">B_{|X_1|+...+|X_m| \times|X_1|+...+|X_m|  } = \begin{bmatrix}0&B_{12}&\cdots&B_{1d}\\B_{21}&0&\cdots&B_{2d}\\\vdots&\vdots&\ddots&\vdots\\B_{d1}&B_{d2}&\cdots&0\end{bmatrix}</script><script type="math/tex; mode=display">\Psi = \begin{bmatrix}\Psi_1^T,\Psi_2^T,...,\Psi_d^T\end{bmatrix}^T\\\Phi = \begin{bmatrix}\Phi_1^T,\Phi_2^T,...,\Phi_d^T\end{bmatrix}^T</script><p>$\mathbb{E}[\sum_{i \ne j} f_i(X_i)f_j(X_j)] = \Psi ^T B \Phi $<br>由于：</p><script type="math/tex; mode=display">\mathbb{E}[f_i(X_i) f_j(X_j)] = \Psi_i^T B_{ij} \Phi_j= \Phi_j^T B_{ji} \Psi_i = \mathbb{E}[f_j(X_j) f_i(X_i)] = \Psi_j^T B_{ji} \Phi_i</script><p>所以我们可以得到：$\Phi_i = \Psi_i$，也就是对于每个变量我们只需要学习一个函数$f_i(X_i)$即可。</p><p>下面是多变量ACE算法的过程：</p><ol><li><p>选择$f = {f_1,f_2,…,f_g}$，这些函数为normalize后的函数</p></li><li><p>$f_i(x_i) \leftarrow \mathbb{E}[ \sum_{j\ne i}f_j(X_j)|X_i = x_i]$ </p></li><li><p>normalize. $f_i(X_i) \leftarrow \frac{f_i(X_i)}{\mathbb{E}\left[ \sum_{i=1}^d f_i^2(X_i)\right]}$</p></li></ol><p>直到最后收敛。</p><p>现在我想说明，实际上如果限定f为线性映射，那么得到的结果实际上就是PCA算法。</p><p><a href="https://wlsdzyzl.top/2018/11/19/Learning-From-Data%E2%80%94%E2%80%94PCA/" target="_blank" rel="noopener">PCA</a>想做的是：</p><script type="math/tex; mode=display">\max \frac{1}{n} \sum_{i=1}^n(X_i^Tu)^2</script><p>而：</p><script type="math/tex; mode=display">\begin{aligned}\frac{1}{n} \sum_{i=1}^n(X_i^Tu)^2 &= \frac{1}{n} \sum_{i=1}^m(\sum_{j=1}^d x_{ij} \mu_j)^2\\&= \frac{1}{n} \sum_{i=1}^n (\sum_{j=1}^d x_{ij}^2 \mu_j^2 + 2\sum_{j \ne q} \underbrace{(x_{ij}\mu_j)}_{f_j(x_ij)}\underbrace{(x_{iq}\mu_q)}_{f_q(x_iq)}) \end{aligned}</script><p>由于normalize, 我们可以使得：</p><script type="math/tex; mode=display">\frac{1}{n}\sum_{i=1}^n \sum_{j=1}^d x_{ij}^2 \mu_j^2 =\sum_{j=1}^d \frac{1}{n}\sum_{i=1}^n  x_{ij}^2 \mu_j^2 = \sum_{j=1}^d \mathbb{E}[f_j^2(X_j)]= d</script><p>而：</p><script type="math/tex; mode=display">\frac{1}{n} \sum_{i=1}^n \sum_{j \ne q} \underbrace{(x_{ij}\mu_j)}_{f_j(x_ij)}\underbrace{(x_{iq}\mu_q)}_{f_q(x_iq)}) = \mathbb{E}[\sum_{j \ne q}f_j(X_j)f_q(X_q)]</script><p>而这正是MACE在做的事情。不过PCA只能发现线性关系，因此它要求f为线性映射。</p><p>更多细节请参考：</p><p><a href="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_pdf/An%20information-theoretic%20approach%20to%20unsupervised%20feature%20selection%20for%20high-dimensional%20data_196602880.pdf" target="_blank" rel="noopener">An Information-theoretic Approach to Unsupervised<br>Feature Selection for High-Dimensional Data</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> ACE </tag>
            
            <tag> PCA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——derive something from Softmax</title>
      <link href="/2018/12/05/Learning-From-Data%E2%80%94%E2%80%94derive-something-from-Softmax/"/>
      <url>/2018/12/05/Learning-From-Data%E2%80%94%E2%80%94derive-something-from-Softmax/</url>
      
        <content type="html"><![CDATA[<p>这周的数据学习课更不知道该起什么题目了。主要是加上一些假设，从Softmax函数开始推导，最后得到一个非常简单的形式，从而大大简化了算法。这次的derivation和上篇讲得东西还是有一些相关的。<br><a id="more"></a></p><h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><p>首先回顾一下上篇博客介绍的内容，从HGR maximal correlation开始推导。依然是离散变量$X$与$Y$。不过稍微做点拓展，我们在提取ｘ，ｙ的信息时，把他们映射到一个ｋ维度的向量，也就是：</p><script type="math/tex; mode=display">f(x) \rightarrow \mathbb{R}^k,g(x) \rightarrow \mathbb{R}^k.</script><p>这时候，和之前一样，做一些推导吧。这时候的相关系数变成了相关矩阵：</p><script type="math/tex; mode=display">\max ρ_{XY}=\max 𝔼 p_{XY}[f(x) g(y)^T]</script><p>我们的约束变成：</p><script type="math/tex; mode=display">\mathbb{E}[f (x)] = \mathbb{E}[ g(y)] = \mathbf{0}\\\mathbb{E}[ f^2(x)] = \mathbb{E}[ g^2(y)] = I_{k \times k}</script><p>问题描述变为：</p><script type="math/tex; mode=display">\begin{aligned}\max \Psi^T B \Phi,s.t. &\langle\sqrt{P_X},\Phi\rangle = \langle\sqrt{P_Y},\Psi\rangle = \mathbf{0};\\&\Phi^T \Phi  =  \Psi^T \Psi  = I_{k \times k}.\end{aligned}</script><p>其中：</p><script type="math/tex; mode=display">\Phi = \begin{bmatrix}\phi(x_1),\phi(x_2),...,\phi(x_{|X|})\end{bmatrix}^T_{|X|\times k},\\\Psi = \begin{bmatrix}\psi(y_1),\psi(y_2),...,\psi(y_{|Y|})\end{bmatrix}^T_{|Y|\times k},\\B_{y,x} =  \frac{p_{XY}(x,y)}{\sqrt{p_X(x)p_Y(y)}},B_{|Y| \times |X|}.</script><p>而这时候的$\Phi$与$\Psi$实际上是由Ｂ的第$2，…,k+1$右左特征向量组成:</p><script type="math/tex; mode=display">\Phi = \begin{bmatrix}\upsilon_2,...,\upsilon_{k+1}\end{bmatrix}\\\Psi = \begin{bmatrix}\mu_2,...,\mu_{k+1}\end{bmatrix}</script><p>$f(x)=\frac{\phi(x)}{\sqrt{p_X(x)}} ,g(y) = \frac{\psi(y)}{\sqrt{p_Y(y)}}$.</p><h2 id="HGR-amp-Softmax"><a href="#HGR-amp-Softmax" class="headerlink" title="HGR &amp; Softmax"></a>HGR &amp; Softmax</h2><p>假设$X,Y$是离散的，并且几乎独立(weakly dependent),也就是$p_{XY}(xy) - p_{X}(x)p_{Y}(y)$非常小。</p><p>还记得softmax function:</p><script type="math/tex; mode=display">Q_{Y|X}(y|X) = \frac{e^{X^TW_y + b_y)}}{\sum_{y' \in \mathcal{Y}} e^{X^TW_{y'}+b_{y'}}}</script><p>在这里，我们把$X,Y$再次进行信息提取，分布为$f(X),g(Y)$. 由于$W_y$与Y值相关，我们可以将$W_y$看作是g(y)。因此写成更通用的形式：</p><script type="math/tex; mode=display">\begin{aligned}Q_{Y|X}(y|x) &= \frac{e^{f^T(x)g(y) + b(y)}}{\sum_{y' \in \mathcal{Y}}e^{f^T(x)g(y')+b(y')}}\\&= \frac{p_Y(y)e^{f^T(x)g(y) + b(y) - \log p_Y(y)}}{\sum_{y' \in \mathcal{Y}}p_Y(y')e^{f^T(x)g(y')+b(y') - \log p_Y(y)}}\end{aligned}</script><p>现在我们定义：$d(y) \triangleq b(y)-\log p_Y(y)$，则：</p><script type="math/tex; mode=display">Q_{Y|X}(y|x) = \frac{p_Y(y)e^{f^T(x)g(y) + d(y)}}{\sum_{y' \in \mathcal{Y}} p_Y(y')e^{f^T(x)g(y')+d(y')}}</script><p>可以看到，如果$f = g = d =  0$，$Q_{Y|X}(y|x) = p_Y(y)$.</p><p>由于我们的假设可以知道,$p_Y(y) \approx Q_{Y|X}(y|x)$，则$f^T(x)g(y)+ d(y) \approx 0$,根据泰勒展开:</p><script type="math/tex; mode=display">\begin{align}e^{f^T(x)g(y) + d(y)} \approx 1 + f^T(x)g(y)+ d(y)\end{align}</script><p>而:</p><script type="math/tex; mode=display">\begin{aligned}\sum_{y' \in \mathcal{Y}} p_Y(y')e^{f^T(x)g(y')+d(y')} &\approx \sum_{y' \in \mathcal{Y}} p_Y(y')[ 1+f^T(x)g(y')+d(y')]\\&= 1 + f^T(x)\sum_{y' \in \mathcal Y} p_Y(y')g(y') + \sum_{y' \in \mathcal Y}p_Y(y')d(y')\\&= 1 +f^T(x)\mathbb{E}_Y[g(Y) ] + \mathbb{E}_Y[d(Y) ] \end{aligned}</script><p>而由泰勒展开$\frac{1}{1+x} \approx  1-x$得到：</p><script type="math/tex; mode=display">\begin{align}\frac{1}{\sum_{ y'\in \mathcal{Y}} p_Y(y' )e^{f^T(x)g(y' )+d(y' )}} \approx 1 -f^T(x)\mathbb{E}_Y[g(Y )] -\mathbb{E}_Y[d(Y )]\end{align}</script><p>结合上面的(1),(2)，我们得到：</p><script type="math/tex; mode=display">\begin{aligned}Q_{Y|X}(y|x) &= \frac{p_Y(y)e^{f^T(x)g(y) + d(y)}}{\sum_{y' \in \mathcal{Y}} p_Y(y')e^{f^T(x)g(y')+d(y')}}\\&\approx p_Y(y)(1 + f^T(x)g(y)+ d(y) )( 1 -f^T(x)\mathbb{E}_Y[g(Y )] -\mathbb{E}_Y[d(Y )])\\& \approx p_Y(y)[1 + f^T(x)g(y) +d(y) - f^T(x)\mathbb{E}_Y[g(Y) ] - \mathbb{E}_Y[d(Y) ]]\\&= p_Y(y)[1+f^T(x)(g(y)-\mathbb{E}_Y[g(Y) ]) + (d(y) - \mathbb{E}_Y[d(Y) ])]\end{aligned}</script><p>现在我们令$\tilde{g}(y) = g(y) - \mathbb{E}_Y[g(Y)]，s.t. \mathbb{E}_Y[\tilde {g}(Y)] = 0$.得到：</p><script type="math/tex; mode=display">Q_{Y|X}(y|x) = p_Y(y)[1+ f^T(x)\tilde g (y) + \tilde d (y)]</script><p>现在我们利用这个式子构建$empirical risk$，实际上也就是$-\frac{1}{n} \sum_{i=1}^n \log Q_{Y|X}(y_i|x_i)$.最小化经验风险(empirical risk)实际上也就是最大化$\mathbb{E}_{p_{XY}} [ Q_{Y|X}(y|x)]$，也是极大似然估计。</p><script type="math/tex; mode=display">\begin{aligned}\log Q_{Y|X}(y|x) &= \log p_Y(y) + \log (1+ f^T(x)\tilde{g}(y) + \tilde{d} (y))\\& \approx \log p_Y(y) + f^T(x)\tilde{g}(y) + \tilde{d}(y) -  \frac{1}{2} [(f^T(x)\tilde{g}(y))^2 + \tilde{d^2}(y) + 2 f^T(x)\tilde{g}(y)\tilde{d}(y)]\end{aligned}</script><p>上述过程用到了泰勒展开：$\log(1+x) \approx x - \frac{x^2}{2}$.</p><p>$\mathbb{E}[\log Q_{Y|X}(Y|X)] = \mathbb{E}[\log p_Y(Y)] + \mathbb{E}[f^T(X)\tilde{g}(Y) ] + \mathbb{E}[\tilde{d}(Y) ] - \mathbb{E}[\frac{1}{2} [(f^T(X)\tilde{g}(Y))^2 + \tilde{d^2}(Y) + 2 f^T(X)\tilde{g}(Y)\tilde{d}(Y)]] $</p><p>现在，我们来说明一些必要的东西：由假设得到$p_{XY}(x,y) - p_X(x)p_Y(y) = \epsilon \cdot \square = o(\epsilon)$，$o(\epsilon)$表示$\epsilon$的无穷小量（这么说其实不准确，因为我们最后要最大化这种无穷小量，显然不合理，可以当作为衡量有多小的量级）。</p><p>因为<script type="math/tex">Q_{Y|X}(y|x) = P_Y(y)[1+f^T(x)\tilde{g}(y) + \tilde{d}(y)] \approx p_{Y},</script><br>同理可以得到$f^T(x)\tilde g (y)  = o(\epsilon),\tilde d (y) = o(\epsilon)$，我们假设对所有的$f,\tilde g,\tilde d$都进行了normalize，也就是$\mathbb{E}f = \mathbb{E}\tilde{g} = \mathbb{E}\tilde{d} = 0$,则：</p><ul><li><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}[f^T(X)\tilde g(Y) ] &= \sum_{x,y} p_{XY}(x,y)f^T(x)\tilde g(y)\\&= \sum_{x,y}(p_{X}(x)p_{Y}(y)f^T(x)\tilde g(y) + o(\epsilon)f^T(x)\tilde g(y))\\&= \sum_{x}p_{X}(x)f^T(x) \sum_{y}p_{Y}(y)\tilde g(y) + o(\epsilon^2)\\&= o(\epsilon^2).\end{aligned}</script></li><li><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}[(f^T(x)g(y) )^2] &= \sum_{x,y}p_{X}(x)p_{Y}(y)(f^T(x)\tilde g(y))^2 + \sum_{x,y} o(\epsilon)(f^T(x)\tilde g(y))^2\\&= \sum_{x,y}p_{XY}(x,y)(f^T(x)\tilde g(y))^2 + o(\epsilon^3)\end{aligned}</script></li><li><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}[f^T(x) \tilde{g}(y)\tilde{d}(y)] &= \sum_{x,y}p_{X}(x)p_Y(y) f^T(x)\tilde g (y) \tilde d (y) + o(\epsilon)\sum_{x,y}f^T(x)\tilde g (y) \tilde d (y)\\&= \sum_{x}p_{X}(x)f^T(x) \sum_{y}p_{Y}(y)\tilde g(y) \tilde d(y) + o(\epsilon^3)\\&=  o(\epsilon^3)\end{aligned}</script></li></ul><p>而我们知道$o(\epsilon^3)$在$o(\epsilon^2)$之前是可以被忽略的。因此最终：</p><script type="math/tex; mode=display">\mathbb{E}[\log Q_{Y|X}] = \mathbb{E}[\log p_Y(Y)] + \mathbb{E}[f^T(X) \tilde g (Y)] - \frac 1 2 \mathbb{E}[(f^T(X) \tilde g (Y))^2] - \frac{1}{2} \mathbb{E}[\tilde{d^2} (y)]</script><p>上式中，第一项为常数，最后一项为非负值，且与前面几项没有约束关系，因此为了最大化上式只需简单令$\frac{1}{2} \mathbb{E}[\tilde{d^2} (y)]=0$，因此最终我们要做的是：</p><script type="math/tex; mode=display">\max_{f,\tilde g} (\underbrace{\mathbb{E}[f^T(x)\tilde g(y)] - \frac{1}{2}\mathbb{E} [(f^T(x)\tilde g(y))^2]}_{\Delta})</script><p>如果我们将$ \mathbb{E}[f^T(x)\tilde g(y)] $对$f(x)$求导，可以得到：</p><script type="math/tex; mode=display">\frac{\partial \Delta}{\partial f(x)} = 0\\f(x) = \land ^{-1}_{\tilde g (Y)} \mathbb{E}[\tilde g(Y)|X = x]</script><p>其中$\land ^{-1}_{\tilde g (Y)}=(\mathbb{E}_{p_Y}[\tilde g(Y){\tilde g}^T(Y)])^{-1}$，也就是我们得到了最佳的$f,\tilde g$.</p><p>同理我们也得到：</p><script type="math/tex; mode=display">\tilde {g ^*}(y) = \land ^{-1}_{f(X)} \mathbb{E}[f(X)|Y = y]</script><p>也就是如果我们向softmax函数中喂入$f(x)$（形式固定）,那么softmax尽量在学的东西，也就是$W$实际上是$g^*$，当然不一定能成功学到这样的形式。</p><p>同样的，利用神经网络进行softmax可以看作是在寻找Ｘ的特征，它找到的最佳形式应该是$f*$.</p><p>简直是头大。实际上我不能保证这篇博客的正确性。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> softmax regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数学——EVD与SVD</title>
      <link href="/2018/11/28/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94EVD%E4%B8%8ESVD/"/>
      <url>/2018/11/28/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94EVD%E4%B8%8ESVD/</url>
      
        <content type="html"><![CDATA[<p>这个博客介绍特征值分解（Eigen Value Decomposition,EVD）和奇异值分解(Singular Value Decomposition),　可以当作机器学习的补充材料。<br><a id="more"></a><br>SVD在线性代数中是一个非常重要的东西。Strang曾经说过：它远远没有得到它应该有的名气。在考研的线性代数中也从来没有见过SVD的身影，不过在原来在做一些图像处理相关的程序时候，经常用到OpenCV中的SVD。</p><h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>SVD和对角化一个矩阵紧密连接在一起，回想一下，如果有一个实对称矩阵$A_{n \times n}$，则有一个正交矩阵$V$和一个对角矩阵$D$，使得$A = VDV^T$。这里$V$的每一列对应$A$的特征值，形成一个$\mathbb{R}^n$空间的正交基，而$D$的对角元素是$D$的特征值。这个就是EVD，eigenvalue decomposition。</p><p>对于SVD来说，我们有一个任意的实矩阵$A_{m \times n}$，有两个正交矩阵：$U$和$V$以及一个对角矩阵$\Sigma$，使得$A = U \Sigma V^T$。这种情况下，$U$是$m\times m$矩阵，而$V$是$n \times n$矩阵，因此$\Sigma$和$A$的形状一样，是$m\times n$，不过它只有对角元素非零。$\Sigma$的对角元素，$\Sigma_{ii} = \sigma_i$，可以被安排成非负以及递减的顺序，其中如果$\sigma_i&gt;0$，它是$A$的奇异值，而$U,V$的列向量分别是$A$的左右奇异向量。</p><p>我们可以把矩阵看作一个线性转换，通过这个想法来进一步发现EVD和SVD之间的相似之处。</p><h3 id="EVD"><a href="#EVD" class="headerlink" title="EVD"></a>EVD</h3><p>对于一个实对称矩阵$A$，这个转换把一个$\mathbb{R}^n$向量依然转换成$\mathbb{R}^n$为向量，也就是domain和codomain都是$\mathbb{R}^n$。另外提一下，假如转换后对应的元素为$T(x)$，则成$T(x)$为一个image，而所有image的集合称为$range$。$V$题提供了一个非常好的正交基，如果一个$\mathbb{R}^n$向量被这个正交基来表示，我们也可以看到，这个转换扩大了一些这个单位正交基中的成分，对应的就是较大的特征值$\sigma_i$。<br>我希望可以举个例子来帮助理解，假如向量$x \in \mathbb{R}^n$:</p><script type="math/tex; mode=display">\begin{aligned}Ax &= V \Sigma V^Tx\\&= \begin{bmatrix}v_1 & \cdots & v^n\\\end{bmatrix}\begin{bmatrix}\sigma_1 &\cdots& 0\\\vdots & \ddots & \vdots\\0 & \cdots & \sigma_n\end{bmatrix}\begin{bmatrix}v_1^T\\\vdots\\v_n^T\end{bmatrix}x \\&= \begin{bmatrix}\sigma_1v_1&\cdots&\sigma_nv_n\end{bmatrix}\begin{bmatrix}v_1^Tx\\\vdots\\v_n^Tx\end{bmatrix}\\&=\sigma_1v_1v_1^Tx + ...+ \sigma_nv_nv_n^Tx\end{aligned}</script><p>观察上面的展开，实际上我们可以发现的是，$V^TX$得到的，实际上是在$V$这个正交基下，$x$的“坐标值”，而$V\Sigma$实际上是经过转换后的坐标轴，放大了对应特征值的倍数。从这里，我们就可以很清楚得看到A这个转换在做什么。</p><h3 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h3><p>现在我们来看看，SVD的解释。同样我们把任意一个实矩阵$A$看作转换,它把$\mathbb{R}^n$向量，转化为$\mathbb{R}^m$，这意味着这个转换$domain$是$\mathbb{R}^n$，而$codomain$是$\mathbb{R}^m$，而image ∈ range ∈ $\mathbb{R}^m$。因此对于domain和range都搞一个单位正交基才是比较合理的，而$U,V$恰好提供了这样的基，分别用来表示domain的向量和range的向量。那么这个转换就和上面一样，变得比较容易理解了，它同样放大了一些成分，对应的是singular value的大小，同时抛弃了一些成分，对应的是singular value为0的方向。SVD告诉我们怎样选择正交基，使得转换被表示成最简单的方式————对角的形式。</p><p>那么我们如何选择得到这些基？想要使中间矩阵的形式是对角的，很容易，只要让$Av_i = \sigma_iu_i$即可。</p><p>为了理解这个，我们假设$m \geq n$，那么如果$A v_i = \sigma_i u_i$，则：</p><script type="math/tex; mode=display">\begin{aligned}AV &= A\begin{bmatrix}v_1&\cdots v_n \end{bmatrix}\\&= \begin{bmatrix}Av_1 & \cdots &Av_n\end{bmatrix}\\&= \begin{bmatrix}\sigma_1 u_1 & \cdots & \sigma_n u_n\end{bmatrix}\\&= U_{m\times n}\Sigma_{n\times_n} \end{aligned}</script><p>这保证了$\Sigma$的对角化，不过我们很容易发现的是上面的系数不对，$\mu$并不满足基的定义，它没有到达$m$个，而$\Sigma$也随之不是$m\times n$形状的矩阵。</p><p>如果我们先保证$V$是单位正交基了，那么$U_{m\times m}$中很多维度是没有什么意义的，因此将$U$扩充为基，并且将$\Sigma$矩阵也对上，对应的元素置0即可。</p><p>如果$m&lt; n$，则是一样的道理，只不过这个维度被$m$限制住了。而且实际上这个$\Sigma$还被$A$的秩限制住，毕竟$\mathbb{R}(AB)\ge \min (\mathbb{R}(A),\mathbb{R}(B))$，而$\mathbb{R}(U)=m,\mathbb{R}(V)=n$，这意味着，r如果要求各个$\sigma_i$不同且$U$为一组基，那么$\sigma_i &gt; 0;i = 1,…,k;k \ge \mathbb{R}(A)$.</p><p>通过上面的想法，我们很容易将A表示为对角形式。不过实际上，即使保证$V$是正交基，我们也很难保证$U$是正交的。因此使得V的正交性能在A下依然保存是非常关键的。而实际上，$A^TA$的特征矩阵正好满足这个条件。</p><p>$A^TA = VDV^T$，也就是对$A^TA$进行EVD。可以得到：</p><script type="math/tex; mode=display">Av_i \cdot Av_j = (Av_i)^T (Av_j) = v_i^TA^TA v_j = v_i^TA^T \lambda_j v_j = \lambda_j v_i v_j = 0</script><p>可以看到，在这种情况下，$\{Av_1,Av_2,…,Av_n\} = \{\sigma_1u_1,…,\sigma_nu_n\}$是互相是正交的，这正是我们想要的。而这个集合中的非零向量，形成了一个$A$的range的正交基。因此，$A^TA$的特征向量和它们与A得到的image，使得$A$可以被表示成对角形式。</p><p>我们继续把上面的分解补全。注意，如果$i = j$，那么$Av_i \cdot Av_j \Vert Av_i \Vert^2= \lambda_i$. 为了让$u_i$是单位向量，我们对其进行标准化：</p><script type="math/tex; mode=display">u_i = \frac{Av_i}{\Vert Av_i\Vert} = \frac{1}{ \sqrt{\lambda_i}} Av_i\\\sigma_i = \sqrt{\lambda_i}</script><p>我们也很容易推导，$\lambda_i \ge 0$的个数是$k$个，可以由秩得到。而$D$中特征值的顺序如果是按照从大到小的顺序排列，那么$\Sigma$中也是一样的递减顺序。</p><p>如果$k&lt; m$，那么将$U$扩展到正交基即可。这样我们就得到了想要的SVD。总结一下，V是$A^TA$的特征向量组成，被称为右侧的奇异向量，$\Sigma$由特征值组成，其中$\sigma_i = \sqrt{\lambda_i}$，而$U$是正交化$Av_i$的结果，有必要的话再进行拓展，使其成为一个正交基。</p><p>需要注意的一点是，我们在这里计算SVD是通过计算$A^TA$的特征值和特征矩阵，但是实际上还有其他的办法，在很多应用中SVD的实际用途是计算出$A^TA$的特征值和特征矩阵。</p><p>在我们的构造方法中，我们从$A^TA$的EVD来得到SVD，而实际上从SVD的角度出发，我们也很容易得到EVD，如果$A = U\Sigma V^T$：</p><script type="math/tex; mode=display">A^TA = V\Sigma^T U^T U \Sigma V^T = V \Sigma^T\Sigma V^T</script><p>可以很容易看到上面正是$A^TA$的EVD，同理也很容易得到：</p><script type="math/tex; mode=display">AA^T = U\Sigma V^TV \Sigma^T U^T = U \Sigma \Sigma^T U^T</script><p>这意味着实际上$U$正是由$AA^T$的特征向量组成的。值得一提的是，如果$A$是是对成矩阵，那么$A^2=A^TA=AA^T$，它们的EVD也是相同的，特征值为$\lambda^2$，其中$\lambda$为A的特征值，而且此时的SVD与EVD是等价的。</p><h2 id="SVD的几何意义"><a href="#SVD的几何意义" class="headerlink" title="SVD的几何意义"></a>SVD的几何意义</h2><p>我们可以通过对单位圆上的点利用A矩阵进行转换，来明白$A$是如何扭曲$\mathbb{R}^n$空间的。假如点x在单位圆(球)上，意味着$x = v_1x_1 + v_2x_2+…+v_nx_n$，其中$\sum_{i=1}^nx_i^2 = 1$，则:</p><script type="math/tex; mode=display">Ax = U\Sigma Vx = x_1\sigma_1u_1 + ...+ x_k\sigma_ku_k.</script><p>假设$y_i = \sigma_ix_i$，则单位球体的image也等于$\sum_{i=1}^k y_iu_i$，其中：</p><script type="math/tex; mode=display">\sum_{i=1}^k \frac{y_i^2}{\sigma_i^2} = \sum_{i=1}^k x_i^2 \ge 1.</script><p>如果$\mathbb{R}(A)= k = n$，那么上述不等式是相等的。其他情况下，意味着一些纬度被抛弃了。 所以$A$的转换实际上是先抛弃$n-k$个维度，将其压缩到$k$维，再通过$\Sigma$来对不同维度的权值进行放缩，最后拓展的$m$维空间。下图展示了这个过程(n=m=3,k=2)：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/G6T%7DO%5B7%5BIW70%5DP0VF2D%5DR89.png" alt=""></p><p>我们可以很容易得到，$\Vert A \Vert_2$，算子范数，定义为$\frac{\Vert Ax \Vert}{\Vert x \Vert}$的最大值，也就是$\sigma_1$，$A$最大的奇异值。也就是：$\Vert Ax \Vert \leq \sigma\Vert x \Vert,x \in \mathbb{R}^n$，当$x$为$v_1$的整数倍时等号成立。</p><h2 id="SVD的分块矩阵以及外积形式"><a href="#SVD的分块矩阵以及外积形式" class="headerlink" title="SVD的分块矩阵以及外积形式"></a>SVD的分块矩阵以及外积形式</h2><p>实际上，SVD可以写成下面分块矩阵的形式：</p><script type="math/tex; mode=display">A = \left [\begin{array}{ccc|ccc}u_1&\cdots&u_k&u_{k+1}&\cdots&u_n\end{array}\right ]\left [\begin{array}{ccc|c}\sigma_1&\cdots&0&0\\\vdots&\ddots&\vdots&\vdots\\0&\cdots&\sigma_k&0\\\hline0&\cdots&0&0\\\vdots&\vdots&\vdots&\vdots\end{array}\right]\begin{bmatrix}v_1^T\\\vdots\\v_k^T\\\hlinev_{k+1}^T\\\vdots\\v_{n}\end{bmatrix}</script><p>这个结果可以写成：</p><script type="math/tex; mode=display">\begin{aligned}A &= \begin{bmatrix}u_1&\cdots&u_k\end{bmatrix}\begin{bmatrix}\sigma_1&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&\sigma_k\end{bmatrix}\begin{bmatrix}v_1^T\\\vdots\\v_k^T\end{bmatrix} + \begin{bmatrix}u_{k+1}&\cdots&u_n\end{bmatrix}\begin{bmatrix}0&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&0\end{bmatrix}\begin{bmatrix}v_{k+1}^T\\\vdots\\v_n^T\end{bmatrix}\\&=\begin{bmatrix}u_1&\cdots&u_k\end{bmatrix}\begin{bmatrix}\sigma_1&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&\sigma_k\end{bmatrix}\begin{bmatrix}v_1^T\\\vdots\\v_k^T\end{bmatrix}\end{aligned}</script><p>上述形式是SVD的另一种表示：$A = U\Sigma V^T$，其中$U$为$m\times k,U^TU=I$，$\Sigma$为$k \times k$对角矩阵，对角元素大于0，$V$为$n \times k,V^TV = I$.</p><p>我们在这里的分块矩阵的公式和一般的矩阵乘积有点不一样，一般来说，两个矩阵相乘$XY$，我们关注的是$X$的行和$Y$的列。在这里，我们将用相反的方法表示。如果两个矩阵$X_{m \times k},Y_{k \times n}$,我们用$x_i$表示X中的第i列，用$y_i^T$表示Y中的第i行，那么：</p><script type="math/tex; mode=display">XY = \sum_{i=1}^k x_iy_i^T</script><p>而$x_i y_i^T$我们称为是这两个向量的外积（Outer Product），也就是矩阵中列乘上行的情况。</p><p>现在回到SVD中，令：</p><script type="math/tex; mode=display">X = \begin{bmatrix}u_1&\cdots&u_k\end{bmatrix}\begin{bmatrix}\sigma_1&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&\sigma_k\end{bmatrix} = \begin{bmatrix}\sigma_1u_1&\cdots&\sigma_ku_k\end{bmatrix}</script><p>以及：</p><script type="math/tex; mode=display">Y = \begin{bmatrix}v_1^T\\\vdots\\v_k^T\end{bmatrix}</script><p>可以得到：<script type="math/tex">A = XY = \sum_{i=1}^k\sigma_iu_iv_i^T.</script></p><p>这是SVD的另一种形式，它提供了A如何转换任何一个向量$x$的另一种解释。</p><script type="math/tex; mode=display">Ax = \sum_{i=1}^k\sigma_iu_iv_i^Tx = \sum_{i=1}^kv_i^Tx \sigma_iu_i</script><p>因为$v_i^Tx$是一个标量。</p><p>这个时候$Ax$被表达为$u_i$的线性组合。所以通过outer product expansion可以看到，通过A转换将x中每个$v_i$成分转换成$u_i$成分，并且以$\sigma_i$的系数放缩。</p><p>这篇博客基本上是下面文献的部分翻译，更多内容请看：<br><a href="https://evolution-video.oss-cn-beijing.aliyuncs.com/wlsdzyzl_pdf/SVD-%5BDan-Kalman%5D.pdf" target="_blank" rel="noopener">SVD</a></p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SVD </tag>
            
            <tag> mathmatics </tag>
            
            <tag> algebra </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——信道及其容量（一）</title>
      <link href="/2018/11/27/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E9%81%93%E5%8F%8A%E5%85%B6%E5%AE%B9%E9%87%8F%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2018/11/27/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E4%BF%A1%E9%81%93%E5%8F%8A%E5%85%B6%E5%AE%B9%E9%87%8F%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>这次来介绍信道以及信道的容量。<br><a id="more"></a></p><h2 id="信道容量的定义以及性质"><a href="#信道容量的定义以及性质" class="headerlink" title="信道容量的定义以及性质"></a>信道容量的定义以及性质</h2><h3 id="通信是什么"><a href="#通信是什么" class="headerlink" title="通信是什么?"></a>通信是什么?</h3><p>物理实体A的作用引发了物理实体B的状态变化，如果A与B的变化存在一致性，我们称AB通信成功。从信息角度来看，也就是比特流端到端的无差错复制。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/7RSY%7B%29157M%7EC%7BH0%298%403KF9V.png" alt=""></p><h3 id="信道的分类"><a href="#信道的分类" class="headerlink" title="信道的分类"></a>信道的分类</h3><h4 id="按照输入输出的形式以及时间取值来划分"><a href="#按照输入输出的形式以及时间取值来划分" class="headerlink" title="按照输入输出的形式以及时间取值来划分"></a>按照输入输出的形式以及时间取值来划分</h4><div class="table-container"><table><thead><tr><th style="text-align:center">取值</th><th style="text-align:center">时间</th><th style="text-align:center">信道分类</th></tr></thead><tbody><tr><td style="text-align:center">离散</td><td style="text-align:center">离散</td><td style="text-align:center">离散信道，数字信道</td></tr><tr><td style="text-align:center">连续</td><td style="text-align:center">离散</td><td style="text-align:center">连续信道</td></tr><tr><td style="text-align:center">连续</td><td style="text-align:center">连续</td><td style="text-align:center">模拟信道</td></tr><tr><td style="text-align:center">离散</td><td style="text-align:center">连续</td><td style="text-align:center">——</td></tr></tbody></table></div><h4 id="按照信道随机过程的特点分类"><a href="#按照信道随机过程的特点分类" class="headerlink" title="按照信道随机过程的特点分类"></a>按照信道随机过程的特点分类</h4><p>离散信道可以表示为n阶转移概率矩阵</p><script type="math/tex; mode=display">Q_{t_1t_2...t_n} = \left \{ q(y_{t_1t_2...t_n} | x_{t_1t_2...t_n}) \right\}</script><ul><li>无记忆信道<script type="math/tex; mode=display">q(y_{t_1t_2...t_n} | x_{t_1t_2...t_n}) = \prod_{i=1}^nq(y_i|x_i)</script></li></ul><p>无记忆信道不代表输出的符号不相关，这个和输入有关。</p><ul><li>平稳信道：<script type="math/tex; mode=display">q(y_i|x_i) = q(y|x)</script></li></ul><h3 id="DMC-Discrete-Memoryless-Channel"><a href="#DMC-Discrete-Memoryless-Channel" class="headerlink" title="DMC(Discrete Memoryless Channel)"></a>DMC(Discrete Memoryless Channel)</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/9LI8H%7DB%281P%5B_KI%409%5BRCI7%242.png" alt=""></p><p>我们知道：</p><script type="math/tex; mode=display">\begin{align}I(X^n;Y^n) = H(Y^n) - H(Y^n|X^n)\end{align}</script><p>接下来分析$ H(Y^n),H(Y^n|X^n)$:</p><script type="math/tex; mode=display">\begin{aligned}H(Y^n)&= H(Y_1) +H(Y_2|Y_1) +...+ H(Y_n|Y_1...Y_{n-1})\\&\leq \sum_{i=1}^n H(Y_i)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}H(Y^n|X^n)&= -\mathbb{E}_{XY}\log q(y^n|x^n) \\&= -\mathbb{E}_{XY}\log \prod_{i=1}^nq(y_1|x_1)\\&= - \mathbb{E}_{XY}\sum_{i=1}^n\log q(y_i|x_i)\\&= -\sum_{i=1}^n \mathbb{E}_{XY}\log q(y_i|x_i)\\&= \sum_{i=1}^n H(Y_i|X_i)\end{aligned}</script><p>将结果带入(1)，我们可以得到：</p><script type="math/tex; mode=display">I(X^n;Y^n) \leq \sum_{i=1}^nI(X_i;Y_i)</script><p>这让我们想到，对一个序列的输入输出互信息，我们可以试图通过处理单个时刻的输入，然后让等号取得，也就得到序列输入输出互信息的最大值。</p><p>为了让上面的等号取得，实际是比较简单，也就是当$Y_i$之间互相独立。下面我们来研究如何让单字母互信息得到最大值。</p><h3 id="信道容量定义"><a href="#信道容量定义" class="headerlink" title="信道容量定义"></a>信道容量定义</h3><p>对于离散无记忆信道，信道容量为：</p><script type="math/tex; mode=display">C = \max_{p(x)}I(X;Y) = \max_{p(x)}I(p,Q)</script><p>当一个信道确定时，$Q$也就确定了，因此我们要做的就是调整输入字母的分布，让这个信道输入输出互信息得到最大，也就得到了信道的容量。之前介绍互信息的时候介绍了$I(p;Q)$这种形式，就是为了方便信道的解释。</p><h2 id="离散无记忆信道的容量"><a href="#离散无记忆信道的容量" class="headerlink" title="离散无记忆信道的容量"></a>离散无记忆信道的容量</h2><p>现在来看一看最简单的信道：离散无记忆信道的容量应如何计算。这一小节主要通过举几个例子，然后再得到普遍的结论。</p><h4 id="无噪声二元信道"><a href="#无噪声二元信道" class="headerlink" title="无噪声二元信道"></a>无噪声二元信道</h4><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/int1.png" alt=""></p><p>输入X，输出Y。由于传输误差错，所以每次传输都传递了1 bit的无差错信息。所以直观来说信道容量为1 bit.</p><p>利用信道容量的定义来计算，则：</p><script type="math/tex; mode=display">C=\max I(X;Y) = \max(H(X) - H(X|Y)) = \max H(X) = 1\\p(X) = (0.5,0.5)</script><p>如果字符个数变成m个，则这个信道容量变为：$\log m$.</p><h4 id="输出不重叠的噪声信道"><a href="#输出不重叠的噪声信道" class="headerlink" title="输出不重叠的噪声信道"></a>输出不重叠的噪声信道</h4><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/int2.png" alt=""></p><p>观察上图，我们发现这个信道有下面几个特点：</p><ol><li>信道存在噪声，输出不确定</li><li>但是不确定性不影响正确估计输入</li><li>信道实际是无差错的</li><li>X到Y是一对多映射<script type="math/tex; mode=display">C = \max I(X;Y) = \max(H(X)-H(X|Y)) = \max(H(X))=1\\p(X) = (0.5,0.5)</script></li></ol><p>因此可以看到即时有噪声，我们依然可以得到无差错的信道传输。</p><h4 id="混乱打字机"><a href="#混乱打字机" class="headerlink" title="混乱打字机"></a>混乱打字机</h4><p>混乱打字机把每个字母以0.5的概率映射为其自身或者下一个字母。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/int5.png" alt=""></p><p>则：</p><script type="math/tex; mode=display">\begin{aligned}C &= \max I(X;Y)\\&= \max(H(Y) - H(Y|X))\\&= \max(H(Y)-1)\\&= \log 26 - 1 = \log 13\end{aligned}</script><p>我们只是在互信息求得这个，但是我们不一定能找到一个实际的概率控制得到这个容量。而实际上，这个容量是可以达到的。</p><p>我们要求输入端只能输入$A,C,E…$这些字母，它们均匀分布，而其他字符出现的概率为0，从而混乱打字机信道退化成了一个输出不重叠噪声信道，这称为无重叠约化。通过这个方法，我们实现了$\log13$的容量。实际上香农告诉我们，任何一种混乱的信道，都可以看作是混乱打字机信道。</p><h4 id="BSC-Binary-Symmetric-Channel"><a href="#BSC-Binary-Symmetric-Channel" class="headerlink" title="BSC(Binary Symmetric Channel)"></a>BSC(Binary Symmetric Channel)</h4><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/int3.png" alt=""></p><script type="math/tex; mode=display">\begin{aligned}C &= \max_{p(x)} I(X;Y)\\&=\max( H(Y) - H(Y|X))\\&=\max(H(Y) - H(p))\\&=1-H(p)\end{aligned}</script><p>我们必须证明这个容量可以取到,也就是一个上确界，这样得到信道的容量才有意义。为了让$H(Y)$最大，那么$p(Y)=(0.5,0.5)$,可以简单的发现这时候$p(X) = (0.5,0.5)$.也就是我们可以通过调制信源的输入概率分布得到这个最大的容量 因此$C_{BSC} = 1 - H(p)$</p><h4 id="EC-删除信道"><a href="#EC-删除信道" class="headerlink" title="EC(删除信道)"></a>EC(删除信道)</h4><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/int4.png" alt=""></p><script type="math/tex; mode=display">C = \max_{p(x)}I(X;Y)</script><script type="math/tex; mode=display">\begin{aligned}I(X;Y) &= H(Y) - H(Y|X)\\&=H(Y) - H(p)\\&\leq \log 3 - H(p)\end{aligned}</script><p>这时候我们就遇到问题了，我们不能通过调制信源的输入概率分布使得$p(Y)=(\frac{1}{3},\frac{1}{3},\frac 1 3)$，因此上面得到的不是信道容量。因此重新计算这个容量,假设$p(X) = (\pi,1-\pi)$：</p><script type="math/tex; mode=display">\begin{aligned}I(X;Y) &= H(Y) - H(p)\\&= H((\pi(1-p),p,(1-\pi)(1-p))) - H(p)\\&= (1-p)H(\pi) + H(p) - H(p)\\&= (1-p)H(\pi)\end{aligned}</script><p>上式中用到了熵的可加性。这时候我们可以取到$H(\pi)=1$，因此得到$C = 1-p$.</p><h3 id="离散无记忆对称信道容量"><a href="#离散无记忆对称信道容量" class="headerlink" title="离散无记忆对称信道容量"></a>离散无记忆对称信道容量</h3><p>实际上，上面的几个信道有很多都属于离散无记忆对称信道。他们的特点是概率转移矩阵$Q$为对称矩阵，使得$H(Y|X)$可以由信道性质确定，大大简化了我们要思考的问题。</p><p>离散无记忆对称信道的定义：<br>若信道的概率转移矩阵的行互为置换，列互为置换，则该信道对称，如果行互为置换，各列之和相等，则该信道弱对称。</p><p>强对称：</p><script type="math/tex; mode=display">\begin{bmatrix}\frac 1 2&\frac 1 3& \frac 1 6\\\frac 1 6&\frac 1 2&\frac 1 3\\\frac 1 3&\frac 1 6&\frac 1 2\end{bmatrix}</script><p>弱对称：</p><script type="math/tex; mode=display">\begin{bmatrix}\frac 1 3 & \frac 1 6 &\frac 1 2\\\frac 1 3 & \frac 1 2 & \frac 1 6\end{bmatrix}</script><p>不管是强对称还是弱对称，他们都有一个好处，那就是$H(Y|X)$不会随着信源的概率分布而改变，是一个常数。</p><p>弱对称信道Q的容量为：$C=\log \vert Y\vert - H(Q的行向量对应的分布)$,容量在输入为等概分布时候取得。</p><p>而EC不是一个对称信道：</p><script type="math/tex; mode=display">Q = \begin{bmatrix}1-p & p & 0\\0 & p & 1-p \end{bmatrix}</script><h3 id="一般离散无记忆信道的容量"><a href="#一般离散无记忆信道的容量" class="headerlink" title="一般离散无记忆信道的容量"></a>一般离散无记忆信道的容量</h3><p>由于$I(p,Q)$是$p$的上凸函数，因此求信道容量实际上可以表述为一个约束的极值问题：</p><script type="math/tex; mode=display">\max _{p} I(p,Q)\\s.t. \sum_{x}p(x)=1;p(x)\ge 0</script><h4 id="kkt-condition"><a href="#kkt-condition" class="headerlink" title="kkt condition"></a>kkt condition</h4><p>设$f(x)$为定义在Ｎ维无穷凸集$S$,<br>$S=\{x = (x_1,x_2,…,x_N):x_i \ge 0,i=1,…,N\}$上的可微上凸函数，设$x^* = {x_1^*,…,x_N^*} \in S$，则$f(x)$在$x = x^*$达到$S$上的极大值的充要条件为：</p><script type="math/tex; mode=display">\frac{\partial f(x)}{\partial x_n}\lvert_{x = x^*} = 0,x_n^* > 0\\\frac{\partial f(x)}{\partial x_n}\lvert_{x = x^*} \leq 0,x_n^* = 0</script><p>我们称$x^*(x^*=(x_1^*,…,x_N^*),x_n^* &gt; 0)$为$S$的内点，而$\exists x_n^* = 0$时，$x^*$为$S$的边界点。</p><p>用图像来看的话会更容易理解：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0794.PNG" alt=""></p><p>上图为：</p><script type="math/tex; mode=display">\min f(x,y)=ax^2-b\log y,0< x <100,0< y <100</script><p>实际上的kkt条件比这个更严谨，可以参考：<a href="https://wlsdzyzl.top/2018/12/07/数学%E2%80%94%E2%80%94KKT-condition/" target="_blank" rel="noopener">kkt condition</a></p><p>由于它是一个凸函数下的充要条件，因此只要我们找到了一个点符合KKT条件，我们就可以称他为全局极值。</p><p>由KKT条件可以得到下面的关于信道容量的定理：</p><p>对于信道矩阵为$Q$的离散无记忆信道，其输入分布$p^*$能使互信息$I(p,Q)$取得最大值的充要条件是：</p><script type="math/tex; mode=display">I(X=x_k;Y) = C,p^*(x_k) > 0\\I(X=x_k;Y) \leq C,p^*(x_k)=0\\k \in {1,2,...,K}</script><p>其中$I(X=x_k;Y) = \sum_{j=1}^J q(y_j|x_k) \log \frac{q(y_j|x_k)}{p(y_j)}$,表示的是信源字母$x_k$传送的平均互信息。</p><p>当然我们拿到一个信道以后，不一定一定要通过这样的方法来求得信道容量，很多时候我们可以联系物理猜到最好的哪个情况。如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/int6.png" alt=""></p><p>我们可以很容易看出来1是最差的情况，因为它可能映射到三种结果，而0,２一样好，因此我们猜测：$p(x_1) = 0,p(x_2)=p(x_0)=0.5$，计算得到：</p><script type="math/tex; mode=display">I(X=x_0;Y) = I(X=x_2;Y)=0.75, I(X=x_1;Y) = 0.0251<0.75</script><p>符合kkt条件，因此它的容量就是0.75.</p><h2 id="信道的组合"><a href="#信道的组合" class="headerlink" title="信道的组合"></a>信道的组合</h2><p>现在我们尝试将信道组合起来。</p><h3 id="级联的独立信道"><a href="#级联的独立信道" class="headerlink" title="级联的独立信道"></a>级联的独立信道</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0008it.jpg" alt=""></p><p>如上图，我们可以得到：</p><ul><li>由数据处理定理可以得到：$I(Y;Z) \ge I(X;Z)$</li><li>随着串联信道数目的增多，整个信道容量趋近于0</li><li>将级联信道的$Q_i$乘起来，得到整个级联信道的Q，可求解级联信道的容量</li><li>Vision：从统计的角度来看，数据处理不会带来信息增益，反而会损失信息<h3 id="输入并联信道"><a href="#输入并联信道" class="headerlink" title="输入并联信道"></a>输入并联信道</h3></li></ul><p>这个信道的特点是，输入相同的X，输出不同的$Y_1,Y_2,…,$构成随机矢量Y。也就是我们将输入X同时送到N个信道中，如图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0009it.jpg" alt=""></p><ul><li>输入并联信道的容量大于任何一个单独的信道，小于$\max H(X)$.</li><li>N个二元对称信道输入并联之后的信道容量，一般来说$N$越大，$C_N$越大，越接近于$H(X)$。</li><li>Vision:通信中的分集，就是典型的输入并联信道（我并不懂通信）</li></ul><h3 id="并用信道"><a href="#并用信道" class="headerlink" title="并用信道"></a>并用信道</h3><p>并用信道的图和并联信道非常像，不过它的输入不是相同的$X$了，而是将$X$费解成了$X_1,X_2,…,X_N$。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0009it.jpg" alt=""></p><ul><li>多输入，多输出。$X$和$Y$是由比侧独立的N个信道传输</li><li>并用信道的容量：$C = \sum_{n=1}^N C_n$</li><li>Vision:通信中的复用，就是典型的并用信道</li></ul><p>虽然并用信道的容量结论很简单，但是在实际中的操作没那么容易。我们不能简单的将信源随意划分，而是让这个划分符合各个信道容量的噪声特性，以达到最好的传输效果。</p><h3 id="和信道"><a href="#和信道" class="headerlink" title="和信道"></a>和信道</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0011it.jpg" alt=""></p><p>和信道和并联信道并用信道不同的是，虽然它有多个信道，但是它并不是同时使用多个，而是每次只使用一个。</p><ul><li>随机应用$N$个信道中的一个，构成一个输入输出信道。</li><li>和信道的容量：$C = \log \sum_{n=1}^N 2^{C_n}$，信道的使用概率$p_n(C) = 2^{C_n - C}$</li><li>Vision: 新型通信技术——机会通信<br>要注意这个结论有点反直觉。我们可能会想，如果某个信道的容量大，一直使用它不就行了吗？但是这样并不会得到最大的信道容量。</li></ul><p>举个例子，如果一个信道的转移矩阵为$Q$:</p><script type="math/tex; mode=display">Q = \begin{bmatrix}1 - \epsilon_1&\epsilon_1&0&0\\\epsilon_1&1 - \epsilon_1 & 0 & 0 \\0&0&\epsilon_2 &1 - \epsilon_2\\0&0&1-\epsilon_2&\epsilon_2\end{bmatrix}</script><p>那么这个信道的容量为多大？</p><p>如果仔细观察，可以发现这个信道实际上是一个和信道。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/it1.png" alt=""></p><script type="math/tex; mode=display">C = \log(2^{C_1} + 2^{C_2})</script><p>如果：<br>$\epsilon_1 = 0,C_1 = 1;\epsilon_2 = 0,C_2 = 0$;</p><p>可以发现，这两个信道一个容量为0,另一个为1,而它们的和信道容量为$\log3&gt;1$。这是因为在选择使用哪个信道的时候，也包含了一定的信息。</p><h2 id="连续信道的容量"><a href="#连续信道的容量" class="headerlink" title="连续信道的容量"></a>连续信道的容量</h2><p><strong>连续信道</strong>时间依旧离散，取值是连续的。这就引发了一个问题：连续随机变量互信息非负但是不一定有限，如果输入输出相等，则此时互信息是无穷的。<br>这样，互信息最大值为信道容量的定义就失去了意义。</p><h3 id="容量费用函数"><a href="#容量费用函数" class="headerlink" title="容量费用函数"></a>容量费用函数</h3><p>首先说明一下，连续信道输入连续，输出连续，而信道特性不能再用一个概率转移矩阵来表示，而是一个概率密度函数。所以我们用三元组$\{X,q(y|x),Y\}$来表示一个连续信道。</p><p><strong>费用函数</strong>: 设对于连续无记忆信道$\{X,q(y|x),Y\}$，有一个函数$b(.)$，对于每一个输入序列$X = x_1x_2…x_n$，$b(x)&gt;0$。称$b$为$X$的费用。设随机矢量$X = X_1X_2…X_n$的联合分布为$p(x)$，则平均费用为：</p><script type="math/tex; mode=display">\mathbb{E}[b(X)] \triangleq \sum_{x}p(x)b(x)</script><p>在费用约束的前提下，求输入输出互信息的最大值，得到<strong>容量费用函数</strong>：<br>设连续信道的$N$维联合输入输出分别为$X,Y$，则其容量－费用函数定义为：</p><script type="math/tex; mode=display">C(\beta) = \lim_{N\rightarrow \infty} \frac{1}{N} \max_{p(x)}\{I(X;Y):\mathbb{E}[b(X)]\leq N \beta \}</script><h3 id="连续无记忆加性噪声信道的容量"><a href="#连续无记忆加性噪声信道的容量" class="headerlink" title="连续无记忆加性噪声信道的容量"></a>连续无记忆加性噪声信道的容量</h3><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/it3.png" alt=""></p><p>这里我们来看一个最简单的连续信道的容量费用函数。这个信道为加性噪声信道。也就输入$X$加上某个$Z$得到$Y$。</p><p>在这种情况下：<script type="math/tex">q(y|x) = P_Z(y-x) = P_Z(z).</script></p><p>我们希望求得的是：</p><script type="math/tex; mode=display">C(P_S) = \max_{p(x):\mathbb{E}_X[X^2] \leq P_S} I(X;Y) = \max_{p(x):\mathbb{E}_X[X^2] \leq P_S} [h(Y) - h(Z)].</script><p>（这里的$\mathbb{E}_X[X^2]$实际上是物理意义上均值为0的X的功率，因此这个约束是功率的约束）<br>之所以能得到上面的结论，因为：</p><script type="math/tex; mode=display">\begin{aligned}h(Y|X) &= -\iint_{XY}P_X(x)q(y|x) \log q(y|x) dxdy\\&=-\iint_{XZ}P_X(x)P_Z(z) \log P_Z(z) dxdz\\&= -\int_z P(z) \log P(z)dz \\&= h(Z)\end{aligned}</script><p>因此在这个情况下：$h(Y|X) = h(Z)$</p><h4 id="高斯噪声"><a href="#高斯噪声" class="headerlink" title="高斯噪声"></a>高斯噪声</h4><p>现在我们假设这个噪声为高斯噪声。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/it2.png" alt=""></p><p>则：</p><script type="math/tex; mode=display">\mathbb{E}[Y^2] = \mathbb{E}[(X+Z)^2] = \mathbb{E}[X^2]+\mathbb{E}[Z^2] = P_S+P_Z</script><p>如果回顾<a href="https://wlsdzyzl.top/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E8%BF%9E%E7%BB%AD%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%86%B5%E5%92%8C%E4%BA%92%E4%BF%A1%E6%81%AF/" target="_blank" rel="noopener">连续随机变量的熵和互信息</a>，我们可以得到：</p><script type="math/tex; mode=display">\max_{p(x):\mathbb{E}[x^2]\leq P_S}h(Y) = \frac 1 2 \log 2\pi e(P_S+P_Z)</script><p>而$h(Z) = \frac 1 2 \log 2 \pi e P_Z$<br>而这时候，我们可以得到：</p><script type="math/tex; mode=display">\begin{aligned}C(P_S) &= \max(h(Y) - h(Z)) = \frac 1 2 \log \frac{P_S+P_Z}{P_Z} \\&=\frac 1 2 \log(1+\frac{P_S}{P_Z})\end{aligned}</script><p>上式中，$\frac{P_S}{P_Z}$也就是常说的信噪比。可以看到，如果想要增加容量，我们可以想方设法提高信源功率，或者减少噪声。这是一个非常重要的公式，拓展到模拟信道的情况上，我们就可以得到著名的香农公式。</p><p>实际上，对于高斯分布的输入，高斯噪声具有最大的破坏力。即，在同样的功率约束条件下，加性高斯噪声使得信道的容量最小。</p><p>对于无记忆加性噪声信道，若输入信号$X$具有高斯分布，加性噪声的功率为$P_N$，则当噪声具有高斯分布的时候，输入输出的互信息达到最小。</p><p>这一点并不难理解，因为噪声带来的影响在最终是要被去除的，而高斯情况下熵最大，去除的越多，留下的越少，所以使得信道容量最小。</p><h4 id="一般的无记忆加性噪声信道容量"><a href="#一般的无记忆加性噪声信道容量" class="headerlink" title="一般的无记忆加性噪声信道容量"></a>一般的无记忆加性噪声信道容量</h4><p>现在我们来看看一般的无记忆加性噪声的信道容量。</p><p>首先，我们必须明确，如果噪声是任意分布的，我们无法获得信道容量的解析解，但是我们可以给出其上界和下界。</p><ul><li>下界：<script type="math/tex; mode=display">\begin{aligned}C(P_S) &= \max_{P(X)} \{I(X;Y):\mathbb{E}[X^2] = P_S\}\\&\ge I(X_G;Y)\ge I(X_G;Y_G) = \frac 1 2 \log(1 + \frac{P_S}{P_Z})\end{aligned}</script></li></ul><p>因为上面我们已经得到了。高斯噪声的破坏力是最大的。</p><ul><li>上界：<script type="math/tex; mode=display">\mathbb{E}[Z^2] = P_N,\mathbb{E}[X^2] = P_S,\mathbb{E}[Y^2] = P_S+P_N\\h(Y)\leq \frac{1}{2}\log [2\pi e (P_s +P_N)]\\C(P_S) \leq h(Y) - h(Z) = \frac 1 2 \log[2\pi e \frac{P_S+P_N}{P_e}]\\</script>上式中：<script type="math/tex; mode=display">P_e \triangleq \frac 1 {2\pi e} \exp[2h(Z)]</script></li></ul><p>说实话，我并不知道这个定义是从何而来。而且$P_e$中还包含着$h(Z)$，又怎么能说是个上界呢？</p><h3 id="并联连续高斯信道"><a href="#并联连续高斯信道" class="headerlink" title="并联连续高斯信道"></a>并联连续高斯信道</h3><p>输入$X_n,P_{S_n}$，信道噪声$Z_n,P_{N_n}$.</p><p>在总功率限定的情况下，求信道容量-费用函数：</p><script type="math/tex; mode=display">C(P_S) = \sup_{P(X)}\{I(X;Y):\sum_{n=1}^N P_{S_n} = P_S\}</script><p>（这里的sup指的是Supremum，上确界）。</p><p>现在我们面临一个优化问题：</p><script type="math/tex; mode=display">\max I(X^n;Y^n) = \sum_i \frac{1}{2} \log (1+\frac{P_{S_i}}{P_{N_i}})</script><p>s.t. $\sum_{i=1}^n P_{S_i} = P_S,P_{S_i} \ge 0$</p><p>这个优化问题解决如下：</p><script type="math/tex; mode=display">\frac{\partial }{\partial P_{S_i}} \left[\sum_{i=1}^n \frac{1}{2} \log(1+\frac{P_{S_i}}{P_{N_i}})  - \lambda (\sum_{i=1}^n P_{S_i} - P_S)\right] = 0\\\frac{1}{2} \frac{P_{N_i}}{P_{S_i}+P_{N_i}} \frac{1}{P_{N_i}} - \lambda = 0, \text{for }1 \leq i \leq n\\P_{S_i} + P_{N_i} = \frac{1}{2\lambda_i}, \lambda = \frac{n}{2(P_S+P_N)}\\P_{S_i} = \frac{P_S+P_N}{n} - P_{N_i},</script><p>要注意，这里我们将信道个数总数写成了$n$，而$P_N$表示的是噪声功率。</p><p>有时候，我们发现，求得的$P_{S_i}$，也就是给该信道分配的功率是小于0的，这时候应该怎么办？</p><h4 id="注水功率"><a href="#注水功率" class="headerlink" title="注水功率"></a>注水功率</h4><p>下面介绍一个很形象的概念，叫注水功率。如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0013it.jpg" alt=""><br>可以看到的是，有的时候水是无法覆盖住某些地方的。这说明的是这个信道的噪声太大了，所以我们应该将其弃用。然后再重新计算这个功率的分配，直到没有负值。</p><h2 id="模拟信道容量"><a href="#模拟信道容量" class="headerlink" title="模拟信道容量"></a>模拟信道容量</h2><p><strong>模拟信道</strong>在时间和取值上都是连续的信道。是自然界最自然的一种信道，如电磁波，光纤，电缆等传播。</p><p>然而实际中模拟信道在数学上的研究是难以进行的。我们只研究最简单的一类模拟信道：AWGN信道。</p><h3 id="AWGN信道"><a href="#AWGN信道" class="headerlink" title="AWGN信道"></a>AWGN信道</h3><p>AWGN（Additive White Gaussian Noise）信道有下面几个特点：</p><ul><li>带宽有限：$W$</li><li>加性噪声：$y(t) = x(t) + z(t)$</li><li>白色噪声：平稳遍历随机过程，功率谱密度均匀分布于整个频域，即功率谱密度（单位带宽噪声功率）为一常数</li><li>高斯噪声：平稳遍历随机过程，瞬时值的概率密度函数服从高斯分布</li></ul><p>这个信道描述如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/it4.png" alt=""></p><p>输入信号：$x(t)$</p><ul><li>带宽有限：输入信号带宽限制在$[-W,W]内$</li><li>时间有限：T</li></ul><p>输出信号：$y(t)$</p><p>噪声信号：$z(t)$</p><ul><li>加性白色高斯噪声</li><li>零均值</li><li>双边功率谱密度：$N(f) = \left \{ \begin{matrix}<br>\frac{N_0}{2} &amp; \vert f\vert \leq W\\<br>0&amp;\vert f\vert &gt; W<br>\end{matrix}<br>\right .<br>$</li></ul><p>信道费用：输入信号的功率</p><h4 id="信号的正交分解"><a href="#信号的正交分解" class="headerlink" title="信号的正交分解"></a>信号的正交分解</h4><ul><li>由于信道频带受限，信号时长受限，所以仅需要$N = 2WT$个采样点就可以表示</li><li>因此信道在时间上可以被离散化为$2WT$个点，在每个点上取值连续</li><li>这样变成了并联的连续信道<br>实际上，上面的采样就是著名的<strong>奈奎斯特</strong>采样。</li></ul><p>之前我们说明了并联的连续信道的容量求法，但是前提是各个信道是独立的。现在我们必须要明白，经过采样的这$N = 2WT$个信道是否互相独立？</p><p>答案是独立的。为了验证他们的独立性，我们只需要验证它们不相关即可，因为在高斯分布下，不相关就意味着独立。证明如下：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0014it.jpg" alt=""><br>(额，这里也不是很懂。对于信号处理和通信方面的知识已经忘的差不多了)</p><p>对于$N$个信道，两两独立，每个噪声功率为$\frac{N_0}{2}$.</p><p>所以利用时域上采样定理将信号变成离散序列后，模拟信道可看成加性白色高斯噪声无记忆连续信道，相当于$N$个高斯加性信道的并联信道。这时候我们可以用注水功率来分配这个功率。</p><p>并联信道总容量费用函数$C_T(P_S) = \frac{1}{2} \sum_{n=1}^{2WT} \log (1+ \frac{P_{S_n}}{P_{N_n}})$</p><p>噪声约束：$P_{N_n} = \frac{N_0}{2} \rightarrow P_N = NP_{N_n} = 2WT\frac{N_0}{2} = WTN_0$</p><p>功率约束：（类似于注水功率分配）</p><script type="math/tex; mode=display">P_{S_n} = \frac{P_ST+P_N}{N} - P_{N_n} = \frac{P_ST+2WT\frac{N_0}{2}}{2WT}-\frac{N_0}{2} = \frac{P_S}{2W}</script><p>这时候，我们就得到了香农公式，AWGN信道的容量为：</p><script type="math/tex; mode=display">C = W \log (1+\frac{P_S}{N_0W})</script><p>上式中，各个量的单位为$C-bps,W-Hz$或者$s^{-1}$,$P_S-Watt,N_0-Watt/Hz$</p><h4 id="Vision-提升容量的各种手段"><a href="#Vision-提升容量的各种手段" class="headerlink" title="Vision:提升容量的各种手段"></a>Vision:提升容量的各种手段</h4><ul><li><p>增加带宽</p><script type="math/tex; mode=display">\lim_{W\rightarrow \infty}C(P_S) = \lim_{W\rightarrow \infty} \frac{P_S}{N_0}\log\left(1+\frac{P_S}{N_0W}\right)^{\frac{N_0W}{P_S}} = \frac{P_S}{N_0} \log e \approx 1.44\frac{P_S}{N_0}</script></li><li><p>增加带宽</p><script type="math/tex; mode=display">\lim_{P_S \rightarrow \infty} C(P_S) \approx \ln\left(\frac{P_S}{N_0W} \right)</script></li></ul><p>因此，对于同样容量的传输要求，可以采用两种方式：减少带宽，发送较大功率的信号，或者增加带宽，用较小功率的信号传输。</p><p>可以看到的是，我们可以不断增加带宽来增加信道容量，不过这个性价比会越来越低，因为这是一个log函数。</p><h4 id="Vision-信息与热力学的联系"><a href="#Vision-信息与热力学的联系" class="headerlink" title="Vision:信息与热力学的联系"></a>Vision:信息与热力学的联系</h4><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0005it.jpg" alt=""></p><p>这里有一个有意思的信息论角度对阿波罗登月的证伪，大家图一个乐，里面有很多假设和实际不符。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0006it.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Info between X and Y/SVD</title>
      <link href="/2018/11/27/Learning-From-Data%E2%80%94%E2%80%94Info-between-X-and-Y-SVD/"/>
      <url>/2018/11/27/Learning-From-Data%E2%80%94%E2%80%94Info-between-X-and-Y-SVD/</url>
      
        <content type="html"><![CDATA[<p>上一周的数据学习，没有课件，老师直接开始从头推了一些神奇的东西出来。所以我也很难给这篇的内容起一个题目，因为是从Ｘ与Ｙ之间的信息推导到SVD的，因此就这么叫吧。<br><a id="more"></a></p><h2 id="info-shared-Between-X-Y"><a href="#info-shared-Between-X-Y" class="headerlink" title="info shared Between X, Y"></a>info shared Between X, Y</h2><p>假如现在有两个离散变量，Ｘ与Ｙ他们是一一对应的。在之前的机器学习问题中，我们知道Ｘ是输入数据，Ｙ是标签。现在忘掉之前的学习算法，从信息的角度来看，我们希望做的，是提取Ｘ与Ｙ之间的公共信息，而这部分才是它们有某种关系的真正原因。因此现在我们的目标变成，从Ｘ与Ｙ的联合分布提取Ｘ与Ｙ之前的公共信息，。</p><p>那么首先遇到的问题：我们是如何提取Ｘ和Ｙ的各自的信息的？我们的做法是利用一个函数，就像linear regression等学习算法一样，也就是：</p><script type="math/tex; mode=display"> X \rightarrow f(X) \rightarrow \mathbb{R}\\ Y \rightarrow g(Y) \rightarrow \mathbb{R}\\</script><p>衡量它们之间的共同信息，我们使用一个比较熟悉的名词：相关系数。我们要做的就是找到合适的$f,g$函数，让它们的共同信息最大，也就是相关系数达到最大（HGR Maximal Correlation）：</p><script type="math/tex; mode=display">\max \rho_{XY} = \max \mathbb{E}_{p_{XY}} [f(x)g(y) ]</script><p>当然我们还有一些限制条件，才能让相关系数为上值。在概率论中我们知道，相关系数的求法：</p><script type="math/tex; mode=display">\begin{aligned}\rho_{XY} &= \frac{Cov(X,Y)}{\sqrt{Var (X) Var (Y)}}\\&= \frac{\mathbb{E}[XY ] - \mathbb{E}[X ] \mathbb{E}[Y ]}{ \sqrt{\mathbb{E}[X^2 ] - \mathbb{E}^2[X ]}}\end{aligned}</script><p>所以可以看到的是，我们应该让</p><script type="math/tex; mode=display">\mathbb{E}[f(x) ] = \mathbb{E}[g(x) ] = 0,\\\mathbb{E}[f^2(x) ] = \mathbb{E}[g^2(x) ] = 1</script><p>这时候，$0\leq\rho_{XY}\leq 1$.当$\rho_{XY} = 0$时，说明二者独立（要注意，这并不意味着E(XY) = 0说明Ｘ，Ｙ独立，实际上相关系数为0才能证明二者独立，只不过我们这里加上了限制，使得$\rho_{XY} = \mathbb{E}[f(x)g(x) ]$）。</p><p>现在，用数学语言来描述这个问题：</p><script type="math/tex; mode=display">\begin{align}\max \mathbb{E}_{p_{XY}} [f(x)g(y) ]& = \sum_{x,y}p_{XY}(x,y)f(x)g(y)\\s.t. &\sum_{x}p_X(x)f(x) = \sum_y p_Y(y)g(y) = 0\\ & \sum_{x}p_X(x)f^2(x) = \sum_y p_Y(y)g^2(y) = 1\end{align}</script><p>为了方便后面的计算，我们要对原式进行一些转换：</p><script type="math/tex; mode=display">\begin{aligned}(1)&= \sum_{x,y} \frac{p_{XY}(x,y)}{\sqrt{p_X(x)p_Y(y)}} [\underbrace{\sqrt{p_X(x)}\cdot f(x)}_{\phi(x)} \underbrace{\sqrt{p_Y(y)}\cdot g(y)}_{\psi(y)}]\\&= \sum_{x,y}  \frac{p_{XY}(x,y)}{\sqrt{p_X(x)p_Y(y)}} \phi(x) \psi(y) = \Psi^TB\Phi \end{aligned}</script><p>上式中：</p><script type="math/tex; mode=display">\Phi = \begin{bmatrix}\phi(x_1),\phi(x_2),...,\phi(x_{|X|})\end{bmatrix}^T_{|X|\times 1},\\\Psi = \begin{bmatrix}\psi(y_1),\psi(y_2),...,\psi(y_{|Y|})\end{bmatrix}^T_{|Y|\times 1},\\B_{y,x} =  \frac{p_{XY}(x,y)}{\sqrt{p_X(x)p_Y(y)}},B_{|Y| \times |X|}.</script><p>经过上面的转换，我们可以得到：</p><script type="math/tex; mode=display">\begin{aligned}(2): &\sum_{x} \sqrt{p_X{x}} \phi(x) = 0 \rightarrow \sqrt{P_X}^T \Phi = 0;\\&\sum_{y} \sqrt{p_Y{y}} \psi(y) = 0 \rightarrow \sqrt{P_Y}^T \Psi = 0;\end{aligned}</script><script type="math/tex; mode=display">(3): \Vert \Phi \Vert^2 = \Vert \Psi \Vert ^2 = 1</script><p>这时候我们的问题变成了：</p><script type="math/tex; mode=display">\begin{aligned}\max \Psi^T B \Phi,s.t. &\langle\sqrt{P_X},\Phi\rangle = \langle\sqrt{P_Y},\Psi\rangle = 0;\\&\Vert \Phi \Vert^2 = \Vert \Psi \Vert^2 = 1.\end{aligned}</script><p>而实际上，上面问题的解正是Ｂ矩阵的最大的奇异向量。</p><h2 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h2><p>接下来，想提一下，什么是奇异值分解(Singular Value Decomposition)：</p><script type="math/tex; mode=display">B = [u　][\Sigma][　v^T],</script><p>其中$u,v$的列向量为Ｂ的左右奇异向量。</p><p>而实际上，$\sqrt{P_X},\sqrt{P_Y}$正是Ｂ矩阵对应的最大的奇异向量。但是显然，我们是不能让它们作为$\Phi,\Psi$的值的，因为这个不满足约束(2):</p><script type="math/tex; mode=display">\langle\sqrt{P_X},\Phi\rangle = \langle\sqrt{P_X},\sqrt{P_X}\rangle = 1 \ne 0;\\\langle\sqrt{P_Y},\Psi\rangle = \langle\sqrt{P_Y},\sqrt{P_Y}\rangle =1 \ne 0.</script><p>不过，好的消息是，实际上$\Phi,\Psi$正是第二大的奇异向量。可以看出来，不同奇异向量是互相正交的，这个和上次说的PCA非常像。实际上，PCA和SVD是有千丝万缕的关系的。</p><p>从上面的分析，我们可以直接得到：</p><script type="math/tex; mode=display">f(x) = \frac{1}{\sqrt{p_X(x)}} \phi^*(x);\\g(y) = \frac{1}{\sqrt{p_Y(y)}} \psi^*(y)</script><p>那么接下来一个问题，如何直接从data中计算出来f,g？</p><p>想要解决上面的问题，首先考虑，如何计算Ｂ的奇异向量。有人说，matlab, openCV. 这里介绍一个简单的算法：Power Iteration.</p><p>首先，我们要知道的是，实际上求奇异值分解，也就是在做PCA(求特征向量和特征值)：</p><script type="math/tex; mode=display">B^TB = v \Sigma^T u^T u \Sigma v^T = v \Sigma^2 v^T,\\BB^T = u \Sigma v^T v \Sigma^T u^T =  u \Sigma^2 u^T</script><p>这里提下特征向量分解(EVD)：$X = v D v^T $, 其中$v$为$X$的特征向量组成的矩阵，而$D$为对角矩阵，对角元素为$X$的特征值，$X$为实对称矩阵。</p><p>所以可以不难得到，Ｂ的奇异向量，也就是$B^TB$与$BB^T$的特征向量，分别对应右侧的和左侧的奇异向量。</p><p>因此我们的问题变成了，如何求eigen vector？</p><h3 id="Power-Iteration"><a href="#Power-Iteration" class="headerlink" title="Power Iteration"></a>Power Iteration</h3><p>给定一个实对称矩阵Ｍ，假设$M = U \Sigma U^T$, 则假设它的特征向量为$\upsilon_1,\upsilon_2,…,\upsilon_n$，对应的特征值$\lambda_1,…,\lambda_n $.</p><ol><li>初始化得到一个向量$\mu_0$，则$\mu_0 = \alpha_1 \upsilon_1+…+\alpha_n \upsilon_n$.</li><li>$\mu_1 = \frac{M\mu_0}{\Vert M\mu_0 \Vert}$</li><li>迭代执行３，得到$\mu_n$</li></ol><p>最后这个算法收敛于最大的特征向量（前提是最大的特征值严格大于其他的特征值，并且初始向量在最大特征向量的方向上分量不为0，这两个条件都比较好满足）。</p><p>这个算法不难理解：</p><script type="math/tex; mode=display">\begin{aligned}\mu_k &=\frac{M \mu_{k-1}}{\Vert M \mu_{k-1} \Vert} \\&= \frac{M \frac{M\mu_{k-2}}{\Vert M \mu_{k-2}\Vert} }{ \Vert M \frac{M\mu_{k-2}}{\Vert M \mu_{k-2}\Vert}  \Vert  }\\&= \frac{M^2 \mu_{k-2}} {\Vert M^2 \mu_{k-2} \Vert}\\&= \frac{M^k \mu_0}{\Vert  M^k \mu_0\Vert}  \\&= \frac{M^k (\alpha_1 \upsilon_1+...+\alpha_n \upsilon_n)}{\Vert  M^k \mu_0\Vert}\\&= \frac{\alpha_1 \lambda_1^k \upsilon_1+...+\alpha_n \lambda_n^k \upsilon_n}{\Vert  M^k \mu_0\Vert}\\&= \frac{\alpha_1 \lambda_1^k (\upsilon_1+\frac{\alpha_2}{\alpha_1}\cdot \frac{\lambda_2^k}{\lambda_1^k} \upsilon_2+...+ \frac{\alpha_n}{\alpha_1}\cdot \frac{\lambda_n^k}{\lambda_1^k} \upsilon_n  )}{\Vert  M^k \mu_0\Vert}\end{aligned}</script><p>上式中$k \rightarrow \infty ,\frac{\lambda_i^k}{\lambda_1^k} \rightarrow 0,i\ne 1$，所以可以得到：</p><script type="math/tex; mode=display">M^k \mu_0 \rightarrow \alpha_1 \lambda_1^k \upsilon_1.</script><p>所以：</p><script type="math/tex; mode=display">\begin{aligned}\mu_k &= \frac{M^k \mu_0}{\Vert  M^k \mu_0\Vert} \\&\rightarrow  \frac{\alpha_1 \lambda_1^k \upsilon_1}{\Vert\alpha_1 \lambda_1^k \upsilon_1 \Vert}\\&= \frac{ \alpha_1 \lambda_1^k \upsilon_1}{\Vert \alpha_1 \lambda_1^k \Vert} \\&= \upsilon_1\end{aligned}</script><p>上面通过power iteration,　我们就得到了最大的特征向量。使用Gram Schmidt procedure，可以求得其他的特征向量。比较容易理解，找到一个已求向量垂直的向量进行Power Iteration，就可以求得第二大特征向量，特征向量从大到小依次被求出。</p><p>现在我们考虑，如何得到Ｂ矩阵的第二大奇异向量。</p><ol><li>选择$\Phi^{(0)}$</li><li>$\Psi^{(0)} = B\Phi^{(0)}$, $\Phi^{(1)} = B^T \Psi^{(0)}$</li><li>迭代第二步</li></ol><p>实际上第二步做的就是:</p><script type="math/tex; mode=display">\Phi^{(1)} = B^TB \Phi^{(0)}, \Psi^{(1)} = BB^T \Psi^{(0)}</script><p>也就是一直在利用Power Iteration迭代求解$B^TB$与$BB^T$的特征向量.</p><p>但是这个如果对初始的值不加以限制，求得的应该是第一大特征向量。如果$\Phi^{(0)} \perp \sqrt{P_X}$，则我们得到了第二大特征向量。</p><p>那么如何直接从数据求得f,g呢？终于到了终极问题。</p><p>上面有这么一个计算:$B\Phi$，实际上拆开的话，每一行就是ｙ固定之后的$p(x,y)$与$\Phi$相乘，我们记做$B \Phi (y)$:</p><script type="math/tex; mode=display">\begin{aligned}B \Phi(y) &= \sum_{x} B(y,x)\phi(x)\\&= \sum_x \frac{p_{XY}(x,y)}{\sqrt{p_X(x)p_Y(y)}} \cdot [\sqrt{p_X(x) f(x)}]\\&=\frac{1}{\sqrt{p_Y{y}}} \sum_x p_{XY}(x,y)f(x)\\&= \sqrt{p_Y(y)} \sum_x \frac{p_{XY}(x,y)}{p_{Y}(y)}f(x)\\&= \sqrt{p_Y(y)} \mathbb{E}[f(x)\vert Y = y] \end{aligned}</script><p>从上面的推导中，我们得到：$g(y) = \mathbb{E}[f(X)\vert Y=y ]$.</p><p>所以从原来的$ \Psi^{(0)} = B\Phi^{(0)} \rightarrow g^{(0)} = \mathbb{E}[f^{(1)}(x) \vert Y=y]$</p><h2 id="ACE算法"><a href="#ACE算法" class="headerlink" title="ACE算法"></a>ACE算法</h2><ol><li>选择<script type="math/tex">f^{(0)}(x), s.t. \mathbb{E}[f^{(0)}(X) ] = 0</script>(注意，这里<script type="math/tex">\mathbb{E}[f^{(0)}(X) ] = P_Xf_X(X) = \sqrt{P_X} \sqrt{P_X}f_X(X) = \sqrt{P_X}\Phi  = 0</script>，也就暗含了$\Phi\perp \sqrt{P_X}$)</li><li><ul><li>$g^{(0)}(y) = \mathbb{E}[f^{(0)}(x)\vert Y=y]$</li><li>$f^{(1)}(x) = \mathbb{E}[g^{(0)}(y)\vert X = x]$</li></ul></li><li>迭代２</li></ol><p>最后ｆ，ｇ都会收敛到最佳的结果。</p><p>这个算法被称为ACE（Alternative Conditional Expectation）算法，当然在实际过程中，我们可以每一步都进行normalize. 而第二步中，条件的ｘ和ｙ的值，有时候是随机选择，在数据量小的时候可以对所有的ｘ和ｙ都进行计算。</p><p>还有一点，如何计算$\mathbb{E}[f^{(i)}(x) \vert Y=y]$?</p><p>其实很简单：首先从$\{(x_1,y_1),…,(x_n,y_n)\}$中提取出来$\{(x_1,y_1),…,(x_k,y_k)\}$,使得$y_1 = … = y_k = y$,然后：</p><script type="math/tex; mode=display">\mathbb{E} = \frac{1}{k}\sum_{i=1}^kf^{(i)}(x_k)</script>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> mathematics </tag>
            
            <tag> SVD </tag>
            
            <tag> ACE </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Kernel PCA</title>
      <link href="/2018/11/20/Learning-From-Data%E2%80%94%E2%80%94Kernel-PCA/"/>
      <url>/2018/11/20/Learning-From-Data%E2%80%94%E2%80%94Kernel-PCA/</url>
      
        <content type="html"><![CDATA[<p>上次说了几个PCA的局限性，其中有一个是它只找各个特征之间的线性关系。如何拓展线性关系到非线性，似乎有点思路，因为之前SVM中说过，可以通过kernel将SVM拓展到非线性的分类。同样通过kernel，我们也可以找到特征之间的非线性关系，从而利用PCA进行数据压缩等操作。<br><a id="more"></a></p><p>对于线性的PCA的扩展，就是将PCA映射到更高维度的空间,使其在更高维度的空间有线性关系：$\phi:\mathbb{R}^n \rightarrow \mathbb{R}^d,d\ge n$.而如何映射，通过一个kernel函数来定义：$k(X_i,X_j) = \phi(X_i)^T\phi(X_j)$或者kernel矩阵$K \in \mathbb{R}^{m \times m}$. 映射完成后，我们就可以在更高维度的空间再使用标准的PCA算法了。不过这个想法是naive的，比如高斯核函数，是映射到无限维度，如果用原来的PCA去求，是不现实的。而且，从下面的分析可以看到，直接求也用不到kernel函数的方便之处。</p><p>映射后的数据的协方差矩阵如下：</p><script type="math/tex; mode=display">\Sigma = \frac 1 m  \sum_{i=1}^m \phi(X_i) \phi(X_i)^T \in \mathbb{R}^{d\times d}</script><p>假如$(\lambda_k,v_k),k=1,…,d$为$\sigma$的特征分解，则：</p><script type="math/tex; mode=display">\Sigma v_k = \lambda_k v_k</script><p>则原来$X_l$的在第k个主要成分的投影为：$\phi(X_l)^Tv_k$. </p><p>到目前位置，我们都没有用到kernel。$\phi(X_i)$是难以计算的，而kernel是容易计算的。因此如何避免$\phi_(X_i)$的计算？</p><p>首先我们知道：</p><script type="math/tex; mode=display">\begin{align}\Sigma v_k = \left (\sum_{i=1}^m \phi(X_i) \phi(X_i)^T \right ) v_k = \lambda _k v_k\end{align}</script><p>实际上，我们可以将$v_k$写成$\phi(X_i)^T$的组合（这个很像是之前的kernel logistic regression用的trick），这里就不证明为什么一定可以写成这个组合了，我觉得应该会用到线性代数的秩的知识。</p><script type="math/tex; mode=display">v_k = \sum_{i = 1} ^m \alpha_i^{(k)} \phi(X_i)</script><p>那么，之前提到的投影可以将上式带入：</p><script type="math/tex; mode=display">\begin{aligned}\phi(X_l)^Tv_k &= \phi(X_l)^T \sum_{i = 1} ^m \alpha_i^{(k)} \phi(X_i)\\&= \sum_{i=1} ^m \alpha_i^{(k)} \phi(X_l)^T\phi(X_i)\\&= \sum_{i=1} ^m \alpha_i^{(k)} k(X_l,X_i)\end{aligned}</script><p>这又引入了一个问题：如何得到$\alpha_i^{(k)}$?</p><p>将$v_k = \sum_{i = 1} ^m \alpha_i^{(k)} \phi(X_i)$带入(1)式,我们得到：</p><script type="math/tex; mode=display">\left[\sum_{i=1}^m \phi(X_i) \phi(X_i)^T \right] \left(\sum_{i=1}^m \alpha_i^{(k)} \phi(X_i) \right) = \lambda_k m \left(\sum_{i=1}^m \alpha_i^{(k)} \phi(X_i) \right)\\\Phi(X)^T \Phi(X) \Phi(X)^T \alpha^{(k)} = \lambda_k m  \Phi(X)^T \alpha^{(k)}\\\Phi(X) \Phi(X)^T \alpha^{(k)} = \lambda_k m \alpha^{(k)}\\K \alpha^{(k)} = \lambda_k m \alpha_k,</script><p>上式中：</p><script type="math/tex; mode=display">\alpha ^{(k)} = \begin{bmatrix}a_1^{(k)}\\\vdots\\a_m^{(k)}\end{bmatrix};\Phi(X) = \begin{bmatrix}\phi(X_1)^T\\\vdots\\\phi(X_m)^T\end{bmatrix} \\K = \begin{bmatrix}k(X_1,X_1)&k(X_1,X_2)&\cdots&k(X_1,X_m)\\k(X_2,X_1)&k(X_2,X_2)&\cdots&k(X_2,X_m)\\\vdots&\vdots\ &\ddots&\vdots\\k(X_m,X_1)&k(X_m,X_2)&\cdots&k(X_m,X_m)\end{bmatrix}</script><p>上式中$\alpha^{(k)}$可以通过求解K的特征向量得到，而K是kernel矩阵。</p><p>我们希望正交化$\alpha^{(k)}$，使得$v_k^Tv_k = 1$（与之前的标准PCA一致）.</p><script type="math/tex; mode=display">v_k^T v_k = (\alpha^{(k)})^T \Phi(X) \Phi(X)^T \alpha^{(k)} = \lambda_k m  ((\alpha^{(k)})^T \alpha^{(k)}).</script><p>所以$\Vert \alpha^{(k)} \Vert^2 = \frac{1}{\lambda_k m} $.</p><p>此外，如果$\mathbb{E}(\phi(X)) \ne 0$，我们还需要中心化$\phi(X)$:</p><script type="math/tex; mode=display">\tilde{\phi}(X_i) = \phi(X_i) - \frac 1 m   \sum_{l=1}^m \phi(X_i)</script><p>而中心化以后的kernel矩阵为：</p><script type="math/tex; mode=display">\tilde{k}(i,j) = \tilde{\phi}(X_i)^T \tilde{\phi}(X_j)</script><p>写成矩阵就是：</p><script type="math/tex; mode=display">\tilde{K} = K -1_m K - K 1_m + 1_mK1_m</script><p>其中：</p><script type="math/tex; mode=display">1_m = \begin{bmatrix}\frac 1 m & \cdots &\frac 1 m\\\vdots & \ddots & \vdots\\\frac 1 m & \cdots &\frac 1 m\end{bmatrix} \in \mathbb{R}^{m\times m}</script><p>我们从前面已经推导出来，计算kernel PCA的$v_k$最终需要的是kernel矩阵，因此使用$\tilde{K}$去计算PCA即可。</p><p>２个问题：</p><ol><li>之前的X不光是中心化的，而且还是Stdev(X) = 1,在kernel PCA中没有考虑这一点吗？</li></ol><p>对于kernel PCA的标准协方差分析是非常困难的。不过协方差的意义在于使得数据范围不会变动过大（如身高ｍ为单位，变化程度可能是１以内，而体重以斤为单位，变化范围为几十），因此如果对原数据进行协方差变0的操作后，假设kernel是对称的，它们的变化范围不会差得过多。</p><ol><li>$ａ^{(k)}$算出来有ｍ个，但是我们不一定把它映射到ｍ维度的空间了。不像原来的PCA，ｎ维有ｎ个特征向量？</li></ol><p>一般来说我们升维时候都会升到无限维度，很少有比ｍ小的。这时候它的特征向量个数就受到了数据个数的限制。如果维度比ｍ小，则特征向量不会真正达到ｍ个。</p><p>总结以下，kernel PCA的步骤：</p><ol><li><p>求出Ｋ</p></li><li><p>求出$\tilde{K}$</p></li><li><p>求出上面的特征值和特征向量，并且根据使得特征向量的长度等于$\frac {1}{\sqrt{\lambda_k m}}$，其中$\lambda_km$也就是对应的特征值。</p></li><li><p>根据求得的特征向量，求得$v_k$.</p></li></ol><p>Kernel PCA的例子：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/KPCA1.png" alt=""></p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/KPCA2.png" alt=""></p><p>kernel PCA经常用于聚类，异常检测等等。它需要找到$m \times m$的特征向量来代替$n \times n$。通过投影到k维主子空间进行降维通常是不可能的，也就是一般不用kernel PCA来进行数据压缩。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> unsupervised learning </tag>
            
            <tag> kernel </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——PCA</title>
      <link href="/2018/11/19/Learning-From-Data%E2%80%94%E2%80%94PCA/"/>
      <url>/2018/11/19/Learning-From-Data%E2%80%94%E2%80%94PCA/</url>
      
        <content type="html"><![CDATA[<p>上节课除了介绍了K-Means，更重点介绍了另外一个算法，PCA（Principal Component Analysis）。<br><a id="more"></a></p><p>PCA中文应该翻译为主要成分分析。这个翻译是直白的，我们也能很容易知道猜得到这个算法在做什么。</p><p>首先举个例子：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/PCA1.png" alt=""></p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/PCA2.png" alt=""></p><p>从上面看出来，有时候很多特征包含了很多的冗余信息。如拥挤程度和人流密度，就有很大的相关性。</p><p>我们需要消除这样的相关性，并且减少噪声。</p><h2 id="PCA描述"><a href="#PCA描述" class="headerlink" title="PCA描述"></a>PCA描述</h2><p>PCA算法的描述如下：</p><p>给定输入${X_1,X_2,…,X_m}，X_i \in \mathbb{R}$.找到输入的一个线性，正交转换W：$\mathbb{R}^n, \mathbb{R}^k$。W将最大方差方向与新空间的坐标轴对其。</p><p>如下图：左侧图片中，$x_1$与$x_2$是高度相关的，右侧图为转换过后的z，它几乎和水平坐标轴平行。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/PCA3.png" alt=""></p><h2 id="推导PCA"><a href="#推导PCA" class="headerlink" title="推导PCA"></a>推导PCA</h2><p>为了方便PCA的推导，我们首先会对数据进行预处理，也就是对其进行normalize,使得Mean(X) =0,Stdev(X) = 1:</p><script type="math/tex; mode=display">X_i := X_i - Mean(X) \leftarrow recenter\\X_i := X_i / Stdev(X) \leftarrow scale</script><p>Stdev(X)为标准偏差函数。</p><p>我们希望在输入中找到让各个样本变化最大的方向的主轴u（找到变分单位向量的主轴），如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/PCA7.png" alt=""></p><p>PCA的目标：</p><ol><li>找到互相正交的主要成分$u_1,u_2,…,u_n$，它们之间互不相关。</li><li>大多数X中的变化会被k个主要成分代表了，这里的$k &lt;&lt; n$.</li></ol><p>根据PCA的目标，我们可以分析PCA的主要步骤：</p><ol><li>找到X在某个向量上的投影，使得$u_1^TX$有最大的方差。</li><li>对于j=2,…n，继续上面的步骤，找到X在某个向量上的投影（与之前的向量正交），使得$u_j^TX$有最大的方差，再次强调：$u_j$与$u_1,…,u_{j-1}$正交。</li></ol><p>因为$\Vert u \Vert = 1$,则$X_i$在$u$上的投影长度为：$X_i^Tu$.而这些投影的方差计算结果如下：</p><script type="math/tex; mode=display">\begin{aligned}\frac 1 m \sum_{i=1}^m (X_i^T u)^2 &= \frac 1 m \sum_{i=1}^m u^TX_iX_i^T u \\&= u^T (\sum_{i=1}^m X_i X_i^T)u\\&= u^T \Sigma u \end{aligned}</script><p>这里的$\Sigma$是$X$的协方差矩阵。</p><p>找到单位向量$u_1$使得投影的方差最大，可以用数学语言描述如下：</p><script type="math/tex; mode=display">u_1 =  argmax_{u:\Vert u \Vert = 1} u^T\Sigma u</script><p>$u_i$是X的第i个主要成分。</p><p>如何求解$u_i$呢？首先，既然$u_i$要与之前的正交，因此这个求解顺序是从1到n。现在我们来分析$u_1$。</p><h4 id="命题1"><a href="#命题1" class="headerlink" title="命题1"></a>命题1</h4><p>$u_1$是协方差矩阵最大的特征向量(eigen vector)。</p><p>证明如下：</p><p>首先，根据数学描述构建Lagrange function：</p><script type="math/tex; mode=display">L(u) = -u^T \Sigma u + \beta (u^Tu - 1)</script><p>to minimize $L(u)$:</p><script type="math/tex; mode=display">\frac{\partial L(u)} {\partial u} = -\Sigma u + \beta u = 0</script><p>因此我们可以确定了u是一个$\Sigma$的特征向量。</p><p>同时,投影方差等于$u^T \Sigma u = u^T \beta u = \beta $.</p><p>为了让方差最大，也就是$\beta$最大。而最大的特征值对应这最大的特征向量。</p><h4 id="命题2"><a href="#命题2" class="headerlink" title="命题2"></a>命题2</h4><p>第j个X的主要成分，也就是$u_j$为$\Sigma$的第j个最大的特征向量。</p><p>为了简化问题，先写出第二个主要成分的数学描述：</p><script type="math/tex; mode=display">u = argmax_{u:\Vert u\Vert = 1;u_1^T u = 0} u^T \Sigma u</script><p>同样地构建Lagrange Function：</p><script type="math/tex; mode=display">L(u) = -u^T\Sigma u + \beta_1 (u^Tu-1 ) + \beta_2 (u_1^Tu)</script><script type="math/tex; mode=display">\frac{\partial L(u)} {\partial u} = -\Sigma u + \beta_1 u + \beta_2 u_1 = 0</script><p>上式中，我们知道两个互相正交的非零向量加起来不可能为0.所以得到：</p><p>$\beta_2 = 0, \Sigma u = \beta_1 u $</p><p>所以按照证明命题1同样的步骤，我们就证明了命题2中的第二个主要成分是成立的.</p><p>同样的证明方法可以继续拓展，$j=3,…,n$，都是成立的。</p><h2 id="PCA的性质"><a href="#PCA的性质" class="headerlink" title="PCA的性质"></a>PCA的性质</h2><p>从上面的推导，我们可以得到的PCA的下面几个性质：</p><ul><li>主要成分投影的方差分别为：</li></ul><p>$Var(X^Tu_j) = u_j^T \Sigma u_j = \lambda_j,j=1,2,…,n$</p><ul><li>不同方差的百分比$\frac {\lambda_j}{\sum_{i=1} ^n \lambda _i}$也就是主要成分的所占比重，也说明了各个主要成分之间是不相关的。</li></ul><h2 id="PCA投影"><a href="#PCA投影" class="headerlink" title="PCA投影"></a>PCA投影</h2><p>确定主要成分后，我们通过将原数据对主要成分投影来得到数据的压缩等效果。也就是：</p><p>$Z_i = [X_{i}^T u_1,X_i^T u_2,…,X_i^T u_n]$</p><p>使用矩阵形式：</p><script type="math/tex; mode=display">\begin{aligned}Z &= \begin{bmatrix}x_{1}^T&X_{2}^T&...&X_{m}^T\end{bmatrix}\begin{bmatrix} |&|&...&|\\u_1 & u_2& ... & u_n\\  |&|&...&|\end{bmatrix}&=XU\end{aligned}</script><p>或者$Z_i = U^TX_i$。</p><p>我们可以看出来，$Z_i$同样是n维度的。而截断转换$Z_k = XU_k$只保留前k个主要成分，用来做维度的压缩，因为前k个主要成分往往占了内容的大部分。</p><h2 id="PCA在做什么？"><a href="#PCA在做什么？" class="headerlink" title="PCA在做什么？"></a>PCA在做什么？</h2><p>PCA删除了输入X中的冗余数据：</p><p>如果经过转换后为Z，则 $cov(Z) = \frac 1 n Z^T Z = \frac 1 n (XW)^T (XW) = \frac 1 n W^T(X^TX)W  = \frac 1 n W^T\Sigma W$.</p><p>由于$\Sigma$是对称矩阵，因此它有实特征值。它的特征分解(eigen decomposition)为：</p><script type="math/tex; mode=display">\Sigma = W Λ W^T，\\where~W = \begin{bmatrix} |&|&...&|\\u_1 & u_2& ... & u_n\\  |&|&...&|\end{bmatrix},Λ = \begin{bmatrix}\lambda _1 &0&\cdots&0\\0&\lambda_2&\cdots&0\\\vdots & \vdots& \ddots &\vdots\\0&0&\cdots&\lambda_n  \end{bmatrix}</script><p>因此： $cov(Z) = W^TW Λ W^TW = Λ $.主成分变换XW对角化了X的样本协方差矩阵.</p><p>PCA的著名例子：Iris Dataset，EigenFaces。</p><h2 id="PCA的限制"><a href="#PCA的限制" class="headerlink" title="PCA的限制"></a>PCA的限制</h2><p>PCA很有用，但是它也有一些明显的缺陷：</p><ul><li>只考虑线性关系</li><li>假设数据是真实并且连续的</li><li>假设输入空间近似正态分布（不过在非正态分布中也可能工作得很好）<br>下面是一个非正态分布的例子：</li></ul><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/PCA6.png" alt=""></p><p>输入：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/PCA4.png" alt=""></p><p>PCA投影：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/PCA5.png" alt=""></p><p>下次我们将主要说明一下第一个缺陷的解决办法：kernel PCA。</p><h2 id="k-means与PCA的对比"><a href="#k-means与PCA的对比" class="headerlink" title="k-means与PCA的对比"></a>k-means与PCA的对比</h2><p>Unsupervised learning algorithm:</p><div class="table-container"><table><thead><tr><th>algorithm</th><th style="text-align:center">low dimension</th><th style="text-align:center">sparse</th><th style="text-align:center">disentangle variations</th></tr></thead><tbody><tr><td>k-means</td><td style="text-align:center">no</td><td style="text-align:center">yes</td><td style="text-align:center">no</td></tr><tr><td>PCA</td><td style="text-align:center">yes</td><td style="text-align:center">no</td><td style="text-align:center">yes</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> unsupervised learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——K-Means Clustering</title>
      <link href="/2018/11/19/Learning-From-Data%E2%80%94%E2%80%94K-Means-Clustering/"/>
      <url>/2018/11/19/Learning-From-Data%E2%80%94%E2%80%94K-Means-Clustering/</url>
      
        <content type="html"><![CDATA[<p>转眼间这一个学期已经过了一半了。开始学习非监督学习算法了。第一个介绍的算法，是K-Means聚类算法。</p><a id="more"></a><p>这是第一篇讲unsupervised learning的算法，先说一下，unsupervised learning试图在做些什么。</p><p>非监督学习和监督学习很像，都是希望学习出一个模型，$x \rightarrow f(x)$。不过非监督没有标签了。所以一般来说非监督学习更难。</p><p>非监督学习的目标，是想找到输入特征X的代表（Representation）。Representation learning problem可以描述为：给定了输入X，找到更简单的特征Z来保存和X一样的信息。</p><p>说了这么多，这哪像是一个学习算法，这更像是压缩算法。实际上，非监督学习就广泛应用于压缩。</p><p>一般，好的representation有以下几个特点：</p><ol><li><p>低维度：把信息压缩得更小</p></li><li><p>稀疏代表：比如一个矩阵，大部分项都是0,可以大大简化计算，称为稀疏矩阵。而稀疏代表也即大部分数据的特征的大部分项都是0.</p></li><li><p>独立代表：disentangle the source of variations.这个翻译是解开变异之源……好中二的感觉。这个是什么意思我也不是很理解。</p></li></ol><p>非监督学习广泛用于数据压缩，异常检测，分类聚类等等。</p><p>而这次要说的算法：K-Means算法，是一个聚类算法。</p><p>聚类的目标是给定一组输入特征，将数据分成几组结合在一起的簇。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/k_means_1.png" alt="k-means-1"></p><p>聚类的理想结果应满足下面的条件：</p><ul><li>在同一个簇中的对象相比于不同的簇的对象来说更为相似。</li></ul><h2 id="K-Means问题描述"><a href="#K-Means问题描述" class="headerlink" title="K-Means问题描述"></a>K-Means问题描述</h2><p>给定n个样本：${X_1,X_2,…,X_n}$，将它们分为k个类（$k\leq n$）$C_1,C_2,…,C_k$，使得簇内平方和（within-cluster sum of squares，WCSS）达到最小：</p><script type="math/tex; mode=display">argmin_C \sum_{j=1}^k \sum{x \in C_j} \Vert x - \mu_j \Vert ^2</script><p>$\mu_j$是一个簇的中心：$\mu_j =\frac{1}{ \vert C_j \vert } \sum_{X \in C_j} X_j$。</p><p>这个问题还有其他几种等价的描述：</p><ul><li><p>最小化簇内协方差：$\sum_{j=1}^k \vert C_j\vert Var(C_j)$</p></li><li><p>最小化相同的簇内点的两两平方偏差：$\sum_{i=1}^k \frac 1 {2\vert C_i \vert} \sum_{x,x’\in C_i} \Vert x - x’ \Vert$</p></li><li><p>最大化簇与簇之间的平方和（BCSS）</p></li></ul><p>在欧几里得空间找到最好的聚类效果（全局最优解）是一个NP-hard问题。因此经常用启发式，迭代式的算法来得到聚类效果，一般得到的是局部最优解。</p><h2 id="Llyod’s-Algorithm"><a href="#Llyod’s-Algorithm" class="headerlink" title="Llyod’s Algorithm"></a>Llyod’s Algorithm</h2><p>虽然全局最优解是一个NP-hard问题，但是得到局部最优解确实非常容易的。在这里介绍Llyod’s Algorithm, 实际上它的过程是异常简单的。整个算法分为下面几步：</p><ol><li><p>随机初始化k个中心：$u_1,u_2,…,u_k$</p></li><li><p>对于每个样本i，$C^{(i)} = argmin_j \Vert X_i - \mu_j \Vert^2$</p></li><li><p>根据聚类结果重新计算$\mu_j$</p></li></ol><p>重复上述过程，直到$\mu$不再改变。</p><p>现在，从非监督学习的目标来重新理解这个聚类算法，它实际上是学习到了一个k-dimentional的稀疏代表。也就是：$X_i$转换到$Z_i$了，而</p><p>$z_{i,j} =\left \{ \begin{matrix}<br>1&amp; if C^{i} = j;\\<br>0&amp; otherwise<br>\end{matrix}<br>\right .<br>$</p><p>它将原来的X特征向量转换成Z维向量。而这个Z矩阵是稀疏的，因为每个向量只有一项值为0.</p><p>因为这个算法只能得到一个局部最优解，因此初始化是很重要的，可能会影响结果。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/k_means_2.png" alt="k-means-2"></p><p>这个算法还留下几个疑问：</p><ol><li>如何初始化？</li></ol><p>Uniformly random sampling, </p><p>kmeans++ [Arthur &amp; Vassilvitskii SODA 2007]: distance-based sampling</p><ol><li>如何自动选择分成几类（k的取值）？</li></ol><p>Cross validation（交叉验证）</p><p>G-Means [Hamerly &amp; Elkan, NIPS 2003]</p><p>说到最后，说几句题外话。数据学习进行了期中考试，我的分数是后30%的水平。我的心里还是挺难过的。虽然我的本科也是很差的排名，但是那是因为我不学习。不过数据学习这门课我学得还是挺认真的。</p><p>我可以给自己找很多借口：没有复习;时间没安排好(第一题花了太长时间)等等，不过主要原因还是实力不够。就算这些我都做到了，我依然及不了格。既然有80分的大佬，那在乎这几分也没什么意思。说明自己还是太菜了。</p><p>希望期末考试可以取得一个好成绩。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> unsupervised learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——Huffman编码实现及其最优性</title>
      <link href="/2018/11/17/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Huffman%E7%BC%96%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%85%B6%E6%9C%80%E4%BC%98%E6%80%A7/"/>
      <url>/2018/11/17/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Huffman%E7%BC%96%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%85%B6%E6%9C%80%E4%BC%98%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p>香农虽然提出了香农码，但是香农码很多情况下离最优码还差得不少。比如：K=2,$p(a_1) = 0.9999,p(a_2) = 0.0001$，这种偏差非常大的情况下，香农码给$a_1,a_2$的编码长度分别为：1,14.而实际上两个值，我们可以仅用一个bit就能区分开来。在这里介绍一个大名鼎鼎的最优前缀编码：Huffman编码。</p><a id="more"></a><p>霍夫曼编码就不介绍了。因为这个东西我也实现过，知道它是怎么做的。不过如何提出来这个编码是非常有意思的。</p><p>霍夫曼码提出之前，人们一直在追求最优前缀编码。霍夫曼在MIT读博士的时候，老师给了一个作业题目：找到最优的二进制编码。霍夫曼想，想要证明已有编码是否是最优的太难了，所以他就想着自己找个编码方式。然后，诞生了霍夫曼编码。</p><p>唉，这就是大佬啊。</p><p>需要注意的是k叉霍夫曼树每个结点要么有k个孩子，要么没有孩子。确定了第一个，每次编码需要减少(k-1)个叶子结点。这意味着，信源的种类个数必须满足：1+n(k-1)。因此有时候需要填充0概率的字符来保证编码过程顺利。</p><p>最优性如何证明？</p><p>留个坑吧。看书上这个证明也挺长的。有时间了看完了再来写（也可能一直没有写）。</p><p>最后发一下多年前实现的huffman二进制编码：<br>Node.java:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hfm_compress;</span><br><span class="line"><span class="keyword">import</span> edu.princeton.cs.algs4.*;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.PriorityQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Node  </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">Code</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> used;</span><br><span class="line">    <span class="keyword">short</span> code;</span><br><span class="line">    <span class="keyword">int</span> size;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Node</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">   <span class="keyword">private</span> Node left;</span><br><span class="line">    <span class="keyword">private</span> Node right;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> frep;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">char</span> symbol;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Node <span class="title">left</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> left;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Node <span class="title">right</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> right;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">(Node l,Node r,<span class="keyword">int</span> f,<span class="keyword">char</span> s)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        left = l;</span><br><span class="line">        right = r;</span><br><span class="line">        frep = f;</span><br><span class="line">        symbol = s;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(Node n)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.frep - n.frep;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">frep</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> frep;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">char</span> <span class="title">symbol</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> symbol;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasLeft</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> !(left == <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasRight</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> !(right == <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String []args)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"wocao"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>HuffmanCompress.java<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hfm_compress;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> edu.princeton.cs.algs4.*;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.PriorityQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HuffmanCompress</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Node <span class="title">BuildTree</span><span class="params">(<span class="keyword">int</span> []frep)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        Node n = <span class="keyword">null</span>;</span><br><span class="line">        Node left = <span class="keyword">null</span>,right = <span class="keyword">null</span>;</span><br><span class="line">        PriorityQueue&lt;Node&gt; pq = <span class="keyword">new</span> PriorityQueue&lt;Node&gt; ();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i!=<span class="number">256</span>;++i)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(frep[i]!=<span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">            n = <span class="keyword">new</span> Node(<span class="keyword">null</span>,<span class="keyword">null</span>,frep[i],(<span class="keyword">char</span>)i);</span><br><span class="line">            pq.add(n);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(pq.size()&gt;<span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            left = pq.poll();</span><br><span class="line">            right = pq.poll();</span><br><span class="line">            n = <span class="keyword">new</span> Node(left,right,left.frep()+right.frep(),(<span class="keyword">char</span>)<span class="number">0</span>);</span><br><span class="line">            pq.add(n);</span><br><span class="line">        &#125;</span><br><span class="line">        n = pq.poll();</span><br><span class="line">       <span class="keyword">return</span> n;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Code [] BuildTable(Node tree)</span><br><span class="line">    &#123;</span><br><span class="line">        Code []table = <span class="keyword">new</span> Code[<span class="number">256</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i!=<span class="number">256</span>;++i)</span><br><span class="line">            table[i] = <span class="keyword">new</span> Code();</span><br><span class="line">         BuildTable(tree,table,(<span class="keyword">short</span>)<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">         <span class="keyword">return</span> table;</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">BuildTable</span><span class="params">(Node tree,Code []table,<span class="keyword">short</span> code,<span class="keyword">int</span> size)</span></span></span><br><span class="line"><span class="function">   </span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(tree.hasLeft())</span><br><span class="line">          BuildTable(tree.left(),table,(<span class="keyword">short</span>)(code&lt;&lt;<span class="number">1</span>),size+<span class="number">1</span>);</span><br><span class="line">      <span class="keyword">if</span>(tree.hasRight())</span><br><span class="line">          BuildTable(tree.right(),table,(<span class="keyword">short</span>)((code&lt;&lt;<span class="number">1</span>)|<span class="number">1</span>),size+<span class="number">1</span>);</span><br><span class="line">      <span class="keyword">if</span>(!tree.hasRight()&amp;&amp;!tree.hasLeft())</span><br><span class="line">      &#123;</span><br><span class="line">          table[tree.symbol()].size = size;</span><br><span class="line">          table[tree.symbol()].code = code;</span><br><span class="line">          table[tree.symbol()].used = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">compress</span><span class="params">(BinaryIn in,BinaryOut out)</span></span></span><br><span class="line"><span class="function">   </span>&#123;</span><br><span class="line">       <span class="keyword">int</span> frep[] = <span class="keyword">new</span> <span class="keyword">int</span> [<span class="number">256</span>];</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i!=<span class="number">256</span>;++i)</span><br><span class="line">       &#123;</span><br><span class="line">           frep[i] = <span class="number">0</span>;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">int</span> max = <span class="number">255</span>;</span><br><span class="line">       ArrayList&lt;Character&gt; data = <span class="keyword">new</span> ArrayList&lt;Character&gt;();</span><br><span class="line">       <span class="keyword">while</span>(!in.isEmpty())</span><br><span class="line">       &#123;</span><br><span class="line">          <span class="keyword">char</span> sym = in.readChar();</span><br><span class="line">          ++frep[sym];</span><br><span class="line">          <span class="keyword">if</span>(frep[sym]&gt;max)</span><br><span class="line">             max = frep[sym];</span><br><span class="line">          data.add(sym);</span><br><span class="line">              </span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i!=<span class="number">256</span>;++i)</span><br><span class="line">       &#123;</span><br><span class="line">           <span class="keyword">int</span> a = frep[i]/(max/<span class="number">255</span>);</span><br><span class="line">           <span class="keyword">if</span>(a == <span class="number">0</span>&amp;&amp;frep[i]&gt;<span class="number">0</span>)</span><br><span class="line">               frep[i] = <span class="number">1</span>;</span><br><span class="line">           <span class="keyword">else</span></span><br><span class="line">               frep[i] = a;</span><br><span class="line">       &#125;</span><br><span class="line">       Node tree = BuildTree(frep);</span><br><span class="line">     </span><br><span class="line">       Code []table = BuildTable(tree);</span><br><span class="line">       Iterator&lt;Character&gt; ii = data.iterator();</span><br><span class="line">       out.write(data.size());</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i!=<span class="number">256</span>;++i)</span><br><span class="line">           out.write(frep[i],<span class="number">8</span>);</span><br><span class="line">     </span><br><span class="line">       <span class="keyword">while</span>(ii.hasNext())</span><br><span class="line">       &#123;</span><br><span class="line">          <span class="keyword">char</span> b = ii.next();</span><br><span class="line">          <span class="keyword">if</span>(table[b].used)</span><br><span class="line">          out.write(table[b].code,table[b].size);</span><br><span class="line">       &#125;</span><br><span class="line">       out.close();</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">expand</span><span class="params">(BinaryIn in,BinaryOut out)</span></span></span><br><span class="line"><span class="function">   </span>&#123;</span><br><span class="line">       <span class="keyword">int</span> size = in.readInt();</span><br><span class="line">     <span class="comment">//  StdOut.println(size);</span></span><br><span class="line">       <span class="keyword">int</span> []frep = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">256</span>];</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i!=<span class="number">256</span>;++i)</span><br><span class="line">           frep[i] =(<span class="keyword">int</span>)in.readChar();</span><br><span class="line">       Node tree = BuildTree(frep);</span><br><span class="line">       Node node = tree;</span><br><span class="line">       <span class="keyword">int</span> ipos = <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">while</span>(size&gt;<span class="number">0</span>)</span><br><span class="line">       &#123;</span><br><span class="line">           <span class="keyword">boolean</span> t = in.readBoolean();</span><br><span class="line">          <span class="comment">// if(node == null)</span></span><br><span class="line">            <span class="comment">//   throw new Exception ("The Tree is not right!");</span></span><br><span class="line">             <span class="keyword">if</span>(t)</span><br><span class="line">             node = node.right();</span><br><span class="line">             <span class="keyword">else</span> node = node.left();</span><br><span class="line">             <span class="keyword">if</span>(node == <span class="keyword">null</span>)</span><br><span class="line">                 <span class="keyword">return</span>;</span><br><span class="line">             <span class="keyword">if</span>(!node.hasLeft()&amp;&amp;!node.hasRight())</span><br><span class="line">             &#123;</span><br><span class="line">                 --size;</span><br><span class="line">                 out.write(node.symbol());</span><br><span class="line">                 node = tree;</span><br><span class="line">             &#125;</span><br><span class="line">                 </span><br><span class="line">       &#125;</span><br><span class="line">     out.close();</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String []args)</span> <span class="keyword">throws</span> IOException</span></span><br><span class="line"><span class="function">   </span>&#123;</span><br><span class="line">       BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(System.in));</span><br><span class="line">       String s1 = reader.readLine();</span><br><span class="line">       String s2 = reader.readLine();</span><br><span class="line">       String s3 = reader.readLine();</span><br><span class="line">       <span class="keyword">if</span>(s1.equals(<span class="string">"compress"</span>))</span><br><span class="line">       &#123;</span><br><span class="line">       compress(<span class="keyword">new</span> BinaryIn(s2),<span class="keyword">new</span> BinaryOut(s3));</span><br><span class="line">       System.out.println(<span class="string">"the file has been compressed ! "</span>);</span><br><span class="line">       File old = <span class="keyword">new</span> File(s2);</span><br><span class="line">       File now = <span class="keyword">new</span> File(s3);</span><br><span class="line">       System.out.println(<span class="string">"Old : "</span>+old.length()+<span class="string">" new : "</span>+now.length()+<span class="string">"\nthe compression ratio is "</span>+(<span class="keyword">double</span>)now.length()/old.length());</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">       &#123;</span><br><span class="line">       expand(<span class="keyword">new</span> BinaryIn(s2),<span class="keyword">new</span> BinaryOut(s3));</span><br><span class="line">       System.out.println(<span class="string">"the file has been expanded ! "</span>);</span><br><span class="line">       File old = <span class="keyword">new</span> File(s2);</span><br><span class="line">       File now = <span class="keyword">new</span> File(s3);</span><br><span class="line">       System.out.println(<span class="string">"Old : "</span>+old.length()+<span class="string">" new : "</span>+now.length());</span><br><span class="line">       &#125;</span><br><span class="line">       </span><br><span class="line">   &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这两个文件放在一个名为hfm_compress的package里。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> code </tag>
            
            <tag> information theory </tag>
            
            <tag> lossless coding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——拟合sin曲线</title>
      <link href="/2018/11/16/Learning-From-Data%E2%80%94%E2%80%94%E6%8B%9F%E5%90%88sin%E6%9B%B2%E7%BA%BF/"/>
      <url>/2018/11/16/Learning-From-Data%E2%80%94%E2%80%94%E6%8B%9F%E5%90%88sin%E6%9B%B2%E7%BA%BF/</url>
      
        <content type="html"><![CDATA[<p>这次的作业是用神经网络来拟合sin曲线。通过实践更能感受到ReLU以及sigmoid，tanh激活函数的区别。<br><a id="more"></a></p><p>作业中已经将整体框架写好，好让我们能专注于算法部分。比较复杂的部分是向量化，因为自己的博客定义的这个矩阵的形式可能是多样的，但是最后的结果肯定是一致的，以及需要传入的参数如何分配。</p><p>我选择传入的input为$a^{(l)}$以及$a^{(l-1)}$，传入的gran_out为$\sigma^{(l)}$中除去乘$g’(z)$的部分。因为导数部分需要上一层的激活函数来决定。</p><p>在作业中定义W,a的方式和我定义$\Sigma,a$的方式正好相反，这是需要注意的地方。</p><p>这个神经网络包含4层：输入层，全连接层（1×80），ReLU层（80×80），输出层（80×1）。</p><p>最后得到的拟合结果和loss曲线如下：</p><p>purelin:</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/1.png" alt=""></p><p>loss history:</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/loss.png" alt=""></p><p>tanh:</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/2.png" alt=""></p><p>loss history:</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/loss_t.png" alt=""></p><p>代码会在作业截止后上传。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>) </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">x = np.linspace(-np.pi,np.pi,<span class="number">140</span>).reshape(<span class="number">140</span>,<span class="number">-1</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">lr = <span class="number">0.02</span>     <span class="comment">#set learning rate</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(np.ones_like(x)+np.exp(-x))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_square_loss</span><span class="params">(y_pre,y_true)</span>:</span>         <span class="comment">#define loss </span></span><br><span class="line">    loss = np.power(y_pre - y_true, <span class="number">2</span>).mean()*<span class="number">0.5</span></span><br><span class="line">    loss_grad = (y_pre-y_true)/y_pre.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> loss , loss_grad           <span class="comment"># return loss and loss_grad</span></span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReLU</span><span class="params">()</span>:</span>                     <span class="comment"># ReLu layer</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        unit_num = input.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># check if the ReLU is initialized.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'W'</span>):</span><br><span class="line">            self.W = np.random.randn(unit_num,unit_num)*<span class="number">1e-2</span> </span><br><span class="line">            self.b = np.zeros((<span class="number">1</span>,unit_num))</span><br><span class="line">        temp = input.dot(self.W) + self.b.repeat(input.shape[<span class="number">0</span>]).reshape(self.W.shape[<span class="number">1</span>],input.shape[<span class="number">0</span>]).T</span><br><span class="line">        <span class="keyword">return</span> np.where(temp&gt;<span class="number">0</span>,temp,<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self,input,grad_out)</span>:</span></span><br><span class="line">        a_lm1 = input[<span class="number">0</span>]</span><br><span class="line">        a_l = input[<span class="number">1</span>]</span><br><span class="line">        derivative = np.where(a_l&gt;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">        sample_num = a_lm1.shape[<span class="number">0</span>]</span><br><span class="line">        delt_W =  a_lm1.T.dot(grad_out*derivative)/sample_num</span><br><span class="line">        delt_b = np.ones((<span class="number">1</span>,sample_num)).dot(grad_out*derivative)/sample_num</span><br><span class="line">        to_back = (grad_out*derivative).dot(self.W.T)</span><br><span class="line">        self.W -= lr * delt_W</span><br><span class="line">        self.b -= lr * delt_b</span><br><span class="line">        <span class="keyword">return</span> to_back</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FC</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_dim,output_dim)</span>:</span>    <span class="comment"># initilize weights</span></span><br><span class="line">        self.W = np.random.randn(input_dim,output_dim)*<span class="number">1e-2</span> </span><br><span class="line">        self.b = np.zeros((<span class="number">1</span>,output_dim))</span><br><span class="line">                       </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span>          </span><br><span class="line"></span><br><span class="line">        <span class="comment">#purelin</span></span><br><span class="line">        <span class="comment">#return input.dot(self.W) + self.b.repeat(input.shape[0]).reshape(self.W.shape[1],input.shape[0]).T</span></span><br><span class="line">        <span class="comment">#tanh</span></span><br><span class="line">        <span class="keyword">return</span> tanh(input.dot(self.W) + self.b.repeat(input.shape[<span class="number">0</span>]).reshape(self.W.shape[<span class="number">1</span>],input.shape[<span class="number">0</span>]).T)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="comment"># backpropagation,update weights in this step</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self,input,grad_out)</span>:</span></span><br><span class="line">        a_lm1 = input[<span class="number">0</span>]</span><br><span class="line">        a_l = input[<span class="number">1</span>]</span><br><span class="line">        sample_num = a_lm1.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment">#purelin</span></span><br><span class="line">        <span class="string">'''delt_W =  a_lm1.T.dot(grad_out)/sample_num</span></span><br><span class="line"><span class="string">        delt_b = np.ones((1,sample_num)).dot(grad_out)/sample_num</span></span><br><span class="line"><span class="string">        to_back = grad_out.dot(self.W.T)'''</span></span><br><span class="line">        <span class="comment">#tanh</span></span><br><span class="line">        delt_W =  a_lm1.T.dot(grad_out*(<span class="number">1</span>-np.power(a_l,<span class="number">2</span>)))/sample_num</span><br><span class="line">        delt_b = np.ones((<span class="number">1</span>,sample_num)).dot(grad_out*(<span class="number">1</span>-np.power(a_l,<span class="number">2</span>)))/sample_num</span><br><span class="line">        to_back = (grad_out*(<span class="number">1</span>-np.power(a_l,<span class="number">2</span>))).dot(self.W.T)</span><br><span class="line">        self.W -= lr * delt_W</span><br><span class="line">        self.b -= lr * delt_b</span><br><span class="line">        <span class="keyword">return</span> to_back</span><br><span class="line"></span><br><span class="line"><span class="comment">#  bulid the network      </span></span><br><span class="line">layer1 = FC(<span class="number">1</span>,<span class="number">80</span>)</span><br><span class="line">ac1 = ReLU()</span><br><span class="line">out_layer = FC(<span class="number">80</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># count steps and save loss history</span></span><br><span class="line">loss = <span class="number">1</span></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line">l= []</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> loss &gt;= <span class="number">1e-4</span> <span class="keyword">and</span> step &lt; <span class="number">15000</span>: <span class="comment"># training </span></span><br><span class="line">            </span><br><span class="line">    <span class="comment"># forward     input x , through the network and get y_pre and loss_grad   </span></span><br><span class="line">    <span class="comment"># To get a[l]</span></span><br><span class="line">    a = [x]</span><br><span class="line">    a.append(layer1.forward(a[<span class="number">0</span>]))</span><br><span class="line">    a.append(ac1.forward(a[<span class="number">1</span>]))</span><br><span class="line">    a.append(out_layer.forward(a[<span class="number">2</span>]))</span><br><span class="line">    <span class="comment">#backward   # backpropagation , update weights through loss_grad</span></span><br><span class="line">    <span class="comment">#sigma and a[l-1] is what the backpropagation needs. If you want get the derivative, the a[l] is also needed.  </span></span><br><span class="line">    sigma = out_layer.backward([a[<span class="number">2</span>],a[<span class="number">3</span>]],a[<span class="number">3</span>] - y)</span><br><span class="line">    sigma = ac1.backward([a[<span class="number">1</span>],a[<span class="number">2</span>]],sigma)</span><br><span class="line">    sigma = layer1.backward([a[<span class="number">0</span>],a[<span class="number">1</span>]],sigma)    </span><br><span class="line">    <span class="comment">#This step is for plotting the initial line.</span></span><br><span class="line">    <span class="keyword">if</span> step == <span class="number">0</span>:</span><br><span class="line">        y_start = a[<span class="number">3</span>]</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line">    loss = mean_square_loss(a[<span class="number">3</span>],y)[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    l.append(loss)</span><br><span class="line">    <span class="comment">#print("step:",step,loss)</span></span><br><span class="line">y_pre = a[<span class="number">3</span>]</span><br><span class="line">    </span><br><span class="line"><span class="comment"># after training , plot the results</span></span><br><span class="line"></span><br><span class="line">plt.plot(x,y,c=<span class="string">'r'</span>,label=<span class="string">'true_value'</span>)</span><br><span class="line">plt.plot(x,y_pre,c=<span class="string">'b'</span>,label=<span class="string">'predict_value'</span>)</span><br><span class="line">plt.plot(x,y_start,c=<span class="string">'black'</span>,label=<span class="string">'begin_value'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.savefig(<span class="string">'1.png'</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.arange(<span class="number">0</span>,len(l)), l )</span><br><span class="line">plt.title(<span class="string">'loss history'</span>) </span><br><span class="line"><span class="comment"># save the loss history.</span></span><br><span class="line">plt.savefig(<span class="string">'loss_t.png'</span>)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> code </tag>
            
            <tag> LFD class </tag>
            
            <tag> neural network </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Activation Function</title>
      <link href="/2018/11/14/Learning-From-Data%E2%80%94%E2%80%94Activation-Function/"/>
      <url>/2018/11/14/Learning-From-Data%E2%80%94%E2%80%94Activation-Function/</url>
      
        <content type="html"><![CDATA[<p>上次lfd的博客讲了神经网络的一些基本内容，包括它的起源，前向传播以及后向传播。实际上，对于一个很重要的部分：activation function，只是简单提到。所以这次着重说一下不同的激活函数之间的区别。<br><a id="more"></a></p><p>你应该还记得有这么一段话：</p><blockquote><blockquote><p>上面的函数中，g为logistic函数，又叫sigmoid函数。当然这个函数不仅仅局限于sigmoid函数，也有relu函数，tanh函数：</p><script type="math/tex; mode=display">\begin{matrix}g(z) = \frac 1 {1+e^{-z}} &(sigmoid)\\g(z) = \max(z,0) &(ReLU)\\g(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}& (tanh)\end{matrix}</script></blockquote></blockquote><p>实际上，实际上使用的也多是这三个函数，或者它们其中某个的变种。</p><p>同样，之前博客也说明了，为什么我们一定要在神经网络中使用非线性函数。所以在这里就不多提了。这篇博客，主要就介绍这3个函数的区别以及他们的使用场景。</p><h2 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h2><p>Logistic Regression是一个非常基本的算法。在二元分类时候，它用的非常多。不过很遗憾的是，在neural network中，我们除了输出层几乎不使用这个函数。</p><p>Logistic Function(Sigmoid Function)的图像如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/sigmoid.png" alt=""></p><p>它的缺点很明显：</p><ol><li>不是以0为中心的</li><li>当|x|比较大的时候，这个函数的梯度非常小，称为饱和区梯度扼杀。</li><li>指数运算较为复杂</li></ol><p>因为1的存在，使得下一层的输入都是正的，那么下一层的梯度就会受限。此外，饱和区梯度太小，再加上指数运算比较复杂，这些使得sigmoid的梯度下降非常缓慢。</p><p>但是sigmoid函数也有非常大的优势，它一般作为输出层的激活函数，因为它将函数输出控制在0,1之间。实际运用中，除了输出层，几乎不用sigmoid函数。</p><h2 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h2><p>tanh为双曲正切函数。它的图像如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/tanh.png" alt=""></p><p>可以看到它和sigmoid函数非常相似，不过它的优点是以0为中心。不过呢它的缺点也比较明显，除了以0为中心，sigmoid有的缺点它都有。不过也因为这点，一般来说它表现的总是会比sigmoid函数更好。所以除了输出层，想要使用sigmoid的地方不如换成tanh函数。</p><h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p>ReLU（Rectified Linear Unit）为线性整流函数，又称为修正线性单元。实际上它是目前最常用的激活函数。<br>它的正半轴没有饱和扼杀梯度的影响，而且运算也非常简单，使得它在神经网络中的收敛速度比其他的激活函数要快很多。它的图像如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/3.png" alt=""></p><p>不过它也有缺点：输出不是以0为中心。而且当x小于0时候梯度将会被扼杀。</p><p>针对ReLU的不足有很多ReLU的改良版，如Leaky ReLU:g(x) = max(0.01z,z)等。这些在实际中比ReLU表现更好，但是使用ReLU依然是最多的选择，实际上ReLU是目前的神经网络的默认激活函数。</p><h2 id="derivative-of-activation-function"><a href="#derivative-of-activation-function" class="headerlink" title="derivative of activation function"></a>derivative of activation function</h2><div class="table-container"><table><thead><tr><th>function</th><th>derivative</th></tr></thead><tbody><tr><td>sigmoid</td><td>$g’(x) = g(x)(1 - g(x))$</td></tr><tr><td>tanh</td><td>$g’(x) = 1-g^2(x)$</td></tr><tr><td>ReLU</td><td>$g’(x) =\left \{ \begin{matrix}0&amp;x<0\\1&x>0\end{matrix}\right .$</0\\1&x></td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> deep learning </tag>
            
            <tag> neural network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——Kraft不等式以及变长编码定理</title>
      <link href="/2018/11/14/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Kraft%E4%B8%8D%E7%AD%89%E5%BC%8F%E4%BB%A5%E5%8F%8A%E5%8F%98%E9%95%BF%E7%BC%96%E7%A0%81%E5%AE%9A%E7%90%86/"/>
      <url>/2018/11/14/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Kraft%E4%B8%8D%E7%AD%89%E5%BC%8F%E4%BB%A5%E5%8F%8A%E5%8F%98%E9%95%BF%E7%BC%96%E7%A0%81%E5%AE%9A%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>上次介绍了香农无损编码定理以及一些不同类别的编码。这次介绍kraft不等式以及huffman编码，并且说明霍夫曼编码的最优性。<br><a id="more"></a></p><p>Kraft不等式为前缀码约束条件。在前缀码中，显然不能使用所有的最短的码字，这样的话前缀码的条件就无法满足。就用二叉树来编码（二进制编码）的时候，如果一个节点被作为码字，则它的子树结点都无法作为码字。</p><h2 id="Kraft不等式"><a href="#Kraft不等式" class="headerlink" title="Kraft不等式"></a>Kraft不等式</h2><p>kraft不等式定义如下：</p><p>任意D-进制码前缀码其码长$l_1,l_2,…,l_m$，满足</p><script type="math/tex; mode=display">\sum_{i} D^{-l_i} \leq 1</script><p>反之，如果码长约束满足上述不等式，则必然可以构造出具有此码长的前缀码。 </p><p>Kraft不等式的证明是非常直接的：</p><ul><li>必要性：</li></ul><p>我们依然从D叉树来考虑这个问题。假如码字最长为$l_{max}$.当一个结点被选做码字的时候，假设这个结点的深度为$l_i$，也就是码长为$l_i$.那么因为它的存在，它子树的结点都不能再次作为码字。因此我们就损失了$D^{l_{max} - l_i}$个叶子结点（注意，这里说的是叶子结点）。</p><p>这棵树的所有叶子结点数目为：$D^{l_max}$.我们最多把所有的叶子结点都给剪掉。</p><p>现在假设一共有m个码字，则：</p><script type="math/tex; mode=display">\sum_{i=1}^m D^{l_{max} - l_i} \leq D^{l_{max}}</script><p>两侧同时除以$D^{l_{max}}$,就得到了kraft不等式。</p><ul><li>充分性</li></ul><p>充分性更好证明。我们只要在树上就可以很容易构造出来这样的编码。</p><p>Kraft不等式给出了即时码的充要条件，但是和最优码长无关。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/kraft.png" alt=""></p><h2 id="任意前缀码码长约束"><a href="#任意前缀码码长约束" class="headerlink" title="任意前缀码码长约束"></a>任意前缀码码长约束</h2><p>对随机变量X进行D进制前缀码编码，得到的码长满足：</p><script type="math/tex; mode=display">L \ge H_D(X)</script><p>等号当且仅当$D^{-l_i} = p_i$时候成立。这个L为平均码长。</p><p>证明如下：</p><script type="math/tex; mode=display">\begin{aligned}L - H_D(X) &= \sum P_i l_i - \sum P_i \log_D \frac 1 {P_i}\\&= \sum P_i \log_D D^{l_i} +\sum P_i \log_D P_i\\&= \sum P_i \log_D P_i - \sum P_i \log _D D^{-l_i}\\&= \sum P_i \log_D \frac{P_i}{D^{-l_i}} ----(1)\\\end{aligned}</script><p>也许大家会觉得从（1）可以直接得到:D(P\Vert D^{-l})，然后由互信息大于0从而完成证明。但这样是不严谨的，因为我们无法保证$\sum D^{-l_i} = 1$.</p><p>因此这里需要做一个归一化处理：<br>令：$r_i = \frac{D^{-l_i}}{\Delta}，\Delta = \sum D^{-l_i}$<br>(这个地方真是不容易想到啊，很容易就不严谨了)</p><p>则（1）可以写为：</p><script type="math/tex; mode=display">\begin{aligned}\sum P_i \log_D \frac{P_i}{D^{-l_i}} &=\sum P_i \log _D \frac{P_i}{r_i}\frac 1 {\Delta}\\&=\sum P_i \log_D \frac{P_i}{r_i} - \log_D \Delta \sum P_i\\&=D(P\Vert r) + \log \frac 1 \Delta\end{aligned}</script><p>而$D(P\Vert r) + \log \frac 1 \Delta \ge 0$（由对数性质，鉴别信息性质以及Kraft不等式决定）.</p><p>所以，我们完成了对上述定理的证明。</p><h2 id="最优前缀码定理（香农第一定理）"><a href="#最优前缀码定理（香农第一定理）" class="headerlink" title="最优前缀码定理（香农第一定理）"></a>最优前缀码定理（香农第一定理）</h2><p>该定理描述如下：</p><p>对随机变量X进行D进制前缀编码，得到的最优码长满足下列不等式：</p><script type="math/tex; mode=display">H_D(X) \leq L^* < H_D(X)+1</script><p>左侧是不用证明的，因为上个定理已经证明了。我们主要需要证明的是右侧。</p><p>香农通过构造香农码来证明右侧：</p><p>取$\lceil \log_D \frac 1{P_i} \rceil$为码字长度，这样的编码是满足kraft不等式的：</p><script type="math/tex; mode=display">\sum D^{-\lceil \log_D \frac 1 {P_i}\rceil} \leq \sum D^{-\log_D \frac 1 {P_i}} = \sum P_i = 1</script><p>因此我们可以根据这个码长来构造出相应的前缀码。</p><p>我们知道：</p><script type="math/tex; mode=display">\log _D \frac 1 {P_i} \leq l_i \leq \log_D \frac 1 {P_i}+1</script><p>如果对上述不等式的所有side求期望，得到：</p><script type="math/tex; mode=display">H_D(X) \leq \sum p_il_i \leq H_D(X) + 1</script><p>这就是香农码,到这里我们就完成了香农第一定理的证明。要注意，香农码不一定是最优的，实际中一般来说它离最优还差很远。</p><h2 id="分组前缀码"><a href="#分组前缀码" class="headerlink" title="分组前缀码"></a>分组前缀码</h2><p>定长编码定理告诉我们，$\epsilon$可以任意小，而变长编码告诉我们，我们付出的代价小于1。能不能让这个代价能保证比1更小呢？这就是分组编码。</p><p>对于信源X进行分组前缀编码，得到的编码长度$L_n^*$满足不等式：</p><script type="math/tex; mode=display">\frac{H(X_1,X_2,...,X_n)}{n} \leq L_n^* \leq \frac{H(X_1,X_2,...,X_n)}{n}  + \frac 1 n</script><p>如果信源稳恒，则$L_n^* \rightarrow H(X)$.</p><p>这要求我们对X进行分组，因此会有解码延迟，也需要缓冲区。但是通过这个，可以使得平均码长代价更小。天下没有免费的午餐。</p><h2 id="编码效率与互信息"><a href="#编码效率与互信息" class="headerlink" title="编码效率与互信息"></a>编码效率与互信息</h2><p>最优前缀码的编码与信源的分布密切相关，但是我们不一定能准确知道信源的分布。如果信源分布估计出现偏差，则平均码长就会受到惩罚。</p><p>Penalty分析：</p><p>可以证明，对于服从p(x)信源X进行前缀编码，如果码字长度取$l(x) = \lceil \log \frac 1 {q(x)}\rceil$，则平均码长满足：</p><script type="math/tex; mode=display">H(p) + D(p\Vert q) \leq E_{p}l(X) < H(p) + D(p\Vert q) +1</script><p>很神奇的是，在penalty中kl divergence出来了。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
            <tag> lossless encoding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——非线性优化</title>
      <link href="/2018/11/14/SLAM%E2%80%94%E2%80%94%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/"/>
      <url>/2018/11/14/SLAM%E2%80%94%E2%80%94%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>实际上从上次介绍的东西，我们理论上已经知道了SLAM是怎么运作的了。从深度图和颜色图，估计相机位姿，通过相机位姿，以及深度图和颜色图，我们实际上就可以去拼接点云或者三维建模了。不过现实往往没有那么容易，如果这么简单SLAM也没什么好研究的了。<br><a id="more"></a><br>实际上，生活中处处充满了噪声。我们采集的数据也是一样。我们无法消除噪声。所以我们得到的运动方程还有观测方程，都不一定（实际上是一定不）是严格成立的，只能近似成立。为了使得状态估计在噪声中有不错的效果，我们必须得进行优化。现实中的优化问题往往是非线性问题，所以这次主要讲的内容是非线性优化。</p><p>实际上机器学习以及信息论中很多地方多多少少涉及到了优化问题，因此看这篇文章到最后会有“很多原来是这个啊”的类似感慨。</p><h2 id="状态估计问题"><a href="#状态估计问题" class="headerlink" title="状态估计问题"></a>状态估计问题</h2><h3 id="最大后验与最大似然"><a href="#最大后验与最大似然" class="headerlink" title="最大后验与最大似然"></a>最大后验与最大似然</h3><p>在前面几次内容中，我们知道了SLAM的数学模型如下：</p><script type="math/tex; mode=display">\left\{\begin{matrix}x_k = f(x_{k-1},\mu_k) + w_k\\z_{k,j} = h(y_j,x_k) + v_{k,j}\end{matrix}\right .</script><p>我们了解到$x_k$是相机的位姿，可以使用变换矩阵或者李代数来表示，即$x_k$可以由$T_k$或者$\exp(\xi_k\hat{})$来表示。我们暂且专注于观测方程。假设位姿为$x_k$对路标$y_j$进行了一次观测，对应到图像的位置为$z_{k,j}$，则观测方程可以表示为：</p><script type="math/tex; mode=display">sz_{k,j} = K \exp(\xi\hat{})y_j.</script><p>上式中$K$为相机内参，而$s$为物体与相机之间的距离。这里的$z_{k,j}, y_j$都用齐次坐标描述。</p><p>现在，考虑高斯噪声：<script type="math/tex">w_k \tilde{} N(0,R_k),v_{k,j} \tilde{} N(0,Q_{k,j}).</script></p><p>在这些噪声的影响下，我们希望通过$z$和$\mu$来推断位姿$x$和地图$y$，这就构成了一个状态估计问题。在之前的研究中，多用滤波器（尤其是卡尔曼滤波器EKF）来求解这个问题。卡尔曼滤波器的特点是只关心当前时刻的状态估计$x_k$，而对之前的状态则不多考虑，也就是假设这一系列状态是符合马尔可夫链的。近些年来的研究多用的是非线性优化的方法，比卡尔曼滤波有更好的效果。</p><p>首先从概率论角度看一下我们探讨的问题。非线性优化中把所有代估计的变量放在一个状态变量当中：</p><script type="math/tex; mode=display">\{x,y\};x = \{x_1,...,x_N\};y=\{y_1,...,y_M\}.</script><p>现在我们要求的是在当前的观测$z$和输入数据$u$的情况下，状态$\{x,y\}$的概率：$P(x,y|z,u)$.这里的$u,z$是其他输入的统称，如果输入图片是没有时间关系的，那么这个问题是Structure from Motion(SfM)问题。</p><p>对于上面这个概率是非常熟悉了，我们已经多次遇到了。利用贝叶斯公式可以得到：</p><script type="math/tex; mode=display">P(x,y|z,u) = \frac{P(z,u|x,y)P(x,y)}{P(z,u)}</script><p>贝叶斯左侧为后验概率，而右侧中$P(x,y)为$先验，$P(z,u|x,y)$为似然。直接求后验分布往往是困难的，而求一个状态最优估计，使得该状态下后验概率最大化(Maximizae a Posterior, MAP)是可行的：</p><script type="math/tex; mode=display">{x^{* },y^*}_{MAP} = \arg\max_{x,y}P(x,y|z,u) = \arg\max_{x,y}P(z,u|x,y)P(x,y)</script><p>进一步，如果我们不在乎先验，得到的就是x,y的最大似然估计(Maximize Likelihood Estimation, MLE)：</p><script type="math/tex; mode=display">{x^* ,y^*}_{MLE} = \arg\max P(z,u|x,y)</script><p>后验的意思是在当前的观测数据下可能出现什么样的状态，而似然的意思是在这个的状态下，出现当前观测数据的概率，因此最大似然的直观意思就是什么样的状态下最可能产生现在的观测数据。最大后验是当前的观测数据下最可能出现什么样的状态。这两者并不是完全等价的。</p><h2 id="引出最小二乘法"><a href="#引出最小二乘法" class="headerlink" title="引出最小二乘法"></a>引出最小二乘法</h2><p>如何求最大似然估计？在高斯分布的假设下，最大似然有比较简单的形式。对于某一次观测：</p><script type="math/tex; mode=display">z_{k,j} = h(y_j,x_k)+v_{k,j},</script><p>由于我们假设噪声$v_{k,j} \tilde N(0,Q_{k,j})$，所以观测数据的条件概率为：</p><script type="math/tex; mode=display">P(z_{j,k}|x_k,y_j) = N(h(y_j,x_k),Q_{k,j})</script><p>它依然是一个高斯分布。为了计算是他最大化的$x_k,y_j$，我们往往使用最小化负对数的方式，也就是加$\log$。<br>高斯分布在负对数下有较好的数学形式，考虑高斯分布$x\tilde{}N(\mu,\Sigma)$，它的概率密度函数展开形式为：</p><script type="math/tex; mode=display">P(x) = \frac{1}{\sqrt{(2\pi)^N det(\Sigma)}}\exp\left(-\frac 1 2 (x - \mu)^T \Sigma^{-1}(x - \mu)\right).</script><p>则：</p><script type="math/tex; mode=display">-\log P(x) = \frac{1}{2}\log \left( (2\pi)^N det(\Sigma)\right) + \frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu).</script><p>对原式求最大化也就是对上式求最小化。上式中第一项与x无关，可以忽略。带入SLAM的观测方程得到：</p><script type="math/tex; mode=display">x^* = \arg\min \left((z_{k,j} - h(x_k,y_j))^T Q_{k,j}^{-1}(z_{k,j} - h(x_k,y_j)) \right).</script><p>我们发现上式等价与最小化噪声项的平方($\Sigma$范数意义下)。因此对于所有的运动和任意的观测，我们定义数据与估计值之间的误差为：</p><script type="math/tex; mode=display">e_{v,k} = x_k - f(x_{k-1},u_k)\\e_{y,j,k} = z_{k,j} - h(x_k,y_j),</script><p>该误差的平方和如下：</p><script type="math/tex; mode=display">J(x) = \sum_k e_{v,k}^T R_k^{-1}e_{v,k} + \sum_k \sum_j e_{y,k,j}^T Q_{k,j}^{-1}e_{y,k,j}</script><p>这样就得到了一个总体意义下的最小二乘问题。它的最优解等价于状态的最大似然估计。</p><h2 id="非线性最小二乘"><a href="#非线性最小二乘" class="headerlink" title="非线性最小二乘"></a>非线性最小二乘</h2><p>对于简单的最小二乘问题，假设：</p><script type="math/tex; mode=display">\min_x \frac 1 2 \Vert f(x)\Vert_2^2.</script><p>如果$f(x)$形式比较简单，我们可以通过导数为0得到最优解，也就是求极值。不过往往我们需要求解的这个问题函数形式并不简单。这时候要使用的就是迭代的方法一步步向着最优解走。也就是$x_{i+1} = x_{i} + \Delta x_i$。当$\Delta x_i$很小的时候迭代停止。这个过程中，比较难的地方在于如何确定这个$\Delta x_i$，使得优化问题有很多方法。</p><h3 id="一阶梯度法和二阶梯度法"><a href="#一阶梯度法和二阶梯度法" class="headerlink" title="一阶梯度法和二阶梯度法"></a>一阶梯度法和二阶梯度法</h3><p>求解增量解最直观的方式是将目标函数在$x$附近进行泰勒展开：</p><script type="math/tex; mode=display">\Vert f(x+\Delta x)\Vert_2^2 \approx \Vert f(x)\Vert_2^2 + J(x)\Delta x+\frac 1 2 \Delta x^T H \Delta x.</script><p>上式中$J$是$\Vert f(x)\Vert_2^2$关于ｘ的导数(雅科比矩阵)，而$H$为二阶导数(海森矩阵)。我们可以选择保留一阶项或者二阶项，分别得到一阶和二阶梯度法。</p><h4 id="一阶梯度法"><a href="#一阶梯度法" class="headerlink" title="一阶梯度法"></a>一阶梯度法</h4><p>保留一阶项，比较好理解，为了朝最低的点走，就是朝着导数的反方向，实际上这个走不能走得太多，一阶展开后最小值是无穷小的，不过走得太多泰勒展开是不成立的，因此一般需要一个学习率：</p><script type="math/tex; mode=display">\Delta x = -J^T(x)</script><p>实际上这就是梯度下降算法。</p><h4 id="二阶梯度法"><a href="#二阶梯度法" class="headerlink" title="二阶梯度法"></a>二阶梯度法</h4><p>对于二阶梯度法：</p><script type="math/tex; mode=display">\Delta x^* = \arg\min (\Vert f(x)\Vert_2^2 + J(x)\Delta x+\frac 1 2 \Delta x^T H \Delta x)</script><p>上式对$\Delta $求导，得到：</p><script type="math/tex; mode=display">H\Delta x = -J^T</script><p>这个方法称为牛顿法。实际上呢，它就是牛顿迭代法，可以看另外一种解释：<a href="https://wlsdzyzl.top/2018/10/16/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Newton-Method/" target="_blank" rel="noopener">Newton Method</a></p><p>无论是一介导数还是二阶导数都是非常直观的，不过梯度下降因为策略是贪心，最后经常走出锯齿路线，使得迭代次数过多，而牛顿法对于海森矩阵的求解，在大规模的情况下是非常耗时的。我们希望能够避免$H$的求解，下面介绍两个SLAM中用的更多的方法。</p><h3 id="高斯牛顿法"><a href="#高斯牛顿法" class="headerlink" title="高斯牛顿法"></a>高斯牛顿法</h3><p>我们想要最小化$\Vert f(x + \Delta x)\Vert_2^2$，一种策略是像上面一样，对他进行泰勒展开，另一种，我们可以先在内部进行泰勒展开：</p><script type="math/tex; mode=display">f(x+\Delta x) \approx f(x) + J(x)\Delta x</script><p>然后最小化$\Vert f(x) + J(x)\Delta x  \Vert_2^2$：</p><script type="math/tex; mode=display">\Delta x^* = \arg\min _{\Delta x} \frac 1 2 \Vert f(x) + J(x)\Delta x \Vert_2^2</script><p>由于泰勒展开，让上面的形式已经比较简单了，所以我们无需再次泰勒展开了。为了方便，我们将上面的形式写成：</p><script type="math/tex; mode=display">\begin{aligned}\frac 1 2 \Vert f(x) + J(x)\Delta x \Vert_2^2 &= \frac{1}{2}( f(x) + J(x)\Delta x)^T ( f(x) + J(x)\Delta x)\\&= \frac{1}{2}\left(\Vert f(x) \Vert_2^2 +2f(x)^TJ(x)\Delta x + \Delta x^TJ^T(x)J(x)\Delta x\right)\end{aligned}</script><p>对上式求导令其为0：</p><script type="math/tex; mode=display">2J^T(x)f(x) + 2J^T(x)J(x)\Delta x = 0</script><p>得到：</p><script type="math/tex; mode=display">J^T(x)J(x) \Delta x = -J^T(x)f(x)</script><p>我们要求的是$\Delta x$，这是一个线性方程组，我们称为增量方程，或者高斯牛顿方程，也叫正规方程。将上式中左侧定义为$H$,右侧定义为$g$，得到：</p><script type="math/tex; mode=display">H\Delta x = g,</script><p>因此，我们在利用$J^TJ$作为海森矩阵的近似。原则上，我们的近似$H$矩阵是可逆且正定，但是实际中经常出现$J^TJ$为半正定矩阵，使用高斯牛顿法时候可能得到奇异矩阵或者病态的情况，此时稳定性较差，导致算法不一定会收敛。有时候得到的$\Delta x$过大，导致结果不减反增。</p><p>尽管高斯牛顿法有缺点，但是它是很多更先进算法(如线搜索方法，line search method)的基础。</p><h3 id="列文伯格-马夸尔特法"><a href="#列文伯格-马夸尔特法" class="headerlink" title="列文伯格-马夸尔特法"></a>列文伯格-马夸尔特法</h3><p>列文伯格-马夸尔特法在一定程度上修正了这些问题，它比高斯牛顿更为健壮，不过它的收敛速度更慢，被称为阻尼牛顿法。</p><p>高斯牛顿中的问题之所以会出现，一定程度上是因为$\Delta$过大的时候，偏离了泰勒近似，所以可以想到的是找一个信赖区间，在区间内我们认为结果可以接受，超过了区间我们认为可能会出问题。</p><p>如何确定信赖区间的范围？一种办法是比较真实减小值和近似减小值的差距：</p><script type="math/tex; mode=display">\rho = \frac{f(x + \Delta x) - f(x)}{J(x)\Delta x}.</script><p>$\rho$的分子是真实减少值，而分母是近似减少值。如果$\rho$比较大，意味这相差不多，可以继续增大范围，如果$rho$近似于１，表示近似一致，而$rho$过小，则表示近似减少的太多了，需要缩小近似范围。</p><p>因此我们可以想象这样一个过程：</p><script type="math/tex; mode=display">\min_{\Delta x_k} \frac 1 2 \Vert f(x_k)+J(x_k)\Delta x_k\Vert^2, s.t. \Vert  D \Delta x_k\Vert^2 \leq \mu.</script><p>这里$\mu$是信赖区域的半径。</p><ul><li>计算$\rho$:<ul><li>如果$\rho &gt; \frac 3 4$，则：$\mu = 2\mu$,</li><li>如果$\rho &lt; \frac 1 4$，则：$\mu = 0.5\mu$,<br>如果$\rho$大于某个阈值表示是可以接受的，令$x_{k+1} = x_k + \Delta x_k$.</li></ul></li></ul><p>这里扩大的倍数等都是经验值，如果没有D，则表示范围是一个球，有了D可以是一个椭球，$D$是一个非负对角阵，一般来说使用$J^TJ$的对角元素平方根，使得在梯度小的维度上约束范围更大一些。</p><p>实际上，这个操作就是正则化的一种，不过用到了优化过程中。利用拉格朗日乘子，我们可以将有约束的优化转化称为无约束的优化：</p><script type="math/tex; mode=display">\min _{\Delta x_k} \frac 1 2 \Vert f(x_k)+J(x_k) \Delta x_k\Vert^2 + \frac{\lambda}{2} \Vert D \Delta x \Vert ^2.</script><p>更大的$\mu$（信赖范围），对应着更小的$\lambda$。对上式求导，得到：</p><script type="math/tex; mode=display">(H + \lambda D^T D)\Delta x = g</script><p>如果取$D=I$，那么当$\lambda$较小的时候（信赖半径较大），采用的就是高斯牛顿方法，如果$\lambda$比较大（信赖半径较小），那么更像是在用普通的梯度下降方法。</p><p>由此可以看到列文伯格-马夸尔特法在一定程度上可以减少奇异以及病态问题。</p><p>这几种方法是最基本的优化方法。一般来说分为两类：line search与trust region，line search是确定方向找步长，如一二阶梯度法，高斯牛顿法，而trust region是确定范围，在范围内找到更合适的点，如列文伯格-马夸尔特法。</p><p>在求解$J^TJ$的时候，由于SLAM中这个矩阵具有稀疏性，简化了计算，使得这种优化方法被广为采纳。此外，在优化时候初始值也很重要，否则这些优化算法往往陷入局部最小值。一般来说，我们会利用ICP,PnP等算法提供一个较好的初始值。</p><h2 id="图优化"><a href="#图优化" class="headerlink" title="图优化"></a>图优化</h2><p>最后简单提一下图优化。图优化牵扯到了图论，把要优化的变量转化为点，而误差项转化为边。对于任何一个最小二乘问题我们都可以构建与之对应的一个图。</p><p>看下图是SLAM中优化对应的图优化模型：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/g2o.jpg" alt=""></p><p>圆圈表示位姿，方框表示路标，而圆圈间的连线表示误差$w_k$，方框与圆圈之间的连线表示误差$v_{k,j}$。</p><p>为什么要用图优化，因为我们可以直观看到问题的结构，图论中很多理论可以用到了。比如先去掉孤立点，或者优先优化度数较大的顶点等等。</p><p>最后，提两个从c++库：ceres与g2o。其中g2o是图优化库。</p><p>关于图优化的更多，参考：<a href="https://www.cnblogs.com/gaoxiang12/p/5244828.html" target="_blank" rel="noopener">图优化</a>.</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——Viewing</title>
      <link href="/2018/11/14/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Viewing/"/>
      <url>/2018/11/14/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Viewing/</url>
      
        <content type="html"><![CDATA[<p>上次图形学的博客中介绍了转换，所以我们可以从世界坐标转换到相机坐标了。不过虽然我们学的是三维模型，不过我们看到的都是二维的。近大远小是小学生都明白的道理，而一个物品的距离等等都会影响它在我们眼中,以及拍摄出来照片的样子。因此这次讲得内容是观察（Viewing）。<br><a id="more"></a></p><h2 id="正交投影（Orthographic-Projection）"><a href="#正交投影（Orthographic-Projection）" class="headerlink" title="正交投影（Orthographic Projection）"></a>正交投影（Orthographic Projection）</h2><p>正交投影是最简单的一个投影方式。它实际上就是三维坐标中的点丢弃一个坐标轴，如我们需要将物体投影到xy平面上，我们就需要丢弃掉z轴。</p><p>它的特点：原来平行的线保持平行。这个特点使得它在很多工程制图中非常有用。</p><p>这个博客会介绍OpenGL中的正交投影（gluOrtho）实现。</p><p>在OpenGL中，gluOrtho做的实际上是将物体转换到一个中心位于坐标轴中心的正方体上。物体原来是个长方体，所以gluOrtho需要提供的是left,right;up,bottom;near,far.</p><p>为什么要这么做？这个是三维pipeline的一步，先映射到正方体上，最后方便投影到真正的屏幕上，也就是映射到平面像素上。</p><p>而映射到中心正方体的边长是2,左右（上下前后）坐标分别为-1,1. 因此如何映射？</p><p>假如提供的left，right;up，bottom;near,far分别值为l,r;u,b;n,f;既然要映射到正方体上，那么需要两部：一个平移，一个缩放。</p><p>首先是平移，平移向量很容易：</p><script type="math/tex; mode=display">t = \begin{bmatrix}-\frac{l+r}{2}\\-\frac{u+b}{2}\\-\frac{n+f}{2}\end{bmatrix}</script><p>再一个是缩放。既然要缩放，比如左右距离的缩放，是从$r - l$缩放到2.因此缩放比例为：$\frac{2}{r-l}$.</p><p>同样的道理，我们可以得到缩放矩阵：</p><script type="math/tex; mode=display">S = \begin{bmatrix}\frac{2}{r - l}&0&0\\0&\frac{2}{u-b}&0\\0&0&\frac{2}{f - n}\end{bmatrix}</script><p>需要注意的是缩放的这些值都是正值。</p><p>然后通过齐次坐标将上面两个结合起来得到转换矩阵：</p><script type="math/tex; mode=display">M = \begin{bmatrix}\frac{2}{r - l}&0&0&-\frac{r+l}{r-l}\\0&\frac{2}{u-b}&0&-\frac{u+b}{u-b}\\0&0&\frac{2}{f - n}&-\frac{f+n}{f-n}\\0&0&0&1\end{bmatrix}</script><p>不过事情还没完。要知道，在OpenGL中，规定我们观察的方向是Z轴的负向（也就是在视点坐标中，x,y的坐标都是有正有负的，但是我们往前看到的东西的z坐标都一定是负的）。所以上面的式子就要有点变化了，我们仍然希望远的投影到+1,而近的投影到-1,这就要求实际上不光要平移到原点，在缩放时候还要将远近两个面颠倒。这时候平移大小变为：$\frac{f+n}{2}$(因为实际坐标是-f,-n),而为了让远的投影到1,而近的投影到-1,这个缩放尺度就要变成负数，使得位置颠倒，因此缩放尺度变为：$-\frac{2}{f-n}$，最后乘进去后，变化的只有一小部分：</p><script type="math/tex; mode=display">M = \begin{bmatrix}\frac{2}{r - l}&0&0&-\frac{r+l}{r-l}\\0&\frac{2}{u-b}&0&-\frac{u+b}{u-b}\\0&0&-\frac{2}{f - n}&-\frac{f+n}{f-n}\\0&0&0&1\end{bmatrix}</script><p>也就是，实际上，只有一项变化了。需要注意的是这里的f和n都是正值。</p><h2 id="透射投影（Perspective-Projection）"><a href="#透射投影（Perspective-Projection）" class="headerlink" title="透射投影（Perspective Projection）"></a>透射投影（Perspective Projection）</h2><p>透射投影中，远处的景色总是更近一点。实际上这就是透射投影。</p><p>下面说的这个东西和SLAM中说的针孔模型很相似：假如有一个点坐标为$X,Y,Z$，而面前有一个屏幕，到针孔的距离为d（d&gt;0），那么在屏幕上这一点的投影为：</p><script type="math/tex; mode=display">X' = -d\frac X Z\\Y' = -d\frac Y Z</script><p>这里负号的存在，还是因为z坐标都是负的。</p><p>而我实际上我们可以将透射投影转换写成这样：</p><script type="math/tex; mode=display">P = \begin{bmatrix}1&0&0&0\\0&1&0&0\\0&0&1&0\\0&0&-\frac {1}{d}&0\end{bmatrix}</script><p>这个矩阵乘起来之后之前的坐标都没有改变，除了最后一项1变成了$-\frac Z d$. 而齐次坐标如果将最后一个转化为1,则之前的X，Y，Z变成了：$-d\frac X Z, -d\frac Y Z,-d$.这是个很巧妙的转换。</p><p>而OpenGL中的透投影函数会更复杂一点。我们还是通过说明gluPerspective，来理解透射映射。</p><p>首先我们需要定义一个新的名词，叫做Viewing Frustum(视锥体)。一个视锥体如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0579.PNG" alt=""></p><p>任何近裁面近的点或者比远裁面远的点都会被遮挡。</p><p>gluPerspective的参数需要：fovy，aspect,zNear,zFar(zNear,zFar&gt;0,后文简写为$Z_n,Z_f$). fovy为视野，可以理解为眼睛睁得大小程度，而aspect定义了视锥的高宽比。</p><p>gluPerspective依然是将这个视锥体的投影结果转换到坐标轴的中心正方体（边长为2），使得近截面的z坐标为1,远截面的z坐标为-1.</p><p>而zNear和zFar代表了我们需要透射投影的最近距离和最远距离。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0581.PNG" alt=""><br>投影到的”屏幕”由下图确定，（其中投影屏幕高为两个单位）：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0580.PNG" alt=""><br>因为要映射到最后的中心正方体（变长为2），所以这个“屏幕”的高已经已经确定了，所以d的距离由$\theta$确定，而$\theta = \frac {fovy}2，d = \cot \theta$.另一方面，高确定为2, 因此aspect实际上改变最终投影的宽窄，由之前的基础，我们先这样写下这个式子：</p><script type="math/tex; mode=display">P = \begin{bmatrix}\frac 1 {aspect}&0&0&0\\0&1&0&0\\0&0&1&0\\0&0&-\frac {1}{d}&0\end{bmatrix}</script><p>既然齐次坐标最终最后一项要转化为1，也就是同时乘以某个数不会影响齐次坐标的大小，我们可以将上面个的矩阵写成：</p><script type="math/tex; mode=display">P = \begin{bmatrix}\frac d {aspect}&0&0&0\\0&1&0&0\\0&0&A&B\\0&0&-1&0\end{bmatrix}</script><p>因为我们最后要影响Z坐标，所以需要改变的值是A和B的位置，而不能让他们为0.从上式求得坐标：</p><script type="math/tex; mode=display">p' = \begin{bmatrix}\frac d {aspect}&0&0&0\\0&d&0&0\\0&0&A&B\\0&0&-1&0\end{bmatrix} \begin{bmatrix}x\\y\\z\\1\end{bmatrix} = \begin{bmatrix}\frac {dx}{aspect} \\dy\\Az+B\\-z\end{bmatrix} =  \begin{bmatrix}-\frac {xd}{aspect*z} \\-\frac{yd}{z}\\-A-\frac B z\\1\end{bmatrix}</script><p>因为我们要让远裁剪面在-1，近裁剪面在+1，因此：</p><script type="math/tex; mode=display">\left \{ \begin{matrix}-A-\frac B {-Z_f} = 1\\-A - \frac B {-Z_n} = =-1\end{matrix}\right .</script><p>得到：</p><script type="math/tex; mode=display">A =-\frac{Z_f+Z_n}{Z_f-Z_n} \\B = -\frac{2 Z_n Z_f}{Z_f - Z_n}</script><p>因此将A，B带入后就是最后gluPerspective得到的矩阵。</p><h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><ul><li>在这里我们不能将$Znear$设置为0,如果那样的话，会导致深度信息无法解析。</li><li>fovy视野越大，我们看到的对象变得越小，这是因为屏幕大小是固定的。</li><li>我不明白为什么openGL要将这个映射到立方体上做的这么复杂，更远的地方（z值更小）映射到1。不过gluPerspective只是一部分，除了透射投影以外，还要得到得到平面坐标，然后映射到屏幕上。</li><li>传入函数的near，far，计算的到的d等都是距离，也就是都是正值，但是为了处理负的坐标值，多了很多麻烦。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> computer graphics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——相机与图像</title>
      <link href="/2018/11/12/SLAM%E2%80%94%E2%80%94%E7%9B%B8%E6%9C%BA%E4%B8%8E%E5%9B%BE%E5%83%8F/"/>
      <url>/2018/11/12/SLAM%E2%80%94%E2%80%94%E7%9B%B8%E6%9C%BA%E4%B8%8E%E5%9B%BE%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<p>SLAM建模的过程中，相机是很重要的一个部分。因此这一讲主要探讨相机的成像模型。<br><a id="more"></a></p><h2 id="相机模型"><a href="#相机模型" class="headerlink" title="相机模型"></a>相机模型</h2><p>相机将三维世界中的坐标映射到二维平面上。这个过程可以用一些几何模型来描述，最简单的称为针孔模型。我们初中物理应该也都学过这个东西。</p><h3 id="针孔相机模型"><a href="#针孔相机模型" class="headerlink" title="针孔相机模型"></a>针孔相机模型</h3><p>假设相机前方为z轴，右侧为x轴，则根据右手坐标定则，y轴朝下。实际上，这个定义使得投影到相机平面后的平面坐标和像素坐标方向一致。这个坐标轴就是相机坐标。而平面坐标，也就是针孔后方的投影平面是一个二元坐标。针孔成像结果是倒立的，假如针孔模型的焦距为f，则：</p><script type="math/tex; mode=display">\frac Z f = - \frac {X}{X'} = -\frac {Y}{Y'}</script><p>负号表示前后左右颠倒。</p><p>为了简化模型，我们可以将成像平面放到针孔前面，与三维空间点一侧，这时候得到的结果是正常的（实际上一般生活中我们都会将这个颠倒结果转换为正常结果，包括我们的脑子也是这么做的）。这时候：</p><script type="math/tex; mode=display">\frac Z f =  \frac {X}{X'} = \frac {Y}{Y'}</script><p>整理可以得到：</p><script type="math/tex; mode=display">X' = f\frac X Z\\Y' = f\frac Y Z</script><p>在相机中，我们最终得到的是一个个像素点。假如成像平面有这么一个像素坐标轴：$o-u-v$.像素坐标轴和平面坐标轴有平移和缩放的关系，假如像素坐标原点平移了$[c_x,c_y ]$,u轴缩放大小为$\alpha$,v轴缩放大小为$\beta$,则（缩放也就是一米有多少像素点，如果一米有10个像素点，则原来的1可能要变为10）：</p><script type="math/tex; mode=display">u = X'\alpha + c_x\\v = Y'\beta + c_y</script><p>将之前的式子带入，并且将$f{\alpha}, f{\beta}$分别记为$f_x,f_y$,因为f的单位为米，而$\alpha,\beta$的单位为像素/米，因此$f_x,f_y$的单位为像素。</p><p>因此上面的式子就可以写为：</p><script type="math/tex; mode=display">\left \{\begin{matrix}u = f_x\frac X Z+c_x\\v = f_y\frac Y Z+c_y\end{matrix}\right .</script><p>如果写成矩阵形式就更明白一点：</p><script type="math/tex; mode=display">\begin{pmatrix}u\\v\\1\end{pmatrix} = \frac 1 Z \begin{pmatrix}f_x&0&c_x\\0&f_y&c_y\\0&0&1\end{pmatrix}\begin{pmatrix}X\\Y\\Z \end{pmatrix}\triangleq \frac 1 Z K P</script><p>一般来说习惯将Z移到右侧。上式中中间量为相机内参，一般来说在出厂之后就固定了。不知道的话也可以用算法进行标定。</p><p>既然有内参，对应的也就有一个外参。我们上面的介绍都是以相机坐标为基础的，而相机坐标实际上是由世界坐标转换的。从世界坐标到相机坐标的转换，之前图形学中介绍，需要旋转R和平移t操作，而R和t就构成了相机的外参，也叫相机的位姿。假如某个点在世界坐标下为$P_w$,则：</p><script type="math/tex; mode=display">ZP_{uv} = Z\begin{bmatrix}u\\v\\1\end{bmatrix} = K(RP_w+t) = KTP_w</script><p>上式中，T为欧式转换矩阵。所以这其中包含了齐次坐标与非齐次坐标的转换。</p><p>从图形学的介绍中我们知道从世界到相机坐标的转换是先旋转后平移的，所以上市中的t是已经转换后的平移矩阵，而非相机的坐标。此外，我们还可以进行归一化处理，使得最后一维值为1，实际上只要将Z轴除进去就好.</p><h3 id="畸变"><a href="#畸变" class="headerlink" title="畸变"></a>畸变</h3><p>畸变分为径向畸变和切向畸变。</p><p>实际上，这些畸变我们在生活中都会经常遇到，由于现实中我们相机会有透镜，所以会引入径向畸变。如拍的照片发现一个直的电线杆变成弯的了，这就是径向畸变。径向畸变离光心越远越明显，有时候是桶形畸变，有时候是枕形畸变，原理类似，因为图像放大率随着与光轴之间的距离增加而变小或者增大。</p><p>切向畸变是由于成像平面与透镜不严格平行导致的。为了纠正畸变，就要用数学把畸变描述出来。</p><p>对于径向畸变，我们可以用一个多项式函数来描述畸变前后的坐标变化：</p><script type="math/tex; mode=display">x_{distorted} = x(1+k_1r^2 + k_2r^4 +k_3r^6)\\y_{distorted} = y(1+k_1r^2 + k_2r^4 +k_3r^6)</script><p>上式中，$[x,y ]^T$是归一化平面点的坐标，而$[x_{distorted},y_{distorted} ]$是畸变后的坐标。</p><p>对于切向畸变：</p><script type="math/tex; mode=display">x_{distorted} = x+2p_1xy+p_2(r^2+2x^2)\\y_{distorted} = y+p_1(r^2+2y^2) + 2p_2xy</script><p>结合起来：</p><script type="math/tex; mode=display">\left\{\begin{matrix}x_{distorted} = x(1+k_1r^2 + k_2r^4 +k_3r^6)+2p_1xy+p_2(r^2+2x^2)\\y_{distorted} = y(1+k_1r^2 + k_2r^4 +k_3r^6)+p_1(r^2+2y^2) + 2p_2xy\end{matrix}\right.</script><p>因此，通过畸变系数，和相机坐标系中的一点，我们可以得到正确的坐标点。然后再通过内参矩阵得到正确的图像坐标。</p><p>去畸变是一个中间过程，我们假设以后的处理图像已经处理过畸变。</p><p>所以单目相机成像过程就是首先通过位姿估计得到相机外参（实际上这个不是成像过程的一部分，但是对于SLAM是非常重要的一步），然后将世界坐标点转换为相机坐标，经过归一化处理，通过内参计算出来像素位置哦。</p><h3 id="双目相机模型"><a href="#双目相机模型" class="headerlink" title="双目相机模型"></a>双目相机模型</h3><p>通过单目相机的成像过程，我们无法知道像素对应的点在空间点的位置。这是因为只要在光心和像素点这条线上，他们都是可以投影到一个点，想要确定它的空间位置，需要知道深度，也就需要通过双目相机或者RGB-D相机。</p><p>双目相机类似于我们的眼睛。我们可以通过眼睛来判断物体与我们之间的距离。一般双目相机都是左右分布的，但也有上下的。不过我们在这里介绍的是以左右分布的。这保证了两个相机的成像只在x坐标上有偏移。</p><p>为了说明白双目相机的成像模型，我们需要将这个模型画出来，需要注意的是，我们像之前一样将成像平面放到光心前面：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0516.JPG" alt=""><br>双目相机两个光心的距离称为基线b，也就是$O_l,O_r$之间的距离。$u_r,u_l$分别为各自成像平面上的坐标，需要注意的是$u_l$为负数。</p><p>考虑一个空间点P，它在左眼和右眼各成一个像，记做$P_l,P_r$.根据相似三角形：</p><script type="math/tex; mode=display">\frac{z-f}{z} = \frac{b-u_l+u_r}{b}</script><p>即：</p><script type="math/tex; mode=display">z = \frac{fb}{u_l - u_r}</script><p>这样就计算出来了距离z。上式中：$u_l - u_r=d$,我们称为视差。可以看到视差越大，则距离越远。实际中上视差最小为1,所以最远的距离就由fb限定了。所以双目相机可以测量的距离是有限的。</p><p>原理简单，但是d不好计算。因为我们需要知道左眼图像的像素出现在右眼图像的哪个位置。因此计算量和精度都会造成问题。</p><h3 id="RGB-D相机模型"><a href="#RGB-D相机模型" class="headerlink" title="RGB-D相机模型"></a>RGB-D相机模型</h3><p>RGB-D相机也就是深度相机，它能够主动测量深度。目前深度相机主要有两个原理：</p><ol><li>红外结构光，如kinect 1代</li><li>飞行时间法，如kinect 2代</li></ol><p>它们原理都需要向目标发射光线。结构光根据返回的结构光图案来计算距离，而飞行时间法则根据光束飞行的时间来计算。RGB-D相机可以获得整个图像的像素深度，一般会输出一一对应的彩色图和深度图。</p><p>当然，RGB-D相机能够实时测量深度，但是使用条件会受限，容易收到其他光线干扰。对于透射材质的物体，因为接受不到反射光，所以无法测量这些点的位置。此外，它在成本，功耗方面都有劣势。</p><h2 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h2><p>接下来熟悉一下OpenCV，是一个开源视觉库。</p><p>下面这段代码简单介绍了一些OpenCV的操作：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;chrono&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc,<span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   cv:: Mat image =   cv::imread(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">if</span>(image.data == <span class="literal">nullptr</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Error:the image file may not exist"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//output some basic information</span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"Width:"</span>&lt;&lt;image.cols&lt;&lt;<span class="string">" height:"</span>&lt;&lt;image.rows&lt;&lt;<span class="string">" channel number:"</span>&lt;&lt;image.channels()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">      cv::imshow(<span class="string">"image"</span>,image);</span><br><span class="line">      cv::waitKey(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">// judge the type of the image</span></span><br><span class="line">    <span class="keyword">if</span>(image.type()!=CV_8UC1 &amp;&amp; image.type()!=CV_8UC3)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"the image must be rgb image or grey-scale map"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//iteration</span></span><br><span class="line">    <span class="comment">//use chrono to compute the time.</span></span><br><span class="line">    chrono::steady_clock::time_point t1 = chrono::steady_clock::now();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">size_t</span> y=<span class="number">0</span>;y&lt;image.cols;++y)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> x = <span class="number">0</span>;x&lt;image.rows;++x)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//left the ptr point at the y row.</span></span><br><span class="line">            <span class="keyword">unsigned</span> <span class="keyword">char</span>* row_ptr = image.ptr&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>&gt;(y);</span><br><span class="line">            <span class="comment">//get position (x,y)'s ptr,because there are image.channels()*1 char.</span></span><br><span class="line">            <span class="keyword">unsigned</span> <span class="keyword">char</span> *data_ptr = &amp;row_ptr[x*image.channels()];</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> c = <span class="number">0</span>;c!=image.channels();++c)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">//Do someting ;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    chrono::steady_clock::time_point t2 = chrono::steady_clock::now();</span><br><span class="line">    chrono::duration&lt;<span class="keyword">double</span>&gt; time_used = chrono::duration_cast&lt;chrono::duration&lt;<span class="keyword">double</span>&gt;&gt;(t2-t1);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"We use "</span>&lt;&lt;time_used.count()&lt;&lt;<span class="string">" seconds to scan the image"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// copy or reference</span></span><br><span class="line">    <span class="comment">//this is a reference,or ptr, so if we change the image_another,the original image will be changed</span></span><br><span class="line">      cv::Mat image_another = image;</span><br><span class="line">    <span class="comment">//let the left top corner(100,100) block to be 0</span></span><br><span class="line">    image_another(  cv::Rect(<span class="number">0</span>,<span class="number">0</span>,<span class="number">100</span>,<span class="number">100</span>)).setTo(<span class="number">0</span>);</span><br><span class="line">      cv::imshow(<span class="string">"image"</span>,image);</span><br><span class="line">      cv::waitKey(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//copy ,clone</span></span><br><span class="line">      cv::Mat image_clone = image.clone();</span><br><span class="line">      image_clone(cv::Rect(<span class="number">0</span>,<span class="number">0</span>,<span class="number">100</span>,<span class="number">100</span>)).setTo(<span class="number">255</span>);</span><br><span class="line">      cv::imshow(<span class="string">"image"</span>,image);</span><br><span class="line">      cv::imshow(<span class="string">"imageclone"</span>,image_clone);</span><br><span class="line">      cv::waitKey(<span class="number">0</span>);</span><br><span class="line">      cv::destroyAllWindows();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>CMakeLists.txt:<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS <span class="string">"-std=c++11"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">find_package</span>(OpenCV REQUIRED)</span><br><span class="line"></span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;OpenCV_INCLUDE_DIRS&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(imageOP imageOP.cpp)</span><br><span class="line"></span><br><span class="line"><span class="keyword">target_link_libraries</span>(imageOP <span class="variable">$&#123;OpenCV_LIBS&#125;</span>)</span><br></pre></td></tr></table></figure></p><h2 id="总结：点云拼接"><a href="#总结：点云拼接" class="headerlink" title="总结：点云拼接"></a>总结：点云拼接</h2><p>现在使用之前介绍的知识，来完成一个点云拼接的任务。这个需要用到高博提供的一些图片数据。地址：<a href="https://github.com/gaoxiang12/slambook/tree/master/ch5/joinMap" target="_blank" rel="noopener">joinMap</a>.</p><p>点云的操作需要用到点云库PCL。</p><p>首先说明以下，知道像素坐标以及深度信息，如何恢复相机坐标？实际上反推非常容易：</p><script type="math/tex; mode=display">X = \frac{u - c_x}{f_x}Z\\Y = \frac{v - c_y}{f_y}Z</script><p>而我们做的也正是用上面的过程来进行点云恢复。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;Eigen/Geometry&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;boost/format.hpp&gt;//format strings</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;pcl/point_types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;pcl/io/pcd_io.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;pcl/visualization/pcl_visualizer.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc,<span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;cv::Mat&gt; colorImgs,depthImgs;</span><br><span class="line">    <span class="built_in">vector</span>&lt;Eigen::Isometry3d,Eigen::aligned_allocator&lt;Eigen::Isometry3d&gt;&gt; poses;<span class="comment">//poses of camera</span></span><br><span class="line">    <span class="function">ifstream <span class="title">fin</span><span class="params">(argv[<span class="number">2</span>])</span></span>;</span><br><span class="line">    <span class="keyword">if</span>(!fin)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"We need information about poses"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i!=<span class="number">5</span>;++i)</span><br><span class="line">    &#123;</span><br><span class="line">        boost::<span class="function">format <span class="title">fmt</span><span class="params">(argv[<span class="number">1</span>]+<span class="built_in">string</span>(<span class="string">"/%s/%d.%s"</span>))</span></span>;<span class="comment">//format of image files</span></span><br><span class="line">        colorImgs.push_back(cv::imread((fmt%<span class="string">"color"</span>%(i+<span class="number">1</span>)%<span class="string">"png"</span>).str()));</span><br><span class="line">        depthImgs.push_back(cv::imread((fmt%<span class="string">"depth"</span>%(i+<span class="number">1</span>)%<span class="string">"pgm"</span>).str(),<span class="number">-1</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">double</span> data[<span class="number">7</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">        <span class="comment">//get poses to data</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> &amp;d:data)</span><br><span class="line">           fin&gt;&gt;d;</span><br><span class="line">        Eigen::<span class="function">Quaterniond <span class="title">q</span><span class="params">(data[<span class="number">6</span>],data[<span class="number">3</span>],data[<span class="number">4</span>],data[<span class="number">5</span>])</span></span>;</span><br><span class="line">        Eigen::<span class="function">Isometry3d <span class="title">T</span><span class="params">(q)</span></span>;</span><br><span class="line">        T.pretranslate(Eigen::Vector3d(data[<span class="number">0</span>],data[<span class="number">1</span>],data[<span class="number">2</span>]));</span><br><span class="line">        poses.push_back(T);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">double</span> cx = <span class="number">325.5</span>;</span><br><span class="line"><span class="keyword">double</span> cy=<span class="number">253.5</span>;</span><br><span class="line"><span class="keyword">double</span> fx = <span class="number">518.0</span>;</span><br><span class="line"><span class="keyword">double</span> fy = <span class="number">519.0</span>;</span><br><span class="line"><span class="keyword">double</span> depthScale = <span class="number">1000.0</span>;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;<span class="string">"try to get pointcloud..."</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line"><span class="comment">//use XYZRGB format </span></span><br><span class="line"><span class="keyword">typedef</span> pcl::PointXYZRGB PointT;</span><br><span class="line"><span class="keyword">typedef</span> pcl:: PointCloud&lt;PointT&gt; PointCloud;</span><br><span class="line"></span><br><span class="line">PointCloud::<span class="function">Ptr <span class="title">pointCloud</span><span class="params">(<span class="keyword">new</span> PointCloud())</span></span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;<span class="number">5</span>;++i)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"transform the images..."</span>&lt;&lt;i&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    cv::Mat color = colorImgs[i];</span><br><span class="line">    cv::Mat depth = depthImgs[i];</span><br><span class="line">    Eigen::Isometry3d T = poses[i];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> v = <span class="number">0</span>;v&lt;color.rows;++v)</span><br><span class="line">     <span class="keyword">for</span> (<span class="keyword">int</span> u = <span class="number">0</span>;u&lt;color.cols;++u)</span><br><span class="line">     &#123;</span><br><span class="line">         <span class="keyword">unsigned</span> <span class="keyword">int</span> d = depth.ptr&lt;<span class="keyword">unsigned</span> <span class="keyword">short</span>&gt;(v)[u];<span class="comment">//get depth of the pixel</span></span><br><span class="line">         <span class="keyword">unsigned</span> <span class="keyword">char</span>* cptr = color.ptr&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>&gt;(v);</span><br><span class="line">         </span><br><span class="line">         <span class="keyword">if</span>(d == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">         Eigen::Vector3d point;</span><br><span class="line">         point[<span class="number">2</span>] = <span class="keyword">double</span>(d) / depthScale;</span><br><span class="line">         point[<span class="number">0</span>] = (u - cx)*point[<span class="number">2</span>]/fx;</span><br><span class="line">         point[<span class="number">1</span>] = (v - cy)*point[<span class="number">2</span>]/fy;</span><br><span class="line">         Eigen::Vector3d pointWorld = T*point;</span><br><span class="line"></span><br><span class="line">         PointT p;</span><br><span class="line">         p.x = pointWorld[<span class="number">0</span>];</span><br><span class="line">         p.y = pointWorld[<span class="number">1</span>];</span><br><span class="line">         p.z = pointWorld[<span class="number">2</span>];</span><br><span class="line">         p.b = cptr[u*color.channels()];</span><br><span class="line">         p.g = cptr[u*color.channels()+<span class="number">1</span>];</span><br><span class="line">         p.r = cptr[u*color.channels()+<span class="number">2</span>];</span><br><span class="line">         pointCloud-&gt;points.push_back(p);</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br><span class="line">pointCloud-&gt;is_dense = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;<span class="string">"points number:"</span>&lt;&lt;pointCloud-&gt;size()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">pcl::io::savePCDFileBinary(<span class="string">"map.pcd"</span>,*pointCloud);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>CMakeLists.txt:<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">find_package</span>(OpenCV REQUIRED)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;OpenCV_INCLUDE_DIRS&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">include_directories</span>(<span class="string">"usr/include/eigen3/"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">find_package</span>(PCL REQUIRED COMPONENT common io)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;PCL_INCLUDE_DIRS&#125;</span>)</span><br><span class="line"><span class="keyword">add_definitions</span>(<span class="variable">$&#123;PCL_DEFINITIONS&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(joinMap joinMap.cpp)</span><br><span class="line"></span><br><span class="line"><span class="keyword">target_link_libraries</span>(joinMap <span class="variable">$&#123;OpenCV_LIBS&#125;</span> <span class="variable">$&#123;PCL_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure></p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0519.PNG" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> opencv </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——李群和李代数</title>
      <link href="/2018/11/09/SLAM%E2%80%94%E2%80%94%E6%9D%8E%E7%BE%A4%E5%92%8C%E6%9D%8E%E4%BB%A3%E6%95%B0/"/>
      <url>/2018/11/09/SLAM%E2%80%94%E2%80%94%E6%9D%8E%E7%BE%A4%E5%92%8C%E6%9D%8E%E4%BB%A3%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<p>在SLAM中，我们需要对姿态进行估计和优化。但是旋转矩阵自身是有约束的，增加优化难度。因此我们需要引入李群和李代数，可以将位姿估计转换为无约束的优化问题。<br><a id="more"></a></p><h2 id="群-Group"><a href="#群-Group" class="headerlink" title="群(Group)"></a>群(Group)</h2><p>群是一种集合加上一种运算的代数结构。如果记集合为$A$，运算为$\cdot$,如果满足以下性质，则称$(A,\cdot)$为群：</p><ol><li>封闭性： $\forall a_1,a_2\in A,a_1 \cdot a_2 \in A$.</li><li>结合律：$\forall a_1,a_2,a_3 \in A (a_1 \cdot a_2) \cdot a_3 = a_1 \cdot (a_2 \cdot a_3)$.</li><li>幺元：$\exists a_0 \in A, s.t. \forall a \in A,a_0\cdot a = a \cdot a_0 = a$.</li><li>逆：$\forall a\in A,\exists a^{-1} \in A, a\cdot a^{-1} = a_0$.</li></ol><p>可以验证旋转矩阵和转换矩阵与矩阵乘法运算都可以构成群。其中旋转矩阵与乘法构成的群为$SO(3)$,特殊正交群，欧式转换矩阵与乘法构成特殊欧氏群$SE(3)$.</p><h3 id="李群（Lie-Group）"><a href="#李群（Lie-Group）" class="headerlink" title="李群（Lie Group）"></a>李群（Lie Group）</h3><p>具有连续（光滑）性质的群。李群既是群也是流形。SO(3),SE(3)都是李群，但是只有定义良好的乘法，没有加法，所以难以进行极限求导（$+\Delta x$）等操作。</p><h2 id="引出李代数"><a href="#引出李代数" class="headerlink" title="引出李代数"></a>引出李代数</h2><p>一种李群，对应一个李代数。李代数用小写表示，如$so(3),se(3)$.</p><p>任意旋转矩阵，则$RR^T = I$.</p><p>考虑R随时间变化，有$R(t)R(t)^T = I$.</p><p>两侧对t求导：$R’(t)R(t)^T + R(t)R’(t)^T = 0$.</p><p>则：$R’(t)R(t)^T = -(R’(t)^T R(t)^T)^T$.</p><p>所以我们可以知道：$R’(t)R(t)^T$是一个反对称矩阵。反对称矩阵都会有一个对应的向量，假设$R’(t)R(t)^T$对应的向量为$\phi(t)$,则：</p><p>$R’(t)R(t)^T = \phi(t)^{\hat{}}$</p><p>两侧同时右乘$R(t)$，得到：</p><p>$R’(t) = \phi(t)^{\hat{}} R(t)$</p><p>所以我们可以看到对R求导之后，多出来一个$\phi(t)$.</p><p>假如$t_0=0,R(t_0) = I$，对于$R(t)$进行泰勒展开：</p><script type="math/tex; mode=display">R(t) \approx R(t_0) + R'(t_0)(t - t_0) = I+\phi(0)t.</script><p>在很短的时间($t=t_0+\Delta t$)里，假设$\phi(t_0)$不会变化，设它为常数$\phi_0$。</p><p>$R’(t) = \phi(t_0)^{\hat{}}R(t) = \phi_0^{\hat{}}R(t)$</p><p>如果解上述微分方程（$R(0) = I$），可以得到：$R(t) = \exp(\phi_0^{\hat{}} t)$</p><p>所以我们就得到了一个在$t_0$附近的近似估计。</p><p>实际上$\phi$就是$SO(3)$对应的李代数。</p><h2 id="李代数"><a href="#李代数" class="headerlink" title="李代数"></a>李代数</h2><p>李代数由一个集合$\mathbb{V}$，一个数域$\mathbb{F}$,一个二元运算$[ ,]$组成。这个运算某一定程度上反映了两个数的差异。李代数满足下面几个性质：</p><ol><li>封闭性：$\forall X,Y \in \mathbb{V},[X,Y ] \in \mathbb{V}$</li><li>双线性：$\forall X,Y,Z \in \mathbb{V},a,b \in \mathbb{F}$,有：<script type="math/tex; mode=display">[aX+bY,Z ]= a[X,Z ] + b[Y,Z ],[Z,aX+bY ] = a[Z,X ]+b[Z,Y ].</script></li><li>自反性：$\forall X \in \mathbb{V},[X, X] = 0$</li><li>雅科比等价：$\forall X,Y,Z \in \mathbb{V},[X, [Y,Z ]] + [Z, [X,Y ]]+ [Y, [Z,X ]] = 0$</li></ol><p>其中二元运算被称为李括号。</p><h3 id="李代数-so-3"><a href="#李代数-so-3" class="headerlink" title="李代数$so(3)$"></a>李代数$so(3)$</h3><p>$so(3) = \{\phi \in \mathbb{R}^3 ,\Phi = \phi ^{\hat{}} \in \mathbb{R}^{3 \times 3}\}$.</p><p>李括号：$[\phi_1,\phi_2 ]= (\Phi_1\Phi_2 - \Phi_2 \Phi_1)^{\hat{}}$.</p><p>Note: $\Phi = \phi^{\hat{}},\phi = \Phi^{\hat{}}$.</p><h3 id="李代数-se-3"><a href="#李代数-se-3" class="headerlink" title="李代数$se(3)$"></a>李代数$se(3)$</h3><p>$se(3) = \left\{<br>    \xi = \begin{bmatrix}<br>    \rho\\<br>    \phi<br>    \end{bmatrix} \in \mathbb{R}^6,\rho \in \mathbb{R}^3,\phi \in so(3),\xi ^{\hat{}} = \begin{bmatrix}<br>    \phi^{\hat{}}&amp;\rho\\<br>    0&amp;0<br>    \end{bmatrix}<br>    \right\}$</p><h2 id="指数与对数映射"><a href="#指数与对数映射" class="headerlink" title="指数与对数映射"></a>指数与对数映射</h2><p>之前引出李代数中推导的$R(t) = \exp(\phi_0t)$,R是李群SO(3)，而$\phi$是李代数so(3).他们之间是有一一对应的关系的。恩，从上面的推导中并不能保证R就是$\phi$的$\exp$映射，但是实际上就是这样做的。</p><p>但是如何对一个$\phi$进行指数映射？映射还需转换为$\Phi$.对于一个矩阵，我们是没法进行$\exp$运算的。因此我们使用泰勒展开：</p><script type="math/tex; mode=display">\exp(A) = \sum_{n=0}^\infty \frac{1}{n!}A^n</script><p>同样上述展开也没那么容易进行，好在还有一些别的方法。</p><p>任何一个向量，我们都可以分解成方向和长度，也就是$\theta \mathbf{a}$.其中$\mathbf{a}$为单位向量。</p><p>然后，我们可以验证的是：</p><p>$\mathbf{a}^{\hat{}}\mathbf{a}^{\hat{}} = \mathbf{aa}^T -I$</p><p>$\mathbf{a}^{\hat{}}\mathbf{a}^{\hat{}}\mathbf{a}^{\hat{}} = -\mathbf{a}^{\hat{}}$</p><p>因为我们$\Phi = \phi^{\hat{}}$,所以上式提供了很好的办法来解决$\exp$问题。经过推导，我们可以得到：</p><script type="math/tex; mode=display">\begin{aligned}\exp(\phi^{\hat{}}) &= \exp(\theta \mathbf{a}^T) = \sum_{n=0}^\infty \frac {1} {n!} (\theta \mathbf{a}^{\hat{}})^n\\&=\cos \theta I + (1 - \cos \theta)\mathbf{aa}^T + \sin \theta \mathbf{a}^{\hat{}}\end{aligned}</script><p>很神奇的事情，上面竟然就是罗德里克斯公式（推导过程实际上不复杂，省略掉了）。</p><p>对应的还有一个对数映射：</p><p>$\phi = \ln(R)^{\hat{}} = \left (\sum_{n=0}^\infty \frac{(-1)^n}{n+1}(R-I)^{n+1} \right)$</p><p>当然，既然我们已经知道罗德里克斯公式了，就不用上式这么复杂的式子去求对数映射了。</p><p>旋转角，和旋转矩阵不是一一对应的，因为旋转矩阵唯一的情况下，旋转角可能有多个（角度多了$2\pi$）。这意味着指数映射是满射的。如果角度限制到$[-\pi,\pi ]$，那么李群和李代数元素就是一一对映的了。</p><p>同样，我们也可以得到$SE(3)$与$se(3)$的指数映射和对数映射:</p><script type="math/tex; mode=display">\begin{aligned}\exp(\xi^{\hat{}}) &= \begin{bmatrix}\sum_{n=0}^\infty \frac{1}{n!}(\phi ^{\hat{}})^n& \sum_{n=0}^\infty \frac{1}{(n+1)!}(\phi^{\hat{}})^n \rho\\0&1\end{bmatrix}& \triangleq \begin{bmatrix}R&J\rho\\0&1\end{bmatrix} = T\end{aligned}</script><p>上式中$J = \frac{\sin \theta}{\theta}I + \left(1 - \frac {\sin\theta}{\theta}\right)\mathbf{aa}^T + \frac{1 - \cos \theta}{\theta} \mathbf{a}^{\hat{}}$</p><p>它的对数映射，右上角与之前一样，而这里的$t = J\rho$,通过$\phi$可以计算出来J，从而解线性方程得到$\rho$.</p><p>J为雅克比矩阵。</p><h2 id="李代数的求导与扰动模型"><a href="#李代数的求导与扰动模型" class="headerlink" title="李代数的求导与扰动模型"></a>李代数的求导与扰动模型</h2><p>之所以要学习李群和李代数，是因为我们的SO(3)和SE(3)都是没有定义加法的。所以无法求导，对于优化非常难办。因此我们想做的是能否将李群和李代数上对应关系运用到求导中，把对李群的求导，转化为对李代数的求导。</p><p>所以我们希望的是：$\exp(\Phi_1 +\Phi_2) = \exp(\Phi_1)\exp(\Phi_2)$.</p><p>很遗憾的是，上面的式子不成立。（告辞）</p><h3 id="BCH公式"><a href="#BCH公式" class="headerlink" title="BCH公式"></a>BCH公式</h3><p>有一个BCH公式，它是对于矩阵来说的以及李群李代数相关的指数相乘展开：</p><p>$<br>\ln(\exp(A)\exp(B)) \approx A+B+\frac 1 2 [A,B ]+\frac 1 {12} [A, [A ,B]]+…<br>$</p><p>可以看到，在数学上，它会有这么多的余项存在的。不过我们做近似的估计。如果$\phi_1$或者$\phi_2$有一个量是小量，我们可以忽略其二次项。直接考虑到李代数的转换：</p><p>$<br>\ln(\exp(\phi_1^{\hat{}})\exp(\phi_2^{\hat{}}))^{\hat{}} \approx<br>\left \{\begin{matrix}<br>J_l(\phi_2)^{-1}\phi_1 +\phi_2&amp;\phi_1为小量\\<br>J_r(\phi_1)^{-1}\phi_2 +\phi_1&amp;\phi_2为小量\\<br>\end{matrix}<br>\right .<br>$</p><p>既然导数模型左或者右加上一个小量，上式中，第一个对应的是$\phi_2$为R对应的李代数，而$\phi_1$为小量，对应到李群，就是R左乘一个小量，第二个式子对应的就是右乘一个小量了。我们后面规定使用为左乘，实际上右乘的J和左乘也相差不多。</p><script type="math/tex; mode=display">J_l = J = \frac {\sin\theta}{\theta} I + (1 - \frac {\sin \theta}{\theta})\mathbf{aa}^T + \frac{1 - \cos \theta}{\theta} \mathbf{a}^{\hat{}}</script><script type="math/tex; mode=display">J_l^{-1} = \frac{\theta}{2} \cot \frac{\theta}{2}I + (1 - \frac{\theta}{2}\cot\frac{\theta}{2})\mathbf{aa}^T - \frac{\theta}{2}\mathbf{a}^{\hat{}}</script><p>右乘的雅科比矩阵：$J_r (\phi) = J_l(-\phi)$.</p><p>也就是：$\exp(\Delta \phi ^{\hat{}})\exp(\phi^{\hat{}}) \approx \exp ((\phi + J_l^{-1}(\phi)\Delta \phi)^{\hat{}})$.</p><p>同理，如果我们在李代数上进行加法：</p><script type="math/tex; mode=display">\exp((\phi+\Delta \phi)^{\hat{}}) = \exp((J\Delta \phi)^{\hat{}})\exp(\phi^{\hat{}})</script><p>上述都是左乘模型。</p><p>同样的，对于SE(3)也有类似的BCH近似公式：</p><script type="math/tex; mode=display">\exp(\Delta \xi ^{\hat{}}) \exp(\xi^{\hat{}}) \approx \exp((\mathcal{J}_l^{-1}\Delta \xi + \xi)^{\hat{}}),\\\exp(\xi^{\hat{}})\exp(\Delta \xi ^{\hat{}})  \approx \exp((\mathcal{J}_r^{-1}\Delta \xi + \xi)^{\hat{}}).</script><p>$\mathcal{J}_l$的形式比较复杂，我们也用不上，就不提了。</p><h3 id="so-3-求导"><a href="#so-3-求导" class="headerlink" title="so(3)求导"></a>so(3)求导</h3><p>我们想要实现对旋转矩阵的求导，由于旋转矩阵是乘法定义的，所以直接在SO(3)上无法定义出来导数。因此要转换到对应的李代数上来求得导数。</p><p>为了得到so(3)上的导数，有两种办法。第一种，是通过so(3)来实现，另一种是给SO(3)左乘一个矩阵来实现。</p><h4 id="导数模型"><a href="#导数模型" class="headerlink" title="导数模型"></a>导数模型</h4><p>根据导数的定义：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial (\exp(\phi^{\hat{}})p)} {\partial \phi}&= \lim_{\delta \phi \rightarrow 0} \frac{\exp((\phi + \delta \phi)^{\hat{}})p - \exp(\phi^{\hat{}})p} {\delta \phi}\\&= \lim_{\delta \phi \rightarrow 0} \frac{\exp((J_l\delta \phi)^{\hat{}})\exp(\phi^{\hat{}})p - \exp(\phi^{\hat{}})p}{\delta \phi}\\&\approx \lim_{\delta \phi \rightarrow 0} \frac{(I+(J_l\delta \phi)^{\hat{}})\exp(\phi^{\hat{}})p - \exp(\phi^{\hat{}})p}{\delta \phi}\\&= \lim_{\delta \phi \rightarrow 0} \frac{(J_l\delta\phi)^{\hat{}}\exp(\phi^{\hat{}})p}{\delta \phi}\\&= \lim_{\delta \phi \rightarrow 0} \frac{-(\exp(\phi^{\hat{}})p)^{\hat{}}J_l\delta\phi}{\delta \phi}\\&= -(Rp)^{\hat{}} J_l\end{aligned}</script><p>上面的过程用到了BCH展开，泰勒近似，以及$\hat{}$的性质：$a^{\hat{}}b = -b^{\hat{}}a $.<br>这里有形式比较复杂的$J_l$,我们不想计算它。所以看看扰动模型。</p><h4 id="扰动模型"><a href="#扰动模型" class="headerlink" title="扰动模型"></a>扰动模型</h4><p>扰动模型是在李群上左乘一个很小的矩阵$\Delta R$,假设它对应的李代数为$\theta$。通过扰动模型得到的导数为$-(Rp)^{\hat{}}$.<br>\begin{aligned}<br>\frac{\partial (Rp)} {\partial \phi}&amp;= \lim_{\theta \rightarrow 0} \frac{\exp(\theta^{\hat{}})\exp(\phi^{\hat{}})p - \exp(\phi^{\hat{}})p} {\theta}\\<br>&amp;=-(Rp)^{\hat{}}<br>\end{aligned}<br>扰动模型求导和上面导数模型可以使用同样的套路，而且更简单。因此就不详细写出来了。</p><p>可以看到扰动模型的比导数模型得到的结果更加简便一些。因此扰动模型相对于导数模型来说更加的实用。</p><h3 id="se-3-求导"><a href="#se-3-求导" class="headerlink" title="se(3)求导"></a>se(3)求导</h3><p>对于se(3)的求导，我们直接给出扰动模型：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial (Tp)}{\partial \xi} &= \lim_{\delta \xi \rightarrow 0} \frac{\begin{bmatrix}\delta \phi^{\hat{}}(Rp+t) + \delta p\\0\end{bmatrix}}{\delta \xi}\\&= \begin{bmatrix}I&-(Rp+t)^{\hat{}}\\0&0\end{bmatrix}\\&\triangleq (Tp)^{\bigodot}\end{aligned}</script><p>如果没有李群和李代数的提出，求导就没有理论依据了。而因为有了李群和李代数这种映射关系，我们可以通过将李群用李代数来表示，而李代数是可以进行求导的。从而实现对旋转矩阵的求导。</p><h2 id="Sophus库"><a href="#Sophus库" class="headerlink" title="Sophus库"></a>Sophus库</h2><p>李群李代数听得人头大。不过，我们不用自己去完成这些东西。对于李群李代数支持比较好的库是sophus，我们就使用这个库来实现slam中李群李代数需要的应用。</p><p>sophus是eigen的一个扩展，它在eigen的基础上实现了一些李群李代数的操作，没有任何别的依赖项。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>; </span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;Eigen/Core&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;Eigen/Geometry&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 李群李代数 库 </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"sophus/so3.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"sophus/se3.h"</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span>** argv )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="comment">/*******************************************/</span></span><br><span class="line">　</span><br><span class="line">    Eigen::Matrix3d R = Eigen::AngleAxisd(M_PI/<span class="number">2</span>, Eigen::Vector3d(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>)).toRotationMatrix();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"RotationMatrix R: \n"</span>&lt;&lt;R&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/***李群*****/</span></span><br><span class="line">    Sophus::<span class="function">SO3 <span class="title">SO3_R</span><span class="params">(R)</span></span>;               <span class="comment">// Sophus::SO(3)可以直接从旋转矩阵构造</span></span><br><span class="line">    Sophus::<span class="function">SO3 <span class="title">SO3_v</span><span class="params">( <span class="number">0</span>, <span class="number">0</span>, M_PI/<span class="number">2</span> )</span></span>;  <span class="comment">// 亦可从旋转向量构造  这里注意，不是旋转向量的三个坐标值，有点像欧拉角构造。</span></span><br><span class="line">    Eigen::<span class="function">Quaterniond <span class="title">q</span><span class="params">(R)</span></span>;            <span class="comment">// 或者四元数(从旋转矩阵构造)</span></span><br><span class="line">    Sophus::<span class="function">SO3 <span class="title">SO3_q</span><span class="params">( q )</span></span>;</span><br><span class="line">    <span class="comment">// 上述表达方式都是等价的</span></span><br><span class="line">    <span class="comment">// 输出SO(3)时，以so(3)形式输出</span></span><br><span class="line">    <span class="comment">//从输出的形式可以看出，虽然SO3是李群，是旋转矩阵，但是输出形式还是向量（被转化成李代数输出）。</span></span><br><span class="line">    <span class="comment">// 重载了 &lt;&lt; 运算符  out_str &lt;&lt; so3.log().transpose() &lt;&lt; std::endl;  </span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"SO(3) from matrix: "</span>&lt;&lt;SO3_R&lt;&lt;<span class="built_in">endl</span>;  <span class="comment">//SO(3) from matrix:      0      0 1.5708  </span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"SO(3) from vector: "</span>&lt;&lt;SO3_v&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"SO(3) from quaternion :"</span>&lt;&lt;SO3_q&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/****李代数*****/</span></span><br><span class="line">    <span class="comment">// 使用对数映射获得它的李代数</span></span><br><span class="line">    <span class="comment">// 所以，李代数 so3的本质就是个三维向量，直接Eigen::Vector3d定义。</span></span><br><span class="line">    Eigen::Vector3d so3 = SO3_R.<span class="built_in">log</span>();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"so3 = "</span>&lt;&lt;so3.transpose()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">// hat 为向量 到反对称矩阵  相当于　^　运算。</span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"so3 hat=\n"</span>&lt;&lt;Sophus::SO3::hat(so3)&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">// 相对的，vee为 反对称矩阵 到 向量  相当于下尖尖运算 </span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"so3 hat vee= "</span>&lt;&lt;Sophus::SO3::vee( Sophus::SO3::hat(so3) ).transpose()&lt;&lt;<span class="built_in">endl</span>; <span class="comment">// transpose纯粹是为了输出美观一些</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">/****李代数求导　更新*****/</span></span><br><span class="line">    <span class="comment">// 增量扰动模型的更新</span></span><br><span class="line">    Eigen::<span class="function">Vector3d <span class="title">update_so3</span><span class="params">(<span class="number">1e-4</span>, <span class="number">0</span>, <span class="number">0</span>)</span></span>; <span class="comment">//假设更新量为这么多</span></span><br><span class="line">    Sophus::SO3 SO3_updated = Sophus::SO3::<span class="built_in">exp</span>(update_so3)*SO3_R;<span class="comment">// 增量指数映射×原李代数</span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"SO3 updated = "</span>&lt;&lt;SO3_updated&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/********************萌萌的分割线*****************************/</span></span><br><span class="line">    <span class="comment">/************特殊欧式群　变换矩阵群　有旋转有平移*********************/</span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"************我是分割线*************"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">// 李群 对SE(3)操作大同小异</span></span><br><span class="line">    Eigen::<span class="function">Vector3d <span class="title">t</span><span class="params">(<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>)</span></span>;           <span class="comment">// 沿X轴平移1</span></span><br><span class="line">    Sophus::<span class="function">SE3 <span class="title">SE3_Rt</span><span class="params">(R, t)</span></span>;           <span class="comment">// 从R,t构造SE(3)</span></span><br><span class="line">    Sophus::<span class="function">SE3 <span class="title">SE3_qt</span><span class="params">(q,t)</span></span>;            <span class="comment">// 从q,t构造SE(3)</span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"SE3 from R,t= "</span>&lt;&lt;<span class="built_in">endl</span>&lt;&lt;SE3_Rt&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"SE3 from q,t= "</span>&lt;&lt;<span class="built_in">endl</span>&lt;&lt;SE3_qt&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">// 李代数se(3) 是一个六维向量，方便起见先typedef一下</span></span><br><span class="line">    <span class="keyword">typedef</span> Eigen::Matrix&lt;<span class="keyword">double</span>,<span class="number">6</span>,<span class="number">1</span>&gt; Vector6d;<span class="comment">// Vector6d指代　Eigen::Matrix&lt;double,6,1&gt;</span></span><br><span class="line">    Vector6d se3 = SE3_Rt.<span class="built_in">log</span>();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"se3 = "</span>&lt;&lt;se3.transpose()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">// 观察输出，会发现在Sophus中，se(3)的平移在前，旋转在后.</span></span><br><span class="line">    <span class="comment">// 同样的，有hat和vee两个算符</span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"se3 hat = "</span>&lt;&lt;<span class="built_in">endl</span>&lt;&lt;Sophus::SE3::hat(se3)&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"se3 hat vee = "</span>&lt;&lt;Sophus::SE3::vee( Sophus::SE3::hat(se3) ).transpose()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 最后，演示一下更新</span></span><br><span class="line">    Vector6d update_se3; <span class="comment">//更新量</span></span><br><span class="line">    update_se3.setZero();</span><br><span class="line">    update_se3(<span class="number">0</span>,<span class="number">0</span>) = <span class="number">1e-4</span>d;</span><br><span class="line">    Sophus::SE3 SE3_updated = Sophus::SE3::<span class="built_in">exp</span>(update_se3)*SE3_Rt;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"SE3 updated = "</span>&lt;&lt;<span class="built_in">endl</span>&lt;&lt;SE3_updated.matrix()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> mathematics </tag>
            
            <tag> sophus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——刚体运动以及Eigen</title>
      <link href="/2018/11/07/SLAM%E2%80%94%E2%80%94%E5%88%9A%E4%BD%93%E8%BF%90%E5%8A%A8%E4%BB%A5%E5%8F%8AEigen/"/>
      <url>/2018/11/07/SLAM%E2%80%94%E2%80%94%E5%88%9A%E4%BD%93%E8%BF%90%E5%8A%A8%E4%BB%A5%E5%8F%8AEigen/</url>
      
        <content type="html"><![CDATA[<p>这次主要介绍一些刚体运动中需要的数学知识以及Eigen库的基本使用。<br><a id="more"></a></p><p>什么是刚体运动？运动过程中不会发生形变。所以实际上刚体的运动也就只有两种：旋转和平移。</p><p>对于三维空间的旋转平移表示，之前的计算机图形学中介绍的比较清楚了。不过还有一些别的概念没有接触，在这里做个补充。</p><h2 id="旋转向量"><a href="#旋转向量" class="headerlink" title="旋转向量"></a>旋转向量</h2><p>之前的旋转使用的是旋转矩阵，旋转矩阵是单位正交矩阵（行列式为1）。实际上会有个问题：旋转操作只需要3个自由度，但是却用了9个量来表示。这说明使用旋转矩阵是有冗余的。因此这里介绍旋转向量。</p><p>我们知道任何旋转都可以使用一个旋转轴和旋转角来描述。旋转向量是一个非常聪明的做法。它的方向代表了旋转轴，而它的长度代表了旋转的角度。</p><p>那么旋转向量与旋转矩阵如何转换呢？如果旋转轴（单位向量）为$\mathbf{n}$，旋转角度为$\theta$，那么旋转向量为$\theta\mathbf{n}$，旋转矩阵可以使用Rodrigues公式来计算出来：</p><script type="math/tex; mode=display">R = \cos \theta I + (1-\cos \theta)\mathbf{nn}^T + \sin \theta \mathbf{n}^\hat{}</script><p>$\mathbf{n}^\hat{}$为向量$\mathbf{n}$的对偶矩阵。这个公式也在之前的图形学博客中做过介绍了。</p><p>如何从旋转矩阵得到旋转向量？</p><p>首先，对于旋转角：</p><script type="math/tex; mode=display">\begin{aligned}tr(R) &= \cos\theta tr(I) +(1 - \cos \theta) tr(\mathbf{nn}^T) + \sin \theta tr (\mathbf{n}^\hat{})\\&= 3\cos \theta + (1-\cos \theta)\\&= 1+ 2\cos\theta\end{aligned}</script><p>所以根据上式可以很简单求得：</p><script type="math/tex; mode=display">\theta = \arccos\left( \frac{tr(R)-1}{2}\right)</script><p>至于$\mathbf{n}$，由于旋转轴的向量旋转后不会发生变化，因此$R\mathbf{n} = \mathbf{n}$.</p><p>所以$\mathbf{n}$为矩阵R特征值为1的对应的特征向量。</p><h2 id="欧拉角"><a href="#欧拉角" class="headerlink" title="欧拉角"></a>欧拉角</h2><p>旋转向量以及旋转矩阵对于人的角度来说都不够直观。因此有了欧拉角的诞生。其实欧拉角就是将一个旋转转化为3个绕坐标轴的转动。因此这个转动的顺序就不唯一了。在航空里可能经常听到“偏航-俯仰-滚转”（yam-pitch-roll），实际上就是欧拉角的一种，等价与ZYX轴的旋转。</p><p>因此欧拉角就是用一个向量$[ r,p,y ]^T$（3个角度）来表示一个旋转。但是欧拉角有个著名的万能锁问题。如果pitch转动了$\pm90°$,则最后一个转动绕的轴实际上和z轴一样，这就使得损失了一个自由度，这被称为奇异性问题（？）。因此欧拉角不适用与插值和迭代，往往用于人工交互。</p><h2 id="四元数"><a href="#四元数" class="headerlink" title="四元数"></a>四元数</h2><p>旋转矩阵用9个量描述，有冗余，而旋转向量和欧拉角却具有奇异性。实际上我们找不到不带奇异性的三维向量描述方式。<br>因此在这里再介绍一个四元数。它用四个量来描述旋转足够紧凑同时也没有奇异性。</p><p>一个四元数$\mathbf{q} = q_0+q_1i+q_2j+q_3k$,有一个实部，3个虚部。其中虚部满足下面的一组式子：</p><script type="math/tex; mode=display">\left\{\begin{aligned}i^2 = j^2 = k^2 = -1\\ij=k,ji = -k\\jk=i,kj = -i\\ki=j,ik = -j\end{aligned}\right.</script><p>有时候也使用一个标量和一个向量来表示四元数：</p><p>$\mathbf{q} = [ s,\mathbf{v} ],s = q_0 \in \mathbb{R},\mathbf{v} = [ q_1,q_2,q_3 ]^T \in \mathbb{R}^3 $.</p><p>如果实部为0,称为虚四元数，如果虚部为0称为实四元数。</p><p>我们能用单位四元数表示三维空间中的任意旋转。不过由于复数的引入，它的表示是有点反直觉的。假如旋转向量为$\mathbf{n} \theta$，则对应的四元数为：</p><script type="math/tex; mode=display">\mathbf{q} = [ \cos \frac \theta 2, n_x\sin \frac \theta 2 ,n_y \sin \frac \theta 2,n_z,\frac \theta 2]^T.</script><p>因此从单位四元数中也很容易得到对应的旋转轴和旋转角度：</p><script type="math/tex; mode=display">\left \{\begin{aligned}\theta = 2 \arccos q_0;[ n_x,n_y,n_z] = [ q_1, q_2,q_3]^T / \sin \frac \theta 2\end{aligned}\right .</script><p>这个式子确实反直觉，给我们赚了一般的感觉。如果对$\theta $加上$2\pi$，相当于没有转动，但是他们对应的四元数却变成原来的相反数了。因此，互为四元数的相反数表示同一个旋转。</p><p>四元数的概念的话现在还很懵比，不知道为什么要这样来表示一个旋转。但是能发展到现在还留下来的一定是有自己的道理。因为四元数每个值都是经过处理的轴和角结合，因此它方便进行插值。听说四元数在游戏开发里应用广泛。具体这些以后再去弄明白，先看一看四元数的基本运算吧。</p><h3 id="加减"><a href="#加减" class="headerlink" title="加减"></a>加减</h3><p>$\mathbf{q}_a \pm \mathbf{q}_b = [ s_a \pm s_b ,\mathbf{v}_a \pm \mathbf{v}_b] $</p><h3 id="乘法"><a href="#乘法" class="headerlink" title="乘法"></a>乘法</h3><p>乘法就是各项轮着相称，最后相加，虚部要按照虚部的规则来乘，最后得到结果：</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{q}_a \mathbf{q}_b &= s_as_b - x_ax_b - y_ay_b - z_az_b\\&+(s_ax_b+x_as_b+y_az_b-z_ay_b)i\\&+(s_ay_b - x_az_b + y_as_b + z_ax_b)j\\&+(s_az_b+x_ay_b-y_ax_b+z_as_b)\end{aligned}</script><p>如果写成向量形式：</p><script type="math/tex; mode=display">\mathbf{q}_a \mathbf{q}_b  = [ s_as_b - \mathbf{v}_a^T\mathbf{v}_b, s_a\mathbf{v}_b + s_b\mathbf{v}_a + \mathbf{v}_a\times \mathbf{v}_b]</script><p>由于最后一项存在，四元数的乘法通常是不可交换的。</p><h3 id="共轭"><a href="#共轭" class="headerlink" title="共轭"></a>共轭</h3><p>$\mathbf{q}_a^* = s_a - x_ai - y_aj-z_ak = [ s_a,-\mathbf{v}_a]$</p><p>$\mathbf{q^ <em>q} = \mathbf{qq^ </em>} = [s_a^2 + \mathbf{vv}^T ,0]$ </p><p>可以看到四元数和共轭相称得到一个实数。</p><h3 id="模长"><a href="#模长" class="headerlink" title="模长"></a>模长</h3><script type="math/tex; mode=display">\Vert \mathbf{q}\Vert = \sqrt{s^2 +x^2+y^2+z^2}</script><p>可以验证：$\Vert \mathbf{q}_a\mathbf{q}_b \Vert = \Vert  \mathbf{q}_a\Vert \Vert  \mathbf{q}_b\Vert$.</p><p>这保证了单位四元数的乘积依然为单位四元数。</p><h3 id="逆"><a href="#逆" class="headerlink" title="逆"></a>逆</h3><p>$\mathbf{q}^{-1} = \frac {\mathbf{q}^*}{\Vert \mathbf{q}\Vert^2}$</p><p>$\mathbf{q}^{-1}\mathbf{q} = \mathbf{qq}^{-1} = 1$</p><p>同时可以知道，单位四元数的逆就是单位四元数的共轭，因为$\mathbf{qq}^* = 1$.</p><p>乘积的逆和矩阵的逆有同样的性质：$(\mathbf{q_a}\mathbf{q_b})^{-1} = \mathbf{q_b}^{-1}\mathbf{q_a}^{-1}$</p><h3 id="数乘和点乘"><a href="#数乘和点乘" class="headerlink" title="数乘和点乘"></a>数乘和点乘</h3><p>$k\mathbf{q} = [ks,k\mathbf{v} ]$</p><p>$\mathbf{q_a} \cdot \mathbf{q_b} = s_as_b + x_ax_b + y_ay_b + z_az_b$</p><h3 id="用四元数表示旋转"><a href="#用四元数表示旋转" class="headerlink" title="用四元数表示旋转"></a>用四元数表示旋转</h3><p>对于一个三维点$p=[x,y,z ]$,绕着转轴$\mathbf{n}\theta$旋转，变为$p’$.我们知道使用矩阵的话，可以这样描述：$p’ = Rp$.但是使用四元数如何描述呢？</p><p>我们把空间的点用虚四元数来描述，则$\mathbf{p} = [0,x,y,z ]$.</p><p>用$\mathbf{q}$来表示旋转: $\mathbf{q} = [\cos \frac \theta 2,\mathbf{n} \sin \theta 2]$.</p><p>则：$\mathbf{p}’ = \mathbf{qpq}^{-1}$.</p><p>可以验证的是经过计算的实部为0,虚部对应的就是$q’$的坐标点。</p><p>可以看到使用四元数来旋转的话也是非常方便的。</p><h3 id="四元数和旋转矩阵的转换"><a href="#四元数和旋转矩阵的转换" class="headerlink" title="四元数和旋转矩阵的转换"></a>四元数和旋转矩阵的转换</h3><p>四元数与旋转矩阵的转换，我们可以想到的是利用旋转向量来做中间的桥梁。不过其中有个arccos函数代价较大，但是实际上可以通过一定的技巧绕过。在这里直接给出四元数到旋转矩阵的转换结果（省略推导过程）：</p><p>设四元数为：$\mathbf{q} = q_0+q_1i+q_2j+q_3k$,则：</p><script type="math/tex; mode=display">R = \begin{bmatrix}1-2q_2^2 - 2q_3^2&2q_1q_2 - 2q_0q_3& 2q_1q_3 + 2q_0q_2\\2q_1q_2+2q_0q_3& 1-2q_1^2-2q_3^2& 2q_2q_3 - 2q_0q_1 \\2q_1q_3-2q_0q_2&2q_2q_3+2q_0q_1&1 - 2q_1^2 - 2q_2^2\end{bmatrix}</script><p>如果知道了旋转矩阵，想要得到四元数：</p><p>$q_0 = \frac{\sqrt{tr(R) + 1}}{2},q_1 = \frac{r_{2,3} - r_{3,2}}{4q_0},q_2 = \frac{r_{3,1} - r_{1,3}}{4q_0},q_3 = \frac{r_{1,2} - r_{2,1}}{4q_0}$</p><p>这里面$r_{i,j}$表示$R$的第i行j列。在计算过程中，如果$q_0$接近于0,则其他3个量就会很大，这是很需要考虑别的方式来表示旋转。</p><h2 id="相似，仿射，射影变换"><a href="#相似，仿射，射影变换" class="headerlink" title="相似，仿射，射影变换"></a>相似，仿射，射影变换</h2><h3 id="相似变换"><a href="#相似变换" class="headerlink" title="相似变换"></a>相似变换</h3><p>相似变换比之前的欧式变换多了一个自由度：</p><script type="math/tex; mode=display">T_S = \begin{bmatrix}sR&\mathbf{t}\\0&1\end{bmatrix}</script><p>这个s允许我们对物体进行均匀缩放。</p><h3 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h3><script type="math/tex; mode=display">T_A = \begin{bmatrix}A&\mathbf{t}\\0&1\end{bmatrix}</script><p>仿射变换不要求A为正交矩阵，只要可逆即可。仿射变换又叫正交投影变换。</p><h3 id="射影变换"><a href="#射影变换" class="headerlink" title="射影变换"></a>射影变换</h3><p>射影变换是最易般的变换。</p><script type="math/tex; mode=display">T_P = \begin{bmatrix}sR&\mathbf{t}\\\mathbf{a}^T&v\end{bmatrix}</script><p>左上角可逆，右上角为平移t,左下角为缩放$\mathbf{a}^T$</p><p>从真实世界到相机照片的变换可以看作为一个射影变换。如果焦距为无限远，则为仿射变换。</p><h2 id="Eigen"><a href="#Eigen" class="headerlink" title="Eigen"></a>Eigen</h2><p>最后介绍一些Eigen库相关的东西。Eigen是一个C++开源线性代数库.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;eigen/core&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;eigen/dense&gt;</span></span></span><br><span class="line"><span class="comment">/*3*3矩阵float型*/</span></span><br><span class="line">Eigen::Matrix&lt;<span class="keyword">float</span>,<span class="number">3</span>,<span class="number">3</span>,&gt; matrix_33;</span><br><span class="line"><span class="comment">/*3维向量，但实际上就是Eigen::Matrix&lt;double,3,1&gt;*/</span></span><br><span class="line">Eigen::Vector3d v_3d;</span><br><span class="line"><span class="comment">//输入</span></span><br><span class="line">v_3d&lt;&lt;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>;</span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;v_3d&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line"><span class="comment">//访问i行j列</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;v_3d(<span class="number">1</span>,<span class="number">0</span>);</span><br><span class="line"><span class="comment">//转置</span></span><br><span class="line">matrix_33.transpose();</span><br><span class="line"><span class="comment">//各项和</span></span><br><span class="line">matrix_33.sum();</span><br><span class="line"><span class="comment">//迹</span></span><br><span class="line">matrix_33.trace();</span><br><span class="line"><span class="comment">//逆</span></span><br><span class="line">matrix_33.inverse();</span><br><span class="line"><span class="comment">//行列式</span></span><br><span class="line">matrix_33.determinant();</span><br><span class="line"><span class="comment">//特征值和特征向量，实对称矩阵确保对角化成功</span></span><br><span class="line">Eigen::SelfAdjointEigenSolver&lt;Eigen::Matrix3d&gt; eigen_solver(matrix_33*matrix_33.transpose());</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; eigen_solver.eigenvalues() &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt; eigen_solver.eigenvectors() &lt;&lt; <span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>Module</th><th>Header file</th><th>Contents</th></tr></thead><tbody><tr><td>Core</td><td>#include &lt; Eigen/Core &gt;</td><td>Matrix和Array类，基础的线性代数运算和数组操作</td></tr><tr><td>Geometry</td><td>#include&lt; Eigen/Geometry &gt;</td><td>旋转、平移、缩放、2维和3维的各种变换</td></tr><tr><td>LU</td><td>#include&lt; Eigen/LU &gt;</td><td>求逆，行列式，LU分解</td></tr><tr><td>Cholesky</td><td>#include &lt; Eigen/Cholesky &gt;</td><td>LLT和LDLT Cholesky分解</td></tr><tr><td>Householder</td><td>#include&lt; Eigen/Householder &gt;</td><td>豪斯霍尔德变换，用于线性代数运算</td></tr><tr><td>SVD</td><td>#include&lt; Eigen/SVD &gt;</td><td>SVD分解</td></tr><tr><td>QR</td><td>#include&lt; Eigen/QR &gt;</td><td>QR分解</td></tr><tr><td>Eigenvalues</td><td>#include&lt; Eigen/Eigenvalues &gt;</td><td>特征值，特征向量分解</td></tr><tr><td>Sparse</td><td>#include&lt; Eigen/Sparse &gt;</td><td>稀疏矩阵的存储和一些基本的线性运算</td></tr><tr><td>稠密矩阵</td><td>#include&lt; Eigen/Dense &gt;</td><td>包含Core/Geometry/LU/Cholesky/SVD/QR/Eigenvalues模块</td></tr><tr><td>矩阵</td><td>#include&lt; Eigen/Eigen &gt;</td><td>包括Dense和Sparse(整合库)</td></tr></tbody></table></div><p>这些东西都被整合在dense模块中。</p><h3 id="eigen几何模块："><a href="#eigen几何模块：" class="headerlink" title="eigen几何模块："></a>eigen几何模块：</h3><p>旋转矩阵直接使用 Matrix3d 或 Matrix3f：</p><p>Eigen::Matrix3d rotationMatrix=Eigen::Matrix3d::Identity();//初始化为一个单位阵。</p><p>旋转向量使用 AngleAxis：</p><p>Eigen::AngleAxisd rotationVector(M_PI/4,Eigen::Vector3d(0,0,1)); //角+轴：沿 Z 轴旋转 45 度</p><p>欧拉角：</p><p>Eigen::Vector3d ea0(yaw,pitching,droll);</p><p>旋转向量-&gt;旋转矩阵：rotationMatrix=rotation_vector.toRotationMatrix();</p><p>旋转向量-&gt;四元数：Eigen::Quaterniond q = Eigen::Quaterniond ( rotation_vector );</p><p>旋转矩阵-&gt;四元数：Eigen::Quaterniond q = Eigen::Quaterniond ( rotation_matrix );</p><p>四元素-&gt;旋转矩阵：Eigen::Matrix3d Rx = q.toRotationMatrix();</p><p>旋转向量-&gt;欧拉角：Eigen::Vector3d eulerAngle=rotationVector.matrix().eulerAngles(0,1,2);</p><p>旋转矩阵-&gt;欧拉角：Eigen::Vector3d euler_angles = rotation_matrix.eulerAngles ( 2,1,0 ); // ZYX顺序，即roll pitch yaw顺序</p><h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><p>这一讲最后说明了世界坐标和相机坐标的转换。世界坐标下的坐标为$\mathbf{p}_w$，相机坐标下的坐标为$mathbf{p}_c$，则二者转换为：</p><script type="math/tex; mode=display">\mathbf{p}_w = T_{c2w}\mathbf{p}_c</script><script type="math/tex; mode=display">\mathbf{p}_c = T_{w2c}\mathbf{p}_w</script><p>值得注意的是，它提到了一般更常用的是从世界坐标到相机坐标的转换，但是从相机坐标到世界坐标的转换却更直观。因为如果相机坐标$\mathbf{p}_c$下为0,则世界坐标$\mathbf{p}_w$就是相机在世界坐标的位置:</p><script type="math/tex; mode=display">\mathbf{p}_w = T_{c2w} = t_{c2w}</script><p>上式中$t_{c2w}$正是相机的位置。也是平移向量。</p><p>所以从相机坐标到世界坐标的转换可以直接看到相机位置。这也是因为从相机坐标到世界坐标的转换是先旋转后平移的特性。先旋转后平移，则平移向量是不用改变的。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> Eigen </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SLAM——基本介绍</title>
      <link href="/2018/11/06/SLAM%E2%80%94%E2%80%94%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/"/>
      <url>/2018/11/06/SLAM%E2%80%94%E2%80%94%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>不出意外的话，以后我的方向应该就是三维重建方向了，而SLAM是一个逃不开的东西。<a id="more"></a></p><p>SLAM（simultaneous localization and mapping），即时定位与地图构建。它是个什么东西？就是将一个机器人放到一个陌生的环境，它能够自我定位并构建出当前环境的三维地图。我们实验室的有一个项目：<a href="http://luvision.net/FlashFusion/" target="_blank" rel="noopener">FlashFusion</a>，和SLAM也有这千丝万缕的关系。</p><p>SLAM已经诞生了30多年了，也取得了很长足的进步吸引了很多学术界的关注，但是一直达不到业界使用的要求。</p><p>SLAM学习的门槛比较高，因为对知识储备以及工程能力都有较高的要求。</p><p>我的这个SLAM打算利用高翔的《SLAM十四讲》来完成。首先第一章是一些大概的介绍以及一些编程的环境的搭建。实际上我对linux还不够熟悉，对于CMake也使用较少。所以这篇博客也会介绍一些这方面的东西。</p><h2 id="传感器介绍"><a href="#传感器介绍" class="headerlink" title="传感器介绍"></a>传感器介绍</h2><p>首先，SLAM需要的一些传感器，有激光，也有相机。实际上我们的重点在于相机，因为相机便宜，而激光很贵。相机分为单目相机，双目相机（Stereo）以及深度相机（RGBD），事件相机（Event）。一般来说使用较多的Stereo和RGBD，单目没有深度，只能同过移动相机来想办法产生深度，Stereo相机通过两个镜头来获得深度，而RGBD相机通过一定的物理手段来获取深度（如红外线，结构光等）。而到后面我们会知道，深度对于SLAM是非常重要的一个信息。</p><p>当我们拍摄一张照片的时候，从3D到2D，会损失了很多信息。所以我们需要深度才能构建三维模型。单目相机，只能通过运动来推算距离（远的运动慢，近的运动快），但是计算比较复杂，也经常出问题，不能避免很多不确定性。</p><h2 id="视觉SLAM框架"><a href="#视觉SLAM框架" class="headerlink" title="视觉SLAM框架"></a>视觉SLAM框架</h2><ul><li>前端（Visual Odometry）</li><li>后端（Optimization）</li><li>回环检测（Loop Closure Detection）</li><li>建图（Mapping）</li></ul><p>这些模块每个都需要很多的知识和精力来学习，所以这里只列出来框架。以后学习完毕之后，在给它们加上超链接。</p><h2 id="数学描述"><a href="#数学描述" class="headerlink" title="数学描述"></a>数学描述</h2><p>我们假设地图是由路标描述的，路标有N个，则路标分别为：$\mathbf{y}_1,…,\mathbf{y}_N$. 而各个时刻的机器人的位置表示为$\mathbf{x}_1,…,\mathbf{x}_k$.其中k为时刻。</p><p>则我们可以用下面两个式子来描述SLAM:</p><script type="math/tex; mode=display">\left \{\begin{aligned}\mathbf{x}_k = f(\mathbf{x}_{k-1},\mu_k,\mathbf{w}_k)\\z_{k,j} = h(\mathbf{y}_j,\mathbf{x}_k,\mathbf{v}_{k,j})\end{aligned}\right.</script><p>上式中，$\mu_k$为传感器读数,$\mathbf{w}_k$为噪声。第一个式子为运动方程，也就是我们通过之前的位置和运动传感器的输入得到了目前时刻的位置。</p><p>第二个式子为观测方程，z为观测数据，$\mathbf{v}_{k,j}$为观测噪声。观测方程中$z$是我们直接观测到的。</p><p>如果我们可以得到$\mathbf{x}_k$与$\mathbf{y}_k$的值，不就实现了定位与建图吗？</p><h2 id="CMake"><a href="#CMake" class="headerlink" title="CMake"></a>CMake</h2><p>在SLAM中C++语言是占有绝对优势的。任何程序都可以使用g++编译，但是对于过于复杂的工程，g++的命令会太长不好操作，因此我们需要使用CMake工具。</p><p>CMake是一种跨平台编译工具，比make更为高级，使用起来要方便得多。CMake主要是编写CMakeLists.txt文件，然后用cmake命令将CMakeLists.txt文件转化为make所需要的makefile文件，最后用make命令编译源码生成可执行程序或静态库(.a)或者共享库（.so(shared object)）。</p><p>实际上，CMake的使用主要在于CMakeList.txt的编写。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.cmake verson，指定cmake版本 </span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.project name，指定项目的名称，一般和项目的文件夹名称对应</span></span><br><span class="line"><span class="keyword">PROJECT</span>(test_sqrt)</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.head file path，头文件目录</span></span><br><span class="line"><span class="keyword">INCLUDE_DIRECTORIES</span>(</span><br><span class="line"><span class="keyword">include</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.source directory，源文件目录</span></span><br><span class="line"><span class="keyword">AUX_SOURCE_DIRECTORY</span>(src DIR_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.set environment variable，设置环境变量，编译用到的源文件全部都要放到这里，否则编译能够通过，但是执行的时候会出现各种问题，比如"symbol lookup error xxxxx , undefined symbol"</span></span><br><span class="line"><span class="keyword">SET</span>(TEST_MATH</span><br><span class="line"><span class="variable">$&#123;DIR_SRCS&#125;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#6.add executable file，添加要编译的可执行文件</span></span><br><span class="line"><span class="keyword">ADD_EXECUTABLE</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> <span class="variable">$&#123;TEST_MATH&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#7.add link library，添加可执行文件所需要的库，比如我们用到了libm.so（命名规则：lib+name+.so），就添加该库的名称</span></span><br><span class="line"><span class="keyword">TARGET_LINK_LIBRARIES</span>(<span class="variable">$&#123;PROJECT_NAME&#125;</span> m)</span><br></pre></td></tr></table></figure><p>aux_source_directory(&lt; dir &gt; &lt; variable &gt;)</p><p>搜集所有在指定路径下的源文件的文件名，将输出结果列表储存在指定的变量中。<br>如果想要生成库文件：<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#静态库</span></span><br><span class="line"><span class="keyword">add_library</span>( name libname.cpp)</span><br><span class="line"><span class="comment">#共享库</span></span><br><span class="line"><span class="keyword">add_library</span>(name_shared SHARED libname.cpp)</span><br></pre></td></tr></table></figure></p><p>当然，Cmake工具还有更多使用的技巧，需要平时做项目的时候去积累。</p>]]></content>
      
      
      <categories>
          
          <category> SLAM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 3D reconstruction </tag>
            
            <tag> SLAM </tag>
            
            <tag> CMake </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Covariance Matrix Derivation</title>
      <link href="/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Covariance-Matrix-Derivation/"/>
      <url>/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Covariance-Matrix-Derivation/</url>
      
        <content type="html"><![CDATA[<p>上周的数据学习课程布置了一个作业，主要做的是对多维高斯分布下求得协方差矩阵的取值。这个和之前将的Generative Learning Algorithm很相关，但是当时是直接给出了协方差矩阵的取值。结果是异常简单的，但是其中的证明可能要费点功夫。<br><a id="more"></a></p><p>题目描述如下：</p><p>Linear Discriminant Analysis (LDA) is a special case of Gaussian Discriminant Analysis (GDA) which assumes that the classes have a common covariance matrix $\Sigma_j = \Sigma, \forall j$. Now suppose all the $\Sigma_j$’s are not equal, and we will get the Quadratic Discriminant Analysis (QDA). The estimations for QDA are similar to those for LDA, except that separate covariance matrices must be estimated for each class. Give the maximum likelihood estimate of Σ j ’s for the case K = 2.</p><p>题目中说，之前博客中介绍的各个分类的$\Sigma$都是一样的，那叫做LDA，如果每个类别都有自己的$\Sigma_j$，则是QDA。让我们推导QDA的协方差矩阵应该是什么样子。</p><p>实际上，对于QDA还是LDA，协方差矩阵的推导是大致一样的，而QDA的最后结果也是非常简单。至于$\phi_j,\mu_j$等相比之下更简单，结果也和之前一样，就不在这里进行证明了。</p><p>这篇博客实际上就是把之前的写的作业发出来，因为我们作业要求为英文，因此下面的证明将为英文。</p><p>Firstly,  we need to know the log Maximum Likelihood Estimate:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}&\log L(\mu_1,...,\mu_k,\Sigma_1,...,\Sigma_k,\phi_1,...,\phi_k)\\ &= \log \prod_{i=1}^m p(x_i,y_i;\mu_1,...,\mu_k,\Sigma_1,...,\Sigma_k,\phi_1,...,\phi_k)\\ &=\log \prod_{i=1}^m p(x_i|y_i;\mu_{y_i},\Sigma_{y_i})p(y_i;\phi_{y_i})\\ &=\log \prod_{i=1}^m \prod_{j=1}^k \mathbf{1}\{y_i=j\} \frac{1}{(2\pi)^{\frac n 2}\vert \Sigma_j\vert ^{\frac 1 2}} e^{-\frac 1 2(x_i-u_j)^T\Sigma^{-1}(x_i-u_j)}p(y_i=k;\phi_{k}) \\ &= \sum_{i=1}^m  \sum_{j=1}^k \mathbf{1}\{y_i=j\}( - \frac 1 2(x_i-u_j)^T\Sigma^{-1}(x_i-u_j) -\frac n 2 \log (2\pi) + \frac 1 2 \log\vert \Sigma_j\vert+\log p(y_i;\phi_{y_i}))\\\end{aligned}\end{equation*}</script><p>If we want to find the Maximum, we need to get the derivative of Sigma. If we cut the useless parts,the function will be look like this:</p><script type="math/tex; mode=display">l = \frac 1 2\sum_{i=1}^m  \sum_{j=1}^k \mathbf{1}\{y_i=j\}(\log\vert \Sigma_j\vert - (x_i-u_j)^T\Sigma^{-1}(x_i-u_j))</script><p>I need to tell some basic rules about derivative of matrix:</p><script type="math/tex; mode=display">\begin{align}\frac { \partial \vert A\vert}{\partial A} = |A|(A^{-1})^T\\\frac {\partial A^{-1}}{\partial x} = A^{-1}\frac{\partial A}{\partial x} A^{-1}     \end{align}</script><p>We could use the (1) to get the $\log |\Sigma_k|$ ‘s derivative. Because of the SPD, we could get:</p><script type="math/tex; mode=display">\begin{align}\frac {\partial \log \vert \Sigma_j \vert}{\partial \Sigma_j} = (\Sigma_j^{-1})^T = \Sigma_j^{-1}\end{align}</script><p>Then, use the rule (2). Because the x is a scalar, so we need to separate the process.First let’s try to find the derivative of $\Sigma_{k,(i,j)}$:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}} &= \Sigma_k^{-1} \frac{\partial \Sigma_k}{ \Sigma_{k,(i,j)}}\Sigma_k^{-1}\\(x_i-u_j)^T\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}}(x_i-u_j)&=  (x_i-u_j)^T\Sigma_k^{-1} \frac{\partial \Sigma_k}{ \Sigma_{k,(i,j)}}\Sigma_k^{-1}(x_i-u_j)\end{aligned}\end{equation*}</script><p>We noticed that $(x_i-u_j)^T\Sigma_k^{-1} = (\Sigma_k^{-1}(x_i-u_j))^T $.</p><p>And the matrix $\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}}$ will be like a n $\times$ n matrix with the exception that the value of the position(i,j) will be 1.</p><p>So we could get:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}(x_i-u_j)^T\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}}(x_i-u_j)&=  (x_i-u_j)^T\Sigma_k^{-1} \frac{\partial \Sigma_k}{ \Sigma_{k,(i,j)}}\Sigma_k^{-1}(x_i-u_j)\\&= [(\Sigma_k^{-1}(x_i-u_j)) (\Sigma_k^{-1}(x_i-u_j))^T]_{(i,j)}\end{aligned}\end{equation*}</script><p>So:</p><script type="math/tex; mode=display">\begin{align}(x_i-u_j)^T\frac{\partial \Sigma_k^{-1}}{\partial \Sigma_{k,(i,j)}}(x_i-u_j) = (\Sigma_k^{-1}(x_i-u_j)) (\Sigma_k^{-1}(x_i-u_j))^T\end{align}</script><p>Now use (3) and (4),we could get: </p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\frac{\partial l}{\partial \Sigma_j} &=\frac 1 2\sum_{i=1}^m \mathbf{1}\{y_i=j\} (\Sigma_j ^{-1}-   (\Sigma_k^{-1}(x_i-u_j)) (\Sigma_k^{-1}(x_i-u_j))^T)\\ &=\frac 1 2\sum_{i=1}^m \mathbf{1}\{y_i=j\} (\Sigma_j ^{-1}-   \Sigma_j^{-1}(x_i-u_j)(x_i-u_j)^T\Sigma_j^{-1})\end{aligned}\end{equation*}</script><p>Because we want to let $\frac{\partial l}{\partial \Sigma_j} = \mathbf{0}$:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\frac 1 2\sum_{i=1}^m  \mathbf{1}\{y_i=j\} (\Sigma_j ^{-1}-   \Sigma_j^{-1}(x_i-u_j)(x_i-u_j)^T\Sigma_j^{-1}) = \mathbf{0}\\\sum_{i=1}^m\mathbf{1}\{y_i=j\} (I - \Sigma_j^{-1}(x_i-u_j)(x_i-u_j)^T) = \mathbf{0}\\\sum_{i=1}^m\mathbf{1}\{y_i=j\} I = \Sigma_j^{-1}\sum_{i=1}^m \mathbf{1}\{y_i=j\}(x_i-u_j)(x_i-u_j)^T\end{aligned}\end{equation*}</script><p>So,for QDA,the $\Sigma_j$ will be like this:</p><script type="math/tex; mode=display">\begin{equation*}\begin{aligned}\Sigma_j = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=j\}(x_i - \mu_{j}) (x_i - \mu_{j})^T}{\sum_{i=1}^m \mathbf{1}\{y_i=j\}}\end{aligned}\end{equation*}</script><p>where $j=1,2$.</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> mathematics </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Neural Network</title>
      <link href="/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Neural-Network/"/>
      <url>/2018/11/06/Learning-From-Data%E2%80%94%E2%80%94Neural-Network/</url>
      
        <content type="html"><![CDATA[<p>这周上的数据学习，主要讲了一些神经网络相关的知识。神经网络是目前最流行的机器学习算法了，甚至由它诞生了一个新的学科：deep learning。因此一篇博客，只能浅浅介绍一些神经网络的基本内容。<br><a id="more"></a><br>据说神经网络制造出来是为了模拟大脑。不过我认为离这个目标还差的远。但是呢，Neural Network确实做出来一些很牛逼的事情，让它成为现在AI中最受欢迎的技术。不过神经网络的概念倒是很早很早就提出了，之前没落是因为计算的性能跟不上。现在又东山再起了。</p><p>即使没有接触过机器学习，也一定听过神经网络学习，以及见过类似下面的图：</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/560px-Artificial_neural_network.svg.png" alt=""></p><p>实际上，这就是神经网络。神经网络的原理不复杂，但是如果嵌套层数比较多，就会需要非常大的计算量。</p><p>对于每一个神经元，我们都可以把它看作之前的一个logistic regression。每一个神经元可以接受输入，然后提供输出，要么作为最终的输出，要么给别的神经元提供输入。</p><h2 id="前向传播（forward-propagation）"><a href="#前向传播（forward-propagation）" class="headerlink" title="前向传播（forward propagation）"></a>前向传播（forward propagation）</h2><p>这意味着，我们的$W$参数将会变成一个”张量”（这么说也许不够准确，因为它不第一层可能有5个神经元，第2层可能有4个，也就是不是一个立方体）。在这里，我们用$\Theta$来表示这个张量。$\Theta^{(i)}$表示第i层的$\theta$参数，而$\Theta^{(i)}_j$表示第i层，第j个theta向量，$Theta^{(i)}_{j,k}$表示的就是某个具体的参数值了。</p><p>我们使用$a^{(i)}_j$按照上面的规则来表示第i层第j个神经元的输出。</p><p>所以，就上面的这个图，我们可以很容易得出：</p><script type="math/tex; mode=display">a_1^{(1)} = g(\Theta_{1,0}^{(1)}x_0 + \Theta_{1,1}^{(1)}x_1 + \Theta_{1,2}^{(2)}x_2+\Theta_{1,3}^{(3)}x_3 )\\a_2^{(1)} = g(\Theta_{2,0}^{(1)}x_0 + \Theta_{2,1}^{(1)}x_1 + \Theta_{2,2}^{(2)}x_2+\Theta_{2,3}^{(3)}x_3 )\\a_3^{(1)} = g(\Theta_{3,0}^{(1)}x_0 + \Theta_{3,1}^{(1)}x_1 + \Theta_{3,2}^{(2)}x_2+\Theta_{3,3}^{(3)}x_3 )a_4^{(1)} = g(\Theta_{4,0}^{(1)}x_0 + \Theta_{4,1}^{(1)}x_1 + \Theta_{4,2}^{(2)}x_2+\Theta_{4,3}^{(3)}x_3 )\\h_{\Theta}(X) =\\\begin{bmatrix} g(\Theta_{1,0}^{(2)}a_0^{(1)} + \Theta_{1,1}^{(2)}a_1^{(1)} + \Theta_{1,2}^{(2)}a_2^{(1)} +\Theta_{1,3}^{(2)}a_3^{(1)}+\Theta_{1,4}^{(2)}a_4^{(1)} )\\g(\Theta_{2,0}^{(2)}a_0^{(1)} + \Theta_{2,1}^{(2)}a_1^{(1)} + \Theta_{2,2}^{(2)}a_2^{(1)} +\Theta_{2,3}^{(2)}a_3^{(1)}+\Theta_{2,4}^{(2)}a_4^{(1)} )\end{bmatrix}\\= [a_1^{(2)},a_2^{(2)} ]^T</script><p>上面的神经网络输出有两项。</p><p>上面的函数中，g为logistic函数，又叫sigmoid函数。当然这个函数不仅仅局限于sigmoid函数，也有relu函数，tanh函数：</p><script type="math/tex; mode=display">\begin{matrix}g(z) = \frac 1 {1+e^{-z}} &(sigmoid)\\g(z) = \max(z,0) &(ReLU)\\g(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}& (tanh)\end{matrix}</script><p>我们定义$a_{j}^1$为原始输入。</p><p>我们可以使用向量化来加速神经网络的计算过程。这个应该不算很稀奇的技术。对于每一层来说，$theta$都是严格的矩阵的,而输入也是一个矩阵。所以每一层的向量化都不算困难。</p><p>通过输入，计算出每一层的输出，然后将这层输出当作下一层的输入，最后得到最后的结果，这就是前向传播。前向传播实际上就是神经网络怎么计算出结果的过程。</p><p>利用神经网络我们可以很容易地实现很复杂的非线性函数的边界，从而进行分类。吴恩达在视频中介绍了用神经网络对与，或非以及异或的实现。不过这些都是相对简单的，复杂的神经网络分析其来完全没有这么容易，这也是神经网络强大的一个原因。</p><p>为了实现多个分类，我们可以将最后的输出定位k个，分别来判断是否为当前类。这个做法实际上one-Vs-all的做法。</p><h2 id="cost-function"><a href="#cost-function" class="headerlink" title="cost function"></a>cost function</h2><p>接下来我们来谈谈neural network的cost function。之前的logistic regression的cost function是通过计算极大似然估计得到的。而神经网络的cost funtion实际上呢也是一样的，不过它的h(x)不再是之前那么简单了，这里的$W$变成了$\Theta$。而且由于输出可能是多元的（多元分类），所以这个cost funtion实际上是各个类别的cost funtion的叠加：</p><script type="math/tex; mode=display">J(\Theta) = -\frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K y_i^{(k)} \log(h_{\Theta}(X_i))_k + (1-y_i^{(k)}) \log (1 - (h_\Theta(X_i))_k)</script><p>如果加上正则化的话，则正则化项为：$\frac \lambda {2m} \sum_{l=1}^{L}\sum_{i=1}^{s_{l}}\sum_{j=1}{s_{l-1}} (\Theta_{i,j}^{(l)})^2$</p><p>需要注意的是这个$s_{l+1}$,为何是这样？$s_l$表示了第l层有多少神经元（如果l=0则表示有多少个原始输入），也就表示了有多少个输入向量，而输入向量的长度则由前一个输入的个数决定，因此$s_{l-1}$实际上输入向量的长度。所以呢，我们先从层数开始，然后到该层的每个神经元，最后再到每个参数的每个取值。<br>（这里和吴恩达的课程的表述稍微有点区别，也就是我的输入是表示为第0层，也就是一共有L+1层，而吴恩达的课程中，共有L层，原来的0变成现在的第1层。不过这意味着，从1开始计数，由于第一层是没有theta参数的，所以第一层计算的实际是下一层的theta，而$s_l$是下一层的输入向量长度，而$s_{l+1}$才是输入向量的个数，至于最后一层的theta由于已经在前一次计算过了，所以这里的regularization为$\frac \lambda {2m} \sum_{l=1}^{L-1}\sum_{i=1}^{s_{l}}\sum_{j=1}{s_{l+1}} (\Theta_{j,i}^{(l)})^2$）.</p><h2 id="向量化（vectorize）"><a href="#向量化（vectorize）" class="headerlink" title="向量化（vectorize）"></a>向量化（vectorize）</h2><p>首先，为了方便后面的说明，我们定义</p><p>$z_{j}^{(i)} = (\Theta_{j}^{(i)})^Ta^{(i-1)}$.</p><p>而$a_{j}^{(i)} = g(z_{j}^{(i)})$.</p><p>$a^{(i-1)} = [a_0^{(i-1)},a_1^{(i-1)},…,a_{s_{i-1}}^{(i-1)} ]$</p><p>希望大家还没有忘记这些符号以及下标的意义。</p><p>如果一个符号，只有层数的上标，没有下标，则意味着它是一个向量(etc.$a^{(i)},z^{(i)}$)，或是一个矩阵$\Theta^{(i)}$.</p><p>通过向量化，我们可以像下面一样通过线性代数库的并行优化，很快的计算出来$z^{(i)}$：</p><script type="math/tex; mode=display">z^{(i)} = \Theta^{(i)} a^{(i-1)}</script><p>上式中：</p><script type="math/tex; mode=display"> \Theta^{(i)}  = \begin{bmatrix} ...  (\Theta_{1}^{(i)})^T ... \\ ...  (\Theta_{2}^{(i)})^T ... \\ ...\\  ...  (\Theta_{s_i}^{(i)})^T ...  \end{bmatrix}</script><p>从这里，我们也可以知道了，为什么g不用identify function（g(z) = z）.因为神经网络的提出，是为了进行非线性的分类和预测。而：</p><script type="math/tex; mode=display">\begin{aligned}z^{(i)} &= \Theta^{(i)} a^{(i-1)}\\&=\Theta^{(i)}  g(z^{(i-1)})\\&=\Theta^{(i)}  z^{(i-1)}\\&= \Theta^{(i)}  \Theta ^{(i-1)} z^{(i-2)}\\&= \Theta^{(i)} \Theta^{(i-1)}...\Theta^{(1)} X_1\end{aligned}</script><p>这意味着我们通过线性的函数来做神经网络是无法得到非线性的分类结果的。</p><p>如果我们再对训练样本利用向量化，</p><script type="math/tex; mode=display">Z^{(l)} = \Theta^{(l)} ( A^{(l-1)})^T</script><p>这时候呢，Z变成矩阵了($s_{l} \times m)$)，A也变成矩阵了（$ m \times s_{l-1} $）。而Z^{(l)}实际如下：</p><script type="math/tex; mode=display">Z^{(l)} =\begin{bmatrix} \vert & ... & \vert\\z^{(l)[1 ]} & ... &z^{(l)[m ]}\\ \vert & ... & \vert\end{bmatrix}</script><h2 id="后向传播（back-propagation）"><a href="#后向传播（back-propagation）" class="headerlink" title="后向传播（back propagation）"></a>后向传播（back propagation）</h2><h3 id="参数初始化（Parameter-Initialization）"><a href="#参数初始化（Parameter-Initialization）" class="headerlink" title="参数初始化（Parameter Initialization）"></a>参数初始化（Parameter Initialization）</h3><p>需要注意的是，神经网络中我们不能简单地将参数初始化为0.经过计算你就会明白，如果参数初始化为0,则计算出来的梯度就是一样的，无法进行梯度下降,无论怎么运行，最后得到的结果为$0.5$(sigmoid)。可以进行随机初始化，给每个参数一个很小的值$N(0,0.1)$.</p><p>在实际中，证明了有比随机初始化更好的方法来进行初始化：Xavier/He initialization.</p><script type="math/tex; mode=display">\Theta ^{(l)} \tilde{} N\left(0,\sqrt{\frac {2}{s_l + s_{l-1}}} \right)</script><h3 id="梯度（gradient）"><a href="#梯度（gradient）" class="headerlink" title="梯度（gradient）"></a>梯度（gradient）</h3><p>后向传播实际上是建立在梯度下降的基础上的，所以最复杂的部分就是计算梯度了。</p><p>假设，这个层数一共有L层，最后的输出是$a^{L}$，因此cost funtion和L层的参数是直接相关的。所以首先计算的就是cost funtion对$\Theta^{(L)}$的梯度。</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial L(\Theta)}{ \partial \Theta^{(L)}} &= -\frac{\partial}{\partial \Theta^{(L)}} \left((1-y)\log (1 - y')  + y\log y'\right)\\&=-(1 - y)\frac{\partial}{\partial \Theta^{(L)}} \log (1 - g(\Theta^{(L)}a^{(L-1)}))  - y \frac{\partial}{\partial \Theta^{(L)}} \log g(\Theta^{(L)}a^{(L-1)})\\&= (1-y)\frac{1}{1 - g(\Theta^{(L)}a^{(L-1)})} g'(\Theta^{(L)}a^{(L-1)}))(a^{(L-1)})^T - y \frac {1}{g(\Theta^{(L)}a^{(L-1)}} g'(\Theta^{(L)}a^{(L-1)}(a^{(L-1)})^T\\&= (1-y)\sigma(\Theta^{(L)}a^{(L-1)})(a^{(L-1)})^T - y(1 - \sigma(\Theta^{(L)}a^{(L-1)})) (a^{(L-1)})^T\\&= (1 - y)a^{(L)} (a^{(L-1)})^T - y (1 - a^{(L)})(a^{(L-1)})^T\\&= (a^{(L)} - y)(a^{(L-1)})^T\end{aligned}</script><p>上述推导过程中，g为sigmoid函数，因此$g’ = \sigma’ = \sigma(1 - \sigma)$.</p><p>$a^{(i)}$我们都是可以通过前向传播得到的。</p><p>然后我们想要计算的是$\Theta{(L-1)},…,\Theta{(1)}$这些的梯度。但是它们是和$L(\Theta)$是没有直接的关系的。不过，在微积分中是有链式求导法则的：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial L}{\partial \Theta^{(L-1)}} &= \frac{\partial L}{a^{(L)}} \frac{a^{(L)}}{\partial \Theta^{(L-1)}}\\ &=\frac{\partial L}{a^{(L)}} \frac{a^{(L)}}{z^{(L)}} \frac{z^{(L)}}{\Theta^{(L-1)}}\\&=\frac{\partial L}{a^{(L)}} \frac{a^{(L)}}{z^{(L)}} \frac{z^{(L)}}{a^{(L-1)}}\frac{a^{(L-1)}}{\Theta^{(L-1)}}\\&=\underbrace{\frac{\partial L}{a^{(L)}} \frac{a^{(L)}}{z^{(L)}}}_{a^{(L)} - y}\underbrace{ \frac{z^{(L)}}{a^{(L-1)}}}_{\Theta^{(L)}}\underbrace{\frac{a^{(L-1)}}{z^{(L-1)}}}_{g'(z^{(L-1)})}\underbrace{\frac{z^{(L-1)}}{\Theta^{(L-1)}}}_{a^{(L-2)}}\end{aligned}</script><p>这其中，一个个的导数都是可以计算出来的。因此我们就得到了最终的梯度：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial L}{a^{(L)}} \frac{a^{(L)}}{z^{(L)}} \frac{z^{(L)}}{a^{(L-1)}}\frac{a^{(L-1)}}{z^{(L-1)}}\frac{z^{(L-1)}}{\Theta^{(L-1)}} = \underbrace{(a^{(L)} - y)}_{s_L\times1}\underbrace{\Theta^{(L)}}_{s_l \times s_{l-1}}\underbrace{g'(z^{(L-1)})}_{s_{l-1} \times 1}\underbrace{a^{(L-2)}}_{s_{l-2} \times 1}\end{aligned}</script><p>不过需要注意的是，上面得到的导数你会发现矩阵的维度可能不合适。因此这个形式必须要重新组织一下：</p><script type="math/tex; mode=display">\underbrace{\frac{\partial L}{\partial \Theta^{(L-1)}}}_{s_{l-1} \times s_{l-2}}=\underbrace{(\Theta^{(L)})^T }_{s_{l-1} \times s_{l}}\underbrace{(a^{(L)}-y)}_{s_l \times 1} .* \underbrace{g'(z^{(L-1)})}_{s_{l-1}\times 1}\underbrace{(a^{(L-2)})^T}_{1 \times s_{l-2}}</script><p>如果想要计算更前面的参数矩阵的导数，这个链式法则会越来越长。</p><p>为了更好的计算各个层的梯度，我们新定义一个符号:</p><script type="math/tex; mode=display">\sigma^{(l)} = \nabla_{z^{(l)}}L(y,y')</script><ul><li><strong>$l = L$</strong></li></ul><p>有时候我们可以直接计算出来$\nabla_{z^{(L)}}L(y,y’)$(g为softmax函数)，有时候需要使用链式法则:</p><p>$\nabla_{z^{(L)}}L(y,y’) = \nabla_{y’}L(y’,y) .* g’(z^{(L)})$</p><ul><li><strong>$l \ne L$</strong></li></ul><p>$\sigma^{l} = ((\Theta^{(l+1))^T}\sigma^{(l+1)}) .*g’(z^{(l)})$</p><ul><li>$\nabla _{\Theta^{(l)}} L = \sigma^{(l)}(a^{(l-1)})^T$</li></ul><p>通过验证你会发现实际上上面说的正是我们推导的内容。</p><p>使用梯度下降,或者SGD（更加常用），最终求得合适的$\Theta$.</p><p>可以看到的$\sigma^{(l)}$的计算，需要的是后向计算，所以这个叫后向传播。</p><p>上面的推导过程都是以一个training example的，对于多个样本可以通过向量化以及矩阵化来加快实现。</p><p>参考文献：</p><p><a href="http://cs229.stanford.edu/notes/cs229-notes-deep_learning.pdf" target="_blank" rel="noopener">css229:deep learning</a></p><p><a href="http://cs229.stanford.edu/notes/cs229-notes-backprop.pdf" target="_blank" rel="noopener">css229:back-prop</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> deep learning </tag>
            
            <tag> neural network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Kernel Logistic Regression</title>
      <link href="/2018/11/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Kernel-Logistic-Regression/"/>
      <url>/2018/11/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Kernel-Logistic-Regression/</url>
      
        <content type="html"><![CDATA[<p>在我们的生活中，其实大部分使用的都是soft-margin SVM，很少会有人真正去使用hard-margin，因为我们无法避免噪声。现在想想，能否将soft-margin svm与我们之前的losgistic regress结合起来，会得到什么样的学习算法？<br><a id="more"></a><br>之前我们试着将soft-margin SVM的数学描述写成了另外一种形式：</p><p><strong>min</strong>  $\frac 1 2 W^TW + C\sum_{n=1}^N max\{1-y_n(W^TX_n+b),0\}.$</p><p>实际上，这个形式如果你仔细观察这个形式，就会发现实际上它和losgistic regression加上L2正则化之后的形式非常的相似：</p><div class="table-container"><table><thead><tr><th>algorithm</th><th>minimize</th><th>constraint</th></tr></thead><tbody><tr><td> regularization by constraint</td><td>$E_{in}$</td><td>$W^TW \leq C$</td></tr><tr><td> hard-margin SVM</td><td>$W^TW$</td><td>$E_{in} = 0$[and more]</td></tr><tr><td> L2 regularization</td><td>$\frac \lambda N W^TW + E_{in}$</td><td></td></tr><tr><td> soft-margin SVM</td><td>$\frac 1 2 W^TW + CN\hat{E_{in}}$</td><td></td></tr></tbody></table></div><p>只不过之前我们用$\lambda$，而现在采用的是一个常数C。我们知道，C越大，也就是对应的$\lambda$越小。在这里，我们将$ max\{1-y(W^TX_n+b),0\}$看作为一种error measurement。</p><p>如果画出这几个错误的曲线与0\1错误的对比：</p><script type="math/tex; mode=display"></script><p>实际上，这两个函数是非常接近的。当$y_n(W^TX_n+b)$很大的时候，logistic regression的$E_{in}(\log_2^{1+e^{-ys}})$和 SVM的$\hat{E_{in}}(max\{1-y(W^TX_n+b),0\})$都是趋于0的,而当$y_n(W^TX_n+b)$非常小（远小于0）的时候，它们的$E_{in}$有都趋于$\vert y_n(W^TX_n+b) \vert$.</p><p>所以我们可以觉得，实际上SVM和logistic regression with L2 regularization几乎在做一样的事情。</p><p>现在我们希望可以将二者结合，例如我们用SVM的值来预测概率，我们也可以得到不错的结果。但是这个实际上没有用到logistic。或者我们用SVM的结果来做Logitsitc regression的初始值，但是既然logistic regression的$E_{in}$是凸函数，因此实际上得到的最终结果区别也不大，也就是实际上就像没有用到SVM。</p><h3 id="Platt’s-Model"><a href="#Platt’s-Model" class="headerlink" title="Platt’s Model"></a>Platt’s Model</h3><p>有一种这样的方法，将目标函数写为：$g(X) = \theta (A(W_{SVM}^T \phi(X) + b_{SVM}) +B)$</p><p>对上面的函数进行Logistic Regression。</p><p>所以这时候的Cost Function变成：</p><script type="math/tex; mode=display">min_{A,B} \frac 1 N \sum_{n=1}^N \log\left( 1+\exp\left( -y_n(A\cdot(W_{SVM}^T\phi(X_n)+b_{SVM})+B)\right)\right)</script><p>这时候的cost funtion 好像看上去非常复杂，但是仔细想一想的话，实际上既然我们已经有了SVM的结果，因此实际上$W_{SVM}^T\phi(X_n)+b_{SVM}$就是一个值，而不再是一个向量，也就是我们只需要两个数的值：A，B。就可以融合SVM和Logistic Regression。</p><p>当然，如果SVM做的好的话，A的值应该是大于0的，B的值应该是接近于0的，因为我们得到的最终的参数分别为$AW_{SVM}^T$与$Ab_{SVM}+AB$，分别对应最终的W和b，如果SVM做的不错，意味着他们和$W_{SVM},b_{SVM}$差距太大。</p><p>上述中$\phi(X)$意味着利用了特征转换，也就是会使用kernel。可以得到比较不错的logistic regression在z空间不错的解。</p><p>但是上面这个办法，不能保证这是logistic regression在Z空间（转换之后的空间）真正最好的解。</p><h3 id="Kernal-Logistic-Regression"><a href="#Kernal-Logistic-Regression" class="headerlink" title="Kernal Logistic Regression"></a>Kernal Logistic Regression</h3><p>想要找到logistic regression在Z空间真正最好的解，一个办法是在Z空间做logistic regression。但是我们的转换实际上是由kernel提供的，方便计算$Z_n^TZ_m$。而logistic regression根本就不是二次规划问题，又如何用到kernel？</p><p>其实，我们一直在求的东西是$W$，$W$的维度是和$Z$的维度一样，那么$W$是不是$Z$的线性组合呢？</p><p>在SVM中，正是这样，还记得$W$怎么算吗：</p><script type="math/tex; mode=display">W = \sum_{n=1}^N \alpha_n y_nX_n</script><p>同样的，在PLA，Logistic Regression中也是这样。假如我们想想$W$的初始值为0,那么每次更新步骤不就是一个系数乘上一个$X_i$的线性组合吗？</p><p>实际上，在L2的regularization中，最好的W都是可以被Z线性组合表示出来的。</p><p>如何证明这件事情？</p><p>我们将optimal $W$ 写为$W^*$.<br>其中$W^*$可以表示为垂直X空间的与平行X空间（线性组合即为平行）的。</p><p>$W^* = W_{\Vert} + W_{\perp}$</p><p>我们可以证明的是，当$W^*$中$W^{\perp}$为0.</p><p>如果$W_{\perp}!=0$,则$W^{*T}X = W_{\Vert}^T X + 0$。</p><p>从另一方面来说：<br>$W^{ * T}W^* = W_{\Vert} ^T W_{\Vert} + W_{\perp}^TW_{\perp} &gt;W_{\Vert} ^T W_{\Vert} $</p><p>这说明$W_{\Vert}$比$W^*$是更好的选择，与假设矛盾。</p><p>所以，$W^{*} = \sum_{n=1}^N\beta_nZ_n$.</p><p>因此，我们将W换成上式，那么就会出现了我们想要的$Z_nZ_m$.</p><p>L2 regularization变成下面的样子：</p><script type="math/tex; mode=display">min_{W} \frac \lambda N \sum_{n=1}^N\sum_{m=1}^N \beta_n\beta_m Z_n^TZ_m + \frac 1 N \sum_{n=1}^N \log \left(1 + \exp\left(-y_n \sum_{m=1}^N \beta_m Z_m Z_n \right) \right)</script><p>我们可以轻易将上式中的$Z_n^TZ_m$换成$k(x_n,x_m)$.从而实现在z空间上logistic regression的最优解。</p><p>从另一方面来说，$ \sum_{n}^N\sum_{m}^N \beta_n\beta_m k(x_n,_m) = \beta ^T K \beta$,可以将它看成一种特殊的正则化。所以实际上我们可以将KLR看成关于转换后的数据在$\beta$上的线性模型（原来是关于W的线性模型）。</p><p>一般来说$beta_n$都不为0,所以这个和SVM中的$\alpha_n$不一样。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——Lossless Encoding</title>
      <link href="/2018/11/02/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Lossless-Encoding/"/>
      <url>/2018/11/02/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Lossless-Encoding/</url>
      
        <content type="html"><![CDATA[<p>信息论算是应用数学，因此我们希望用熵，互信息这些东西来解决一些实际的问题。首先介绍下无失真编码定理，它早已经被广泛用在我们生活当中了。<br><a id="more"></a></p><p>首先，说到无失真编码，我们首先想到的是无损压缩了。无损压缩实际上是一个最大熵的问题。这样的情况下，能包含最多的信息，如果信息量一定，也就是最大熵的情况下需要平均较小的比特数（比如一个均匀分布随机变量X的熵为3,另一个非均匀分布随机变量熵Y也为3，那么|Y|&gt;|X|,如果普通编码的话，Y的编码更长，但是它们包含的信息量却是一样的）。我们都知道的是，在均匀分布的时候熵是最大的。但是我们不能选择信源的分布，因为信源就在那里已经确定了。我们能否通过一个映射，一一对应的映射，使得一个非等概分布逐渐走向等概呢？答案是，可以，但是这太反直觉了。是啊虽然反直觉，但是它不反数学，所以它就是对的。</p><h2 id="渐进等同分割性质（Asymptotic-Equipartition-Property）"><a href="#渐进等同分割性质（Asymptotic-Equipartition-Property）" class="headerlink" title="渐进等同分割性质（Asymptotic Equipartition Property）"></a>渐进等同分割性质（Asymptotic Equipartition Property）</h2><h3 id="大数定律（Law-of-Large-Number）"><a href="#大数定律（Law-of-Large-Number）" class="headerlink" title="大数定律（Law of Large Number）"></a>大数定律（Law of Large Number）</h3><p>这里先伯奴利大数定律(属于弱大数定律)。实际上所有的大数定律都在说一件事：当实验次数非常大的时候，频率趋向于概率（经验分布逼近于统计分布）。</p><script type="math/tex; mode=display">\frac{S_n}{n} \xrightarrow{p} p</script><p>更精确一点的说法：</p><script type="math/tex; mode=display">\forall N, \exists \epsilon >0,\sigma>0, \text{where }n > N,p(\vert \frac{s_n}{n} - p\vert \geq \epsilon) <\sigma.</script><p>另外一个大数定理（辛钦大数定律）：</p><script type="math/tex; mode=display">\begin{align}\frac 1 n \sum_{i=1}^n X_i\xrightarrow{p} EX\end{align}</script><p>渐进等同分割性质定义如下：</p><p>如果$X_1,X_2,…$是独立同分布的离散随机变量，分布服从$p(x)$,则</p><p>$-\frac 1 n \log p(X_1,X_2,…,X_n) \xrightarrow{p} H(X)$</p><p>使用上面的更准确的写法如下：</p><script type="math/tex; mode=display">\forall N, \exists \epsilon>0, \sigma >0, \text{where }n > N,p(\vert - \frac 1 n \log p(X_1,X_2,...,X_n) - H(X)\vert \geq \epsilon) <\sigma.</script><p>即$p(X_1,X_2,…,X_n)\approx 2^{-nH(X)}$.</p><p>这个定理可以使用弱大数定理地证明：</p><script type="math/tex; mode=display">\begin{aligned}&-\frac 1 n \log p(X_1,X_2,...,X_n)\\& = -\frac 1 n \log p(X_1)p(X_2)...p(X_n)\\&=-\frac 1 n \sum_{i=1}^n \log p(X_i)\end{aligned}</script><p>因为我们知道，$X_1,X_2,…,X_n$是互相独立的，因此，$\log X_1,\log X_2,…,\log X_n$也是互相独立同分布的。利用(1)：</p><script type="math/tex; mode=display">\begin{aligned}-\frac 1 n \sum_{i=1}^n \log p(X_i) &= -E(\log p(X))\\ &= \sum_{x \in \mathcal{X}} (-p(x)\log p(x)) \\&= H(X)\end{aligned}</script><p>这意味着，当n很大的时候，一个序列出现的概率是几乎相等的，这个概率为$2^{-nH(X)}$.</p><h2 id="（弱）典型序列（Typical-Sequence）"><a href="#（弱）典型序列（Typical-Sequence）" class="headerlink" title="（弱）典型序列（Typical Sequence）"></a>（弱）典型序列（Typical Sequence）</h2><p>典型序列定义如下：<br>相对于分布$p(x)$和序列$(x_1,x_2,…,x_n) \in X_n$,典型序列集合$A_\epsilon ^ {(n)}$定义为满足下列不等式约束的所有序列$\mathbf{x}$的集合：</p><script type="math/tex; mode=display">2^{-n(H(X)+\epsilon)} \leq p(\mathbf{x}) = p(x_1,x_2,...,x_n) \leq 2^{-n(H(X)-\epsilon)}</script><p>所以典型序列具有以下性质：</p><ol><li>若$\mathbf{x} \in A_\epsilon ^ {(n)}$,则$H(X)-\epsilon \leq -\frac 1 n \log p(\mathbf{x}) \leq H(X) + \epsilon$.</li><li>若$n$足够大，$Pr(A_\epsilon ^{(n)}) \geq 1 - \epsilon $</li><li>$\vert A_\epsilon ^{(n)}\vert \leq 2^{n(H(X)+\epsilon)}$</li><li>$\vert A_\epsilon ^{(n)}\vert \geq (1-\epsilon)2^{n(H(X)-\epsilon)}$</li></ol><p>性质1,2可以用定义得到。因此这里证明3和4.</p><p>3.</p><script type="math/tex; mode=display">\begin{aligned}1 &= \sum_{x^n \in \mathcal{X}}P(x^n)\\&\geq \sum_{x^n \in A_\epsilon ^{(n)}} p(x^n)\\&\geq \sum_{x^n \in A_\epsilon ^{(n)}} 2^{-n(H(x)+\epsilon)}\\&= 2^{-n(H(x)+\epsilon)}\vert A_\epsilon ^{(n)} \vert\end{aligned}</script><p>4的证明首先要使用性质2。</p><script type="math/tex; mode=display">\begin{aligned}1 - \epsilon &\leq Pr\{A_\epsilon ^{(n)}\}\\&\leq \sum_{x^n \in A_\epsilon ^{(n)}} 2 ^{-n(H(X) - \epsilon)}\\&= 2 ^{-n(H(X) - \epsilon)} \vert A_\epsilon ^{(n)}\vert \end{aligned}</script><p>所有可能出现的序列一共有$|X|^n$种，大多数情况下，$ 2^{m(H(X)+\epsilon)} &lt;&lt; |X|^n$.所以典型序列集合只是所有可能集合的一个很小（尤其是原来分布远离均匀分布的时候）的子集。但是它几乎一定会出现，而且每个典型序列出现的概率几乎一样，如下图所示。这是很好的消息，为我们刚开始提出来的映射提供了很好的思路。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/Screenshot_2019-01-10%20Introduction%20pdf%20-%20Elements_of_Information_Theory_Elements%20pdf.png" alt=""></p><h2 id="定长编码定理-香农第一定理"><a href="#定长编码定理-香农第一定理" class="headerlink" title="定长编码定理(香农第一定理)"></a>定长编码定理(香农第一定理)</h2><p>假设$X^n$是由独立同分布离散随机变量$X\tilde{}p(X)$构成的序列。对于任意正数$\epsilon$，总有足够大的n，可以找到一个一一映射，将$X^n$映射到二进制序列，且满足:</p><script type="math/tex; mode=display">E\left[\frac 1 n l(X^n) \right] \leq H(X)+\epsilon</script><p>上式中，$l(X^n)$表示的是编码需要的bit数。</p><p>接下来提供证明：</p><script type="math/tex; mode=display">\begin{aligned}E(l(X^n)) &= \sum_{x \in \mathcal{X}} p(x) l(x)\\&= \sum_{x \in A_\epsilon ^{(n)}} p(x) l(x) + \sum_{x \in \overline{A_\epsilon ^{(n)}}} p(x) l(x)\\& \leq \sum_{x \in A_\epsilon ^{(n)}} p(x) [ n(H(X)+\epsilon)+1+1 ] + \sum_{x \in \overline{A_\epsilon ^{(n)}}} p(x) [ n\log \vert X\vert +2 ]\\&=[ n(H(X)+\epsilon)+1+1 ] Pr\{ A_\epsilon ^{(n)}\} +  [ n\log \vert X\vert +2] Pr\{\overline{A_\epsilon ^{(n)}}\} \\&\leq n(H(X)+\epsilon)+2 +  n\epsilon \log\vert X\vert+2\epsilon= n(H(X) + \epsilon ')\end{aligned}</script><p>其中 $\epsilon’ = \epsilon + \epsilon \log \vert X \vert +\frac 2 n + \frac {2\epsilon}{n}$,可以看到的是$n \rightarrow \infty,\epsilon’ \rightarrow 0$.</p><p>上面证明过程中值得注意的事情是，为什么要加2？第一个加一是为了处理log后为非整数的情况，第二个+1是留一个比特位置来区分典型序列与非典型序列的编码。</p><p>但是，定长编码定理是无法应用到工业界的。因为它需要对序列长度为n来进行编码，由于精确度的要求，这个n往往很大（上亿），这在现实中是无法实现的。</p><p>顺便我们证明一下，平均每个字符编码所需要的bit数一定是大于等于$H(X)$.</p><p>假设$X^n \rightarrow M \in C = \underbrace{\{1,2,3,…,2^{nR}\}}_{need ~nR~ bits} \rightarrow \hat{X}^n$.</p><p>意思就是，$M$为$X^n$编码后的结果，它一定是属于后面的某个数字。</p><p>如果我们想要$P_e = 0$,也就是无失真编码，那么根据Fano不等式：</p><script type="math/tex; mode=display">H(X^n|M) = 0</script><p>因此：</p><script type="math/tex; mode=display">\begin{aligned}nH(X) &= H(X^n)\\&=H(X^n) - H(X^n|M)\\&=I(X^n,M)\\&=H(M) - H(M|X^n)\\&\leq H(M) \leq nR\end{aligned}</script><p>所以可以得到：$R\ge H(X)$.</p><p>可见，熵是平均码长的下界。</p><h2 id="码的类型"><a href="#码的类型" class="headerlink" title="码的类型"></a>码的类型</h2><h3 id="非奇异码"><a href="#非奇异码" class="headerlink" title="非奇异码"></a>非奇异码</h3><p>若一个码C可以将不同的x映射为不同的$D^*$中 的序列，即：</p><script type="math/tex; mode=display">x \ne x' \rightarrow C(x) \ne C(x')</script><p>则该码为非奇异码。</p><p>但是仅仅是非奇异码的序列可能会有歧义（很好笑）。$x_1 \rightarrow 0,x_2 \rightarrow 1,x_3 \rightarrow 01$，那么我收到$01$就不知道该如何介绍它了。</p><h3 id="唯一可译码"><a href="#唯一可译码" class="headerlink" title="唯一可译码"></a>唯一可译码</h3><p>唯一可译码是非奇异码的子集。称码$C^*$为码$C$的扩展，当$C^*$是有限长X的序列到有限长D序列的映射，且满足：</p><script type="math/tex; mode=display">C(x_1,x_2,...,x_n) = C(x_1)C(x_2)...C(x_n)</script><p>则该码为唯一可译码。</p><p>从另一方面来说，如果码的扩展为非奇异码，则该码为唯一可译码。</p><p>换句话说，没有码字是码字的组合。</p><p>这样的也是有缺点的，因为解码器复杂度要求较高。如$x_1 = 01,x_2 = 10,x_3 = 0111$,当收到0110的时候，在前三个的时候解码器预测可能是个$x_3$,但是最后一个不满足，因此就需要回退。</p><h3 id="即时码（前缀码）"><a href="#即时码（前缀码）" class="headerlink" title="即时码（前缀码）"></a>即时码（前缀码）</h3><p>前缀码大家就比较熟悉了。前缀码是唯一可译码的子集。如常用的霍夫曼编码。它的意思是没有什么码字是另一个码字的前缀。所以解码器只要发现有认识的，立马就可以解码了，所以叫即时码。</p><p>莫尔斯电码是非奇异码，但不是唯一可译码。汉语也不是唯一可译码，因为断句不对就会引起歧义。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
            <tag> lossless encoding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——连续随机变量的熵和互信息</title>
      <link href="/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E8%BF%9E%E7%BB%AD%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%86%B5%E5%92%8C%E4%BA%92%E4%BF%A1%E6%81%AF/"/>
      <url>/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94%E8%BF%9E%E7%BB%AD%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%86%B5%E5%92%8C%E4%BA%92%E4%BF%A1%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<p>如何将离散随机变量的这些概念推广到连续随机变量？<br><a id="more"></a></p><p>使用黎曼积分，我们可以得到：</p><script type="math/tex; mode=display">\begin{aligned}H(X) &= -\sum_{x} p(x)\Delta x \log p(x) \Delta x\\&= -\sum_{x}p(x)\log p(x)\Delta x - -\sum_{x}p(x)\log \Delta x\Delta x \end{aligned}</script><p>上式中，最后一项是趋于负无穷的。</p><p>这意味着连续随机变量包含的信息是无穷的。但是无穷的是无法研究的，因此香农重新给了一个微分熵的定义，它在数学上不够严格，但是在实际上却非常有用。</p><script type="math/tex; mode=display">h(X) = \int _{-\infty }^{+\infty} p(x)\log p(x) dx</script><p>可以看到它在形式上与离散形式的熵是非常相似的。</p><p>同时也有联合熵：</p><script type="math/tex; mode=display">h(X,Y) = -\int p(x,y)\log p(x,y) dxdy</script><p>条件熵：</p><script type="math/tex; mode=display">h(X|Y) = -\iint p(x,y) \log p(x|y) dxdy = -\int p(y) \int p(x|y) \log p(x|y) dx dy</script><p>不等式关系：<br>$<br>h(X,Y) = h(X) + h(Y|X) = h(Y) + h(X|Y)<br>$</p><p>$<br>h(X|Y) \leq h(X), h(Y|X) \leq h(Y)<br>$</p><p>$<br>h(X,Y)\leq h(X) + h(Y)<br>$</p><p>这些不等式都是存在的，与离散形式一致，但是要注意的是h(X)不一定是非负的了。</p><p>例如：</p><script type="math/tex; mode=display">X:p(x) = \left \{ \begin{array}{c}     \frac 1 {b-a} , a \leq x \leq b;\\    0, otherwise;    \end{array}    \right.</script><p>那么它的微分熵实际上等于$\log(b-a)$.当$b-a&lt;1$的时候，这个熵是小于0的。</p><h3 id="高斯分布的微分熵"><a href="#高斯分布的微分熵" class="headerlink" title="高斯分布的微分熵"></a>高斯分布的微分熵</h3><p>高斯分布概率密度如下：</p><p>$X:p(x) = \frac{1}{\sqrt {2 \pi \sigma}} exp [-\frac{(x-m)^2}{2\sigma ^2}]$</p><p>而它的微分熵为$h(x) = \frac 1 2 \log 2 \pi e \sigma^2$.</p><p>这个需要记住。当然只要带进定义就可以推算出来的。值得注意的是，它的微分熵和m（期望）是无关的</p><p>给定m和$\sigma$的情况下，当连续变量服从高斯分布的时候，微分熵最大。</p><h3 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a>互信息</h3><p>$I(X;Y) = \iint p(x,y) \log \frac{p(x,y)}{p(x)p(y)}dxdy$</p><p>可以直接使用黎曼积分得到，与离散的情况也非常一致。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——Fano不等式</title>
      <link href="/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Fano%E4%B8%8D%E7%AD%89%E5%BC%8F/"/>
      <url>/2018/11/01/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Fano%E4%B8%8D%E7%AD%89%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>从$X$到$Y$到$\hat{X}$，其中$\hat {X}$是对原有的$X$的估计,而Y可以看作是一个中间过程，可以想象类似于编码解码的过程。这之间有什么联系？<br><a id="more"></a></p><p>实际上，$X\rightarrow Y \rightarrow \hat X$形成了一个Markov链。</p><p>Fano不等式如下：</p><script type="math/tex; mode=display">P_e = Pr(X \ne \hat{X})\\H(P_e) + P_e \log|X| \geq H(X|\hat{X}) \geq H(X|Y)</script><p>证明如下：</p><script type="math/tex; mode=display">E =\left \{    \begin{array}{c}    0,X = \hat{X}\\    1,X \ne \hat{X}    \end{array} \right.</script><p>则：$H(E) = H(P_e)$。注意：当不等的时候为$1$，这个E可以看为错误。</p><p>现在考虑$H(E,X|\hat{X})$。由之前的条件熵可以知道：</p><script type="math/tex; mode=display">\begin{align}H(E,X|\hat {X}) &= H(X|\hat{X}) + H(E|X,\hat{X}) \\&=H(E|\hat{X})+H(X|E,\hat{X}) \end{align}</script><p>很容易知道(1)中，$H(E|X,\hat{X}) = 0$，因为E的值就是由$X,\hat{X}$确定的。</p><p>(2)中，$H(E|\hat{X}) \leq H(P_e)$（条件减少熵）。而第二项$H(X|E,\hat{X})$满足：</p><script type="math/tex; mode=display">H(X|E,\hat{X}) = P_e H(X|X \ne \hat{X},\hat{X}) + (1-P_e) H(X|X = \hat{X},\hat{X}).</script><p>这步还是比较难懂的。</p><p>上式中，$P_e H(X|X \ne \hat{X},\hat{X}) \leq P_e \log |X|,H(X|X = \hat{X},\hat{X}) = 0 $。</p><p>因此组合起来： $H(X|\hat{X}) \leq  H(P_e) + \log |X|$。</p><p>这里注意下，如果$\hat X \in \mathcal{X}$，那么我们可以得到：</p><script type="math/tex; mode=display">P_e H(X|X \ne \hat{X},\hat{X}) \leq P_e \log (|X| - 1)</script><p>这时候Fano不等式可以更紧一点：</p><script type="math/tex; mode=display">H(P_e) + P_e \log(|X|-1) \geq H(X|\hat{X}) \geq H(X|Y)</script><p>这就得到了Fano不等式的第一个不等号。</p><p>接下来证明$I(X;Y)\geq I(X;\hat{X})$。</p><script type="math/tex; mode=display">\begin{aligned}I(X;Y,\hat{X}) &= I(X;Y) + I(X;\hat{X}|Y)\\&= I(X;\hat{X}) + I(X; Y|\hat{X})\end{aligned}</script><p>上式中， $I(X;\hat{X}|Y) = 0$。除去Y的信息，$X,\hat{X}$是统计独立的，而两个系统的互信息是大于等于0的。所以可以得到：</p><script type="math/tex; mode=display">I(X,Y) \geq I(X;\hat{X}).</script><p>这告诉我们编码过程中，原有信息只会衰减，而不可能增大。</p><p>得到上式后，第二个不等式很快就可以得出：</p><script type="math/tex; mode=display">H(X) - H(X|Y) \geq H(X) - H(X|\hat {X})\\H(X|\hat{X})\geq H(X|Y)</script><p>所以整个不等式就得到了：</p><p>$H(P_e) + P_e \log|X| \geq  H(X|\hat {X}) \geq H(X|Y)$。</p><p>最后，Fano不等式也有更松一点的形式：</p><script type="math/tex; mode=display">1 + P_e \log|X| \geq \ H(X|\hat {X}) \geq H(X|Y)</script><p>这个很容易理解。因为形式简单，在平时解题中我们对这个不等式用的更多一点。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——the Convexity</title>
      <link href="/2018/10/31/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94the-Convexity/"/>
      <url>/2018/10/31/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94the-Convexity/</url>
      
        <content type="html"><![CDATA[<p>这篇博客来介绍熵，互信息，鉴别信息的凸性，与优化有着重要的关系。<a id="more"></a></p><h2 id="凸集-Convex-Set"><a href="#凸集-Convex-Set" class="headerlink" title="凸集(Convex Set)"></a>凸集(Convex Set)</h2><p>凸集：在欧氏空间中，凸集是对于集合内的每一对点，连接该对点的直线段上的每个点也在该集合内的集合。</p><p>凸集有：实数，概率矢量集合等。整数，有理数等不是凸集。</p><p>想要研究凸函数，首先凸函数一定要定义在凸集上。而概率矢量集合为凸集，是一个好消息。</p><p>凸函数有个坑。就是中国教材总是叫凸函数和凹函数，但是实际上中国的凸函数，是有最大值的函数，而非国外的convex function（最小值）。另外一种比较好的叫法是上凸和下凸，这个就容易区分了，上凸函数有最大值，下凸函数有最小值。</p><p>严格的数学定义：</p><ul><li>定义在凸集D上的函数$f(x)$如果满足$f(\lambda \alpha + (1-\lambda)\beta) \leq \lambda f(\alpha) + (1-\lambda) f(\beta)$,则为下凸函数。</li></ul><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/ConvexFunction.svg/768px-ConvexFunction.svg.png" alt=""></p><ul><li>定义在凸集D上的函数f(x)如果满足$f(\lambda \alpha + (1-\lambda)\beta) \geq \lambda f(\alpha) + (1-\lambda) f(\beta)$,则为上凸函数。</li></ul><h2 id="Jenson不等式"><a href="#Jenson不等式" class="headerlink" title="Jenson不等式"></a>Jenson不等式</h2><p>如果f是下凸函数，且X是离散随机变量，则$Ef(X)\geq f(EX)$,并且如果f是严格下凸函数，则上式中等号说明X为常数，及X与EX以概率1相等。（其中E为平均取值）。</p><p>由Jenson不等式可以推出<strong>对数求和不等式</strong>：<br>对于非负实数$a_1,a_2,…,a_n;b_1,b_2,…,b_n$有</p><script type="math/tex; mode=display">\sum _{i=1}^n a_i \log \frac{a_i}{b_i} \geq \left(\sum_{i=1}^na_i \right) \log \frac{\sum _{i=1}^n a_i}{\sum _{i=1}^n b_i}</script><p>这个式子的证明如下：</p><p>首先，当$t&gt;0$时，$t \log t$为一个严格下凸函数.可自行用导数证明。<br>由Jenson不等式可以得到：</p><script type="math/tex; mode=display"> Et \log Et \leq \ E(t \log t)\\i.e. \sum \alpha_i f(t_i) \geq  f(\sum \alpha _i t_i)\\</script><p>令$\alpha _i = \frac {b_i}{B},t_i=\frac {a_i}{b_i}, B = \sum_{b_i}$，代入上式可以得到：</p><script type="math/tex; mode=display"> \sum \frac{b_i}{B}\frac{a_i}{b_i} \log (\frac{a_i}{b_i}) \geq(\sum \frac{b_i}{B}\frac{a_i}{b_i}) \log(\sum \frac{b_i}{B}\frac{a_i}{b_i})\\ \sum \frac{a_i}{B} \log (\frac{a_i}{b_i}) \geq (\sum \frac{a_i}{B}) \log{\sum \frac {a_i}{B}}\\ \sum a_i \log {\frac {a_i}{b_i}} \geq (\sum a_i) \log {\frac {\sum a_i}{\sum b_i}}</script><p>在这里要学会如何构造去证明这个不等式。</p><h2 id="凸性"><a href="#凸性" class="headerlink" title="凸性"></a>凸性</h2><h3 id="鉴别信息的凸性"><a href="#鉴别信息的凸性" class="headerlink" title="鉴别信息的凸性"></a>鉴别信息的凸性</h3><p>$D(p\Vert q)$是$(p,q)$的下凸函数。即若存在$(p_1,q_1)$和$(p_2,q_2)$,则</p><script type="math/tex; mode=display">\lambda D(p_1\Vert q_1) + (1 - \lambda) D(p_2\Vert q_2) \geq D(\lambda p_1 + (1-\lambda)p_2 \Vert \lambda q_1+(1 - \lambda)q_2)</script><p>上式对所有的$0\leq \lambda \leq 1$成立。</p><p>证明如下：</p><script type="math/tex; mode=display">\begin{aligned}D(\lambda p_1 + (1-\lambda)p_2 \Vert \lambda q_1+(1 - \lambda)q_2)&=\sum_{x \in \mathcal{X}} \left [ \lambda p_1(x)+ \overline {\lambda} p_2(x) \right] \log \frac{\lambda p_1(x)+ \overline {\lambda} p_2(x)}{\lambda q_1(x)+ \overline {\lambda} q_2(x)}\\& \leq \sum_{x \in \mathcal{X}} \lambda p_1(x) \log {\frac{p_1(x)}{q_1(x)}} +  \overline {\lambda} p_2(x) \log \frac{p_2}{q_2}\\&= \sum_{x \in \mathcal{X}} \lambda D(p_1 \Vert q_1) + \overline {\lambda} D(p_2 \Vert q_2)\end{aligned}</script><p>可以看到上式的证明利用到了之前的对数求和不等式。</p><h3 id="熵的凸性"><a href="#熵的凸性" class="headerlink" title="熵的凸性"></a>熵的凸性</h3><p>知道了鉴别信息的下凸性质，证明熵的凸性就非常容易。</p><p>$H(X) = \log |X| - D(p\Vert u)$</p><p>上式中，u不变，是均匀分布的情况，这时候D是一个下凸函数，而很明显$\log |X|$不变，因此$H(X)$是一个上凸函数。其实大家也很容易理解。因为均匀分布式的熵最大，也就是有最大值。</p><h3 id="互信息的凸性"><a href="#互信息的凸性" class="headerlink" title="互信息的凸性"></a>互信息的凸性</h3><p>下面来证明互信息的凸性。</p><p>互信息定义为下：</p><script type="math/tex; mode=display">I(X;Y) = I(p;Q) =  \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x)q(y|x)\log \frac{q(y|x)}{\sum _{x \in \mathcal{X}}p(x)q(y|x)}</script><p>这样的写法，对于信道传输的模型更有帮助。</p><p>首先如果给定Q，这意味着给定了信道：</p><p>Fix $Q =[q(y|x)]$</p><script type="math/tex; mode=display">\begin{aligned}I(X;Y) &= H(Y) - H(Y|X)\\&= H(Y) - \sum_{x \in \mathcal{X}} p(x)H(Y|X=x)\\&= H(Y) - \sum_{x \in \mathcal{X}} p(x) \sum_{y in \mathcal{Y}} q(y|x) \log {q(y|x)}\end{aligned}</script><p>上式中既然Q已经给定，因此H(Y|X)也就是p(x)线性组合。因此整个函数为上凸减去线性，依然为上凸函数。</p><p>如果给定p：</p><p>Fix $p(x)$:</p><script type="math/tex; mode=display">\begin{aligned}I(X;Y) = D(p(x,y)\Vert p(x)(y))\\p(x,y) = p(x)q(y|x)\\p(y) = \sum_{x \in \mathcal{X}} p(x)q(y|x)\end{aligned}</script><p>因此p(x,y),p(y),p(x)p(y)都是q(y|x)的线性组合。而D本身是下凸函数。所以互信息固定p(x)时候为下凸函数。可用于有失真编码。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Generative Learning Algorithm</title>
      <link href="/2018/10/29/Learning-From-Data%E2%80%94%E2%80%94Generative-Learning-Algorithm/"/>
      <url>/2018/10/29/Learning-From-Data%E2%80%94%E2%80%94Generative-Learning-Algorithm/</url>
      
        <content type="html"><![CDATA[<p>之前我们介绍的分类算法，包括，logistic regression，PLA甚至加上linear regression，他们都是试图找到一条线然后来将两种类别分开。这种算法叫做Discriminative Learning Algorithm，他们的由来，都是直接去估计$P(Y|X)$,这样的话根据新样本的X，从而预测Y。<a id="more"></a></p><p>接下来我们想介绍的是另外一种思路来解决分类问题。我们不再直接估计$P(Y|X)$,而是估计$P(X|Y)$.也就是，我们希望从当前的样本中学到X的特征看上去应该是什么样子，从鸡的样本中学到鸡的样子，从狗的样本中学到狗的样子。这样的算法叫做Generative Learning Algorithm（生成学习算法）。当然，我们最后要知道的还是$P(Y|X)$,不过根据Bayes理论可以知道：</p><script type="math/tex; mode=display">P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}</script><p>我们知道：</p><p>$argmax_yp(y|x) = argmax_y \frac{p(x|y)p(y)}{p(x)} = argmax_y p(x|y)p(y) = WhatWePredict$</p><p>所以我们真正需要解决的是$P(x|y)P(y)$.</p><p>当然，如果想要求得P(X),可以通过全概率公式：$P(X) = P(y=1)\cdot P(X|y=1) +P(y=0)\cdot P(X|y=0)$.</p><p>下面介绍两个最常见的生成学习算法：Gaussian Discriminant Analysis(高斯判别分析)与Naive Beyas(朴素贝叶斯模型)。</p><h3 id="Gaussian-Discriminate-Analysis"><a href="#Gaussian-Discriminate-Analysis" class="headerlink" title="Gaussian Discriminate Analysis"></a>Gaussian Discriminate Analysis</h3><p>高斯判别模型主要用于输入是连续的时候，也就是X的特征值是属于实数集的。首先来复习一下多维高斯分布模型，它是高斯判别模型的基础：</p><p>一般来说，多维高斯分布简写为：X \tilde{} N(\mu,\Sigma).</p><ul><li>$\mu \in \mathbb{R}^n$ 是平均向量。</li><li>$\Sigma \in \mathbb{R}^{n \times n}$是协方差矩阵。$\Sigma$是对称的SPD（ symmetric and positive definite matrix）.</li></ul><p>它的概率密度函数如下：</p><script type="math/tex; mode=display">p(x;\mu,\Sigma) = \frac{1}{(2\pi)^{\frac n 2}\vert \Sigma\vert ^{\frac 1 2}} e^{-\frac 1 2(x-u)^T\Sigma^{-1}(x-u)}</script><p>均值和协方差对分布有什么影响？利用一个二维的向量来说的话，有下面几张图可以看看：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/mg1.png" alt=""></p><p>这三张图分别对应着协方差矩阵为$I，2I,\frac 1 2 I$的情况。其中<br>$I = \begin{bmatrix}<br>1&amp;0\\<br>0&amp;1<br>\end{bmatrix}$.</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/mg2.png" alt=""></p><p>从上图又可以看出来，协方差矩阵非对角线的数字变化的时候，对它的图形似乎扭向一边了。实际上这代表了两个特征间的相关程度。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/mg3.png" alt=""></p><p>最后一个就是$mu$的变化，很显而易见，图形的中心改变了。</p><p>现在假如有一个分类问题，其中$X \in \mathbb{R}^n$,利用高斯判别模型的话，我们会有以下假设：</p><script type="math/tex; mode=display">y\tilde{} Bernuolli(\Phi)\\p(x|y=0)\tilde{}N(\mu_0,\Sigma)\\p(x|y=1)\tilde{}N(\mu_1,\Sigma)</script><p>从上面看出来，我们对于两个模型的生成采用的$\mu$不一样，但是$\Sigma$一样，这样不光保证了两个模型的形状一样，简化了计算过程，最后可以用它们接触点的切线来当做分割线，从而实现与之前Discriminative学习算法的比较。</p><p>Note:现在n为向量的维度，而m为样本个数。</p><p>和往常一样，我们求它的log极大似然估计：</p><script type="math/tex; mode=display">\begin{align}l(\Phi,\mu_0,\mu_1,\Sigma)&= \log \prod_{i=1}^{m}p(X_i,y_i;\Phi,\mu_0,\mu_1,\Sigma)\\&= \log \prod_{i=1}^m p(X_i|y_i;\mu_0,\mu_1,\Sigma)p(y_i;\Phi) \end{align}</script><p>上述的式子中的参数取值如下：</p><script type="math/tex; mode=display">\Phi = \frac 1 m \sum_{i=1}^m \mathbf{1}\{ y_i = 1\}\\\mu_b = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=b\}X_i}{\sum_{i=1}^m \mathbf{1}\{y_i=b\}},b=0,1\\\Sigma = \frac 1 m \sum_{i=1}^m(X_i - \mu_{y_i})(X_i - \mu_{y_i})^T</script><p>我们希望生成的模型如下：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0366.JPG" alt=""></p><p>如果画等高线图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/mg4.png" alt=""> </p><p>我们会发现找到一条线，它属于0或者1的概率是相等的。因此我们就找到了这条线。</p><h4 id="GDA与Logistic-Regression"><a href="#GDA与Logistic-Regression" class="headerlink" title="GDA与Logistic Regression"></a>GDA与Logistic Regression</h4><p>在上面的推导过程中我们发现：</p><script type="math/tex; mode=display">\begin{align}P(y=1|X;\Phi,\mu_0,\mu_1,\Sigma) &=  \frac{p(X|y=1)p(y=1)}{p(X|y=1)p(y=1)+p(X|y=0)p(y=0)}\\&=\frac {1}{1+e^{-\theta ^TX}}\end{align}</script><p>上式中：$\theta = \begin{bmatrix} \log \frac{1-\Phi}{\Phi} - \frac 1 2(\mu_0^T\Sigma^{-1}\mu_0 - \mu_1^T \Sigma^{-1}\mu_1) \ \Sigma ^{-1}(\mu_0 - \mu_1)\end{bmatrix}$.</p><p>如果还记得上次讲过的exponential family，我们应该知道对于伯奴利分布$(y|x \tilde{} B(\psi))$的canonical link funtion是 $\log \frac{\psi}{1-\psi}$.</p><p>因此$\theta ^X = \log \frac{\psi}{1-psi} = \log \frac{p(y=1|X)}{p(y=0|X)} = \log \frac {p(X|y=1)p(y=1)}{p(X|y=0)p(y=0)}$</p><p>这意味着：如果$p(x|y)\tilde{}N(\mu,\Sigma)$,则$p(y|x)$是logistic function.但是从logistic regression是无法推出来GDA的。</p><p>如果我们的假设正确，GDA模型更高效，效果也更好，但是logistic regression因为比较简单，对于即使假设错误了依然有很好的鲁棒性。GDA最大化联合分布，而LR最大化的是概率分布。</p><p>所以我们发现，GDA并不像普通的学习算法那样需要去进行cost funtion的优化。这得益于我们假设整个正样本的X服从一个高斯分布。而之前的学习方法，每个样本因为X不同各个样本之间服从分布的参数都会不一致，也就是每个样本在给定y的时候有一个自己的分布（如逻辑回归，每个样本都有不同的概率，而它预测的是伯奴利分布，也就是每个样本服从不同的伯奴利分布；又如线性回归，每个样本有不一样的$\mu$）。</p><h3 id="Naive-Beyas"><a href="#Naive-Beyas" class="headerlink" title="Naive Beyas"></a>Naive Beyas</h3><p>下面介绍朴素贝叶斯模型。它用来处理输入为离散数据时候的情况。假如有这么一个例子：垃圾邮件分类。如何定义邮件的特征？当然定义的是其中的单词了。但是这个世界上单词有很多很多，而垃圾邮件很可能更包含了很多无意义的字符组合，这样特征就更多了。</p><p>假设给一个大小为n的字典（这个n可能很大，50000或者100000），而一个邮件的特征值会像下面的样子：</p><script type="math/tex; mode=display">\begin{bmatrix}1\\0\\.\\.\\.\\1\\.\\.\\.\end{bmatrix} \begin{matrix}a\\aadjsa\\.\\.\\.\\b\\.\\.\\.\end{matrix}</script><p>1或者0代表了在这个邮件中是否出现了。</p><p>现在希望对$P(X|Y)$建模。对于一封垃圾邮件：</p><script type="math/tex; mode=display">p(x_1,x_2,...,x_n|y) = p(x_1|y)p(x_2|y,x_1),...,p(x_n|y,x_1,...,x_{n-1})</script><p><em>使用了概率论中的链式法则。这个规则我也不了解，概率论还需要学习</em></p><p>这样的计算是非常复杂的。因此朴素贝叶斯模型中有一个假设：$x_i$在给定y之后是条件独立的。这意味着：$p(x_n|y,x_1,…,x_{n-1}) = p(x_n|y)$.</p><p>所以$p(x_1,x_2,…,x_n|y) = \prod _{i=1}^np(x_i|y)$.</p><h4 id="多变量伯奴利事件模型"><a href="#多变量伯奴利事件模型" class="headerlink" title="多变量伯奴利事件模型"></a>多变量伯奴利事件模型</h4><p>$p(x,y) = p(y)p(x|y) = p(y) \prod _{i=1}^n p(x_i|y)$.</p><p>这个模型假设了每封邮件是以$\Phi_y$随机生成的。如果给定y，每个单词是独立的包含在信息里的，而这个概率为$p(x_i=1|y) = \Phi_{i|y}$.</p><p>这个模型参数如下：</p><ul><li>$\Phi_y = p(y=1)$</li><li>$\Phi_{i|y=0} = p(x=1|y=0)$</li><li>$\Phi_{i|y=1} = p(x=1|y=1)$</li></ul><p>同样的，接下来要做的依然是求log极大似然估计：</p><script type="math/tex; mode=display">\begin{align}L(\Phi_y \Phi_{i|y=1},\Phi_{i|y=0}) &=\log \prod_{i=1}^m p(X_i,y_i)\\ &= \log \prod_{i=1}^m p(X_i|y_i)p(y_i)\\ &= \log \prod_{i=1}^m \prod_{j=1}^np(x_j|y_i)\end{align}</script><p>不难想象，各个参数的取值如下：</p><script type="math/tex; mode=display">\Phi_y = p(y=1) = \frac 1 m \sum_{i=1}^m \mathbf{1}\{y_i=1\}\\\Phi_{j|y=b} = \frac {\sum_{i=1}^m \mathbf{1}\{y_i = b\} \cdot \mathbf{1}\{ x_j=1\} }{\sum_{i=1}^m \mathbf{1}\{y_i = b\} },b=0,1</script><p>当给了一个新的样本的时候，我们计算$p(y=1|x)$:</p><script type="math/tex; mode=display">\begin{align}p(y=1|X) &= \frac{p(X|y=1)p(y=1)}{p(X)}\\&= \frac{p(y=1)\prod _{i=1}^n p(x_i|y=1)}{p(X|y=1)+p(X|y=0)}\\&=\frac{p(y=1)\prod _{i=1}^n p(x_i|y=1)}{p(y=0)\prod _{i=1}^n p(x_i|y=0)+ p(y=1)\prod _{i=1}^n p(x_i|y=1)}\end{align}</script><p>然后根据概率是否大于0.5来进行预测。</p><h4 id="Laplace-Smoothing"><a href="#Laplace-Smoothing" class="headerlink" title="Laplace Smoothing"></a>Laplace Smoothing</h4><p>这个模型是有一个缺点的：如果新的样本的单词从来没有在训练集合里出现过，那么：</p><script type="math/tex; mode=display">\Phi_{j|y=b} = \frac {\sum_{i=1}^m \mathbf{1}\{y_i = b\} \cdot \mathbf{1}\{ x_{i,j}=1\} }{\sum_{i=1}^m \mathbf{1}\{y_i = b\} } = 0,b=0,1</script><p>也就是垃圾邮件和非垃圾邮件里出现它的概率都为0.那么最后预测结果为$\frac 0 0$,这就没法计算了。</p><p>所以我们需要进行Laplace平滑。对于没有出现过的词，我们给他赋一个较小值，而不是让他为0：</p><script type="math/tex; mode=display">\Phi_j = \frac{\sum_{i=1}^m \mathbf{1}\{z_i = j\}+1}{m+k}</script><p>为了最后使得$\Phi_j$的和为0,所以k为类比的个数，即$\sum_{i=1}^k\Phi_i = 1$。</p><p>所以最后的估计就成了下面的样子：</p><script type="math/tex; mode=display">\Phi_{j|y=b} = \frac {\sum_{i=1}^m \mathbf{1}\{y_i = b\} \cdot \mathbf{1}\{ x_{i,j} = 1\} +1}{\sum_{i=1}^m \mathbf{1}\{y_i = b\} +2},b=0,1</script><p>除此之外其他地方是一样的。</p><h4 id="Naive-Bayes-and-Multinomial-Event-Model"><a href="#Naive-Bayes-and-Multinomial-Event-Model" class="headerlink" title="Naive Bayes and Multinomial Event Model"></a>Naive Bayes and Multinomial Event Model</h4><p>现在有一个新的方法，就是多项式模型。</p><p>现在$x_i \in {1,…,\vert V \vert}$,其中|V|为字典的长度。而n为信息的长度，也就是现在每个样本的特征数已经不一样了，因为我们没法保证每封信长度一样。</p><p>对字典中每个词都进行编号：</p><div class="table-container"><table><thead><tr><th>dictionary id</th><th>1</th><th>2</th><th>…</th><th>1300</th><th>…</th><th>2400</th><th>…</th></tr></thead><tbody><tr><td>word</td><td>a</td><td>aa</td><td>…</td><td>free</td><td>…</td><td>gift</td><td>…</td></tr></tbody></table></div><p>多项式模型中有下面几个假设：</p><ul><li>信息随机地被以概率$p(y)$生成</li><li>$x_1,x_2,…,x_n$独立同分布</li><li>$p(x_1,x_2,…,x_n,y) = p(y)\prod _{i=1}^n p(x_i|y)$</li></ul><p>假设$p(x_i=k|y)$对所有的$k$来说都相等。<br>则该模型参数如下：</p><ul><li>$\Phi_y = p(y)$ </li><li>$\Phi_{k|y=1} = p(x_j = k|y=1)$ for any $j \in \{1,…,n\}$</li><li>$\Phi_{k|y=1} = p(x_j = k|y=0)$ for any $j \in \{1,…,n\}$</li></ul><p>则出现训练样本的概率为:</p><script type="math/tex; mode=display">\begin{align}L(\Phi_y,\Phi_{k|y=0},\Phi_{k|y=1}) &= \prod_{i=1}^m p(x_i,y_i)\\&= \prod_{i=1}^m p(y_i)p(x_i|y_i)\\&=\prod_{i=1}^m p(y_i) \prod_{j=1}^{n_i} p(x_{i,j}|y_i;\Phi_y,\Phi_{k|y=1},\Phi_{k|y=0})\end{align}</script><p>各个参数取值如下：</p><script type="math/tex; mode=display">\Phi_y = \frac 1 m \sum_{i=1}^m \mathbf{1}\{y_i=1\}\\\Phi_{k|y=1} = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=1\}\cdot (\sum_{j=1}^{n_i}\mathbf{1}\{x_i=k\}) +1}{\sum_{i=1}^m \mathbf{1}\{y_i=1\}+|V|}\\\Phi_{k|y=0} = \frac{\sum_{i=1}^m \mathbf{1}\{y_i=0\}\cdot (\sum_{j=1}^{n_i}\mathbf{1}\{x_i=k\}) +1}{\sum_{i=1}^m \mathbf{1}\{y_i=0\}+|V|}</script><p>最后，预测值为：$p(y=1|x) = \frac{p(x|y=1)p(y)} {p(x|y=1)+p(x|y=0)}$</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> mathematics </tag>
            
            <tag> classification </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息论——Basic Conception</title>
      <link href="/2018/10/29/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Basic-Conception/"/>
      <url>/2018/10/29/%E4%BF%A1%E6%81%AF%E8%AE%BA%E2%80%94%E2%80%94Basic-Conception/</url>
      
        <content type="html"><![CDATA[<p>开一个栏目来记录信息论的学习。希望今年这门课不要挂掉。<a id="more"></a></p><h2 id="信息熵-Entropy"><a href="#信息熵-Entropy" class="headerlink" title="信息熵(Entropy)"></a>信息熵(Entropy)</h2><p>香农定义了信息熵，从而为通信时代奠定了数学基础。首先直观的说明一下什么是信息？香农说：信息是用来消除随机不确定性的东西。这个说法实在是太抽象了。</p><p>考虑两个简单的例子：1,明天太阳从东方升起；2，明天太阳要爆炸。哪句话包含了更多的信息？</p><p>直观上来讲，明显是第二句。因为第一句是句“废话”。所以我们可以这样理解，概率越小的事它的信息量越大。如果一件事发生概率为1，那它包含的信息为0.如果一件事发生概率为0，它的信息量为$\infty$.另外，如果两个事件是独立的，他们两个发生的信息量是二者之和。所以写成函数形式：<br>如果有两个独立事件a,b,假如f(x)表示x的信息量，则：</p><script type="math/tex; mode=display">\text{If }p(a)>p(b), f(a)< f(b);\\f(0) = \infty, f(1) = 0;f(ab) = f(a)+f(b)</script><p>通过上面的性质，结合概率，其实我们还是比较容易想到的是log函数。 f(x) = -log p(x),满足上面的所有条件。不过这是直观猜测，后面去证明一下log函数是唯一满足信息的定义的函数。</p><p>现在说明一下信息熵的定义：$H(X) =- \sum _{x \in \mathcal{X}} p(x) \log p(X)$.信息熵是用来衡量一个系统的信息量，如果基于之前对事件信息的定义的话，从直观来讲这个定义是合理的。现在证明它不光是合理的，而且是唯一的。</p><p>香农给出信息熵函数满足的三个条件：</p><ul><li>连续性</li><li>等概时的单调递增特性</li><li>可加性</li></ul><p>用数学语言描述如下：</p><ul><li>$f(X) = f(P_x)$ is continuous on $P_x$.</li><li>$g(N) = f(\frac 1 N,\frac 1 N,…,\frac 1 N)$. If $M &gt; N, g(M)&gt;g(N).$</li><li>$f(P_1,P_2,…,P_N) = f(P_1+P_2+…+P_M,P_{M+1},…,P_N) + (P_1+…+P_M)f(P_1’+P_2’+…+P_M’),P_i’ = \frac{P_i}{\sum_{j=1} ^M P_j}$</li></ul><p>现在根据上面三个假设来证明我们之前猜测的信息度量函数不光是正确的而且是唯一的。</p><p>首先考虑均匀分布的情况：</p><p>$X~Unif:$</p><script type="math/tex; mode=display">\begin{aligned}g(MN) &= f(\frac 1 {MN},...,\frac{1}{MN})\\&=f(\frac 1 M,\frac 1 {MN},...,\frac 1 {MN}) + \frac 1 M f(\frac 1 N,...,\frac 1 N)\\ &= f(\frac 1 M,...,\frac 1 M) +\sum_{i=1}^M \frac 1 M f( \frac 1 N ,...,\frac 1 N)\\ &= g(M) + g(N)\end{aligned}</script><p>由以上的推论：</p><script type="math/tex; mode=display">g(S^m) = g(S) \cdot g(S^{m-1}) = mg(S) ---------------------(1)</script><p>取四个正整数$s,m,t,n \in N$,使得$s^m \leq t^n &lt; s^{m+1}$,由于单调增可以得到：</p><script type="math/tex; mode=display">g(s^m) \leq g(t^n) < g(s^{m+1}) \\mg(s) \leq ng(t) < (m+1)g(s) \\\frac m n \leq \frac {g(t)}{g(s)} < \frac {m+1}{n}</script><p>可以得到：</p><script type="math/tex; mode=display">\left\vert \frac m n - \frac {g(t)}{g(s)} \right\vert \leq \frac 1 n ---------(2)</script><p>如果讲上面的4个整数应用到log函数上，可以得到:</p><script type="math/tex; mode=display">m\log s\leq n\log t < (m+1) \log s\\\left\vert \frac m n - \frac {\log t }{\log s} \right\vert \leq \frac 1 n -------(3)</script><p>利用$|a ± b| \leq |a|+ |b|$,结合不等式(2),(3)：</p><script type="math/tex; mode=display">\left \vert \frac {g(t)}{g(s)} - \frac {\log t}{\log s} \right \vert \leq \frac 2 n</script><p>当N取足够大时，$\frac {g(t)}{g(s)} \rightarrow \frac {\log t}{\log s}$</p><p>因此我们可以得到：$g(t) = C \log t = -\sum _{i=1}^T \frac 1 t \log \frac 1 t$.</p><p>下来我们要考虑非均匀分布的情况。</p><p>假设$X\sim P_x(x)$,令$P(n) = \frac{m_n}{\sum_{i=1}^N m_i} = \frac{m_n}{M}$.</p><p>实际上上面各个字母意思可以用摸球来考虑：$m_1$个红球，$m_2$个绿球，…,共M个球,N种颜色，而$P(1)$也就是摸到红球的概率。考虑：</p><script type="math/tex; mode=display">\begin{aligned}g(M) &= f(\frac 1 M,...,\frac 1 M)\\&=f(\frac {m_1} {M},\frac {m_2}{M},...,\frac{m_N}{M}) +\sum _{i=1}^N \frac {m_i} {M}f(\frac {1}{m_i},...,\frac {1}{m_i})\\&= f(P_1,P_2,...,P_N) + \sum_{i=1}^N P_ig(m_i)\end{aligned}</script><p>对上面等式稍加变形：</p><script type="math/tex; mode=display">\begin{aligned}f(P_1,P_2,...,P_N) &= g(M) - \sum_{i=1}^N P_ig(m_i)\\&= C \log M (\sum_{i=1}^N P_i)- \sum_{i=1}^N P_ig(m_i)\\&= C\sum _{i=1}^N P_i(\log M - \log m_i )\\&= -C\sum_{i=1}^N P_i \log P_i\end{aligned}</script><p>这就得到了我们对熵的度量函数的形式。在不同的信息度量中常数C以及log的底数是不同的，而最常用的log底数为2，也就产生了bit。</p><p>现在X的分布是有理数，但是即使是无理数也是成立的。具体的证明就不展开了。</p><p>对于信息度量的假设条件，实际上香农的定义不是唯一的。数学家A.I.Khinchin曾经给出这样的假设：</p><ul><li>连续性</li><li>可加性</li><li>极值条件<script type="math/tex; mode=display">max f(p_1,p_2,...,p_N) = f(\frac 1 N,...,\frac 1 N)</script></li><li>零概率事件不影响不确定性<script type="math/tex; mode=display">f(p_1,p_2,...,p_N) = f(p_1,p_2,...,p_N,0)</script></li></ul><p>实际上这个条件中的3,4条件等价于香农的第二个条件。证明如下：</p><script type="math/tex; mode=display"> f(\frac 1 N,...,\frac 1 N)  =  f(\frac 1 N,...,\frac 1 N,0)< f(\frac 1 {N+1},\frac 1 {N+1},...,\frac 1 {N+1})</script><p>而上式实际上就是等概时候的单调性。</p><h3 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h3><p>Definition:<br>$H(X,Y) = -\sum _{x \in \mathcal{X}}\sum_{y \in \mathcal{Y}} P(x,y) \log P(x,y)$</p><p>$H(X,Y)$实际上是X与Y系统的联合包含的信息量。需要考虑的问题：$H(X,Y) ? H(X)+H(Y)$。</p><h3 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h3><p>Definition:</p><script type="math/tex; mode=display">\begin{aligned}H(Y|X) &= \sum_{x \in \mathcal{X}} p(x)H(Y|X=x)\\ &= - \sum_{x \in \mathcal{X}}p(x) \sum_{y \in \mathcal{Y}} p(y|x)\log p(y|x)\\ &= - \sum_{x \in \mathcal{X}}\sum_{y \in \mathcal{Y}} p(x,y) \log p(y|x)\end{aligned}</script><p>请不要以为$H(Y|X) = -\sum_{x \in \mathcal{X}}\sum_{y \in \mathcal{Y}} p(y|x) \log p(y|x)$.</p><p>条件熵的实际上是知道X的信息之后，Y的剩余信息量。</p><p>值得注意的是$H(Y|X=x)$不是一个条件熵，条件熵是根据两个系统而言的，而在这个中，实际上只有一个加了条件的系统：$Y|X=x$.</p><p>当X,Y独立时，$H(Y|X) = H(Y),H(X|Y) = H(X)$.在直觉上这个也是非常正确的。同时我们用物理思维理解这件事，应该可以得到：$H(X,Y) = H(X) + H(Y|X)$.</p><p>现在用严格的数学证明来证明上面的式子是成立的：</p><p>首先我们希望简化一下熵的写法：$H(X) = \mathbb{E}_x \log \frac 1 {p(X)}$($\mathbb{E}$表示数学期望).</p><p>有了这个写法，证明变得就很简单：</p><script type="math/tex; mode=display">P(X,Y) = P(X)P(Y|X)\\\log P(X,Y) = \log P(X)+ \log P(Y|X)\\\mathbb{E}_{X,Y}P(X,Y) = \mathbb{E}_{X,Y} \log P(X) + \mathbb{E}_{X,Y} \log P(Y|X)\\H(X,Y) = H(X) + H(Y|X)</script><p>上述证明没有写清负号，但是完全不影响结果。</p><p>根据上面可以推断出别的结论(如果利用画图就更好理解)：</p><ul><li><p>$H(X,Y|Z) = H(X|Z) + H(Y|X,Z)$</p><p>推论：$H(X_1,X_2,…,H_n) =  \sum _{i=1} ^N H(X_i|X_{i-1},…,X_1)$</p></li></ul><h3 id="信息熵的性质"><a href="#信息熵的性质" class="headerlink" title="信息熵的性质"></a>信息熵的性质</h3><ul><li><p>对称性：<br>$H(P_1,P_2,…,P_N) = H(P_{k(1)},P_{k(2)},…,P_{k(N)})$</p></li><li><p>非负性： $H(P) \geq 0$</p></li><li><p>可加性： $H(X,Y) = H(X) + H(Y|X)$</p></li><li><p>条件减少熵： $H(X|Y) \leq H(X)$<br>(条件熵，而非针对Y的某一特定取值，也就是不意味着$H(X|Y=y) \leq H(X)$)</p></li><li><p>最大离散熵定理：$H(p_1,p_2,…,p_n) \leq H(\frac 1 N ,…,\frac 1 N) = \log N = \log |X|$.</p></li></ul><h2 id="互信息-Mutual-Information"><a href="#互信息-Mutual-Information" class="headerlink" title="互信息(Mutual Information)"></a>互信息(Mutual Information)</h2><p>互信息描述了两个系统之间的关系。互信息的定义：$I(X;Y) = H(X) - H(X|Y)$.</p><p>也可以直接定义互信息为:$I(X;Y)= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}}p(x,y) \log \frac{p(x,y)}{p(x)p(y)}$.</p><p>互信息还有另一种写法：$I(X;Y) = I(p;Q) =  \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x)q(y|x)\log \frac{q(y|x)}{\sum _{x \in \mathcal{X}}p(x)q(y|x)}$.式子中Q为知道x后y的条件概率矩阵。这个写法一般对于后面的信道传输是非常有帮助的。如果现在不理解，可以先放下。</p><p>从另一方面来说：$I(X;Y) = H(X)+H(Y) - H(X,Y)$.从直观上也是很容易理解的。</p><p>很明显互信息$I(X;Y) = I(Y;X)$,具有对称性。如果X与Y独立，$I(X;Y)=0$；如果X与Y一一对应，则$I(X;Y) = H(X) = H(Y)$.</p><p>互信息和信道容量有着千丝万缕的关系。</p><h3 id="多变量的互信息"><a href="#多变量的互信息" class="headerlink" title="多变量的互信息"></a>多变量的互信息</h3><p>如果有随机变量X，Y，Z，则$I(X;Y,Z) = H(X) - H(X|Y,Z) = H(Y,Z) - H(Y,Z|X)$.</p><p>或者从数学定义上：</p><script type="math/tex; mode=display">I(X;Y,Z)= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} \sum_{z \in \mathcal{Z}}p(x,y,z) \log \frac{p(x|y,z)}{p(x)} = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} \sum_{z \in \mathcal{Z}}p(x,y,z) \log \frac{p(x,y,z)}{p(x)p(y,z)}</script><h3 id="条件互信息"><a href="#条件互信息" class="headerlink" title="条件互信息"></a>条件互信息</h3><p>定义$I(X;Y|Z)$为知道Z的信息之后，X与Y之间的互信息。它的定义如下：</p><p>$I(X;Y|Z) = H(X|Z) - H(X|Y,Z)= H(Y|Z) - H(Y|X,Z)$.</p><p>也可以直接定义条件互信息为:</p><script type="math/tex; mode=display">I(X;Y|Z) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} \sum_{z \in \mathcal{Z}} p(x,y,z) \log {p(x,y|z)}{p(x|z)p(y|z)}</script><p>下面是几条条件互信息的推论，同样，使用画图的方法来理解会更加容易：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/Screenshot_2019-01-11%20Introduction%20pdf%20-%20Elements_of_Information_Theory_Elements%20pdf.png" alt=""></p><script type="math/tex; mode=display">I(X;Y|Z) = H(X|Z) - H(X,Y|Z) + H(Y|Z)</script><script type="math/tex; mode=display">\begin{aligned}I(X;Y|Z) = &H(X,Z) - H(Z) - H(X,Y,Z) + H(Z)+H(Y,Z) - H(Z)\\&=H(X,Z)+H(Y,Z)-H(X,Y,Z)-H(Z)\end{aligned}</script><p>有条件减少熵，但是没有条件减少互信息。条件互信息非负。</p><ul><li><p>对称性 $I(X;Y)=I(Y;X)$</p></li><li><p>非负性 $I(X;Y) \geq 0$</p></li><li><p>极值性 $I(X;Y) \leq min\{H(X),H(Y)\}$</p></li><li><p>可加性 $I(X_1,X_2,…,X_n;Y) = \sum_{i=1} ^n I(X_i;Y|X_{i-1},…,X_1)$</p></li></ul><p>可加性用画图来表示的话也更清晰。</p><p>下面介绍一个用互信息来解决的题目。如果有25个小球，其中只有一个重量和其他的不一致。有一个天平，可以检测轻重，或者一样重。那么最少用几次才能一定找出不一样重量的小球?也许你能找到3次的方法，但是如何证明2次是不可以？</p><p>只有一个重量不一样，如果是均匀分布，则信息熵为$H(X) = \log_2^{25}$.假设进行了N次实验，则互信息为$I(X^N;X)$.</p><script type="math/tex; mode=display">\begin{aligned}I(X^N;X) &\leq H(X^N) \leq H(X_1,X_2,...,X_N)\\       &\leq H(X_1)+...+H(X_n)\\       &= N\log _2^3.\\\end{aligned}</script><p>我们希望的是互信息和原来的熵一样大，这样才能反应它的情况。</p><script type="math/tex; mode=display">\begin{aligned}H(X) = I(X^N;X) \leq N \log_2^3\\      \log 2^{25} \leq N log_2^3\\      N \geq 3\end{aligned}</script><p>所以可以得到N必须大于等于3.信息论很多时候给了我们一个上界。</p><h2 id="鉴别信息-K-L-divergence"><a href="#鉴别信息-K-L-divergence" class="headerlink" title="鉴别信息(K-L divergence)"></a>鉴别信息(K-L divergence)</h2><p>鉴别信息表示两个分布之间的距离，定义如下：</p><script type="math/tex; mode=display">D(p\Vert q) = \sum_{x \in \mathcal{X}}p(x)\log \frac{p(x)}{q(x)}</script><ul><li>当p = q的时候，$D(p\Vert q) =0$. </li><li>鉴别信息具有非负性。</li></ul><p>但是鉴别信息不能说是严格的信息度量。它不具有对称性，也不满足三角不等式（？？）。</p><h3 id="鉴别信息，熵，互信息"><a href="#鉴别信息，熵，互信息" class="headerlink" title="鉴别信息，熵，互信息"></a>鉴别信息，熵，互信息</h3><ul><li><p>$H(X) = \log |X| - D(\mathbf{p}\Vert \mathbf{u})$。上式中u表示平均分布。证明如下：</p><script type="math/tex; mode=display">\begin{aligned}H(X) &= -\sum _{x \in \mathcal{X}}p(x)\log p(x) \\&=\log N - \log N+ \sum_{x \in \mathcal{X}}p(x) \log p(x)\\&= \log |X| + \sum_{x \in \mathcal{X}} p(x)\log \frac 1 N + \sum_{x \in \mathcal{X}}p(x) \log p(x)\\&= \log |X| -  D(\mathbf{p}\Vert \mathbf{u})\end{aligned}</script></li><li><p>$I(X;Y) = D(p(x,y)\Vert p(x)p(y)) $</p></li></ul><p>这个证明两边根据定义展开就可以直接得到。</p><p>信息论真是抽象啊。</p>]]></content>
      
      
      <categories>
          
          <category> 信息论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> information theory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——Homework1</title>
      <link href="/2018/10/26/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Homework1/"/>
      <url>/2018/10/26/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Homework1/</url>
      
        <content type="html"><![CDATA[<p>完成第一个作业（实际上是第二个）。这个作业还是比较费劲的，一个原因是对OpenGL十分不熟悉。<br><a id="more"></a></p><p>首先，openGL中，Z轴指向屏幕外，Y轴指向上侧，X轴指向右侧。这是一个需要注意的地方。</p><p>其次，openGL中3D的呈现，实际上是模拟一个相机再看这个物品。在作业中，可以知道的是茶壶放在世界坐标的原点，而刚开始的视点是(0,0,5).</p><p>作业要完成左右旋转，而实际上就是视点相对于视点相对于世界坐标要转动。在这里，我规定的转动方向是向左的话，看到茶壶的左侧，也就是视点向左侧转动，而不是让茶壶向左侧转动（那样的话我们能看到的实际上变成了右侧）。其他方向也是一样的道理。</p><p>为了让视点的坐标转动，首先要完成rotate函数的定义，这个函数直接使用Rodrigues公式就可以求得旋转矩阵。代码如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mat3 Transform::rotate(<span class="keyword">const</span> <span class="keyword">float</span> degrees, <span class="keyword">const</span> vec3&amp; axis) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">  <span class="comment">// You will change this return call</span></span><br><span class="line">vec3 _axis = glm::normalize(axis);</span><br><span class="line"><span class="keyword">float</span> theta = degrees/<span class="number">360</span>* pi;</span><br><span class="line">mat3 a_ta = mat3(_axis.x*_axis.x, _axis.x*_axis.y, _axis.x*_axis.z, _axis.y*_axis.x, _axis.y*_axis.y, _axis.y*_axis.z, _axis.z*_axis.x, _axis.z*_axis.y, _axis.z*_axis.z);</span><br><span class="line">mat3 I = mat3(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">mat3 Astar = mat3(<span class="number">0</span>, -_axis.z, _axis.y, _axis.z, <span class="number">0</span>, -_axis.x, -_axis.y, _axis.x, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> a_ta + (I - a_ta)*<span class="built_in">cos</span>(theta) + Astar * <span class="built_in">sin</span>(theta);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>很尴尬的是我不知道OpenGL中有什么简洁的办法计算$\mathbf{a}\mathbf{a}^T$，因此用手把它敲出来了。</p><p>第二个就是定义向左的函数。OpenGL中，除了视点坐标以外还有一个up向量，表示视点坐标向上的方向，也就是我们头发所指的方向。因为我们需要用两个向量来确定视点坐标系（这个后面再说）。所以我们在移动视点的时候也要移动up向量。</p><p>左右转的时候，很容易，我们不需要改变up向量，因为我们就是绕着up向量转的。所以这个很简单就可以写出来（需要注意的是转动角度的方向和转动轴向量也是符合右手定则的，这是之前推公式的结果。向左转的话，$\theta$应该取负，然而代码中<strong>我并没有取负，依然得到想要的结果</strong>）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Transform::left(<span class="keyword">float</span> degrees, vec3&amp; eye, vec3&amp; up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">mat3 r = rotate(degrees,up);</span><br><span class="line">eye = r * eye;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而上下转的时候就需要注意了，我们绕的轴就变了，实际上上下转的时候我们绕的轴是up向量与视点向量叉乘的结果，而up向量转动后也要作相应的转变。还记得up向量与eye始终垂直，那么可以看作是它的法向量。因此，法向转换就用到了:$(M^{-1})^T$.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Transform::up(<span class="keyword">float</span> degrees, vec3&amp; eye, vec3&amp; up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE </span></span><br><span class="line">mat3 r = rotate(degrees, -glm::cross(eye, up));</span><br><span class="line">up = glm::transpose(glm::inverse(r))*up;<span class="comment">//up vector is not easy to compute</span></span><br><span class="line">eye = r * eye;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后一个就是lookAt函数。要想写出来lookAt函数，首先要知道lookAt在做什么。lookAt函数是做的事情，是把茶壶投影到视点坐标当中。如果lookAt返回的是0向量，那么我们看到的茶壶的内部。</p><p>这就要求我们要建立一个坐标系出来了。之前讲过建坐标的方法，但是u,v,w只要符合右手定则就好，其他的不做要求。但是OpenGL中，z轴是朝着平面外的，因此我们就必须规定视点的向量就是z轴的方向，对应着w。接着用叉乘（up与eye向量）做出u轴，朝右的向量，最后求得v轴即可。这就建立了视点坐标。</p><p>建立视点坐标后又如何得到原来的点在该坐标系下的坐标呢？我们可以看出来这需要两步：旋转和平移。旋转和平移是不可逆的，因此我们首先要注意顺序。这个问题有点棘手。在lookAt函数中，我们需要做的是先平移再旋转（为毛我觉得是先旋转后平移？可能我对OpenGL又有什么误解。如果是移动坐标系的话是先平移后旋转的）。</p><p>（好吧，经过实际计算了之后我明白了。其实想象移动点的话是比较抽象的，但是点的移动实际上就是坐标系的相对运动。因此lookAt函数可以看作将世界坐标系移动到相机坐标系。而这个时候的移动比较容易理解的是先平移后旋转，因为如果先旋转了，平移时候加上相机坐标得到的并不是原相机的位置，因为坐标轴方向变了。而对应到点，一样也是先平移后旋转的。</p><p>至于为什么gluLookAt需要物体的中心坐标，我是因为物体本身也有一个自己的局部坐标系，需要用中心坐标（世界坐标），才能通过将局部坐标进行一个偏移，得到世界坐标后，继续上面的平移旋转操作，本题中中心坐标为(0,0,0)，所以没有便宜，局部坐标就是世界坐标）</p><p>如果理解了之前的旋转矩阵，我们就知道旋转矩阵实际上就是坐标系的三个单位向量，而旋转后的结果就是该点在该坐标系的坐标值，因此很容易得到：<br>$r = \begin{bmatrix}<br>\mathbf{u}\\<br>\mathbf{v}\\<br>\mathbf{w}<br>\end{bmatrix}$.</p><p>而平移的量实际上就是当前$eye$取负。这个也很好理解。然后得到了平移旋转矩阵：<br>$\begin{bmatrix}<br>R_{3 \times 3}&amp; R_{3 \times 3}\mathbf{eye}_{3 \times 1}\\<br>0_{1\times 3}&amp;1<br>\end{bmatrix}$</p><p>这就得到了最后的lookAt函数。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mat4 Transform::lookAt(vec3 eye, vec3 up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">vec3 w = glm::normalize(eye);</span><br><span class="line">vec3 u = glm::normalize(glm::cross(up, eye)) ;</span><br><span class="line">vec3 v = glm::normalize(glm::cross(w, u));</span><br><span class="line">mat3 r = mat3(u,v,w );</span><br><span class="line">vec3 t = vec3(-glm::dot(u,eye), -glm::dot(v,eye), -glm::dot(w,eye));</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; t.x &lt;&lt; t.y &lt;&lt; t.z &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">mat4 result = mat4(r[<span class="number">0</span>][<span class="number">0</span>], r[<span class="number">0</span>][<span class="number">1</span>], r[<span class="number">0</span>][<span class="number">2</span>], t.x, r[<span class="number">1</span>][<span class="number">0</span>], r[<span class="number">1</span>][<span class="number">1</span>], r[<span class="number">1</span>][<span class="number">2</span>], t.y, r[<span class="number">2</span>][<span class="number">0</span>], r[<span class="number">2</span>][<span class="number">1</span>], r[<span class="number">2</span>][<span class="number">2</span>], t.z, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">return</span> glm::transpose(result);</span><br><span class="line">  <span class="comment">// You will change this return call</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我一直不明白为什么最后要加一个transpose.</p><p>现在我知道了OpenGL（glm）中矩阵构造时候是列优先的，如m[0][1],指的是第0列第1行。所以我构造出来的所有矩阵都应该加个转置，这也解释了为什么上面代码degree没有取负依然得到了正确的结果。正确代码如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">mat3 Transform::rotate(<span class="keyword">const</span> <span class="keyword">float</span> degrees, <span class="keyword">const</span> vec3&amp; axis) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">  <span class="comment">// You will change this return call</span></span><br><span class="line">vec3 _axis = glm::normalize(axis);</span><br><span class="line"><span class="keyword">float</span> theta = degrees/<span class="number">180</span>* pi;</span><br><span class="line">mat3 a_ta = mat3(_axis.x*_axis.x, _axis.x*_axis.y, _axis.x*_axis.z, _axis.y*_axis.x, _axis.y*_axis.y, _axis.y*_axis.z, _axis.z*_axis.x, _axis.z*_axis.y, _axis.z*_axis.z);</span><br><span class="line">mat3 I = mat3(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">mat3 Astar = mat3(<span class="number">0</span>, -_axis.z, _axis.y, _axis.z, <span class="number">0</span>, -_axis.x, -_axis.y, _axis.x, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> glm::transpose(a_ta + (I - a_ta)*<span class="built_in">cos</span>(theta) + Astar * <span class="built_in">sin</span>(theta));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Transforms the camera left around the "crystal ball" interface</span></span><br><span class="line"><span class="keyword">void</span> Transform::left(<span class="keyword">float</span> degrees, vec3&amp; eye, vec3&amp; up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line"></span><br><span class="line">mat3 r = rotate(-degrees,up);</span><br><span class="line"></span><br><span class="line">eye = r * eye;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; eye.x &lt;&lt; eye.y &lt;&lt; eye.z &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Transforms the camera up around the "crystal ball" interface</span></span><br><span class="line"><span class="keyword">void</span> Transform::up(<span class="keyword">float</span> degrees, vec3&amp; eye, vec3&amp; up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE </span></span><br><span class="line">mat3 r = rotate(-degrees, -glm::cross(eye, up));</span><br><span class="line">up = glm::transpose(glm::inverse(r))*up;<span class="comment">//up vector is not easy to compute</span></span><br><span class="line">eye = r * eye;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Your implementation of the glm::lookAt matrix</span></span><br><span class="line">mat4 Transform::lookAt(vec3 eye, vec3 up) &#123;</span><br><span class="line">  <span class="comment">// YOUR CODE FOR HW1 HERE</span></span><br><span class="line">vec3 w = glm::normalize(eye);</span><br><span class="line">vec3 u = glm::normalize(glm::cross(up, eye)) ;</span><br><span class="line">vec3 v = glm::normalize(glm::cross(w, u));</span><br><span class="line">mat3 r = mat3(u,v,w );</span><br><span class="line">vec3 t = vec3(-glm::dot(u,eye), -glm::dot(v,eye), -glm::dot(w,eye));<span class="comment">//-r * eye;</span></span><br><span class="line">mat4 result = mat4(r[<span class="number">0</span>][<span class="number">0</span>], r[<span class="number">0</span>][<span class="number">1</span>], r[<span class="number">0</span>][<span class="number">2</span>], t.x, r[<span class="number">1</span>][<span class="number">0</span>], r[<span class="number">1</span>][<span class="number">1</span>], r[<span class="number">1</span>][<span class="number">2</span>], t.y, r[<span class="number">2</span>][<span class="number">0</span>], r[<span class="number">2</span>][<span class="number">1</span>], r[<span class="number">2</span>][<span class="number">2</span>], t.z, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">return</span> glm::transpose(result);</span><br><span class="line">  <span class="comment">// You will change this return call</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>最后结果：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_0296.GIF" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> homework </tag>
            
            <tag> computer graphics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——Transformation</title>
      <link href="/2018/10/25/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Transformation/"/>
      <url>/2018/10/25/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Transformation/</url>
      
        <content type="html"><![CDATA[<p>上次博客最后一个主题矩阵，只说了句矩阵可以完成很多转换。而这次就主要来说明各种转换。<br><a id="more"></a></p><p>所有的转换我们都是通过矩阵和向量完成的。</p><h3 id="缩放（Scale）"><a href="#缩放（Scale）" class="headerlink" title="缩放（Scale）"></a>缩放（Scale）</h3><script type="math/tex; mode=display">Scale(s_x,s_y,s_z) = \begin{pmatrix}s_x&0&0\\0&s_y&0\\0&0&s_z\end{pmatrix} \ Scale^{-1}(s_x,s_y,s_z) = \begin{pmatrix}s_x^{-1}&0&0\\0&s_y^{-1}&0\\0&0&s_z^{-1}\end{pmatrix}</script><p>上述中$s_x,s_y,s_z$分别为各个坐标轴的缩放倍数。实际的转换过程如下：</p><script type="math/tex; mode=display">\begin{pmatrix}s_x&0&0\\0&s_y&0\\0&0&s_z\end{pmatrix} \begin{pmatrix}x\\y\\z\end{pmatrix} = \begin{pmatrix}s_xx\\s_yy\\s_zz\end{pmatrix}</script><h3 id="错切（Shear）"><a href="#错切（Shear）" class="headerlink" title="错切（Shear）"></a>错切（Shear）</h3><p>错切可以将一个矩形转换成平行四边形。</p><script type="math/tex; mode=display">Shear(s_x,s_y) = \begin{pmatrix}s_x&a\\0&s_y\end{pmatrix} \ Shear^{-1}(s_x,s_y) = \begin{pmatrix}s_x&-a\\0&s_y\end{pmatrix}</script><p>上面式子主要完成的是对于y&gt;0的点前移，y&lt;0的点后移，而各点的y坐标不变。从而产生了错切的感觉。得到的结果：$y’=y,x’=x+ay$.</p><h3 id="旋转（Rotation）"><a href="#旋转（Rotation）" class="headerlink" title="旋转（Rotation）"></a>旋转（Rotation）</h3><p>2维空间的旋转变换次序是没有影响的，但是对于三维空间却可能得到不一样的结果。</p><h4 id="2D-rotation"><a href="#2D-rotation" class="headerlink" title="2D rotation"></a>2D rotation</h4><p>这里说的旋转是绕着原点旋转。</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix} = \begin{bmatrix}\cos \theta & - \sin \theta\\\sin \theta &\cos \theta\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}</script><p>有趣的是：$R^T R = I$</p><h4 id="3D-rotation"><a href="#3D-rotation" class="headerlink" title="3D rotation"></a>3D rotation</h4><p>3D的rotation相比于2D的要复杂很多。但是实际上我们可以这样去理解：二维的旋转，相当于绕着Z轴旋转，因为z坐标不会变。</p><p>因此可以得到绕各个坐标轴旋转的矩阵：</p><script type="math/tex; mode=display">R_z = \begin{pmatrix}\cos \theta & - \sin \theta & 0\\\sin \theta &\cos \theta & 0\\0&0&1\end{pmatrix}</script><p>同样的道理也就可以得到绕x轴与绕y轴的旋转：</p><script type="math/tex; mode=display">R_x = \begin{pmatrix}1&0&0\\0&\cos \theta & - \sin \theta \\0&\sin \theta &\cos \theta \\\end{pmatrix} \ R_y = \begin{pmatrix}\cos \theta & 0&- \sin \theta \\0&1&0\\\sin \theta &0 &\cos \theta\end{pmatrix}</script><p>同样的:$R^TR = I$.</p><p>如果我们仔细观察可以发现，3D中R的各个行（列）向量满足一个三维坐标系的要求：单位向量且正交。因此如果我们将旋转矩阵写成下面的形式：</p><script type="math/tex; mode=display">R = \begin{pmatrix}x_u & y_u & z_u\\x_v & y_v & z_v\\x_w & y_w & z_w\end{pmatrix}</script><p>则</p><script type="math/tex; mode=display">R_p = \begin{pmatrix}x_u & y_u & z_u\\x_v & y_v & z_v\\x_w & y_w & z_w\end{pmatrix}\begin{pmatrix}x_p\\y_p\\z_p\end{pmatrix} = \begin{pmatrix}\mathbf{u} \cdot \mathbf{p} \\\mathbf{v} \cdot \mathbf{p} \\\mathbf{z} \cdot \mathbf{p}\end{pmatrix}</script><p>上式最后一项正是$\mathbf{p}$在uvw坐标轴下的坐标值。因此旋转的本质实际上是将它映射到另一个坐标系当中了。</p><p>对于旋转矩阵如何求逆？因为旋转矩阵是正交矩阵，所有$R^{-1} = R^T$.</p><p>3D旋转是不可交换的。</p><p>但是上面的旋转矩阵相对来说比较简单，因为是绕着坐标轴旋转的。那么有没有办法绕着任意一个向量旋转$\theta$的公式？</p><h5 id="罗德里格旋转-Rodrigues-公式"><a href="#罗德里格旋转-Rodrigues-公式" class="headerlink" title="罗德里格旋转(Rodrigues)公式"></a>罗德里格旋转(Rodrigues)公式</h5><p>接下来这个公式就是用来解决上述问题的。假设向量（点）$b$绕着单位向量$\mathbf{a}$旋转$\theta$.</p><p>$\mathbf{b}=\mathbf{b}_{∥}+\mathbf{b}_{⊥}$，分布表示平行与垂直于$\mathbf{a}$的分量。很容易知道，$\mathbf{b}_{∥}$在旋转过程中是不变的。</p><p>$\mathbf{b}_{∥} = \mathbf{a} \cdot \mathbf{b} \mathbf{a}$</p><p>$\mathbf{b}_{⊥} = 1 -\mathbf{b}_{∥}$</p><p>然后我们要考虑到$\mathbf{b}_{⊥}$是如何旋转的。实际上它旋转的平面是垂直于$\mathbf{a}$与$\mathbf{b}$的，容易想到利用叉乘来构造：</p><p>$\mathbf{c} = \mathbf{a} \times \mathbf{b}$，而且由于叉乘的性质，$\mathbf{c}$的长度恰好等于$\mathbf{b}_{⊥}$.</p><p>现在旋转角度是$\theta$，则旋转后的向量在$\mathbf{b}_{⊥}$与$\mathbf{c}$方向上的投影分别是$\mathbf{b}_{⊥} \cos \theta$与$\mathbf{c} \sin \theta$.</p><p>旋转后的向量边上上述向量之和，并且希望写成旋转矩阵的形式（矩阵乘以向量）：</p><script type="math/tex; mode=display">\begin{align}b' &= \mathbf{b}_{⊥} \cos \theta +\mathbf{c} \sin \theta + \mathbf{b}_{∥}\\&= (\mathbf{b} -\mathbf{a} \cdot \mathbf{b} \mathbf{a} )\cos \theta +\mathbf{a} \times \mathbf{b} \sin \theta +\mathbf{a} \cdot \mathbf{b} \mathbf{a}\\&= \mathbf{a}\mathbf{a}^T \mathbf{b} + (I -\mathbf{a}\mathbf{a}^T)\mathbf{b} \cos \theta + A^* \sin \theta \mathbf{b} \end{align}</script><p>所以$R(\mathbf{a},\theta) =\mathbf{a}\mathbf{a}^T+ (I -\mathbf{a}\mathbf{a}^T)\cos \theta + A^* \sin \theta$.</p><p>上式是计算机图形学中很重要的一个基础公式。</p><h3 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h3><p>如果要回到原来的样子，可以对所有的转换求逆。但是要注意的是：$M = M_1M_2M_3,M^{-1} = M_3^{-1}M_2^{-1}M_1^{-1}$.</p><h3 id="齐次坐标转换（Homogeneous-Coordinates）"><a href="#齐次坐标转换（Homogeneous-Coordinates）" class="headerlink" title="齐次坐标转换（Homogeneous Coordinates）"></a>齐次坐标转换（Homogeneous Coordinates）</h3><p>不知道有没有人有这么一个疑问：为什么没有平移？？平移应该是最简单的转换，但是实际起来的实现却没有那么容易。首先做个尝试：</p><script type="math/tex; mode=display">\begin{pmatrix}x'\\y'\\z'\end{pmatrix} = \begin{pmatrix}?&?&?\\?&?&?\\?&?&?\end{pmatrix}\begin{pmatrix}x\\y\\z\end{pmatrix}=\begin{pmatrix}x+5\\y\\z\end{pmatrix}</script><p>中间的矩阵怎么做？有人会说将第一行第一列写为$\frac 5 z$即可，但是这就失去了转换矩阵的意义。转换矩阵中不应该包含我们要转换的坐标的信息。</p><p>计算机图形学中，解决这个问题的方法就说用齐次坐标，先看一下下面的转换：</p><script type="math/tex; mode=display">\begin{pmatrix}x'\\y'\\z'\\w'\end{pmatrix} = \begin{pmatrix}1&0&0&5\\0&1&0&0\\0&0&1&0\\0&0&0&1\end{pmatrix}\begin{pmatrix}x\\y\\z\\1\end{pmatrix}=\begin{pmatrix}x+5\\y\\z\\1\end{pmatrix}</script><p>通过加入一个其次坐标w而实现了平移。而加入这个量不会对上面提到的旋转等操作产生影响，而且他有很多的好处，因此被普遍用于图形相关的软件与硬件中。</p><h4 id="平移-Translate"><a href="#平移-Translate" class="headerlink" title="平移(Translate)"></a>平移(Translate)</h4><script type="math/tex; mode=display">\begin{pmatrix}x'\\y'\\z'\\w'\end{pmatrix} = \begin{pmatrix}1&0&0&T_x\\0&1&0&T_y\\0&0&1&T_z\\0&0&0&1\end{pmatrix}\begin{pmatrix}\mathbf{p}_x\\\mathbf{p}_y\\\mathbf{p}_z\\1\end{pmatrix}=\begin{pmatrix}\mathbf{p}_x+T_x\\\mathbf{p}_y+T_y\\\mathbf{p}_z+T_z\\1\end{pmatrix} = \mathbf{p}+T</script><p>主要旋转平移矩阵和平移旋转矩阵是不一样的，因为平移矩阵实际上需要的是最右侧的一个向量：</p><p>旋转平移矩阵：</p><script type="math/tex; mode=display">\begin{bmatrix}R_{3 \times 3}&T_{3 \times 1}\\0_{1 \times 3}&1\end{bmatrix}</script><p>平移旋转矩阵:</p><script type="math/tex; mode=display">\begin{bmatrix}R_{3 \times 3}&R_{3 \times 3}T_{3 \times 1}\\0_{1\times 3}&1\end{bmatrix}</script><p>仔细推导就可以得到上面的结果。</p><h3 id="法向转换（Normal-Transformation）"><a href="#法向转换（Normal-Transformation）" class="headerlink" title="法向转换（Normal Transformation）"></a>法向转换（Normal Transformation）</h3><p>法向的转换并不会按照平面各个点的转换进行。</p><p>假如原来的切线向量为$\mathbf{t}$,原来的法向向量为$\mathbf{n}$，转换矩阵为$M$，则切线向量是会依照原来的转换而改变的：$\mathbf{t}’ = M\mathbf{t}$.</p><p>假设转换完成后的法向向量为$\mathbf{n}’ = Q\mathbf{n}$.</p><p>当然不管什么时候，法向与切向都应该是垂直的：$\mathbf{n}’^T\mathbf{t’} = 0$</p><p>可以得到：</p><script type="math/tex; mode=display">\mathbf{n}^TQ^TM \mathbf{t} = 0.</script><p>因此我们希望$Q^TM = I$,所以得到：$Q = (M^{-1})^T$.</p><p>当然上面的解并不是唯一解，但是计算机图形学是工程学科，我们希望的是能够解决这个问题即可。</p><p>需要注意的是：$M$为3×3矩阵。因为法向和切向是向量，所以平移不会影响法向和切向。</p>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> computer graphics </tag>
            
            <tag> transformation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>图形学——Basic Math</title>
      <link href="/2018/10/24/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Basic-Math/"/>
      <url>/2018/10/24/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E2%80%94%E2%80%94Basic-Math/</url>
      
        <content type="html"><![CDATA[<p>加入了智能成像实验室，但是我对计算机图形学了解还太浅，因此需要学习一些图形学的基础知识。本篇博客先介绍一些很简单的数学基础。<br><a id="more"></a></p><h3 id="右手坐标系"><a href="#右手坐标系" class="headerlink" title="右手坐标系"></a>右手坐标系</h3><p>首先是XYZ坐标轴，一般我们使用的坐标轴是符合右手定则的。这也是大多数数学教材使用的坐标轴的定义。右手定则即用右手从X轴方向握向Y轴方向，这时候伸出大拇指，大拇指的朝向就是Z轴的方向。实际上这是一个很基础的知识，但是我过去没多久才发现自己一直不知道这个东西。直到计算第二型曲面积分时候发现结果总是相反才发现。</p><h3 id="向量点乘和叉乘"><a href="#向量点乘和叉乘" class="headerlink" title="向量点乘和叉乘"></a>向量点乘和叉乘</h3><h4 id="点乘（Dot-Product）"><a href="#点乘（Dot-Product）" class="headerlink" title="点乘（Dot Product）"></a>点乘（Dot Product）</h4><p>$\mathbf{a} \cdot \mathbf{b} = \vert a \vert \vert b\vert \cos {\theta}$</p><p>$\theta = \cos ^{-1} \frac {\mathbf{a} \cdot \mathbf{b}}{\vert a \vert \vert b\vert}$</p><p>实际上在笛卡尔坐标系中求解两个向量的点乘是非常容易的：</p><p>$\mathbf{a} = x_a \mathbf{x} + y_a \mathbf{y},\mathbf{b} = x_b \mathbf{x} + y_b \mathbf{y}$</p><p>则：$\mathbf{a} \cdot \mathbf{b} = x_a x_b + y_a y_b$</p><p>因此点乘可以用来求两个向量的夹角。</p><p>另一个点乘的应用是求某个向量到另一个向量上的投影，如$\mathbf{a}$在$\mathbf{b}$上的投影长度实际上是$\vert \mathbf{a} \vert \cos \theta$，而$\vert \mathbf{a} \vert \cos \theta = \frac {\vert \mathbf{b}\vert\vert \mathbf{a} \vert \cos \theta}{\mathbf{b}} = \frac {\mathbf{a} \cdot \mathbf{b}}{\vert \mathbf{b}\vert}$.</p><p>同样的想要求投影之后的向量也很简单，只要用长度乘上$\mathbf{b}$方向的单位向量即可：<br>$\mathbf{p} =  \frac {\mathbf{a} \cdot \mathbf{b} \mathbf{b}}{\vert \mathbf{b}\vert ^2}$.</p><h4 id="叉乘（Cross-Product）"><a href="#叉乘（Cross-Product）" class="headerlink" title="叉乘（Cross Product）"></a>叉乘（Cross Product）</h4><p>$\vert \mathbf{a} \times \mathbf{b} \vert= \vert \mathbf{a} \vert \vert \mathbf{b}\vert \sin \theta$</p><p>上面为叉乘的长度，除此之外，叉乘得到的是一个向量，它的方向符合右手定则，也与原来两个向量垂直。</p><p>从右手定则可以很容易推导出：$\mathbf{a} \times \mathbf{b} = - \mathbf{b} \times \mathbf{a}$.</p><p>同时也有以下的一些等式：</p><script type="math/tex; mode=display">\mathbf{x} \times \mathbf{y} = \mathbf{z},\mathbf{y} \times \mathbf{x} = -\mathbf{z}</script><script type="math/tex; mode=display">\mathbf{a} \times \mathbf{a} = \mathbf{0}</script><script type="math/tex; mode=display">\mathbf{a} \times (\mathbf{b} + \mathbf{c}) = \mathbf{a} \times \mathbf{b}+ \mathbf{a} \times \mathbf{c}</script><script type="math/tex; mode=display">\mathbf{a} \times (k\mathbf{b}) = k(\mathbf{a} \times \mathbf{b})</script><p>在笛卡尔坐标系下，叉乘的计算也不算困难：</p><script type="math/tex; mode=display">\mathbf{a}\times \mathbf{b} = \begin{vmatrix} \mathbf{x}&\mathbf{y}&\mathbf{z}\\x_a&y_a&z_a\\x_b&y_b&z_b\end{vmatrix} = \begin{pmatrix} y_az_b - y_bz_a,\\z_ax_b - x_az_b,\\x_ay_b - y_ax_b \end{pmatrix}</script><p>而且也可以写成下面的形式：</p><script type="math/tex; mode=display">\mathbf{a}\times \mathbf{b} = A^* \mathbf{b}\begin{pmatrix}0&-z_a&y_a\\z_a&0&-x_a\\-y_a&x_a&0\end{pmatrix} \begin{pmatrix}x_b\\y_b\\z_b\\\end{pmatrix}</script><p>上式中$A^*$被成为向量$\mathbf{a}$的对偶矩阵。</p><h3 id="坐标系-Coordinate-Frames"><a href="#坐标系-Coordinate-Frames" class="headerlink" title="坐标系(Coordinate Frames)"></a>坐标系(Coordinate Frames)</h3><p>坐标系并不是只有XYZ，XYZ只是标识而已。任何满足下面条件的三个向量，都可以作为坐标系：</p><ul><li>$\vert \mathbf{u} \vert = \vert \mathbf{v} \vert = \vert \mathbf{w} \vert = 1$</li><li>$\mathbf{u} \cdot \mathbf{v} = \mathbf{v} \cdot \mathbf{w} = \mathbf{u} \cdot \mathbf{w} = 0$</li><li>$\mathbf{w} = \mathbf{u} \times \mathbf{v}$</li></ul><p>任何一个向量可以写成各个坐标系的投影之和：</p><script type="math/tex; mode=display">\mathbf{p}  = (\mathbf{p} \cdot \mathbf{u} ) \mathbf{u} + (\mathbf{p} \cdot \mathbf{v}) \mathbf{v} + (\mathbf{p} \cdot \mathbf{w})\mathbf{w}</script><p>如何使用两个非零非同方向的向量创造一个坐标系（在三维重建中可能会经常碰到）？</p><script type="math/tex; mode=display"> \mathbf{u} = \frac {\mathbf{a}}{ \vert \mathbf{a}\vert},\mathbf{w} = \frac {\mathbf{a} \times \mathbf{b}}{\vert \mathbf{a} \times \mathbf{b} \vert}, \mathbf{v}= \mathbf{w} \times \mathbf{v}.</script><p>从上面我们可以看到叉乘对于创建一个坐标系的作用。</p><h3 id="矩阵（Matrix）"><a href="#矩阵（Matrix）" class="headerlink" title="矩阵（Matrix）"></a>矩阵（Matrix）</h3><p>$(AB)^{-1} = B^{-1}A^{-1}$,因为$ AB B^{-1} A^{-1} = I$.</p><p>通过矩阵可以实现空间点的各种转换。</p>]]></content>
      
      
      <categories>
          
          <category> 图形学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mathematics </tag>
            
            <tag> computer graphics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Generalized Linear Model</title>
      <link href="/2018/10/22/Learning-From-Data%E2%80%94%E2%80%94Generalized-Linear-Model/"/>
      <url>/2018/10/22/Learning-From-Data%E2%80%94%E2%80%94Generalized-Linear-Model/</url>
      
        <content type="html"><![CDATA[<p>这次数据学习课上，讲的是Generalized Linear Model。我心里想着是要概况线性模型，我应该都清楚吧。上课了之后才发现，这实际上是广义线性模型，有很多新东西。然而我还是睡着了。<br><a id="more"></a></p><p>首先引入一个概念，叫做<strong>指数族分布</strong>。</p><h3 id="Exponential-Family"><a href="#Exponential-Family" class="headerlink" title="Exponential Family"></a>Exponential Family</h3><p>如果一个分布可以被写成下面的形式：</p><script type="math/tex; mode=display">p(y;\eta) = b(y)e^{\eta ^T T(y) - a(\eta)}</script><p>那么这个分布属于Exponential Family。其中：</p><p>$\eta$: natural/canonical parameter(自然参数) </p><p>$T(y)$: suﬃcient statistic of the distribution(充分统计量) </p><p>$a(η)$: log partition function(对数划分函数)</p><p>其中$a(\eta)$是一个归一化常数的对数。也就是：</p><p>$p(y;\eta) = b(y)e^{\eta ^T T(y) - a(\eta)} = \frac {b(y)e^{\eta^T T(y)} } {e^{a(\eta)} }$</p><p>$\sum_{y} p(y;\eta) = 1(or \int _y p(y;\eta) dy = 1) $</p><p>我们可以得到：<br>$a(\eta) = \log {\left(\sum _y b(y)e^{\eta ^T T(y)} \right)}$</p><p>指数分布族有很多成员，实际上我们熟悉的很多分布都是指数分布族的。下面举几个例子：</p><h4 id="Bernoulli-Distribution"><a href="#Bernoulli-Distribution" class="headerlink" title="Bernoulli Distribution"></a>Bernoulli Distribution</h4><p>伯努利分布应该是最简单的分布之一了。$y \in {1,0}$，而且$p(y=1) = φ,p(y=0) = 1 - φ$，因此它的分布可以写成下面的样子：</p><p>$p(y;φ) = φ^y(1-φ)^{1-y}$</p><p>如何将它转化为指数族的形式？</p><ul><li><p>$\eta = \log {\frac {\phi } {1-\phi} }$</p></li><li><p>$T(y) = y$</p></li><li><p>$a(\eta) = \log {(1 + e^{\eta})}$ </p></li><li><p>$b(y) = 1$</p></li></ul><h4 id="Gaussian-Distribution-unit-variance"><a href="#Gaussian-Distribution-unit-variance" class="headerlink" title="Gaussian Distribution(unit variance)"></a>Gaussian Distribution(unit variance)</h4><p>高斯分布也是很常见的分布，这里我们先说明一下unit variance的情况，也就是$\sigma = 1$。它的概率密度如下：</p><script type="math/tex; mode=display">p(y;\mu) = \frac 1 {\sqrt{2 \pi} } exp\left(- \frac {(y - \mu)^2}{2} \right)</script><ul><li><p>$\eta = \mu$</p></li><li><p>$ T(y) = y$</p></li><li><p>$a(\eta) = \frac {\eta ^2} {2}$</p></li><li><p>$b(y) = \frac 1 {\sqrt{2 \pi} } e^{-\frac {y^2}{2} } $</p></li></ul><h4 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h4><p>现在将目标放到普通的高斯分布上。</p><script type="math/tex; mode=display">p(y;\mu) = \frac 1 {\sqrt{2 \pi \sigma ^ 2} } exp\left(- \frac {(y - \mu)^2}{2\sigma ^ 2} \right)</script><ul><li><script type="math/tex; mode=display">\eta = \left[\begin{matrix} \frac {\mu}{\sigma^2} \\ -\frac {1}{2\sigma^2} \end{matrix}\right]</script></li><li><script type="math/tex; mode=display">  T(y) = \left[ \begin{matrix} y \\y^2 \end{matrix}\right]</script></li><li><p>$a(\eta) = \frac {\mu^2}{2\sigma^2} + \log {\sigma}$</p></li><li><p>$b(y) = \frac 1 {\sqrt {2 \pi} }$</p></li></ul><p>这里情况变得就稍微复杂了点。</p><h4 id="Poisson-Distribution-Poisson-lambda"><a href="#Poisson-Distribution-Poisson-lambda" class="headerlink" title="Poisson Distribution:Poisson($\lambda$)"></a>Poisson Distribution:Poisson($\lambda$)</h4><p>泊松分布平时我们接触不如前两项多。泊松分布一般可以用在估计一个固定的时间段内某个事情发生的次数，假设各个事件之间互相独立，它们发生有一个固定的比率$\lambda$.</p><p>泊松分布的概率密度函数如下：</p><script type="math/tex; mode=display">p(y;\lambda) = \frac {\lambda ^y e ^{- \lambda} }{y!}</script><ul><li><p>$\eta = \log {\lambda}$</p></li><li><p>$T(y) = y$</p></li><li><p>$a(\eta) = e^{\eta}$</p></li><li><p>$b(y) = \frac {1}{y!}$</p></li></ul><h3 id="Generalized-Linear-Models"><a href="#Generalized-Linear-Models" class="headerlink" title="Generalized Linear Models"></a>Generalized Linear Models</h3><p>所以什么是广义线性模型？GLM是从来自于指数族分布$y|X;\theta$一种构造线性模型的方法。</p><p>广义线性模型的设计动机为：</p><ul><li>相应变量y可以是任意分布</li><li>允许y的任意函数（链接函数）可以随输入值x线性变化</li></ul><p>广义线性模型形式化定义有下面几个假设：</p><ol><li>$y|x;\theta$ ~ Exponential Family($\eta$),如高斯分布，伯努利分布，泊松分布等</li><li>假设目标函数是$h(x) = \mathbb{E}[T(y)|x]$</li><li>自然常数$\eta$和输入$X$是线性相关的：$\eta = \theta^TX$ or $\eta_i = \theta_i^T X (\eta = \Theta^T X)$ </li></ol><p>将自然参数与分布平均值连接得到：$\mathbb{E}[T(y);\eta]$.</p><p>权威响应函数（Canonical response function）g给出了分布平均值：$g(\eta) = \mathbb{E}[T(y);\eta]$.</p><p>则 $\eta = g^{-1}(\mathbb{E}[T(y);\eta])$,被称为权威链接函数（canonical link function）。</p><p>写成广义线性模型，可以得到：$\mathbb{E}(T(y);\eta)=\frac{d}{d\eta}a({\eta})$（证明较为复杂）。因此，可以很轻易得求出假设函数。</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><h4 id="Ordinary-Least-Square"><a href="#Ordinary-Least-Square" class="headerlink" title="Ordinary Least Square"></a>Ordinary Least Square</h4><p>应用GLM到下面的假设：</p><ol><li><p>$y|X;\theta ~ N(\mu,1)$,则$\eta = \mu,T(y) = y$.</p></li><li><p>Derive Hypothesis function $h_\theta(X) = \mathbb{E}[y|X;\theta] = \mu = \eta$.</p></li><li><p>Adopt linear model $\eta = \theta ^TX $: $h_\theta (X) = \eta = \theta ^T X$.</p></li></ol><p>Canonical response function:$g(\eta) = \mu = \eta$</p><p>Canonical link function:$\eta = g^{-1}(\mathbb{E}[T(y);\eta] = g’(\mu) = mu$</p><h4 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h4><ol><li><p>$y|X;\theta ~ Bernoulli(\phi)$，则$\eta = \log {\left(\frac {\phi}{1 - \phi}\right)},T(y) = y$</p></li><li><p>Derive hypothesis function $h_\theta(X) = \mathbb{E}[y|X;\theta] = \phi = $,则$\phi = \frac {1}{1 + e^{-\eta} }$</p></li><li><p>Adopt linear model $\eta = \theta ^T X$: $h_\theta(X) = \phi = \frac {1}{1 + e^{-\theta^TX} }$</p></li></ol><p>Canonical response function:$ φ = g(η) = sigmoid(η)$ </p><p>Canonical link function : $η = g^{−1}(φ) = logit(φ)$</p><h4 id="Possion-Regression"><a href="#Possion-Regression" class="headerlink" title="Possion Regression"></a>Possion Regression</h4><ol><li><p>$y|X;\theta ~ P(\lambda)$,则$\eta = \log{\lambda},T(y) = y$</p></li><li><p>Derive hypothesis function $h_\theta(X) = \mathbb{E}[y|X;\theta] = \lambda = e^{\eta}$</p></li><li><p>Adopt linear model $\eta = \theta^TX$: $h_\theta (X) = \lambda = e^{\theta^TX}$</p></li></ol><p>Canonical response function:$\lambda = g(\eta) = e^{\eta}$</p><p>Canonical link function:$\eta = g^{-1}(\lambda) = log(\lambda)$</p><h4 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h4><p>最后我们来推断下Softmax Regression，因为softmax是多维的分布，所以还是有点难度的。</p><p>首先我们应该写出它的分布函数如下：</p><script type="math/tex; mode=display">p(y;\theta) = \prod_{i=1}^k \phi_i^{\mathbf{1}\{y = i\} }</script><p>然后需要做的是把它写成Exponential Family的形式.</p><p>如果照着平时的思路下来，我们会发现，$a(\eta) = 0$,这是不允许发生的（Why？）。因此我们需要想办法，如果把$\phi_k$移到最后，又如何保证前面没有$y$的影响？</p><p>仔细观察上式，我们发现可以将上式写为：$\prod _{i=1}^k \left(\frac{\phi_i}{\phi_k} \right)^{\mathbf{1}\{y=i\} } \phi_k$. (!!!Genius!).</p><ul><li><p>$\eta = \left [ \begin{matrix}<br>\log{\frac {\phi_1}{\phi_k} }\\<br>\log{\frac {\phi_2}{\phi_k} }\\<br>…\\<br>\log{\frac{\phi_{k-1} }{\phi_k} }<br>\end{matrix} \right ]$</p></li><li><p>$T(y) = \left[<br>  \begin{matrix}<br>  \mathbf{1}\{y=1\}\\<br>  \mathbf{2}\{y=2\}\\<br>  …\\<br>  \mathbf{k-1}\{y=k-1\}<br>  \end{matrix}<br>  \right]$</p></li><li><p>$b(y) = 1$</p></li><li><p>$a(\eta) = -\log{(\phi_k)}$</p></li></ul><p>有了上面的格式，如何运用线性模型就比较顺理成章了。</p><ol><li><p>$y|X;\theta ~ P(\Phi)$,则$\eta ,T(y)$如上。</p></li><li><p>Derive hypothesis function :</p><script type="math/tex; mode=display">h_\theta(X) = \mathbb{E}[y|X;\theta] = \Phi = \begin{bmatrix} \frac {e^{\eta_1} }{\sum _{i=1}^k e^{\eta_i} }\\\frac {e^{\eta_2} }{\sum _{i=2}^k e^{\eta_i} }\\...\\1 - \frac {e^{\eta_k} }{\sum _{i=1}^k e^{\eta_i} }\end{bmatrix}</script><p>(注意，在这里为了方便我们定义$\eta_k = \log { {\eta_k}{\eta_k} } = 0$)</p></li><li><p>Adopt linear model $eta = \Theta^TX$:</p><p>$ h_\Theta (X)  =\begin{bmatrix}<br>\frac {e^{\theta_1^TX} }{\sum _{i=1}^k e^{\theta_i^TX} }\\<br>\frac {e^{\theta_2^TX} }{\sum _{i=1}^k e^{\theta_i^TX} }\\<br>…\\<br>1 - \frac {e^{\theta_k ^TX} }{\sum _{i=1}^k e^{\eta_i^TX} }<br>\end{bmatrix} $</p></li></ol><p>Canonical response function:$\phi_i = g(\eta) =\frac  {e^{\eta_i} }{\sum _{i=2}^k e^{\eta_i} }$</p><p>Canonical link function:$\eta_i = g^{-1}(\phi) = \log {\frac {\phi_i}{\phi_k} }$.</p><p>因此，根据广义线性模型，我们可以推出需要的hypothesis funtion的形式，从而进行进一步的学习。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> mathematics </tag>
            
            <tag> exponential family </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Learning From Data——Softmax Regression</title>
      <link href="/2018/10/16/Learning-From-Data%E2%80%94%E2%80%94Softmax-Regression/"/>
      <url>/2018/10/16/Learning-From-Data%E2%80%94%E2%80%94Softmax-Regression/</url>
      
        <content type="html"><![CDATA[<p>Learning From Data是研究生修的一门课，其实也就是机器学习的另一种叫法。第一门课中介绍了Linear Regression，Logistic Regression，Softmax Regression.虽然前两个都学过，但是还是有一些收获，比如另外的解释方法等等。<a id="more"></a></p><h2 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h2><p>这次Linear Regression主要学习到的新的东西是，从概率角度来理解为什么使用Least Square.</p><p>假设目标函数是 $Y = W^Tx+ \epsilon$，其中$\epsilon$是N维向量.假设$\epsilon$是独立同分布（IID）的，而且满足高斯分布$N(0,\sigma)$,则:</p><script type="math/tex; mode=display">p(y_n|X_n,W) = \frac 1 {\sqrt{2\pi }\sigma } exp \left(-\frac{(Y_n - W^TX_n)^2}{2\sigma ^2} \right)</script><p>而出现这个样本的概率如下：</p><p>$L(W) = p(Y|X,W) = \prod _{n=1}^N p(y_n|X_n,W)$.</p><p>我们想要求得最大概率估计（Maximum Likelihood Estimation）:$W_{MLE} = \arg\max_W(L{W})$.</p><p>展开之前我们应该加个log，因为我们喜欢sum而不是prod。如下：</p><script type="math/tex; mode=display">\begin{array} {l}\log{L(W)} &= \sum _{n=1}^N(\log{\frac 1 {\sqrt {2 \pi} \sigma}}- \frac 1 {2\sigma ^2 } (Y_n - W^TX_n)^2 \log e )\\ &= m \log{\frac 1 {\sqrt {2 \pi }\sigma}} - \frac 1 {2\sigma ^2 }  \sum_{n=1}^N  (Y_n - W^TX_n)^2 \end{array}</script><p>所以，$\arg\max_{W} (L(W)) = \arg\min_{W} (\sum_{n=1}^N  (Y_n - W^TX_n)^2 )$.这也正是我们的cost function的定义。</p><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>Logistic Regression学习了从另一种角度思考得到另一种定义cost function的方法，当然最终效果是一致的。</p><p>之前的logsitic regression对于$P(X_i \bigcap y_i)$的估计如下：</p><script type="math/tex; mode=display">P(X_i \bigcap y_i) =\frac {(y_i+1)} 2 P(X_i) \times P(y_i = +1|X_i) +\frac {(1 - y_i)} 2 P(X_i) \times (1 - P(y_i = +1|X_i))</script><p>实际上有另外一种可以达到一样的效果,不过此时我们需要的就是另外一种对$y$的定义了：$y \in {0,1}$:</p><script type="math/tex; mode=display">P(X_i \bigcap y_i) = (P(X_i) \times P(y_i = 1|X_i))^{y_i} (P(X_i) \times (1 - P(y_i = 1|X_i)))^{1-y_i}</script><p>因此出现这个样本的概率为：</p><script type="math/tex; mode=display">L(W) = \prod _{i=1}^N (P(X_i \bigcap y_i) = P(X_i) \times h_w(X_i) )^{y_i} (P(X_i) \times (1-h_W(X_i)))^{1-y_i} .</script><p>我们可以略去这些$P(X_i)$,因为这是确定的而且也不是我们需要注意的。<br>这时候log之后，得到最后的cost funtion的形式与之前就有了一些不同：</p><script type="math/tex; mode=display">f(W) = -\sum _{i=1}^N (y_i \log h_W{X_i} + (1 - y_i)\log{ (1 -h_W{X_i})})</script><p>接下来要做的就是求这个函数的梯度，但是为了看的清楚，首先说明下各个函数的意义：</p><script type="math/tex; mode=display">h_W(X) = \frac 1 {1 - e^{-g_W(X)}}</script><script type="math/tex; mode=display">g_W(X) = W^TX</script><p>求梯度过程如下：</p><script type="math/tex; mode=display">\begin{array}{l}\nabla f(W) &= -\sum _{i=1} ^N( y_i logh_W(X_i) + (1-y_i) log(1-h_W(X_i)))\\&= -\sum_{i=1}^N \left[ \frac {y_i}{h_W(X_i)} - \frac {1-y_i}{1-h_W(X_i)} \right] h_W'(x)\\&= -\sum_{i=1}^N\left[y_i + \frac {1-y_i}{e^{-g_W(X_i)}} \right] \frac {e^{-g_W(X_i)}}{1 - e^{-g_W(X_i)}} g_W'(X_i) \\\ &= -\sum_{i=1}^N\left[ \frac 1 {1 - e^{-g_W(X_i)}} - y_i \frac {1 - e^{-g_W(X_i)}}{1 - e^{-g_W(X_i)}} \right] g_W'(X_i)\\&=-\sum_{i=1}^N(y_i - h_W(X_i))X_i  \end{array}</script><p>而且这个cost function的好处是，利用梯度下降的时候它和线性回归的步骤是非常相似的,线性回归中：</p><script type="math/tex; mode=display">\frac {\partial f(W)}{\partial w_j} = \sum _{i=1}^N(y_i - g_{W}(X_i))x_{i,j}.</script><p>即</p><script type="math/tex; mode=display">\nabla f(W) = \sum_{i=1}^N (y_i - g_{W}(X_i))X_i.</script><p>最后回到两种不同的cost funtion，实际上二者除了negative，positive的标识数字不同，另外一种是在定义$P(X_i \bigcap y_i) $的时候，因为要忽略另外一种情况，一个办法是将它变成1相称，另一个办法是变成0相加。这两个cost funtion最终都会得到比较理想的结果。</p><h2 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h2><p>Softmax Regression是一种多维分类算法。依然是站在概率的角度来讨论。</p><p>假设共有k类，即$y \in {1,…,k}$.我们先给出一个概率估计，之前得概率估计是logistic函数，现在我们给出另一种情况：</p><script type="math/tex; mode=display">h_W(X_i) = \left [    \begin{matrix}p(y_i = 1|X_i;W_1)\\p(y_i=2|X_i;W_2)\\...\\p(y_i=k|X_i;W_k) \end{matrix}\right] = \frac 1 {\sum _{j=1}^k e^{W_j^TX_i}}  \left[\begin{matrix} e^{W_1^TX_i}\\ e^{W_2^TX_i}\\ ...\\ e^{W_k^TX_i} \end{matrix}\right]  = softmax(W,X_i)</script><p>同时我们定义:$softmax(z_i) = p（y = i|X,W） = \frac {e^{z_i}}{\sum _{j=1}{k} e^{z_j}}$，此时$i \in {1,…,k}$.</p><p>当然，W参数也会发生变化：</p><script type="math/tex; mode=display">W = \left[\begin{matrix}-W_1^T-\\-W_2^T-\\...\\-W_k^T- \end{matrix}\right]</script><p>因此我们确定了给定$W$和$X$的时候，$y$的概率。</p><p>而出现当前样本的概率（我们忽略$P(W,X)$,像之前一样它不会影响结果）：</p><script type="math/tex; mode=display">L(W) = \prod_{i=1}^{N} P(y_i|X_i,W).</script><p>其实我们可以想象的是这个式子展开了后会很复杂，因为对$y_i$可能的各个情况也要连乘。不如先log好了：</p><script type="math/tex; mode=display">\begin {array}{l} F(W) = \log{L(W)} &= \sum_{i=1}^N \log {p(y_i|X_i,W) }\\ &= \sum_{i=1}^N \log{\prod_{j=1}^k p_{W_j}(j|X_i,W)^{\mathbf{1}\{y_i = j\}}}\\ &= \sum_{i=1}^N \sum_{j=1}^k \mathbf{1}\{y_i = j\} \log { \frac {e^{W_jX_i}}{\sum _{l=1}^k e^{W_l^TX_i}}}\end {array}</script><p>这个东西，其实我推算的时候对他的符号表示已经很头大了。但是它虽然复杂但原理不难懂，和logistic regression的道理基本上一样的。</p><p>最后，我们就是要求这个函数的梯度了。这个函数的梯度求解想必是非常复杂的，但是实际上没有想象的那么麻烦。最后的结果也非常的简单：</p><script type="math/tex; mode=display">\nabla _{W_j} F(W) = \sum _{i=1}^m \left( \mathbf{1}\{y_i = j\} \log {\frac {e^{W_j^TX_i}}{\sum _{l=1}^k e^{W_l^TX_i}}} + \mathbf{1}\{y_i \ne j\} \log {\frac {e^{W_{y_i}^TX_i}}{\sum _{l=1}^k e^{W_l^TX_i}}} \right)</script><p>我们仔细观察原式就可以化简上面的样子。为了简化后面的步骤，假设$g(W_l) = W_l^TX_i$.<br>第一种情况$ {y_i = j}$：</p><script type="math/tex; mode=display">f_1(W) = \log {\frac {e^{g(W_j)}}{\sum_{l=1}^k e^{g(W_l)}}}</script><script type="math/tex; mode=display">\begin{array}{l}\nabla _{W_j} f_1(W)  &= \frac {\sum_{l=1}^k e^{g(W_l)}}{e^{g(W_j)}} \cdot \frac { -e^{2g(W_j)}+ (\sum_{l=1}^k e^{W_l})e^{W_j}}{(\sum_{l=1}^k e^{g(W_l)})^2} \cdot g'(W_j)\\&= \frac{\sum_{l=1}^k e^{g(W_l) - e^{g(W_j)}}}{\sum_{l=1}^k e^{g(W_l)}} \cdot g'(W_j) \\\ &= (1 - p(y_i = j|X_i,W))X_i\end{array}</script><p>第二种情况$y_i \ne j$,假设$y_i = q \ne j$:</p><script type="math/tex; mode=display">f_2(W) = \log {\frac {e^{g(W_q)}}{\sum_{l=1}^k e^{g(W_l)}}}</script><script type="math/tex; mode=display">\begin{array}{c}\nabla _{W_j} f_2(W) &=\frac {\sum_{l=1}^k e^{g(W_l)}}{e^{g(W_q)}} \cdot \frac { -e^{g(W_j) e^{g(W_q)}}}{(\sum_{l=1}^k e^{g(W_l)})^2} \cdot g'(W_j)\\&= - p(y_i = j|X_i,W)X_i\end{array}</script><p>也是两种情况的差别只有前面是否加一个1。合并两种情况，可以得到：</p><script type="math/tex; mode=display">\nabla _{W_j} F(W) = \sum _{i=1} ^N [(\mathbf{1}\{y_i=j\} - p(y_i=j|X_i,W))X_i]</script><p>上面推出来的要注意是我们想要最大化的函数。</p><p>而cost funtion的梯度应该是： $\sum _{i=1} ^N [(-\mathbf{1}\{y_i=j\} + p(y_i=j|X_i,W))X_i] $</p><p>对于softmax regression我们需要知道，它的参数$W_j$之间并不是独立的，因为各个概率加起来为1，有这个约束后实际上，只要知道$k-1$个参数，就可以确定这个模型。</p><p>实际上，可以很容易证明logistic regression 是 softmax regression的特殊情况。</p><p>以上就是上节课学到的所有新东西。</p>]]></content>
      
      
      <categories>
          
          <category> 数据学习课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> LFD class </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数学——Newton Method</title>
      <link href="/2018/10/16/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Newton-Method/"/>
      <url>/2018/10/16/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Newton-Method/</url>
      
        <content type="html"><![CDATA[<p>梯度下降时候，有时候我们可以使用Newton Direction.牛顿迭代法其实大家听起来很熟悉的。<br><a id="more"></a></p><p>首先来说明下，简单的牛顿迭代法的原理。牛顿迭代法是求近似解的一个办法，很多时候解无法算出来，我们只能用牛顿迭代法来一步步逼近。</p><p>首先给个很直观的例子，也就是一维的函数。先观看一下下面的gif。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/NewtonIteration_Ani.gif" alt=""></p><p>为了求得$f(x) = 0$,我们从图上直观看到可以一直这样逼近，最终会逼近到f(x) = 0的解。</p><p>原理是，如果我们将f(x)一阶泰勒展开,得到：</p><script type="math/tex; mode=display">f(x) \approx f(x_0)+f'(x_0)(x - x_0) = g(x)</script><p>而上式g(x) = 0是很容易解决的：$x = x_0 - \frac {f(x_0)}{f’(x_0)}$.</p><p>因为泰勒只是近似，因此上述得到的解并不是真正的解，只是离原有的解更接近了。也就是，牛顿迭代法种，下一步更新策略为:$x_{n+1} =x_n - \frac {f(x_n)}{f’(x_n)} $.</p><p>如何将牛顿迭代法用来解决优化问题？我们知道优化问题，想要得到最小值，或者最大值，在该点导数是为0的，这个问题就变成了，如何找到导数为0的点，那么就很简单了，对于一维函数的优化问题迭代步骤如下:$x_{n+1} =x_n - \frac {f’(x_n)}{f’’(x_n)} $.</p><p>多维函数来说，情况较为复杂一点，因为高纬度的二阶导数实在是很多。不过原理也是变化不大的，我们需要利用Hessian矩阵：</p><p>$x_{n+1} = x_{n+1}-H_f^{-1}(x_n)\nabla f(x_n)$.</p><p>Hessian矩阵定义如下：</p><script type="math/tex; mode=display">H_f = \begin{bmatrix} \frac {\partial^2f}{\partial x_1^2}& \frac {\partial^2f}{\partial x_1 \partial x_2}&...&\frac {\partial^2f}{\partial x_1 \partial x_n} \\\frac {\partial^2f}{\partial x_2 \partial x_1}& \frac {\partial^2f}{\partial x_2 \partial x_2}&...&\frac {\partial^2f}{\partial x_2 \partial x_n} \\...\\\frac {\partial^2f}{\partial x_n \partial x_1}& \frac {\partial^2f}{\partial x_n \partial x_2}&...&\frac {\partial^2f}{\partial x_n^2} \end{bmatrix}</script><p>可以看到的是，如果维度较高，这个海森矩阵的求逆是非常耗费时间的。一般来说，优化问题时候，维度较低的情况下，它的效果还是非常好的，比梯度下降更快。</p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Soft-Margin Support Vector Machine</title>
      <link href="/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Soft-Margin-Support-Vector-Machine/"/>
      <url>/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Soft-Margin-Support-Vector-Machine/</url>
      
        <content type="html"><![CDATA[<p>之前提到的之前的SVM会overfitting除了模型过于复杂，另一个问题就是它要将样本分类在训练集上做到完全正确。这时候一些噪声就会很大程度上影响结果。为了适应这些噪声，不得不做出很复杂的模型。<a id="more"></a></p><p>因此有时候我们希望可以容忍一些样本被错误分类。因此原有的数学条件就需要改变一下了。</p><p>现在我们回到最开始描述的问题：</p><p><strong>min</strong>  $\frac 1 2 W^TW$</p><p>$s.t.  y_n(W^TX_n+b) \ge 1,n =1,2,…,N $.</p><p>现在我们不要求所有的$ y_n(W^TX_n+b) \ge 1$,可以容忍一些错误。当然这个错误不能无限大。假设现在被分错的样本犯的错误是$\xi _n$,那么问题可以被描述为下：</p><p><strong>min</strong>  $\frac 1 2 W^TW + C\sum_{n=1}^N\xi_n$</p><p>$s.t.  y_n(W^TX_n+b) \ge 1 - \xi_n,n =1,2,…,N $.</p><p>$\xi_n \ge 0,n=1,2,…,N$</p><p>仔细看上面的描述我们可以发现，如果一个样本没有犯错，那么它对应的$\xi_n = 0$.如果一个样本犯错了，那么它对应的$\xi_n = 1 - y_n(W^TX_n+b)$.</p><p>因此实际上上面的问题也可以被描述成下面的形式：</p><p><strong>min</strong>  $\frac 1 2 W^TW + C\sum_{n=1}^N \ell(y_i,W^TX_i+b)$</p><p>where  $\ell(\cdot,\cdot)$ is the hinge loss defined by $\ell(x,y) \triangleq max\{1-yz,0\}$.</p><p>常数$C$的作用在于我们可以接受的犯错程度大小。可以想象的是如果$C$比较大，整个目标既然在最小化上面的式子，那么$\xi_n$的值就会变得非常小，也就是我们可以对划分错误的容忍度是比较小的，如果$C$比较大，那么容忍度则较大，因此这里也有一个权衡。</p><p>我们从上面的描述出发继续推导这个问题的Lagrange Dual Problem：</p><script type="math/tex; mode=display">\frac 1 2||W||^2 + C\sum_{n=1}^N \xi_n + \sum_{n=1}^N \alpha_n(1 - \xi_n - y_n(W_TX_n+b)) + \sum_{n=1}^N(-\beta \xi_n)</script><p>这个时候，实际上所有的关于$W,b$的偏导数与之前都是一致的。在这里就不详细推导了，只是最后我们需要对$\xi_n$求偏导：</p><script type="math/tex; mode=display">\frac {\partial \ell} {\partial \xi_n} = 0 = C - \alpha_n - \beta _n</script><p>由上式可以得到：$\beta _n = C - \alpha_n$因为我们有参数限制，$\alpha_n \ge 0,\beta_n \ge 0,n=1,…,N$,因此实际上我们可以得到的约束是：$ 0 \leq \alpha_n \leq C$.</p><p>同时由上面的结论，再结合原来的式子，还可以消掉的是$\xi$.</p><p>因此最后得到的那些KKT条件与原来HardMagin唯一的不同就在于$\alpha_n$的限制变了。从这里可以看出来$C$的作用:$C$很大的时候，说明这个限制相对原来较小，也就是要求犯错较少（因为原来的情况我们是不允许犯错误的）。</p><p>通过二次规划，我们可以一样得到$\alpha_n $的值，从而得到$W$，与$b$.但是需要注意的是$b$与之前的算法不一样了。</p><p>之前我们通过$a_n(1 - y_n(W^TX_n+b)) = 0$，通过找到是支持向量的点（$a_n \ne 0$）,从而通过该点计算出来$b = y_n - W^TX_n$.</p><p>而此时，我们想要计算的$b = y_n - y_n \xi_n - W^TX_n$.</p><p>有个问题，我们不知道$\ell_n$的值啊（其实我们是知道的$\xi_n = max(1 - y_n(W^TX_n+b),0)$，不过这是要等$b$求出来之后）。但是我们知道另一个信息$\beta_n \xi_n = (C - \alpha_n) \xi_n = 0$，这意味着如果$\alpha_n \ne C$的点，$\xi = 0$.所有实际上我们需要的是$0&lt;\alpha_n &lt; C$的点，这时候$\xi= 0$,可以计算出$b = y_n - W^TX_n$，这样的点叫free Support Vector.个别时候我们无法找到$free Support Vector$，那么这个$b$的值只能用kkt条件来限制了。</p><p>这里，我们希望可以仔细思考一下$\alpha_n$背后是否有什么指示。</p><p>如果$\alpha_n = 0$，那么$1 - \xi_n - y_n(W^TX_n +b) \leq 0$，可以得到的是这些点一般是完全没有错误的，这点和之前是一样的。</p><p>否则，$C&gt;\alpha_n &gt; 0$，则我们通过上面的推导也知道$\xi_n = 0$.这意味着，它们对应的$y_n(W^TX_n+b) = 1$.所以这些点是Support Vector，它们定义了最宽的分界线。</p><p>还有一种情况，$\alpha_n = C$.这种点就是被分错的点了，$\xi \ne 0$，但是$ 1 - \xi - y_n(W^TX_n+b) = 0$.要注意的是这里的分错并不一定是分类结果错误，还有可能是在分到margin中间去了。</p><p>上面的内容就是Soft Margin SVM，但是值得注意的是，我们需要调一个参数：C，如果C过大，仍然可能会overfitting。</p><p>Soft Margin SVM可以与Kernel结合，在实际中使用比Hard Margin SVM更加频繁。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Kernel Support Vector Macine</title>
      <link href="/2018/10/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Kernel-Support-Vector-Macine/"/>
      <url>/2018/10/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Kernel-Support-Vector-Macine/</url>
      
        <content type="html"><![CDATA[<p>上次遇到的问题是，Q矩阵的计算，仍然可能需要耗费很大计算量，也就是对于很高维度的特征转换，我们不一定能高效解决，更不用说无限维度。<a id="more"></a></p><p>因此这次引入了核函数，告诉我们如何高效地对待特征转换地问题。</p><h2 id="Polynomial-Kernel"><a href="#Polynomial-Kernel" class="headerlink" title="Polynomial Kernel"></a>Polynomial Kernel</h2><p>为了方便起见，我们希望可以把原来问题描述中的$X$换为$Z$,表示$Z$是$X$经过特征转换之后得到的高维度空间，而假设$X$维度是较低的。因此，现在的问题描述如下：</p><p>$min_{\alpha} \frac 1 2 \sum_{n=1}^N \sum_{m=1}^N a_na_my_ny_mZ_n^TZ_m - \sum_{n=1}^N \alpha_n$</p><p> <strong>subject to</strong> $\sum_{n=1}^N y_n\alpha_n = 0;a_n \ge 0,n=1,…,N$</p><p>上次我们也介绍了Q矩阵的计算，其中$q_{n,m} = y_ny_mZ_n^TZ_m$.这其中包含了对$Z$向量的乘积，因此隐含了很大的计算量。</p><p>假设，我们对$X$到$Z$向量的转换表示如下：$Z = \phi(X)$,那么上式中$Z_n^TZ_m = \phi(X_n)^T\phi(X_m)$.</p><p>我们知道，对于单单$X_n^TX_m$的计算是容易完成的，那么能不能通过什么办法用上面的计算来代替原来的硬算？</p><p>假设如下：$\phi(X) = {1,x_1,x_2,x_3…x_d,x_1^2,x_1x_2,…x_2x_1,x_2^2,…,x_dx_1,…x_d^2}$.</p><p>那么$\phi(X_n)^T\phi(X_m) = 1 + \sum_{i=1}^{d}x_i^nx_i^m + \sum_{i=1}^d\sum_{j=1}^d x_i^nx_j^nx_i^mx_j^m $</p><p>$\phi(X_n)^T \phi(X_m) = 1+X_n^TX_m + \sum_{i=1}^{d}x_i^nx_i^m  \sum_{j=1}^{d} x_j^n x_j^m = 1+X_n^TX_m + (X_n^TX_m)^2 $.</p><p>可以发现，通过这样的变换，我们很轻易地计算出$Z_n^TZ_m$.</p><p>在这里，我们称$k(X,X’) = 1+X^TX’ + (X^TX’)^2 $为一种核函数。如果我们对特征转换再进行一些处理，比如：$\phi(X) = {1,\sqrt 2 x_1,\sqrt 2 x_2,\sqrt 2 x_3…\sqrt 2 x_d,x_1^2,x_1x_2,…x_2x_1,x_2^2,…,x_dx_1,…x_d^2}$,</p><p>那么最后得到的是$k(x,x’) = (1+X^TX’)^2$。实际上，我们也可以转换到更高维的空间，继续推广到更一般的：$K(x,x’) = (\zeta + \xi x^Tx’)^d$. 这就是很有名的Polynomial Kernel。</p><p>当然，通过多项式核函数，我们无法实现无限维度的转换。</p><h2 id="Gaussian-Kernel-RBF-Kernel"><a href="#Gaussian-Kernel-RBF-Kernel" class="headerlink" title="Gaussian Kernel(RBF Kernel)"></a>Gaussian Kernel(RBF Kernel)</h2><p>对于高斯Kernel的介绍，我们尝试用另一种办法来推导。为了方便起见，我们假设维度只有一维，即$X = {x}$.</p><p>在这里直接给出$K(X,X’)$的定义如下：$K(X,X’) = e^{-(x -x’)^2}$.</p><p>然后我们一步步推向前推导，说明它其实是无限维度转换后的$X^TX$.</p><script type="math/tex; mode=display">\begin{align}K(X,X') &= e^{-(x - x')^2}\\&= e^{-x^2} e^{-(x')^2}e^{2xx'} \\&=Taylor=>e^{-x^2}e^{-(x')^2}(\sum _{i=0} ^ {\infty} \frac {(2xx')^2}{i!})\\&= \sum_{i=0}^{\infty} \frac {(\sqrt 2 x)^i}{\sqrt{i!}}e^{-x^2} \frac {(\sqrt 2 x')^i}{\sqrt{i!}} e^{-(x')^2}\end{align}</script><p>因此，这个转换就是 $\phi(x) = exp(-x^2)(1,\sqrt{\frac 2 {1!}}X,\sqrt{\frac {2^2}{2!}}X^2,…)$</p><p>可以证明的是，上升到多维度，Gaussian Kernel：</p><p>$K(X,X’)$ = $e^{-\gamma ||X - X’||^2}$ with $\gamma &gt; 0$.</p><p>这就是高斯核函数。但是需要注意的一点，高斯核函数放大无限维度空间，所以如果参数$\gamma$不当，仍然有可能overfitting.如下图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/TAE0Z%7D9NZWU7D%291%7EI8C1SLY.png" alt=""></p><h2 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h2><p>还有一个核函数，叫线性核函数：$K(x,x’) = x^Tx’$.</p><p>这个核函数，简单，也迅速，但是能力有限。</p><p>多项式核函数：$K(x,x’) = (\zeta + \xi x^tx’)^d$.</p><p>相对于线性核函数，它的能力强了很多，但是调参很难，因为有3个参数。相应的它的速度没有线性那么快。而且如果d很大,要么结果很接近0，要么很大，不会取得很好的结果。因此，它一般来说，只在d比较小的时候适用。</p><p>高斯核函数：$K(X,X’)$ = $e^{-\gamma ||X - X’||^2}$</p><p>高斯核函数很强大，计算速度比线性的略慢，但是也不差。但是它可能太过强大了，需要慎重适用，因为可能出现过拟合的情况。但是总体来说，一般来说高斯核函数是最常用的。</p><p>当然，还有很多别的核函数，只需要满足Mercer定理即可。</p><blockquote><p>Mercer定理：</p><p>如果函数K是$\mathcal{R}^n \times \mathcal{R}^n-&gt;\mathcal{R}$上的映射（也就是从两个n维向量映射到实数域）。那么如果K是一个有效核函数（也称为Mercer核函数），那么当且仅当对于训练样例${x_1,x_2,…x_n}$，其相应的核函数矩阵是对称半正定的。</p></blockquote><p>我们可以发现，kernel的区别实际上是特征转换的区别，只不过某些特征转换可以更容易地计算Q矩阵。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Dual Support Vector Machine</title>
      <link href="/2018/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Dual-Support-Vector-Machine/"/>
      <url>/2018/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Dual-Support-Vector-Machine/</url>
      
        <content type="html"><![CDATA[<p>之前说明了linear SVM的，但是实际上依然还有一些问题。虽然在一定程度上，linear SVM会减小特征转换带来的复杂度，但是另一方面，它依然依赖着d.<a id="more"></a>如果d过大，即使使用很多现有的QP工具，依然很难得到结果。如何处理数据维度很大，甚至是无穷维的情况？这是我们想要解决的问题。</p><p>但是要注意的事，实际上的数学推导非常复杂，因此在这里我只会做简单的推导，来慢慢达到自己的目标。</p><p>首先我们拿出来上次讨论到最后的成型的问题：</p><p><strong>$\min$</strong>  $\frac 1 2 W^TW$</p><p>$s.t.  y_n(W^TX_n+b) \ge 1,n =1,2,…,N $.</p><p>我们可以想到的是利用拉格朗日乘数，类似于之前的正则化，来构造一个函数$\zeta(W,b,\alpha)$,定义如下：</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) = \frac 1 2 W^TW + \sum _{n = 1} ^{N} \alpha_n (1 - y_n(W^TX_n+b))</script><p>我们要做的SVM是：$\min_{W,b}(\max_{ \alpha_i \ge 0,i=1,…,n} \zeta (W,b,\alpha) )$,很神奇的，我们需要的那些约束都融入到一个式子当中了。在这里，希望简单可以说明一下，实际上我们上面的SVM与原来的效果是一样的。</p><p>首先，如果原来的约束不满足，则：$y_n(W^TX_n+b) <1$，那么$(1-y_n(w^tx_n+b))>0$，而要最大化$\zeta(W,b,\alpha)$，$\alpha$又大于等于0，那么可以肯定的是$\sum _{n = 0} ^{N} \alpha_n (1 - y_n(W^TX_n+b)) $最后的结果是无穷大了，它一定不会被选上；</1$，那么$(1-y_n(w^tx_n+b))></p><p>如果原来的约束满足的话，$(1 - y_n(W^TX_n+b)) \leq 0$,因为它小于0，要最大化$\zeta(W,b,\alpha)$，只能使得$\sum _{n = 0} ^{N} \alpha_n (1 - y_n(W^TX_n+b)) $等于0，也就是最后得到的结果是$\zeta(W,b,\alpha) = \frac 1 2 W^TW$，因此实际上最终求的的最大值，依然是满足条件的。</p><p>通过这样就很巧妙地将条件与我们想要做的优化问题融合成了一个式子。</p><p>而且我们很容易知道的事：$\min_{W,b}(\max_{\alpha_i \ge 0,i=1,…,n} \zeta (W,b,\alpha) ) \ge \min_{W,b} \zeta (W,b,\alpha ‘)$,上式中$\alpha’$是个定值，<br>也就可以推断出来：$\min_{W,b}(\max_{\alpha_i \ge 0,i=1,…,n} \zeta (W,b,\alpha) ) \ge \max_{\alpha_i \ge 0,i=1,…,n}( \min_{W,b} \zeta (W,b,\alpha ‘))$.</p><p>更令人兴奋的是，在这些条件下：</p><p>1.convex primal</p><p>2.feasible primal（true if separable）</p><p>3.linear constraints</p><p>上式的等号是成立的。</p><p>因此我们只需要解决右边的部分就好了。这就是Lagrange Duality，拉格朗日对偶。（为何不解左边？emmm，$\alpha$ 是一个向量，N维的，一般来说N&gt;&gt;d+1）</p><p>嗯，但是似乎这个式子，还是很复杂，全部写出来看一下：</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) = \frac 1 2 W^TW + \sum _{n = 1} ^{N} \alpha_n (1 - y_n(W^TX_n+b))</script><p>首先，要在把$\alpha$看作定值的情况下找到最小值，那么我们知道它一定满足的条件：</p><script type="math/tex; mode=display">\frac {\partial \zeta}{\partial b} = \sum _{n=1}\alpha_n y_n = 0</script><p>因此，上面的式子变成了：</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) = \frac 1 2 W^TW + \sum _{n = 1} ^{N} \alpha_n (1 - y_nW^TX_n)</script><p>简化了很大一部分。然后求$W$的偏导：</p><script type="math/tex; mode=display">\frac {\partial \zeta}{\partial W} = W - \sum_{n=1}^N \alpha_n y_nX_n = 0</script><p>我们可以得到$  \sum_{n=1}^N \alpha_n y_nX_n = W$,因此最后式子简化为：</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) =   \sum _{n = 1} ^{N} \alpha_n - \frac 1 2 W^TW.</script><p>式子又简单了很多。同时我们再继续将$W$替换:</p><script type="math/tex; mode=display">\zeta(W,b,\alpha) =   \sum _{n = 1} ^{N} \alpha_n - \frac 1 2 ||\sum_{n=1}^N \alpha_n y_nX_n||^2.</script><p>而且不要忘了我们最之前推导的： $\alpha_n (1 - y_n(W^TX_n+b)) = 0$.</p><p>因此，现在的式子里面已经没有$W$与$b$了，我们要做的就是</p><p>$\max_{\alpha_i \ge 0,i=1,…,n,\sum y_n \alpha_n = 0,W =\sum \alpha_n y_nX_n } - \frac 1 2 ||\sum_{n=1}^N \alpha_n y_nX_n||^2 +  \sum _{n = 1} ^{N} \alpha_n$.</p><p>总结一下，要解决对偶问题得到上面的结果，需要达到的条件：</p><p>1.primal feasible： $y_n(W^TX_n+b) \ge 1$</p><p>2.dual feasible: $a_n \ge 0$</p><p>3.dual-inner optimal:$\sum y_n \alpha_n = 0;W =\sum \alpha_n y_nX_n$</p><p>4.primal-inner optimal: $\alpha_n (1 - y_n(W^TX_n+b)) = 0$.</p><p>上面的这些条件，被称为KKT（Karush-Kuhn-Tucker）条件，对于优化问题是非常必要的。哇，之前听过的高大上的名词逐渐拨开云雾见青天了。</p><p>我们将上面的式子继续展开：</p><script type="math/tex; mode=display">-\frac 1 2 \sum_{n=1}^N \sum_{m=1}^N a_na_my_ny_mX_n^TX_m + \sum_{n=1}^N \alpha_n.</script><p>接下来我们开始尝试最大化上面的这个式子,首先依然我们把最大化问题转化成为最小化问题，用数学语言描述：</p><p>$\min_{\alpha} \frac 1 2 \sum_{n=1}^N \sum_{m=1}^N a_na_my_ny_mX_n^TX_m - \sum_{n=1}^N \alpha_n$</p><p> <strong>subject to</strong> $\sum_{n=1}^N y_n\alpha_n = 0;a_n \ge 0,n=1,…,N$</p><p> 因为式子中没有$W$,我们暂时将约束中的$W$去掉，专注这个问题，最后再尝试计算出$W$.</p><p> 而这个如果仔细观察，我们会发现它是一个QP问题。也就是通过现成的工具，可以计算出最佳的$\alpha$.</p><p> 计算出最佳的$\alpha$，可以很轻易地计算出$W$，而且通过约束也能轻易地计算出$b$.而且我们可以通过约束发现，其实相当一大部分$\alpha_n=0$，而$\alpha \ne 0$的那些点，也正是我们的支撑向量。</p><p> 最后，我们提出一个疑问：这个计算方法，真的和维度没关系了吗？恐怕不是，维度隐含在了计算$Q$矩阵当中了.这还是没有达到我们的目的。这需要下一个改进：kernel。</p><h2 id="p-s-QP问题的解决"><a href="#p-s-QP问题的解决" class="headerlink" title="p.s. QP问题的解决"></a>p.s. QP问题的解决</h2><p> 一般来说，解决QP问题的工具，需要提供下面几个参数：</p><p>optimal $\alpha$ $\leftarrow$ $QP(Q,\mathbf{p},A,\mathbf{c})$</p><p> $\min_{\alpha}$  $\frac 1 2 \alpha ^T Q \alpha + p^T\alpha$</p><p>subject to $a_i^T \alpha \ge C_i$, for i = 1,2,…</p><p>因此，在本例中，Q：<br>$q_{n,m} = y_ny_mX^nX^m;$</p><p>$\mathbf{p} = -1_N;$</p><p>$a_1 = Y ,a_2 = -Y;a_3 = 1_N$</p><p>$c_1 = 0,c_2 = 0,c_3 = 0;$</p><p>当然，具体的参数类型还要看具体的工具包，但是所需参数都不难从已知的条件转换得到。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Linear Support Vector Machine</title>
      <link href="/2018/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Linear-Support-Vector-Machine/"/>
      <url>/2018/10/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Linear-Support-Vector-Machine/</url>
      
        <content type="html"><![CDATA[<p>这个名字真是很奇怪。想要了解为何叫这么奇怪的名字，就要深入了解这个东西。<br><a id="more"></a><br>首先需要回顾的是之前的Perceptron Learning Algorithm。如果这个资料线性可分，使用PLA算法，一定可以找到一个很好的线或者超平面（hyperplane）来将这个资料分开，但是这个线或者是超平面的个数可能是无数个，它们是否是一样好的？如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/JRN%5BZGK%29K_J5YLHU4I3EBGF.png" alt=""></p><p>上面3条线，对于PLA算法来说是一样好的，因此运行到哪一条，都是无法预测的。但是从我们的角度来看，我们会选择第三条，因为这条线更robust，可以容忍更多测量误差，如第一条，有一个离红色点很近的样本的话，它更大概率是negative的，但是第一条就会将它归类到positive。因此，选择第三条线，可以更好地避免overfitting。</p><p>为了想解决这个问题，我们需要将问题提炼成数学语言。首先我们想要求的是灰色区域最大的：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/9Y%60%60IZO%7BW%285P%28RI%24KPP14LP.png" alt=""></p><p>我们称灰色区域为margin。而这个margin，实际上是最近的两个点到中间这条线的距离。</p><p>那么我们就要先想象，点到平面（或者超平面）的距离如何计算？</p><p>如果一个超平面的方程为$W^TX + b = 0$,则任意两个在该平面的点$x’$与$x’’$都应该满足上式，也就是</p><script type="math/tex; mode=display">\left\{\begin{array} W^TX'+b = 0\\W^TX''+b = 0\end{array}\right</script><p>因此可以得到：$W^T(X’-X’’) = 0$.<br>而$(X’-X’’)$可以表示平面上的任何一个向量，这说明了，$W$是该平面的法向量。</p><p>而一个点到平面的距离，实际上就是该点到任何平面上一点连接得到的向量对该平面法向量的一个投影。计算投影长度的办法其实很简单,首先我们有$ab = |a||b|cos\theta$,因此只要规定a的长度为1，那么这两个向量的数量积的绝对值就是向量的长度。因此我们可以得到：</p><script type="math/tex; mode=display">d = |\frac {W^T }{||W||}(X - X')| = |\frac 1 {||W||}(W^TX + b)|.</script><p>这样，我们就得到了一个点到一个超平面的距离。</p><p>实际上一个超平面的表示方法是无穷的，比如$WTX+b = 0$与$2W^TX+2b= 0$是一个平面，如果我们将经过距离超平面最近的点的与超平面平行的平面表示为:$W^X+b = ±1$，那么d的形式就更简单了：$d = \frac 1 {||W||}$.</p><p>上面的距离中还是加了绝对值，但是因为这个问题的前提是将所有的点都分类正确，因此$y_i(WX_i+b)\ge 0$.</p><p>所以用数学语言描述我们的问题如下：</p><p>max $\frac 1 {||W||}$</p><p>$s.t. min_{n = 1,…,N} y_n(W^TX_n+b) = 1$.</p><p>注意的是为什么最小的点$y_n(W^TX_n+b) = 1$,因为距离较远的话，根据距离公式$(W^TX+b)$会更大。</p><p>上面的问题依然是很难解决的，我们希望可以继续放松这个约束。如果是所有点$y_n(W^TX_n+b) \ge 1$如何呢？</p><p>这里利用反证法证明，放宽到上面的约束依然没有问题，距离直线最近的点依然是满足$y_n(W^TX_n+b) = 1$：</p><p>如果我们找到最近的点$X_n$，它满足的是$y_n(W^TX_n+b) =a (a&gt;1)$，而且得到了最大的$\frac 1 {||W||}$，那么对上式左右同时除以a,而$\frac W a$比$W$更小，也就是这个$\frac 1 {||W||}$并不是最大的。这就矛盾了。因此依然只有在$y_n(W^TX_n+b) =1$的时候才能取得最大值。所以放大这个约束，我们依然可以得到一样的最终结果。</p><p>之前我们一直在求得是最小值，我们希望在这里也可以转换成为求最小值，同时范数是需要根号的，而因为范数和范数的平方是单调递增的，因此转化为范数的平方不会影响结果，同时再添上一个$\frac 1 2$，为了以后计算的方便。</p><p>因此，最终的用数学语言描述我们的问题的版本如下：</p><p>min  $\frac 1 2W^TW$</p><p>$s.t.  y_n(W^TX_n+b) \ge 1,n =1,2,…,N $.</p><p>这个问题实际上是一个QP（二次规划）问题。而二次规划问题，我们可以借助很多工具，提供必要的参数，求得最佳解。</p><p>上术问题就是svm问题。为什么叫support vector machine？我们需要注意的是，实际上决定最终线的，只有可能是最边上的点，而决定最终结果的点，就叫做支持向量。</p><p>当我们面对线性无法可分的情况，就需要使用之前介绍的特征转换（nonlinear transform），将当前的点转换到更高维度的空间中去，使其成为线性可分。</p><p>最后，我们在这里想要简单说明一下这背后的理论基础，为什么寻找最粗的那条线，可以获得更好的robustness？</p><p>这就又回到了vc dimension.假设我们找到的比较粗的线（margin较大），是我们要的标准。那么具有这么大margin的线，能将空间中的N个样本分成的dichotomy的个数就会少很多，也就是有效vc dimension会变低。当然，这个问题无法像PLA时候那样分析，因为具体能分多少，与样本之间的距离也很重要，具体样本得到的结果也不同，但是可以证明的是,如果这些样本在一个半径为R的圆内，margin长度为ρ：</p><script type="math/tex; mode=display">d_{vc}(\mathcal{A}_{\rho}) \leq min(\frac {R^2}{ρ^2} ,d)+1 \leq d+1</script><p>之前介绍的feature transform有个问题是太过于复杂导致vc dimension会变得很大，而我们可以看出来通过SVM我们某种程度上可以处理好这种情况。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数学——Lagrange Multiplier</title>
      <link href="/2018/10/09/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Lagrange-Multiplier/"/>
      <url>/2018/10/09/%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94Lagrange-Multiplier/</url>
      
        <content type="html"><![CDATA[<p>拉格朗日乘数法，是我们大学或者考研过来的耳熟能详的名词了。我们接触他的时候，应该是在求条件极值的时候。<br><a id="more"></a><br>求$f(x,y)$在$g(x,y)=0$的条件下的极值。需要利用拉格朗日乘数构造新的式子：</p><p>$w(x,y,\lambda ) = f(x,y)+\lambda g(x,y)$</p><p>让$w(x,y,\lambda)$分别对$x,y,\lambda$求偏导，并令其为0：</p><script type="math/tex; mode=display">\left \{\begin{array}{}    w'_x(x,y,\lambda) = f'_x(x,y)+\lambda g'_x(x,y) = 0\\    w'_y(x,y,\lambda) = f'_y(x,y)+ \lambda g'_y(x,y) = 0\\    w'_{\lambda}(x,y,\lambda) = g(x,y) = 0\end{array}\right .</script><p>不过大学的时候，我虽然会这么计算，但是却不知道原理。现在希望从原理解释一下，为什么要这么算。</p><p>暂时我想到了两种解释办法：</p><p>1.我们首先要知道的一个前提是，$g(x,y) = 0$在任意一点$(x_0,y_0)$切线的法向量为$(g’_x(x_0,y_0),g’_y(x_0,y_0))$.想象现在有一个点在约束的这条线上移动，为了找到让$f(x,y)$值最小的点，首先我们求出$f(x,y)$在当前点的梯度，梯度也就是朝着这个方向（或者反方向）前进，$f(x,y)$的值会变大（或者变小）,因此只要梯度与这条线上该点的法向量不平行，我们总是可以将梯度投影到该点的切线上，也就是依然能抄着切线的某个方向运动，让$f(x,y)$的值变小（如果要找到最大值，就是变大）。当梯度与法向量平行的时候，不论朝着哪个方向，都无法让$f(x,y)$的值变小，因此这个点就是一个极值小点。</p><p>而我们知道的，上面的法向量，实际上是$g(x,y)$在该点的梯度，因此我们有在极值点的时候：</p><script type="math/tex; mode=display"> \nabla f(x,y) = \lambda \nabla g(x,y)</script><p>上式中，$\lambda$的正负取决于要的是极大值点还是极小值点。而上面的式子，实际上就与方程组的前两个方程一致。</p><p>2.另一个办法，画出等高线图。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/2012101621500549.png" alt=""></p><p>可以比较清晰地看出来，当$g(x,y)=0$与等高线相切的点是极小值。因为你只能在$g(x,y)=0$的这条线上移动，那么别的地方总会比它大（或者大）。那怎么求相切的部分的点呢？首先，等高线的方程，实际上是曲线到(x,y)平面的投影，方程为$f(x,y)=C$,同样的，既然相切，那么他们在该点的法向量一定是平行的。计算法向量，又回到了前面的内容：</p><script type="math/tex; mode=display">  \nabla f(x,y) = \lambda \nabla g(x,y)</script><p>联立$g(x,y)=0$即可得到原来的方程组。</p><p>现在我们知道了条件极值如何解出来，但是这只是拉格朗日乘数法的一部分。拉格朗日乘数法是一种寻找变量受一个或多个条件所限制的多元函数的极值的方法。首先上面的条件限制只有一个，另外上面的条件也很简单，是在$g(x,y)=0$，如果我们要的是$g(x,y) \leq 0$的呢？</p><p>如果$f(x,y)$极值点本身就在上面的约束范围内，那么相当于没有约束，也就是$\lambda = 0$，否则在边界上，又回到了上面的问题：$g(x,y)=0$.总之，$\lambda g(x,y) = 0$.因此我们需要改变联立条件即可。</p><p>上面的式子，都是$\lambda$也会变化的情况。但是，在机器学习的正则化中，我们往往给出的式子是形如这样$E_{in} + \frac \lambda N \VertW\Vert^2$.而且这个$\lambda$可能是个定值。如果$\lambda$固定，得到的又是什么值？</p><p>我们可以推断出来的是如果$E_{in}$找到了最小的地方，那么$W$也就为0，否则$\nabla E_{in}$与$W$的比值是一个定值。从这些里得不到很有用的信息。但是从另一个角度来说，它确实限制了$W$的大小，虽然目前不知道具体限定到哪个范围。$\VertW_{reg}\Vert \leq \VertW_{lin}\Vert$是一定的，可以从反证法证明：如果$\VertW_{lin}\Vert&lt;\VertW_{reg}\Vert$,那么$E_{in}$也会小，正则项也更小，所以这时候的$E_{reg}$比使用$W_{reg}$的更佳，也就是前面找到的不可能是最小值。</p><p>另一个拉格朗日乘数法重要的在机器学习中的应用，是在SVM中。 </p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）作业4</title>
      <link href="/2018/10/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A4/"/>
      <url>/2018/10/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A4/</url>
      
        <content type="html"><![CDATA[<p>机器学习基石的最后一次作业，总共20道题目。<br><a id="more"></a><br><strong>1. Deterministic noise depends on $\mathcal{H}$, as some models approximate $f$ better than others. Assume $\mathcal{H}’\subset \mathcal{H}$ and that $f$ is fixed. In general (but not necessarily in all cases), if we use $\mathcal{H}’$ instead of $\mathcal{H}$, how does deterministic noise behave?</strong></p><p>a. In general, deterministic noise will decrease.</p><p>b. In general, deterministic noise will increase.</p><p>c. In general, deterministic noise will be the same.</p><p>d. If $d_{\text{vc}}(\mathcal{H}’) \le \frac{1}{2} d_{\text{vc}}(\mathcal{H})$, deterministic noise will increase, else it will decrease.</p><p>e. If $d_{\text{vc}}(\mathcal{H}’) \le \frac{1}{2} d_{\text{vc}}(\mathcal{H})$, deterministic noise will decrease, else it will increase.</p><p>deterministic noise出现的原因，是$H$无法完美的模拟f.而$H’$是$H$的子集，也就是它的模型复杂度更低，一般来说更无法模拟目标函数，它的deterministic noise应该是上升的，选b。</p><p><strong>2. Consider the following hypothesis set for $\mathbf{x} \in \mathbb{R}^dx$ defined by the constraint:</strong></p><script type="math/tex; mode=display">\mathcal{H}(d, d_0) = \{ h ~|~ h(\mathbf{x}) = \mathbf{w}^\mathrm{T}\mathbf{x}; w_i = 0 \hspace{1 mm} \mbox{for} \hspace{1mm} i \geq d_0 \},</script><p><strong>which of the following statements is correct?</strong></p><p>a. $H(10,3)⊂H(10,4)$</p><p>b. $H(10,3)∪H(10,4)=\{\}$</p><p>c. $H(10,3)⊃H(10,4)$</p><p>d. $H(10,3)∩H(10,4)=\{\}$</p><p>e. none of the other choices</p><p>这个题目的约束不算难，也就是有一个额外的参数$d_0(d_0 \leq d)$,w下标比$d_0$大的固定为0.选项中$d_0$只有3与4两个选项，而$d_0 = 3$的$H$是包含在$d_0=4$的$H$中的，因为对于前者来说，$w_3$的值也确定了，自由度为3，后者自由度为4，$w_0$可以为0也可以为其他值.因此答案选a.</p><p>For Questions 3-4, consider the augmented error $E_{\text{aug}}(\mathbf{w}) = E_{\text{in}}(\mathbf{w}) + \frac{\lambda}{N} \mathbf{w}^T \mathbf{w}$ with some $\lambda &gt; 0$.</p><p><strong>3. If we want to minimize the augmented error $E_{\text{aug}}(\mathbf{w})$ by gradient descent with $\eta$ as learning rate, which of the following is a correct update rule?</strong></p><p>a. $w(t+1)⟵w(t)+ηλ\nabla E \in (w(t))$.</p><p>b. $w(t+1)⟵w(t)-ηλ\nabla E \in (w(t))$.</p><p>c. $w(t+1)⟵(1− \frac {2\eta \lambda} {N})w(t)−η\nabla E \in (w(t))$.</p><p>d. $w(t+1)⟵(1+ \frac {2\eta \lambda} {N})w(t)−η\nabla E \in (w(t))$.</p><p>e. none of the other choices</p><p>这个题目也是比较简单的。梯度下降就是朝着梯度的反方向前进，因此只用求出来梯度就可以。$W^TW$的梯度很简单是$2W$，其他的与之前的一致，因此答案选c。</p><p><strong>4. Let $\mathbf{w}_{\text{lin}}$ be the optimal solution for the plain-vanilla linear regression and $\mathbf{w}_{\text{reg}}(\lambda)$ be the optimal solution for minimizing $E_{\text{aug}}$ in Question 3, with $E_{\text{in}}$ being the squared error for linear regression. Which of the following is correct?</strong></p><p>a. none of the other choices</p><p>b. $||W_{reg}(\lambda)|| \leq ||W_{lin}||$ for any $\lambda &gt; 0$</p><p>c. $||W_{reg}(\lambda)|| \geq ||W_{lin}||$ for any $\lambda &gt; 0$</p><p>d. $||W_{reg}(\lambda)||$ is always a non-decreasing function of $\lambda$ for $\lambda \ge 0$</p><p>e. $||W_{reg}(\lambda)||$ is always a constant function of $\lambda$ for $\lambda \ge 0$</p><p>要明白这个题目，首先要知道什么是$||W||$，这个意思是$W$向量的范数，也就等于$W^TW$.对于之前题目添加的regularization来说，限制实际上是$W^W \leq C$.如何推导？<br>最低点$\nabla E_{aug} = 0$，也就是$\nabla E_{in} = - \frac {2\lambda} {N} W$,因此最低点$\nabla E_{in}$与$W$的长度比值是一定的，也就是$W$向量的长度被确定到了一个值。而因为一直在朝约束条件下最低点走，因次$\nabla E_{in}$也是接近平缓的也就是值比较小，所以这意味着$W$最后是比较小的。</p><p>从另一个角度来看，范数一定是大于零的，为了找到最低点当然是让范数尽量小，也就是正则化相当于给各个参数增加了惩罚，想让他们变得更小。</p><p>因此这个题目的答案选择b.如果没有约束情况下得到的最好的$W$也满足约束，也就是等于的情况，其他时候$||W_{lin}|| &gt; ||W_{reg}||$</p><p><strong>5. You are given the data points: $(-1,0)$, $(\rho,1)$, $(1,0)$,$ \rho \ge 0$, and a choice between two models:</strong></p><ul><li>constant $h_0(x)=b_0$ and</li><li>linear $h_1(x)=a_1x+b_1$</li></ul><p>For which value of $\rho$ would the two models be tied using leave-one-out cross-validation with the squared error measure?</p><p>a. $\sqrt{\sqrt {3}+4}$</p><p>b. $\sqrt{\sqrt{3} - 1}$</p><p>c. $\sqrt{9+4 \sqrt{6}}$</p><p>d. $\sqrt{9 - \sqrt{6}}$</p><p>e. none of the other choice</p><p>使用Leave-One-Out Cross验证来得到$E_{val}$。对于第一种情况，$h(x)=b_0$是个常量。对于第二种情况是个直线。首先要计算出两种模型的$E_{val}$.</p><p>第一种模型：</p><ul><li>第一个为验证集：则$E_{in} = \frac 1 2 ((b_0-1)^2 + b_0^2)$,则$E_{in}$最小的时候$b_0 = 0.5$，$err = 0.5 \times 0.5 = 0.25$.</li><li>第二个为验证集：则$E_{in} = b_0^2$,因此$b_0 = 0$,err = 1.</li><li>第三个为验证集，情况与第一种情况一致，$err =0.25$.</li></ul><p>因此这时候的$E_{val} = (1+0.25+0.25)/3 = 0.5$.</p><p>第二种模型：</p><ul><li>第一个为验证集：则计算出来得到$a_1 = \frac 1 {p-1},b_1 = \frac 1 {1-p}$,则预测值是$\frac 2 {1-p}$,$err = \frac 4 {(1-p)^2}$.</li><li>第二个为验证集，得到的是一个常熟：$h(x) = 0$.这种情况下$err = 1$.</li><li>第三个为验证集，则计算出来得到$a_1 = \frac 1 {p+1},b_1 = \frac 1 {1+p}$,则预测值是$\frac 2 {1+p}$,$err = \frac 4 {(1+p)^2}$.</li></ul><p>这时候的$E_{val} =(1 + \frac 4 {(1-p)^2} + \frac 4 {(1+p)^2} )/3$.</p><p>题目中说了，两个模型都适用到该样本集。那么上面两个应该是相等的。可以解出来：$p^2 = 9±4\sqrt {6}$,而$9-4 \sqrt 6 &lt; 0$，因此正确答案是 $9+ 4 \sqrt {6}$.答案选c。 </p><p>For Questions 6-7, suppose that for 5 weeks in a row, a letter arrives in the mail that predicts the outcome of the upcoming Monday night baseball game.</p><p><strong>6. Assume there are no tie. You keenly watch each Monday and to your surprise, the prediction is correct each time. On the day after the fifth game, a letter arrives, stating that if you wish to see next week’s prediction, a payment of NTD $1000$ is required. Which of the following statement is true?</strong></p><p>a. There are 31 win-lose predictions for 5 games.</p><p>b. If the sender wants to make sure that at least one person receives correct predictions on all 5 games from him, the sender should target to begin with at least 5 people.</p><p>c. To make sure that at least one person receives correct predictions on all 5 games from the sender, after the first letter `predicts’ the outcome of the first game, the sender should target at least 16 people with the second letter.</p><p>d. To make sure that at least one person receives correct predictions on all 5 games from him, at least 64 letters should be sent before the fifth game.</p><p>e. none of the other choice</p><p>这个题目讲的是一个小把戏。5场比赛，每场比赛只有正负两个情况。因此一共可能出现的情况有$2^5=32$种。a错误。32种情况，当然要32个人，因此b错误。至少发出去的信有（32+16+8+4+2=62）封，d错误。而c，第一个结果出来后，会有一半的人收到错误的预测，因此第二封信只需要发给正确的那些人就好了，也就是16个人.</p><p><strong>7. If the cost of printing and mailing out each letter is NTD 10. If the sender sends the minimum number of letters out, how much money can be made for the above `fraud’ to succeed once? That is, one of the recipients does send him NTD 1000 to receive the prediction of the 6-th game?</strong></p><p>a. NTD 340</p><p>b. NTD 370</p><p>c. NTD 400</p><p>d. NTD 430</p><p>e. NTD 460</p><p>上面一道题目推断出来，至少要发送62封信才能保证有个人收到所有预测结果。而最后一个人收到的全部正确的预测后还要在加发一封，来骗钱。也就是63封，所以答案是NTD 370，选b.</p><p>For Questions 8-10, please read the following story first. In our credit card example, the bank starts with some vague idea of what constitutes a good credit risk. So, as customers $\mathbf{x}_1, \mathbf{x}_2,…,\mathbf{x}_N$ arrive, the bank applies its vague idea to approve credit cards for some of these customers based on a formula $a(\mathbf{x})$. Then, only those who get credit cards are monitored to see if they default or not.</p><p><strong>8. For simplicity, suppose that the first $N=10000$ customers were given credit cards by the credit approval function $a(\mathbf{x})$. Now that the bank knows the behavior of these customers, it comes to you to improve their algorithm for approving credit. The bank gives you the data $(\mathbf{x}_1, y_1), … , (\mathbf{x}_N, y_N)$. Before you look at the data, you do mathematical derivations and come up with a credit approval function. You now test it on the data and, to your delight, obtain perfect prediction.</strong></p><p>What is $M$, the size of your hypothesis set?</p><p>a. $1$</p><p>b. $N$</p><p>c. $2^N$</p><p>d. $N^2$</p><p>e. We have no idea about it.</p><p>利用数学推理想到了一个函数做出了很好的预测，因此这个vc dimension是无法计算的，但是因为没有经过数据的学习，这个H的大小应该是1，选择a.</p><p><strong>9. With such an $M$, what does the Hoeffding bound say about the probability that the true average error rate of $g$ is worse than $1\%$ for $N=10,000$?</strong></p><p>a. $\leq 0.171$</p><p>b. $\leq 0.221$</p><p>c. $\leq 0.271$</p><p>d. $\leq 0.321$</p><p>e. none of the other choices</p><p>霍夫丁不等式的简单应用：$P[\nu  - \upsilon|&gt; \epsilon ] \leq 2 e^{-2\epsilon ^2N}$。上述中$\epsilon = 0.01,N = 10000$,得到答案为0.2706705664732，答案选c.</p><p><strong>10. You assure the bank that you have a got a system $g$ for approving credit cards for new customers, which is nearly error-free. Your confidence is given by your answer to the previous question. The bank is thrilled and uses your $g$ to approve credit for new customers. To their dismay, more than half their credit cards are being defaulted on. Assume that the customers that were sent to the old credit approval function and the customers that were sent to your g are indeed i.i.d. from the same distribution, and the bank is lucky enough (so the “bad luck” that “the true error of gg is worse than $1\%$’’ does not happen). Which of the following claim is true?</strong></p><p>a. By applying $a(\mathbf{x}) \mbox{ NOR } g(\mathbf{x})$ to approve credit for new customers, the performance of the overall credit approval system can be improved with guarantee provided by the previous problem.</p><p>b. By applying $a(\mathbf{x}) \mbox{ NAND } g(\mathbf{x})$ to approve credit for new customers, the performance of the overall credit approval system can be improved with guarantee provided by the previous problem.</p><p>c. By applying $a(\mathbf{x}) \mbox{ OR } g(\mathbf{x})$ to approve credit for new customers, the performance of the overall credit approval system can be improved with guarantee provided by the previous problem.</p><p>d. By applying $a(\mathbf{x}) \mbox{ AND } g(\mathbf{x})$ to approve credit for new customers, the performance of the overall credit approval system can be improved with guarantee provided by the previous problem.</p><p>e. none of the other choices</p><p>这个题目中说到，利用之前的推断出来的g，本应该有很好的表现，但是却得到了很差的表现。为什么？我们要注意一个事：Sample Bias。虽然题目中说了，新的顾客和之前系统的顾客是来自于同一分布的，但是我们得到的test数据的分布并不是原先的顾客分布。test数据中，顾客的信息并不是随机得到的，而是先经过了$a(x)$的筛选。上面的霍夫曼不等式的理论保证是在同一分布的前提下，因此首先要经过$a(x)$的筛选，然后再用$g(x)$来判断。因此答案选d.</p><p>For Questions 11-12, consider linear regression with virtual examples. </p><p><strong>11. That is, we add $K$ virtual examples $(\tilde{\mathbf{x}}_1, \tilde{y}_1),(\tilde{\mathbf{x}}_2, \tilde{y}_2),\dots, (\tilde{\mathbf{x}}_K, \tilde{y}_K)$ to the training data set, and solve$<br>\min \limits _{\mathbf{w}} \frac{1}{N+K} \left(\sum_{n=1}^N (y_n - \mathbf{w}^T \mathbf{x}_n)^2 + \sum_{k=1}^K (\tilde{y}_k - \mathbf{w}^T \tilde{\mathbf{x}}_k)^2\right)$.We will show that using some “special” virtual examples, which were claimed to be a possible way to combat overfitting in Lecture 9, is related to regularization, another possible way to combat overfitting discussed in Lecture 10. Let $\tilde{\mathbf{X}} = [\tilde{\mathbf{x}}_1 \tilde{\mathbf{x}}_2 \ldots \tilde{\mathbf{x}}_K]^T$, and $\tilde{\mathbf{y}} = [\tilde{y}_1, \tilde{y}_2, \ldots, \tilde{y}_K]^T$. What is the optimal $\mathbf{w}$ to the optimization problem above, assuming that all the inversions exist?</strong></p><p>a. $(\mathbf{X}^T\mathbf{X})^{-1}(\widetilde {\mathbf{X}}^T\widetilde{\mathbf{y}})$</p><p>b. $(\mathbf{X}^T\mathbf{X})^{-1}(\mathbf{X}^T \mathbf{y}+\widetilde {\mathbf{X}}^T\widetilde{y})$</p><p>c. $(\mathbf{X}^T\mathbf{X} + \widetilde{\mathbf{X}}^T\widetilde{\mathbf{X}})^{-1}(\widetilde {\mathbf{X}}^T\widetilde{\mathbf{y}})$</p><p>d. $(\mathbf{X}^T\mathbf{X} + \widetilde{\mathbf{X}}^T\widetilde{\mathbf{X}})^{-1}(\mathbf{X}^T \mathbf{y} +\widetilde {\mathbf{X}}^T\widetilde{\mathbf{y}} )$</p><p>e. none of the other choice</p><p>这个题目说起来也容易。既然把虚拟数据也融合进去了，当然各部分都要计算，很容易排除其他答案,选择d。</p><p><strong>12. For what $\tilde{\mathbf{X}} and $\tilde{\mathbf{y}}$ will the solution of the linear regression problem above equal to</strong></p><script type="math/tex; mode=display">\mathbf{w}_{\text{reg}} = \mathrm{argmin}_{\mathbf{w}} \frac{\lambda}{N} \|\mathbf{w}\|^2 + \frac{1}{N} \|\mathbf{X}\mathbf{w}-\mathbf{y}\|^2?</script><p>a. $\tilde{\mathbf{X}} = I, \tilde{\mathbf{y}} = 0$</p><p>b. $\tilde{\mathbf{X}} = \sqrt {\lambda}I, \tilde{\mathbf{y}} = 0$</p><p>c. $\tilde{\mathbf{X}} = \lambda I, \tilde{\mathbf{y}} = \mathbf{1}$</p><p>d. $\tilde{\mathbf{X}} = \sqrt{\lambda} \mathbf{X}, \tilde{\mathbf{y}} = \mathbf{y}$</p><p>e. none of the other choice</p><p>这个问题乍一看，摸不着头脑。一个是矩阵中求逆操作，另一个是最小化一个函数（argmin(f(x))的定义之前已经说过）。但是换个办法的话，其实很容易解决，我们可以想象一下11题中需要最小化的函数$E_{in}$，则可以得到：</p><script type="math/tex; mode=display">W_{vir} = argmin_w \frac 1  {N+K} (||\tilde{\mathbf{X}}\mathbf{w} - \tilde{\mathbf{y}}||^2 +  ||\mathbf{X}\mathbf{w} - \mathbf{y}||^2).</script><p>最小化的话无论前面有没有$\frac 1 N$或者其他常数都是无所谓的。<br>想要让二者最后结果相等，使得去掉常数之后相等即可，则，$\tilde{\mathbf{X}} = \sqrt {\lambda}I, \tilde{\mathbf{y}} = 0$.因此这道题目答案选b。</p><p><strong>13. Consider regularized linear regression (also called ridge regression) for classification</strong></p><script type="math/tex; mode=display">\mathbf{w}_{\text{reg}} = \mbox{argmin}_{\mathbf{w}} \left(\frac{\lambda}{N} \|\mathbf{w}\|^2 + \frac{1}{N} \|\mathbf{X}\mathbf{w}-\mathbf{y}\|^2\right) .</script><p>Run the algorithm on the following data set as $\mathcal{D}$:<br><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw4_train.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw4_train.dat</a></p><p>and the following set for evaluating $E_{out}$:<br><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw4_test.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw4_test.dat</a></p><p>Because the data sets are for classification, please consider only the 0/1 error for all Questions below.</p><p>Let $\lambda = 10$, which of the followings is the corresponding $E_{in}$and $E_{out}$?</p><p>a. $E_{in} = 0.015,E_{out} = 0.020$</p><p>b. $E_{in} = 0.030,E_{out} = 0.015$</p><p>c. $E_{in} = 0.035,E_{out} = 0.020$</p><p>d. $E_{in} = 0.050,E_{out} = 0.045$</p><p>e. $E_{in} = 0.020,E_{out} = 0.010$</p><p>这道题目是线性回归的一个改进。相对于之前的代码也只要做些许的改进就可以了。利用之前的第12题的结论，我们依然可以一步得到结果。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sign</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> +<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(data,W=[])</span>:</span></span><br><span class="line">    nx = []</span><br><span class="line">    ny = []</span><br><span class="line">    ox = []</span><br><span class="line">    oy = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> data[i][<span class="number">-1</span>] == <span class="number">-1</span>:</span><br><span class="line">            nx.append(data[i][<span class="number">0</span>])</span><br><span class="line">            ny.append(data[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ox.append(data[i][<span class="number">0</span>])</span><br><span class="line">            oy.append(data[i][<span class="number">1</span>])</span><br><span class="line">    plt.scatter(nx,ny,marker=<span class="string">"x"</span>,c=<span class="string">"r"</span>)</span><br><span class="line">    plt.scatter(ox,oy,marker=<span class="string">"o"</span>,c=<span class="string">"g"</span>)</span><br><span class="line">    <span class="keyword">if</span> len(W)!=<span class="number">0</span> :</span><br><span class="line">        print(W)</span><br><span class="line">        x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">50</span>)</span><br><span class="line">        y = -W[<span class="number">1</span>] / W[<span class="number">2</span>] * x - W[<span class="number">0</span>] / W[<span class="number">2</span>]</span><br><span class="line">        plt.plot(x, y, color=<span class="string">"black"</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ridge_regression_one_step</span><span class="params">(data,_lambda)</span>:</span></span><br><span class="line">    X_matrix = []</span><br><span class="line">    Y_matrix = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        temp = [<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data[i])<span class="number">-1</span>):</span><br><span class="line">            temp.append(data[i][j])</span><br><span class="line"></span><br><span class="line">        X_matrix.append(temp)</span><br><span class="line">        Y_matrix.append([data[i][<span class="number">-1</span>]])</span><br><span class="line">    X = np.mat(X_matrix)</span><br><span class="line">    hatX = math.sqrt(_lambda)*np.eye(len(data[<span class="number">0</span>]))</span><br><span class="line">    <span class="comment">#print(hatX)</span></span><br><span class="line">    hatY = np.mat([ <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> data[<span class="number">0</span>]]).T</span><br><span class="line">    Y = np.mat(Y_matrix)</span><br><span class="line">    W = (X.T*X + hatX.T*hatX).I*(X.T*Y+hatX.T*hatY)</span><br><span class="line">    <span class="keyword">return</span> W.T.tolist()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Ein</span><span class="params">(data,W)</span>:</span></span><br><span class="line">    err_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        res = W[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,len(W)):</span><br><span class="line">            res += W[j]*data[i][j<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> sign(res) != data[i][<span class="number">-1</span>]:</span><br><span class="line">            err_num+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> err_num</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataFrom</span><span class="params">(path)</span>:</span></span><br><span class="line">    separator = re.compile(<span class="string">'\t|\b| |\n'</span>)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">with</span> open(path,<span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        s = f.readline()[:<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">while</span> s:</span><br><span class="line">            temp = separator.split(s)</span><br><span class="line">            result.append([float(x) <span class="keyword">for</span> x <span class="keyword">in</span> temp])</span><br><span class="line">            s = f.readline()[:<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line">    data = readDataFrom(<span class="string">"./train.dat"</span>)</span><br><span class="line">    <span class="comment">#print(data)</span></span><br><span class="line">    data_test =  readDataFrom(<span class="string">"./test.dat"</span>)</span><br><span class="line">    W = ridge_regression_one_step(data,<span class="number">10</span>)</span><br><span class="line">    print(<span class="string">"Ein"</span>,Ein(data,W)/len(data))</span><br><span class="line">    print(<span class="string">"Eout"</span>,Ein(data_test,W)/len(data_test))</span><br><span class="line">    visualize(data,W)</span><br></pre></td></tr></table></figure></p><p>可以得到最后的运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ein 0.05</span><br><span class="line">Eout 0.045</span><br></pre></td></tr></table></figure></p><p>因此答案选择d.</p><p><strong>14. Following the previous Question, among $\log_{10} \lambda= \left\{2, 1, 0, -1, \ldots, -8, -9, -10 \right\}$. What is the $\lambda$ with the minimum $E_{in}$? Compute $\lambda$ and its corresponding $E_{in}$ and $E_{out}$ then select the closest answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log_{10}^{\lambda} = -2,E_{in} = 0.030,E_{out} = 0.040$</p><p>b. $log_{10}^{\lambda} = -4,E_{in} = 0.015,E_{out} = 0.020$</p><p>c. $log_{10}^{\lambda} = -6,E_{in} = 0.030,E_{out} = 0.040$</p><p>d. $log_{10}^{\lambda} = -8,E_{in} = 0.015,E_{out} = 0.020$</p><p>e. $log_{10}^{\lambda} = -10,E_{in} = 0.030,E_{out} = 0.040$</p><p>这个题目只需要对上面题目的执行函数做一些改动即可：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    minEin = <span class="number">1</span></span><br><span class="line">    minEout = <span class="number">1</span></span><br><span class="line">    minEinI = <span class="number">-1</span></span><br><span class="line">    minEoutI = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">-10</span>,<span class="number">3</span>):</span><br><span class="line">        _lambda = math.pow(<span class="number">10</span>,i)</span><br><span class="line">        data = readDataFrom(<span class="string">"./train.dat"</span>)</span><br><span class="line">        <span class="comment"># print(data)</span></span><br><span class="line">        data_test = readDataFrom(<span class="string">"./test.dat"</span>)</span><br><span class="line">        W = ridge_regression_one_step(data, _lambda)</span><br><span class="line">        ein = Ein(data, W) / len(data)</span><br><span class="line">        eout = Ein(data_test, W) / len(data_test)</span><br><span class="line">        print(i,<span class="string">"Ein:"</span>, ein,<span class="string">"Eout:"</span>, eout)</span><br><span class="line">        <span class="keyword">if</span> ein&lt;=minEin:</span><br><span class="line">            minEin = ein</span><br><span class="line">            minEinI = i</span><br><span class="line">        <span class="keyword">if</span> eout &lt;= minEout:</span><br><span class="line">            minEout = eout</span><br><span class="line">            minEoutI = i</span><br><span class="line">    print(<span class="string">"minEin:"</span>,minEinI,<span class="string">"minEout:"</span>,minEoutI)</span><br></pre></td></tr></table></figure></p><p>得到结果：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">-10</span> Ein: <span class="number">0.015</span> Eout: <span class="number">0.02</span></span><br><span class="line"><span class="number">-9</span> Ein: <span class="number">0.015</span> Eout: <span class="number">0.02</span></span><br><span class="line"><span class="number">-8</span> Ein: <span class="number">0.015</span> Eout: <span class="number">0.02</span></span><br><span class="line"><span class="number">-7</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.015</span></span><br><span class="line"><span class="number">-6</span> Ein: <span class="number">0.035</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-5</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-4</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-3</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-2</span> Ein: <span class="number">0.03</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">-1</span> Ein: <span class="number">0.035</span> Eout: <span class="number">0.016</span></span><br><span class="line"><span class="number">0</span> Ein: <span class="number">0.035</span> Eout: <span class="number">0.02</span></span><br><span class="line"><span class="number">1</span> Ein: <span class="number">0.05</span> Eout: <span class="number">0.045</span></span><br><span class="line"><span class="number">2</span> Ein: <span class="number">0.24</span> Eout: <span class="number">0.261</span></span><br><span class="line">minEin: <span class="number">-8</span> minEout: <span class="number">-7</span></span><br></pre></td></tr></table></figure></p><p>可以看到Ein最小的是$\lambda = 10^{-8}$(相等取最大的),因此答案选d.</p><p><strong>15. Following the previous Question, among $\log_{10} \lambda= \left\{2, 1, 0, -1, \ldots, -8, -9, -10 \right\}$. What is the $\lambda$ with the minimum $E_{out}$? Compute $\lambda$ and its corresponding $E_{in}$ and $E_{out}$ then select the closest answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log_{10}^{\lambda} = -1,E_{in} = 0.015,E_{out} = 0.015$</p><p>b. $log_{10}^{\lambda} = -3,E_{in} = 0.015,E_{out} = 0.015$</p><p>c. $log_{10}^{\lambda} = -5,E_{in} = 0.015,E_{out} = 0.030$</p><p>d. $log_{10}^{\lambda} = -7,E_{in} = 0.030,E_{out} = 0.015$</p><p>e. $log_{10}^{\lambda} = -9,E_{in} = 0.030,E_{out} = 0.030$</p><p>答案在上个题目中已经得到了。答案选d.</p><p><strong>16. Now split the given training examples in $\mathcal{D}$ to the first 120 examples for $\mathcal{D}_{\text{train}}$ and 80 for $\mathcal{D}_{\text{val}}$. $\textit{Ideally, you should randomly do the 120/80 split. Because the given examples are already randomly permuted, however, we would use a fixed split for the purpose of this problem.}$</strong></p><p><strong>Run the algorithm on $\mathcal{D}_{\text{train}}$ to get $g^-_\lambda$, and validate $g^-_\lambda$ with $\mathcal{D}_{\text{val}}$. Among $\log_{10} \lambda= \left\{2, 1, 0, -1, \ldots, -8, -9, -10 \right\}$. What is the $\lambda$ with the minimum $E_{train}(g^-_\lambda)$? Compute $\lambda$ and the corresponding $E_{train}(g^-_\lambda)$, $E_{val}(g^-_\lambda)$ and $E_{out}(g^-_\lambda)$ then select the closet answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log _10^{\lambda} = 0,E_{train}(g_{\lambda}^-) = 0.000,E_{val}(g_{\lambda}^-) = 0.050,E_{out}(g_{\lambda}^-) = 0.025$</p><p>b. $log _10^{\lambda} = -2,E_{train}(g_{\lambda}^-) = 0.010,E_{val}(g_{\lambda}^-) = 0.050,E_{out}(g_{\lambda}^-) = 0.035$</p><p>c. $log _10^{\lambda} = -4,E_{train}(g_{\lambda}^-) = 0.000,E_{val}(g_{\lambda}^-) = 0.010,E_{out}(g_{\lambda}^-) = 0.025$</p><p>d. $log _10^{\lambda} = -6,E_{train}(g_{\lambda}^-) = 0.010,E_{val}(g_{\lambda}^-) = 0.010,E_{out}(g_{\lambda}^-) = 0.025$</p><p>e. $log _10^{\lambda} = -8,E_{train}(g_{\lambda}^-) = 0.000,E_{val}(g_{\lambda}^-) = 0.050,E_{out}(g_{\lambda}^-) = 0.025$</p><p>这道题目依然用之前的程序就可以完成，只需要修改主函数。这里使用到了验证集，需要添加的就是验证相关的代码。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    minEtrain = <span class="number">1</span></span><br><span class="line">    minEval = <span class="number">1</span></span><br><span class="line">    minEout = <span class="number">1</span></span><br><span class="line">    minEvalI = <span class="number">-1</span></span><br><span class="line">    minEtrainI = <span class="number">-1</span></span><br><span class="line">    minEoutI = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">-10</span>,<span class="number">3</span>):</span><br><span class="line">        _lambda = math.pow(<span class="number">10</span>,i)</span><br><span class="line">        data = readDataFrom(<span class="string">"./train.dat"</span>)</span><br><span class="line">        data_train = data[<span class="number">0</span>:<span class="number">120</span>]</span><br><span class="line">        data_val = data[<span class="number">120</span>:<span class="number">200</span>]</span><br><span class="line">        <span class="comment"># print(data)</span></span><br><span class="line">        data_test = readDataFrom(<span class="string">"./test.dat"</span>)</span><br><span class="line">        W = ridge_regression_one_step(data_train, _lambda)</span><br><span class="line">        etrain = Ein(data_train, W) / len(data_train)</span><br><span class="line">        eval = Ein(data_val,W)/len(data_val)</span><br><span class="line">        eout = Ein(data_test, W) / len(data_test)</span><br><span class="line">        print(i,<span class="string">"Etrain:"</span>, etrain,<span class="string">"Eval:"</span>,eval,<span class="string">"Eout:"</span>, eout)</span><br><span class="line">        <span class="keyword">if</span> etrain&lt;=minEtrain:</span><br><span class="line">            minEtrain = etrain</span><br><span class="line">            minEtrainI = i</span><br><span class="line">        <span class="keyword">if</span> eval &lt;= minEval:</span><br><span class="line">            minEval = eval</span><br><span class="line">            minEvalI = i</span><br><span class="line">        <span class="keyword">if</span> eout &lt;= minEout:</span><br><span class="line">            minEout = eout</span><br><span class="line">            minEoutI = i</span><br><span class="line">    print(<span class="string">"minEtrain:"</span>,minEtrainI,<span class="string">"minEval:"</span>,minEvalI,<span class="string">"minEout"</span>,minEoutI)</span><br></pre></td></tr></table></figure></p><p>最后输出如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">-10</span> Etrain: <span class="number">0.008333333333333333</span> Eval: <span class="number">0.125</span> Eout: <span class="number">0.04</span></span><br><span class="line"><span class="number">-9</span> Etrain: <span class="number">0.0</span> Eval: <span class="number">0.1</span> Eout: <span class="number">0.038</span></span><br><span class="line"><span class="number">-8</span> Etrain: <span class="number">0.0</span> Eval: <span class="number">0.05</span> Eout: <span class="number">0.025</span></span><br><span class="line"><span class="number">-7</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-6</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-5</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-4</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-3</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-2</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.021</span></span><br><span class="line"><span class="number">-1</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.022</span></span><br><span class="line"><span class="number">0</span> Etrain: <span class="number">0.03333333333333333</span> Eval: <span class="number">0.0375</span> Eout: <span class="number">0.028</span></span><br><span class="line"><span class="number">1</span> Etrain: <span class="number">0.075</span> Eval: <span class="number">0.125</span> Eout: <span class="number">0.08</span></span><br><span class="line"><span class="number">2</span> Etrain: <span class="number">0.3416666666666667</span> Eval: <span class="number">0.4125</span> Eout: <span class="number">0.414</span></span><br><span class="line">minEtrain: <span class="number">-8</span> minEval: <span class="number">0</span> minEout <span class="number">-2</span></span><br></pre></td></tr></table></figure></p><p>因此答案选择e.</p><p><strong>17. Following the previous Question, among $\log_{10} \lambda= \left\{2, 1, 0, -1, \ldots, -8, -9, -10 \right\}$.What is the $\lambda$ with the minimum $E_{val}(g^-_\lambda)$? Compute $\lambda$ and the corresponding $E_{train}(g^-_\lambda)$, $E_{val}(g^-_\lambda)$ and $E_{out}(g^-_\lambda)$ then select the closet answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log _10^{\lambda} = 0,E_{train}(g_{\lambda}^-) = 0.033,E_{val}(g_{\lambda}^-) = 0.038,E_{out}(g_{\lambda}^-) = 0.028$</p><p>b. $log _10^{\lambda} = -3,E_{train}(g_{\lambda}^-) = 0.000,E_{val}(g_{\lambda}^-) = 0.028,E_{out}(g_{\lambda}^-) = 0.038$</p><p>c. $log _10^{\lambda} = -6,E_{train}(g_{\lambda}^-) = 0.066,E_{val}(g_{\lambda}^-) = 0.038,E_{out}(g_{\lambda}^-) = 0.038$</p><p>d. $log _10^{\lambda} = -9,E_{train}(g_{\lambda}^-) = 0.033,E_{val}(g_{\lambda}^-) = 0.028,E_{out}(g_{\lambda}^-) = 0.028$</p><p>e. $log _10^{\lambda} = -10,E_{train}(g_{\lambda}^-) = 0.066,E_{val}(g_{\lambda}^-) = 0.028,E_{out}(g_{\lambda}^-) = 0.028$</p><p>答案在上面已经给出。答案选择a.</p><p><strong>18. Run the algorithm with the optimal $\lambda$ of the previous Question on the whole $\mathcal{D}$ to get $g_\lambda$. Compute $E_{in}(g_\lambda)$ and $E_{out}(g_\lambda)$ then select the closet answer.</strong></p><p>a. $E_{in}(g_{\lambda}) = 0.015,E_{out}(g_{\lambda}) = 0.020$</p><p>b. $E_{in}(g_{\lambda}) = 0.025,E_{out}(g_{\lambda}) = 0.030$</p><p>c. $E_{in}(g_{\lambda}) = 0.035,E_{out}(g_{\lambda}) = 0.020$</p><p>d. $E_{in}(g_{\lambda}) = 0.045,E_{out}(g_{\lambda}) = 0.030$</p><p>e. $E_{in}(g_{\lambda}) = 0.055,E_{out}(g_{\lambda}) = 0.020$ </p><p>根据17题选出来最佳的$\lambda = 0$，因此在全数据集上再次进行学习，得到的结果在14题的分析中已经呈现，答案是c.</p><p>可以看到的是利用验证，我们选出来了一个很贴近最佳$E_{out}$的答案了。</p><p>For Questions 19-20, split the given training examples in $\mathcal{D}$ to five folds, the first $40$ being fold 1, the next $40$ being fold 2, and so on. Again, we take a fixed split because the given examples are already randomly permuted.</p><p><strong>19.  What is the $λ$ with the minimum $E_{cv}$, where $E_{cv}$ comes from the five folds defined above? Compute $\lambda$ and the corresponding $E_{cv}$ then select the closet answer. Break the tie by selecting the largest $\lambda$.</strong></p><p>a. $log_{10}^{\lambda} = 0,E_{cv} = 0.030$</p><p>b. $log_{10}^{\lambda} = -2,E_{cv} = 0.020$</p><p>c. $log_{10}^{\lambda} = -4,E_{cv} = 0.030$</p><p>e. $log_{10}^{\lambda} = -6,E_{cv} = 0.020$</p><p>d. $log_{10}^{\lambda} = -8,E_{cv} = 0.030$</p><p>这个题目要做交叉验证。因此需要写一个新的交叉验证的函数cv。同时也要需要修改主函数。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#添加的函数cv</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cv</span><span class="params">(data,fold_count,_lambda)</span>:</span></span><br><span class="line">    <span class="comment"># disorder data</span></span><br><span class="line">    ecv = <span class="number">0</span></span><br><span class="line">    each_c = len(data)/fold_count</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(fold_count):</span><br><span class="line">        val = data[int(i*each_c):int((i+<span class="number">1</span>)*each_c)]</span><br><span class="line">        train = data[<span class="number">0</span>:int(i*each_c)]</span><br><span class="line">        train.extend(data[int((i+<span class="number">1</span>)*each_c):<span class="number">-1</span>])</span><br><span class="line">        W = ridge_regression_one_step(train,_lambda)</span><br><span class="line">        ecv +=Ein(val,W)/len(val)</span><br><span class="line">    <span class="keyword">return</span> ecv/fold_count</span><br></pre></td></tr></table></figure></p><p>最后得到结果如下：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">-10</span> Ecv: <span class="number">0.05</span></span><br><span class="line"><span class="number">-9</span> Ecv: <span class="number">0.05</span></span><br><span class="line"><span class="number">-8</span> Ecv: <span class="number">0.03</span></span><br><span class="line"><span class="number">-7</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-6</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-5</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-4</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-3</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-2</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">-1</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">0</span> Ecv: <span class="number">0.034999999999999996</span></span><br><span class="line"><span class="number">1</span> Ecv: <span class="number">0.06</span></span><br><span class="line"><span class="number">2</span> Ecv: <span class="number">0.28500000000000003</span></span><br><span class="line">minEcv: <span class="number">-8</span></span><br></pre></td></tr></table></figure></p><p>因此答案选择d.</p><p><strong>20. Run the algorithm with the optimal $\lambda$ of the previous problem on the whole $\mathcal{D}$ to get $g_\lambda$. Compute $E_{in}(g_\lambda)$ and $E_{out}(g_\lambda)$ then select the closet answer.</strong></p><p>a. $E_{in}(g_\lambda) = 0.005,E_{out}(g_\lambda) = 0.010$</p><p>b. $E_{in}(g_\lambda) = 0.015,E_{out}(g_\lambda) = 0.020$</p><p>c. $E_{in}(g_\lambda) = 0.025,E_{out}(g_\lambda) = 0.020$</p><p>d. $E_{in}(g_\lambda) = 0.035,E_{out}(g_\lambda) = 0.030$</p><p>e. $E_{in}(g_\lambda) = 0.045,E_{out}(g_\lambda) = 0.020$</p><p>上面得到的最好的$\lambda = 10^{-8}$，全部数据去学习的话，得到的$E_{in}$和$E_{out}$在14题目解析中也能看到,答案选b。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）总结</title>
      <link href="/2018/10/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E6%80%BB%E7%BB%93/"/>
      <url>/2018/10/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>到了现在机器学习基石的课程就结束了。最后有一些实际利用学习的原则和小tips，用来作为总结。<br><a id="more"></a></p><h2 id="Occam’s-Razor"><a href="#Occam’s-Razor" class="headerlink" title="Occam’s Razor"></a>Occam’s Razor</h2><p>Entities must not be multiplied beyond necessity.</p><p>使用的模型要尽量简单。我们知道越复杂的模型可以解释的样本更多，但是一个样本集如果被简单的模型所解释，那么从另一方面来说这个数据集更可能存在一定的规律性。因为即使是随机产生的样本，复杂的模型依然可以解释。而对于完全随机的样本是没有学习的必要的（可见No Free Lunch定理）。因此我们尽量使用简单的模型去解释样本，在泛化能力上等等相对于复杂模型来说都会更好。越简单越好。</p><h2 id="Sampling-Bias"><a href="#Sampling-Bias" class="headerlink" title="Sampling Bias"></a>Sampling Bias</h2><p>1948年美国总统大选，Truman versus Dewey.一家报社为了提前预测大选结果，利用电话进行民意调查，得到的结果是Dewey Defeat Truman，然而最后的结果是Truman赢得了大选。而民意调查既没有出错，也没有出现运气不好的情况，为何会这样？当年电话是比较昂贵的，因此接受民意调查的都是比较富有的阶级，在这些人中对Dewey的支持率更高，但是占了大多数人的中下阶级对Truman的支持更好，因此出现了这样的结果。</p><p>在我们所有的上述的这些理论推论中，我们都假设训练与测试集，都来自同一分布。而现实中，比如上面的例子，这样的情况并不是经常会碰到。保证我们获得的训练集与真实的数据来自同一分布是比较困难的。因此在实际操作中我们要注意尽可能让训练集与测试集来自同一分布。比如在预测电影时，可能每个人看的前7部电影是训练集，后三步用来测试，这就不是同一分布，因为观影顺序可能是很重要的,有一定的意向，而不是随机的。因此在学习时需要适当加重后面几部电影的权重，或者利用后面几部来做验证集。总之，Sampling Bias也是常见的影响学习效果的原因。</p><h2 id="Data-Snooping"><a href="#Data-Snooping" class="headerlink" title="Data Snooping"></a>Data Snooping</h2><p>数据“偷窥”。这是之前也一直提到的，如用自己的眼睛来决定学习算法。这时候可能会算上意外的VC dimension，但是我们却不知道。但是实际上，不光用眼睛，很多时候Data snooping很难以避免，一些小小的动作就会影响到这些东西。比如一直在前人的模型上改进发表论文，虽然你可能没有去看数据，但是确实利用了之前的模型，它就在一定程度上包含了数据的信息。偷窥数据的结果就是使得自己学习的模型过于乐观，可能会造成overfitting，这也是overfitting很难处理的一个原因。</p><p>有几个小的建议，就是在不看数据之前，想好需要用到的特征量；保证测试数据的封锁，使其不受到污染。对于避免Data Snooping的做法可能需要多年的经验，其中的机制因为组合太多很复杂，因此这个需要慢慢体会。</p><p>机器学习是人工智能，数据挖掘，统计理论的交集，它为今天人类生活带来了很多便利，如语音处理人脸识别等等。希望自己可以学好这门课程并且付诸实践。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> tips </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Validation</title>
      <link href="/2018/09/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Validation/"/>
      <url>/2018/09/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Validation/</url>
      
        <content type="html"><![CDATA[<p>上次regularization最后留下了一个问题：$\lambda$的选择。其实仔细想想，从学习机器学习到现在，我们面临的选择，可不止一个$\lambda$.<br><a id="more"></a></p><p>模型的选择（PLA，POKCET，Linear Regression，Logistic Regression），特征转换的方法（用什么样的多项式转换），Regularizer的选择等等，这些组合起来足够让人头大。而实际上，也没有一种永远都表现得很好的组合，对于不同的问题需要不同的方法，也就是做选择是必须的。</p><p>为了简化问题，我们就仅以不同的假说的选择为例。其他的选择也与这个类似。</p><p>假设我们目前有2个$H$，一个$H_2$,另一个$H_{10}$，应该选择哪一个？</p><p>一个简单的想法，是利用$E_{in}$去判断。但是这个想法太naive了。我们之前讲过过拟合了，如果用$E_{in}$去判断，那就不用想了，因为$H_{10}$一定比$H_2$要好，而且如果两个模型一个加了$regularization$，它的表现一定不如另一个.而且如果两个$H$没有交集，从两个$E_{in}$中选择一个好的，那么实际上是在两个$H$的并集中选择，这也就意味着增大了代价，更容易得到不好的$E_{out}$。</p><p>另一种简单的想法，用测试数据来判断。这是一个很好的办法。我们知道$E_{test}$与$E_{out}$是满足霍夫丁不等式的，因此可以得到：</p><script type="math/tex; mode=display">E_{out} \leq E_{test}+O(\sqrt {\frac{\log M}{N_{test}}})</script><p>所以用测试集来从模型中选择一个最好的是可行的。但是测试集从哪里来？</p><p>一般来说，测试集是锁在老板的柜子中。测试集相当于考试试卷，用来评判最终的分数.我们无法得到测试集，这就像考试前你想让自己做到最好，你没法用考试的卷子来测试自己，这叫作弊。</p><p>但是我们可以自己测验自己。这就是validation。</p><p>从给到的训练集当中，我们随机挑出一部分（保证iid），用来当作val集，其余部分用来训练模型。然后通过val集来选出表现最好的g’.为什么不是g？因为毕竟它的训练集相对于之前要少了很多，所以加个标识以区分。</p><p>一般来说，得到g’以后，也就是选出了我们想要的那个$H$，然后我们要做的就是将验证集再次融合回去，用这个整体的训练集在该假说上训练。毕竟某种程度上来说，N越大，得到的模型是越好的。而且</p><script type="math/tex; mode=display">E_{out}(g_{H_{chosen}}) < E_{out}(g'_{H_{chosen}})</script><p>上式是实际中的一个很常见的式子，但理论上要这么保证还需要一定的限制条件。</p><p>假设我们从N个训练样本中挑出K个来做验证集，当然这个K的大小是会影响结果的。如果K很大，那么很开心，$E_{val}$与$E_{out}$更有可能很接近，这对于选择g’来说是很好的，但是K过大意味着留下来的训练样本过少，g’与g差别很大，可能导致我们无法找到应该选择的那个$H$；另一方面，K很小，g与g’相差很小，但是$E_{val}$与$E_{out}$可能实际上差的很远，也不能得到好的结果。因此这又是一个难题。<br>一般来说有下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%7ELN%7EMS5IB6G61%40DWBDM51OE.png" alt=""><br>可以看到如果K过大，导致训练g’的训练集很小，使得它的学习效果很差，甚至不如不用验证的情况。</p><p>为了解决这个问题，引入一种新的工具：交叉验证。</p><p>首先我们考虑一种很极端的情况：K=1.每次留出一个来做验证，对于单个样本来说它当然无法代表$E_{out}$.但是如果我们对这个过程进行N次，所有的样本都曾做过验证集，最后求出来$E_{val}$的平均值，可以证明它就能代表g’的$E_{out}$.上面的办法，叫做leave-one-out cross validation.假设它得到的错误我们称为$E_{looc}$，则有下面的证明：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/VQVY7%5B%60%5BQA%40AT%7BQ_S24LDQ4.png" alt=""><br>(上面的证明我是看不大懂的)</p><p>这似乎是个很好的方法，但是它有个很致命的缺陷：计算量（N）倍的力气去计算g’。</p><p>因此，实际中我们很少用leave one out cross，而使用V-Fold Cross。将样本分为10（或者其他数）份，然后留一份作为val集，像上面一样交叉验证。这样需要的力气就是10倍，可以接受，而且能得到比非交叉验证更好的结果。</p><p>对于其他情况的选择，也可以用这样的办法，因为我们最终目的是得到尽量好的$E_{out}$。</p><p>最后，validation依然是为了做选择，因此它的结果依然是比较optimistic，算法最终的衡量还是要通过测试集，而不是将最好的validation结果作为衡量标准，这是自欺欺人的表现。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> validation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Regularization</title>
      <link href="/2018/09/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Regularization/"/>
      <url>/2018/09/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Regularization/</url>
      
        <content type="html"><![CDATA[<p>上篇博客说了overfitting的情况，有一些比较高级的处理overfitting的办法，其中有一个就是regularization，中文中叫做正则化。<br><a id="more"></a></p><p>从前面的nonlinear transform中也说明了，复杂的假说一般会包括了简单的假说。例如一个2次的假说，与10次的假说，他们的区别，就是10次的比二次的多了更多三次及以上的特征。也就是二次假说实际上是十次假说加上了一个限制：三次及以上的特征前面的权重（w）为0.这样就使得假说变得简单了不少.</p><p>如果放宽这个限制，假如较为简单的模型特征量有r个，在复杂模型中，最多有r个特征的权重不为0，在一定程度上，也可以很好的减少这个复杂度。只不过让人遗憾的是，在这样的假说中选出最佳的$\mathbf w$（权重向量）被证明了是一个NP-hard问题，没有一个很好的解决办法.</p><p>如果个数是整数，要挑出最好的，很容易有NP-hard问题，但是将这个拓宽到实数领域，我们往往可以通过数学工具得到最佳解。例如在这里，我们继续拓宽这个限制：让这些$w^2$和小于一个常数$C$，似乎也可以起到类似的效果。</p><p>为了简化问题，举个很简单的例子如：对于只有一个特征量的样本集，$H_2 = w_0+w_1x+w_2X^2$，而$H_{10} = w_0+w_1x+w_2x^2+…+w_{10}x^{10}$.</p><p>对于$H_2$来说，$H_{10}$中限制为$w_3 = w_4 = w_5 = …= w_{10} = 0$.</p><p>对于上面说的第二种假设，$H_{10}$限制为:$\sum _{n = 0} ^{10} [[w_n \ne 0]] \leq 3$.</p><p>对于第三种假设，$H_{10}$限制为:$\sum_{n = 0}^{10} w_n^2 \leq C$ 即$W^TW \leq C$.</p><p>那么，我们已经知道了最后一个才有可能求得最佳解。如何去做？</p><p>高维度的figure我们无法想象，我也不知道怎么去称呼，但是如果是二维，这个限制是一个圆，如果是三维，这个限制是一个球。假设我们依然称这个限制为一个球，而没有限制的最低点不在这个球内。因此梯度下降的结果就是达到了球的边缘，但是依然想要走下坡路。无路可走的情况，是梯度与该法向量的方向平行了，而只要梯度与该法向量的方向不不平行，我们总是可以朝着某个方向走使得$E_{in}$继续减少。因此这个过程终止的时候，就是该点的法向量与$E_{in}$的梯度平行了，而值得注意的是边缘某点的法向量实际上就是$W$.如果我们称做这个结果$W$为$W_{REG}$，那么有个结果：$W_{REG} = \lambda ▽E_{in}$.</p><p>其中这个$lambda$是一个常熟.我们知道，线性回归中梯度为$▽E_{in} = \frac 2 N (X^TX - Y^TXW)$，为了简化，我们将$\lambda$写为$ \frac {2\lambda} N$,最后得到：</p><script type="math/tex; mode=display">▽E_{in}+ \frac 2 N \lambda W_{REG} = 0.</script><p>如果$\lambda$提前知道，那么我们就可以求得$W_{REG}$的值.</p><p>如果对上式左边求积分可以得到： </p><script type="math/tex; mode=display">f(W) = E_{in} + \frac \lambda N W_{REG}</script><p>所以可以很神奇地发现，对于原来的问题的求解可以很有效地转变成了求$f(W)$的最小值，它就是正则化后的$E_{in}$，因此新的$cost-function$变成了下面的样子：</p><script type="math/tex; mode=display">min_{W \in R^{Q+1}} \frac 1 N \sum _{n = 0} ^N (\mathbf{w}^T \theta(X_n) - y_n)^2 + \frac {\lambda} N \sum {q=0} ^Q w_q^2</script><p>tips：对于多项式正则化，因为一般来说我们会将特征值的范围限定到$[-1,1]$(原因以后再探讨),这导致高次项的影响可能变得非常小，为了处理这种情况需要用到一个正交化处理，关键词“Legendre polynomial”。效果更好。需要了解更多的话可以去搜索.</p><p>$\lambda$由$C$确定（这是不严谨的说话。但是实际中给定\lambda就可与将$W$限定到一个范围，因此给出C的人也更容易给出一个$\lambda$），实际应用时，给$\lambda$一个很小的值就可与很好地处理过拟合的情形，如果过大，可能会出现欠拟合的情况.</p><p>接下来需要继续说明的是regularization，与vc理论之间的关系。实际上，即使加上了regularization，对于一个假说来说，在数学计算上它的vc dimention依然很大，依然会付出很大的代价。但是regularization的作用是什么？它将我们需要寻找的范围局限在了一定范围内，在这个范围内，可能都是比较好的$h$,因此有效的vc dimension减少了，也就更有可能得到比较好的$E_{out}$。</p><p>如何选择regularizer？</p><p>1.首先，如果我们知道目标函数的一些特点，就可以指引我们选择一些好的regularizer，比如：如果知道目标函数是偶函数，可以只对奇次项的特征进行正则化。</p><p>2.选择平滑的，如$\sum _{q=0} ^ Q |w_q|$.这个也叫L1 regularizer（L1正则化）.相对于L2来说它效果往往更好一点，因为更加平滑，但是不好解。</p><p>3.选择好优化的，如L2，也就是上文提到的。</p><p>除此之外，还有$\lambda$的选择。如图，不同的noise级别需要的$lambda$也不同：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/QWA_KMVHC_%7DZWJF3%607C%5DQYA.png" alt=""></p><p>如何选择一个合适的$\lambda$也非常重要，这就需要用到下一节所讲的Validation。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> overfitting </tag>
            
            <tag> regularization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Overfitting</title>
      <link href="/2018/09/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Overfitting/"/>
      <url>/2018/09/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Overfitting/</url>
      
        <content type="html"><![CDATA[<p>Overfitting（过拟合）是机器学习中可能最让人头疼的问题了。对应Overfitting的是Underfitting（欠拟合），相比之下戏份就少了很多。<a id="more"></a></p><p>简单来说，Underfitting，是$E_{in}$高，$E_{out}$也很高。于是人们会想方设法地减少$E_{in}$，认为这样就可以得到较好地结果。但是不幸的是，有时候$E_{in}$已经很低了，这个模型依然有很高的$E_{out}$.这就很让人头疼。这就是overfitting。想要更好的解决Overfitting，理解一些数学理论如VC dimension是很有帮助的，给我们提供了更多出现这种情况的原因和解决的思路。</p><p>其实Overfitting我们之前也早有提及过。</p><p>首先来看一下overfitting的简单的例子：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/RPA%5DK%7D%5DD%5BU%251EL%7B1EM%29I%24W4.png" alt=""></p><p>对于目标函数产生的资料，加上了一点noise，在训练集样本很少的情况下，出现了上面的情况：目标函数的$E_{in}$，比我们得到的这个与目标函数差了十万八千里的函数的$E_{in}$更大。我们的算法选择的是$E_{in}$最小的，因此就选择了表现很差的模型。</p><p>从上面的样例我们想到了nonlinear transform，当我们进行特征转换的时候，vc dimension大大增加，使得付出的代价变得很高，在样本不够的情况下，很容易得到很差的$E_{out}$，这就是一种overfitting.于是又一次看到了这张图。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/M%29P32DW%29EE9%7BWB%246A08T8%29X.png" alt=""></p><p>当然，造成上面的结果有一点原因是噪声，但是即使没有噪声，最多最多，他们的$E_{in}$也是一样的，而且实际中，没有噪声的情况是很少出现的。这说明了造成overfitting的两个原因：1.noise过多。很好理解，更好的适应了noise，它的泛化能力当然不行；2.使用过于复杂的模型，去估计较为简单的目标函数。一般来说，简单的函数只是复杂模型的特例，而且因为噪声的原因往往目标函数不能完美拟合，但是复杂的模型就能做的非常完美。但是另一方面，它的泛化能力也大大下降了。</p><p>如果我们采用复杂的模型估计复杂的函数呢？在我们心里可能会想，这下总会好点了吧。因为复杂的目标函数，你不用复杂的模型，根本就不可能完美地估计出来。似乎有点道理，我们来看下面地例子：</p><p>用10次的多项式产生一些数据，加上噪声。我们分布用10次的$H$与2次的$H$来对它进行拟合：</p><p>目标函数：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%29L%29Y%40YB1U%7DTN%5BLRL%7BJ%7E_N%7E9.png" alt=""></p><p>拟合结果：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/Z%7DIA11%7BHHKFR%7EOFL6VV%60YH3.png" alt=""></p><p>通过对比，我们惊奇地发现，二次的拟合结果，虽然$E_{in}$做得不如，但是$E_{out}$比10次的更好！</p><p>如果我们使用二次的多项式，那首先我们不可能做到完美，但是我们发现，有时候它的表现比更复杂地模型模拟的更好，尽管原来的模型非常地复杂。</p><p>想要了解这其中的原因，我们来观察一下两个$H$的learning curve：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/9RVH8F%297JG%40RGRIUHHFJ%7EV2.png" alt=""></p><p>对于右侧的我们是熟悉的，观察右侧的$H_{10}$的学习曲线，我们发现，虽然当N区域无穷的时候，它有更好的性能，但是在灰色区域里，它是Overfitting的。因此，overfitting的最关键的原因：数据量不够多。</p><p>因为模型越复杂，可以走的路就越多，在资料量小的时候，可能很多条路都会完美走过这条道，而其他的部分可能差的很远。这依然可以用VC dimension来解释，代价太大了，为了降低代价，必须需要更大的N.</p><p>当然，上面的例子中依然有noise的存在。Noise或多或少影响了复杂模型的性能，而且越复杂模型它的影响可能越大。对于没有noise的模型，是否还有上面的结果？</p><p>利用50次目标函数产生的数据，依然用$H_2$与$H_{10}$去模拟：</p><p>目标函数：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/UTID8V4V%28O3TP%5BTE%24J%5BT_%24U.png" alt=""></p><p>拟合结果：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/T%7EY9M6%24%605S_DUHD8CPA0B9X.png" alt=""></p><p>可以看到二次函数依然比10次函数表现得更好。原因和上面一样。所以没有很多数据量的支撑，使用较为简单的模型往往效果更好。</p><p>这时候我们会纳闷，这明明没有noise啊，为什么会这样？过于复杂的模型与简单的假设似乎带来了和noise类似的结果。</p><p>在机器学习领域中，对于过于复杂的模型本身带来的类似于noise的效果，被称为Deterministic Noise.</p><p>对于普通的noise，我们假设为高斯噪声（Gaussian Noise）。对于Gaussian Noise与Deterministic Noise对于模型的影响，$Q_f$为目标函数的次数，那么可以用下面的图来形象展示出来：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%28%25V%25Z8QJM%29V8%5D2NS%240%254IZK.png" alt=""></p><p>可以看出来，两种噪声带来的效果相近，可以通过增加N来避免过拟合的情况。</p><p>值得注意的是，右侧图中，左下角依然有一块会过拟合。需要注意，上述图中$H$的次数是不变的，因此，如果$Q_f$小于$H$的次数，会出现第一种情况，power过强的情况.</p><p>实际上，deterministic noise与电脑产生伪随机数的原理很相似，过于复杂的模型，造成了随机噪声的效果。</p><p>总结一下，Overfitting出现的原因：<br>1.N太小<br>2.Stochastic(Gaussian) Noise<br>3.Deterministic Noise<br>4.Too Much Power</p><p>如何对付overfitting是个很复杂的话题。首先直观来说，降噪，增加样本。降噪，可以通过修正label与去除错误的样本来实现，而增加样本往往没有那么容易，某些情况下我们可以自己创造data.另外还有两种比较复杂的做法，也有很好的效果：Regularization 与 Validation.以后会专门写博客来介绍。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> overfitting </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）作业3</title>
      <link href="/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A3/"/>
      <url>/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A3/</url>
      
        <content type="html"><![CDATA[<p>总共20道题目。<a id="more"></a><br><strong>1. Consider a noisy target $y = {\bf w}_f^T{\bf x} + \epsilon$, where $\mathbf{x} \in \mathbb{R}^d$ (with the added coordinate $x_0=1$), $y\in\mathbb{R}$, $\mathbf{w}_f$ is an unknown vector, and $\epsilon$ is a noise term with zero mean and $\sigma^2$ variance. Assume $\epsilon$ is independent of ${\bf x}$ and of all other $\epsilon$’s. If linear regression is carried out using a training data set $\mathcal{D} = \{(\mathbf{x}_1, y_1), \ldots, ({\bf x}_N, y_N)\}$, and outputs the parameter vector $\mathbf{w}_{\rm lin}$, it can be shown that the expected in-sample error $E_{\rm in}$ with respect to $\mathcal{D}$ is given by:</strong></p><script type="math/tex; mode=display">\mathbb{E}_{\mathcal{D}}[E_{\rm in}(\mathbf{w}_{\rm lin})] = \sigma^2\left(1 - \frac{d + 1}{N}\right)</script><p>For $\sigma = 0.1$ and $d = 8$, which among the following choices is the smallest number of examples $N$ that will result in an expected $E_{\rm in}$ greater than 0.008?</p><p>a. 10</p><p>b. 25</p><p>c. 100</p><p>d. 500</p><p>e. 1000</p><p>这道题目中，已经给出了$E_{in}$的期望值如何计算，只需要将$\sigma = 0.1,d = 8$带入上式即可，算出来的是$N = 45$的时候，$E_{in}$的期望值为0.008，而为了使得期望值变得更大，$N$的值也要变得更大，因此上面选项中最小的大于45的$N$是100，选c（Note:Greater意思是更大，而不是更好）.</p><p><strong>2. Recall that we have introduced the hat matrix $\mathrm{H} = \mathrm{X}(\mathrm{X}^T\mathrm{X})^{-1}\mathrm{X}^T$ in class, where $\mathrm{X} \in \mathbb{R}^{N\times (d+1)}$ containing $N$ examples with $d$ features. Assume $\mathrm{X}^T\mathrm{X}$ is invertible and $N &gt; d+1$, which statement of $\mathrm{H}$ is true?</strong></p><p>a. none of the other choices</p><p>b. $\mathrm{H}^{1126} = \mathrm{H}$</p><p>c. $(d+1)$ eigenvalues of $\mathrm{H}$ are bigger than 1.</p><p>d. $N - (d+1)$ eigenvalues of $\mathrm{H}$ are 1</p><p>e. $\mathrm{H}$ is always invertible</p><p>从<a href="https://wlsdzyzl.top/2018/08/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression/#more" target="_blank" rel="noopener">linear regression</a>中，我们直到$H$矩阵的作用是在$X$空间做$Y$的投影，来得到$Y’$，而投影一次与投影10次没什么太大区别，因此b是正确的。$H$的自由度是$N - (d+1)$，而它的特征值应该是有(N - d+1)个不为0，而且特征值也不是一定的，只是与特征向量成比例，因此c，d是不对的。</p><p><strong>3. Which of the following is an upper bound of $[[sign(w^Tx)≠y]]$ for $y \in \{-1, +1\}$?</strong></p><p>a. $err(W) = \frac 1 2 e ^{(-yW^TX)}$</p><p>b. $err(W) = [W^TX \geq y]$</p><p>c. $err(W) = max(0,1 - yW^TX)$</p><p>d. $err(W) = max(0, -yW^TX)$</p><p>e. none of the other choices</p><p>这个题目最直观的看法依然是画图，a-red,b-blue,c-yellow,d-green,$[sign(W^TX) \neq y]$-black,按照上面的颜色画图如下：<br>当y = 1 时：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/8%5B%24IX%25Y9N86%5DB%2856AA%243TEE.png" alt=""><br>当 y = -1时：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%7BAK_J8U02WEX%247%5BMUS3O1%24B.png" alt=""><br>从上面的图中我们可以很直观看到只有yellow线是符合的，因此这个题目答案为c.</p><p><strong>4. Which of the following is a differentiable function of $\mathbf{w}$ everywhere?</strong></p><p>a. $err(W) = \frac 1 2 e ^{(-yW^TX)}$</p><p>b. $err(W) = [W^TX \geq y]$</p><p>c. $err(W) = max(0,1 - yW^TX)$</p><p>d. $err(W) = max(0, -yW^TX)$</p><p>e. none of the other choices</p><p>differentiable function 意思是可微函数。所以很明显答案是a.</p><p><strong>5. When using SGD on the following error functions and `ignoring’ some singular points that are not differentiable, which of the following error function results in PLA?</strong></p><p>a. $err(W) = \frac 1 2 e ^{(-yW^TX)}$</p><p>b. $err(W) = [W^TX \geq y]$</p><p>c. $err(W) = max(0,1 - yW^TX)$</p><p>d. $err(W) = max(0, -yW^TX)$</p><p>e. none of the other choices</p><p>PLA更新策略：</p><script type="math/tex; mode=display">W_{n+1} = W_{n} + yX</script><p>使用SGD，也就是随机选择一个样本求$err(W)$的导数来更新。对于梯度下降中，对于下一步的做法是：</p><script type="math/tex; mode=display">W_{n+1} = W_{n} - \alpha \frac {d_{err{W}}}{d_W}</script><p>其中$\alpha$是学习率，这道题目中应该为1.</p><p>因此主要是要求得导数。实际上，我们从上面的题目中可以轻易的看出，对于 a,b一定是不正确的，而c，d的导数是一样的：$\frac {d_{err{W}}}{d_W}  =  -yX$，因此就更新的步骤来说，它们两个都是合适的。</p><p>但是我们不能都选上，要注意PLA算法做更新的时候是找到错误的点，如果点是正确的，我们则不应该更新。而c选项是PLA的Upper bound，从上面题目的图中也可以看到，如果$y = -1，W^TX \in [-1,1]$之间PLA是不会更新的，而c在这个时候依然会选择更新。所以这个题目的正确答案是d.</p><p>For Questions 6-10, consider a function $E(u,v) = e^u + e^{2v} + e^{uv} + u^2 - 2 u v + 2 v^2 - 3 u - 2 v$.</p><p><strong>6. What is the gradient $\nabla E(u, v)$ around $(u, v)=(0, 0)$?</strong></p><p>a. $(0,-2)$</p><p>b. none of the other choices</p><p>c. $(-3,1)$</p><p>d. $(3,-1)$</p><p>e. $(-2,0)$</p><p>这道题目不算难。 $\nabla E(u,v) = (e^u+ve^{uv}+2u - 2v - 3, 2e^{2v}+ue^{uv}-2u +4v - 2)$，代入$(0，0)$得到$(-2,0)$，答案为e.</p><p><strong>7. In class, we have taught that the update rule of the gradient descent algorithm is $(u_{t+1}, v_{t+1}) = (u_t, v_t) - \eta \nabla E(u_t, v_t)$. Please start from $(u_0, v_0) = (0, 0)$, and fix $\eta=0.01$. What is $E(u_{5}, v_{5})$ after five updates?</strong></p><p>a. 4.904</p><p>b. 3.277</p><p>c. 2.825</p><p>d. 2.361</p><p>e. 1.436</p><p>这个题目虽然迭代次数不多，但是因为有$\exp$函数计算，还是比较复杂的。因此我编写梯度下降的程序来计算这道题目。</p><p>函数gradient_decent要传入4个参数：start开始值，get_gradicent 一个计算梯度的函数，eta学习率，i_times为迭代次数。</p><p>其他的函数包括计算梯度，更新W（update），以及计算$err$，程序代码如下：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_gradient</span><span class="params">(para)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [math.exp(para[<span class="number">0</span>])+para[<span class="number">1</span>]*math.exp(para[<span class="number">0</span>]*para[<span class="number">1</span>])+<span class="number">2</span>*para[<span class="number">0</span>]<span class="number">-2</span>*para[<span class="number">1</span>]<span class="number">-3</span>,<span class="number">2</span>*math.exp(<span class="number">2</span>*para[<span class="number">1</span>])+para[<span class="number">0</span>]*math.exp(para[<span class="number">0</span>]*para[<span class="number">1</span>] )- <span class="number">2</span>*para[<span class="number">0</span>]+<span class="number">4</span>*para[<span class="number">1</span>]<span class="number">-2</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_decent</span><span class="params">(start,get_gradient,eta,i_times)</span>:</span></span><br><span class="line">    last = copy.deepcopy(start)</span><br><span class="line">    <span class="keyword">while</span>(i_times&gt;<span class="number">0</span>):</span><br><span class="line">        i_times-=<span class="number">1</span></span><br><span class="line">        update(last,get_gradient(last),eta)</span><br><span class="line">    <span class="keyword">return</span> last</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(last,gradient,eta)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span>  range(len(last)):</span><br><span class="line">        last[i] = last[i] - eta * gradient[i]</span><br><span class="line">    <span class="keyword">return</span> last</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Ein</span><span class="params">(para)</span>:</span></span><br><span class="line">    u = para[<span class="number">0</span>]</span><br><span class="line">    v = para[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> math.exp(u)+math.exp(<span class="number">2</span>*v)+ math.exp(u*v)+math.pow(u,<span class="number">2</span>)<span class="number">-2</span>*u*v+<span class="number">2</span>*math.pow(v,<span class="number">2</span>)<span class="number">-3</span>*u - <span class="number">2</span>*v</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    print(gradient_decent([<span class="number">0</span>,<span class="number">0</span>],get_gradient,<span class="number">0.01</span>,<span class="number">5</span>))</span><br><span class="line">    print(Ein(gradient_decent([<span class="number">0</span>,<span class="number">0</span>],get_gradient,<span class="number">0.01</span>,<span class="number">5</span>)))</span><br></pre></td></tr></table></figure></p><p>最后输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[0.09413996302028127, 0.0017891105951028273]</span><br><span class="line">2.8250003566832635</span><br></pre></td></tr></table></figure></p><p>因此答案选c.</p><p><strong>8. Continuing from Question 7. If we approximate the $E(u + \Delta u, v + \Delta v)$ by $\hat{E}_2(\Delta u, \Delta v)$, where $\hat{E}_2$ is the second-order Taylor’s expansion of $E$ around $(u,v)$. Suppose $\hat{E}_2(\Delta u, \Delta v) = b_{uu} (\Delta u)^2 + b_{vv} (\Delta v)^2 + b_{uv} (\Delta u)(\Delta v) + b_u \Delta u + b_v \Delta v + b $, What are the values of $(b_{uu}, b_{vv}, b_{uv}, b_u, b_v, b)$ around $(u, v) = (0, 0)$?</strong></p><p>a. none of the other choices</p><p>b. $(3,8,-1,-2,0,3)$</p><p>c. $(3,8,-0.5,-1,-2,0)$</p><p>d. $(1.5,4,-0.5,-1,-2,0)$</p><p>e. $(1.5,4,-1,-2,0,3)$</p><p>这个题目不算难，实际上是一个多维函数的二阶泰勒展开，而$b{_uu}$则是对$u$求二阶偏导再除以$2!$。只要一项项计算上面的值就可以了。<br>$b_{uu} = 3,b_{vv} = 8,b_{uv} = -1,b_{u} = -2,b_{v} = 0,b = 3$，二元泰勒展开因此答案是e.   </p><p><strong>9. Continue from Question 8 and denote the Hessian matrix to be $\nabla^2 E(u, v)$, and assume that the Hessian matrix is positive definite. What is the optimal $(\Delta u, \Delta v)$ to minimize $\hat{E}_2(\Delta u, \Delta v)$? (The direction is called the Newton Direction.)</strong></p><p>a. $+(\nabla^2E(u,v))^{-1}\nabla E(u,v)$</p><p>b. $-(\nabla^2E(u,v))^{-1}\nabla E(u,v)$</p><p>c. none of the other choices</p><p>d. $+\nabla ^2 E(u,v) \nabla E(u,v)$</p><p>e. $-\nabla ^2 E(u,v) \nabla E(u,v)$</p><p>其实这个题目我不是很清楚。这其中涉及到了海森矩阵以及牛顿方向。通过简单的了解，如果一个点的梯度为0向量，而且在该点的海森矩阵为正定矩阵，那么该点为极小值点。题目中说明了海森矩阵为正定矩阵，因此找这个极值点，如果不知道牛顿方向，我就会按照梯度下降的来。而查阅了牛顿方向之后，牛顿方向就是e选项。所以选择b.</p><p>当然，这个题目实际上就是搜出来的答案，真正想要理解需要更加深入地去看线性代数。</p><p><strong>10. Use the Newton direction (without \eta) for updating and start from $(u_0, v_0) = (0, 0)$. What is $E(u_{5}, v_{5})$ after five updates?</strong></p><p>a. 4.904</p><p>b. 3.277</p><p>c. 2.825</p><p>d. 2.361</p><p>e. 1.436</p><p>这道题目，当然我还是想借助程序来完成，不过这次的程序相比之前会更麻烦一点。因为之前设置好了接口，也就是在梯度下降的时候传入求得梯度的函数，因此这里我们只需要写出计算 $\nabla ^2 E(u,v) \nabla E(u,v)$的函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Newton_direction</span><span class="params">(para)</span>:</span></span><br><span class="line">    u = para[<span class="number">0</span>]</span><br><span class="line">    v = para[<span class="number">1</span>]</span><br><span class="line">    hs = [[math.exp(u)+math.pow(v,<span class="number">2</span>)*math.exp(u*v)+<span class="number">2</span>,math.exp(u*v)+v*u*math.exp(u*v)<span class="number">-2</span>],</span><br><span class="line">          [math.exp(u*v)+v*u*math.exp(u*v)<span class="number">-2</span>,<span class="number">4</span>*math.exp(<span class="number">2</span>*v)+math.pow(u,<span class="number">2</span>)*math.exp(u*v)+<span class="number">4</span>]]</span><br><span class="line">    m = mat(hs)</span><br><span class="line">    <span class="keyword">return</span> (m.I*mat([get_gradient([u,v])]).T).T.tolist()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p><p>最后在主函数中修改传入的学习率与求梯度的函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Ein(gradient_decent([<span class="number">0</span>,<span class="number">0</span>],Newton_direction,<span class="number">1</span>,<span class="number">5</span>)))</span><br></pre></td></tr></table></figure></p><p>得到结果：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">因此答案选d.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**11. Consider six inputs $\mathbf&#123;x&#125;_1 = (1, 1)$, $\mathbf&#123;x&#125;_2 = (1, -1)$, $\mathbf&#123;x&#125;_3 = (-1, -1)$, $\mathbf&#123;x&#125;_4 = (-1, 1)$, $\mathbf&#123;x&#125;_5 = (0, 0)$, $\mathbf&#123;x&#125;_6 = (1, 0)$. What is the biggest subset of those input vectors that can be shattered by the union of quadratic, linear, or constant hypotheses of $\mathbf&#123;x&#125;$?**</span><br><span class="line"></span><br><span class="line">a. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_2,\mathbf&#123;x&#125;_3$</span><br><span class="line"></span><br><span class="line">b. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_2,\mathbf&#123;x&#125;_3,\mathbf&#123;x&#125;_4,\mathbf&#123;x&#125;_5,\mathbf&#123;x&#125;_6$</span><br><span class="line"></span><br><span class="line">c. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_2,\mathbf&#123;x&#125;_3,\mathbf&#123;x&#125;_4$</span><br><span class="line"></span><br><span class="line">d. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_3$</span><br><span class="line"></span><br><span class="line">e. $\mathbf&#123;x&#125;_1,\mathbf&#123;x&#125;_2,\mathbf&#123;x&#125;_3,\mathbf&#123;x&#125;_4,\mathbf&#123;x&#125;_5$</span><br><span class="line"></span><br><span class="line">首先，我们可以看到特征量的个数是2（$d=2$），而由前面的推导可以知道，最高次为2次时候，它可以组成的新的特征值的个数为5，而它的vc dimension是小于等于6的.一种可行的办法是将x空间投影到z空间以后，用线性的办法来shatter这6个点，再返回看原来的x组合而成的特征是否能够满足这6个特征量。但是实际上这还是复杂的。也可以利用梯度下降，跑程序来对上述选项来进行排除。具体答案是多少还需要进一步进行排除。这个答案是b.可以shatter6个点.</span><br><span class="line"></span><br><span class="line">**12. Assume that a transformer peeks the data and decides the following transform $\boldsymbol&#123;\Phi&#125;$ &quot;intelligently&quot; from the data of size $N$. The transform maps $\mathbf&#123;x&#125; \in \mathbb&#123;R&#125;^d$ to $\mathbf&#123;z&#125; \in \mathbb&#123;R&#125;^N$, where**</span><br><span class="line">$$</span><br><span class="line">(\boldsymbol&#123;\Phi&#125;(\mathbf&#123;x&#125;))_n = z_n = \left[\left[ \mathbf&#123;x&#125; = \mathbf&#123;x&#125;_n \right]\right]</span><br><span class="line">$$</span><br><span class="line">Consider a learning algorithm that performs PLA after the feature transform.Assume that all $\mathbf&#123;x&#125;_n$ are different, $30%$ of the $y_n$&apos;s are positive, and $sign(0)=+1$. Then, estimate the $E_&#123;out&#125;$ of the algorithm with a test set with all its input vectors $\mathbf&#123;x&#125;$ different from those training $\mathbf&#123;x&#125;_n$&apos;s and $30%$ of its output labels $y$ to be positive. Which of the following is not true?</span><br><span class="line"></span><br><span class="line">a. PLA will halt after enough iterations.</span><br><span class="line"></span><br><span class="line">b. $E_&#123;out&#125; = 0.7$</span><br><span class="line"></span><br><span class="line">c. $E_&#123;in&#125; = 0.7$</span><br><span class="line"></span><br><span class="line">d. All $\mathbf&#123;Z&#125;_n$&apos;s are orthogonal to each other.</span><br><span class="line"></span><br><span class="line">e. The transformed data set is always linearly separable in the $\mathcal&#123;Z&#125;$ space.</span><br><span class="line"></span><br><span class="line">要明白这个题目首先要读懂题意。</span><br><span class="line">题目中对原来的向量进行了特征转换，原来向量为d维，新的向量为N维，每一个样本对应的新的Z向量是 $[ [[x_i = x_1]], [[x_i = x_2]],...,[[x_i = x_n]]]^T$,题目中已经告知，$X_n$是各不相同的，因此我们可以直到$Z$向量会类似于：$[1,0,...,0]^T,[0,1,...,0]^T,...,[0,0,...,1]$.在这样的样本上进行PLA算法。我们可以知道这种情况是最好的情况，是可以被shatter的，PLA一定会停止，而且他们是互相正交的。因此答案就在b，c中选择。而既然PLA会停止说明找到了最小的$E_&#123;in&#125;$，此时$E_&#123;in&#125;$为0.因此答案选c.</span><br><span class="line"></span><br><span class="line">至于c为何是正确的，首先，因为测试集的样本与原来的训练集样本也没有一致的，因此他们得到的转换后的z向量为n维0向量.而题目中说明了$sign(0)=+1$，因此它会将所有的测试样本都判别为positive，而实际上只有30%为positive，因此测试得到的$E_&#123;out&#125;$为70%.</span><br><span class="line"></span><br><span class="line">For Questions 13-15, consider the target function:</span><br><span class="line">$$</span><br><span class="line">f(x_1, x_2) = \mbox&#123;sign&#125;(x_1^2 + x_2^2 - 0.6)</span><br><span class="line">$$</span><br><span class="line"></span><br><span class="line">**13. Generate a training set of N = 1000N=1000 points on $X=[−1,1]$ with uniform probability of picking each $\mathbf&#123;x&#125; \in \mathcal&#123;X&#125;$. Generate simulated noise by flipping the sign of the output in a random $10\%$ subset of the generated training set.**</span><br><span class="line"></span><br><span class="line">Carry out Linear Regression without transformation, i.e., with feature vector:</span><br><span class="line">$$</span><br><span class="line">(1,x_1,x_2)</span><br><span class="line">$$</span><br><span class="line"></span><br><span class="line">to find the weight $\mathbf&#123;w&#125;_&#123;\rm lin&#125;$, and use $\mathbf&#123;w&#125;_&#123;\rm lin&#125;$ directly for classification. What is the closest value to the classification $(0/1)$ in-sample error ($E_&#123;\rm in&#125;$)? Run the experiment $1000$ times and take the average $E_&#123;\rm in&#125;$ in order to reduce variation in your results.</span><br><span class="line"></span><br><span class="line">a. 0.1</span><br><span class="line"></span><br><span class="line">b. 0.3</span><br><span class="line"></span><br><span class="line">c. 0.5</span><br><span class="line"></span><br><span class="line">d. 0.7</span><br><span class="line"></span><br><span class="line">e. 0.9</span><br><span class="line"></span><br><span class="line">这次作业与之前不一样了，很早就遇到编程题目了，而且前面有几道题目虽然不是编程题目，我也依然是用程序计算出来的。</span><br><span class="line"></span><br><span class="line">这个题目想要用程序解答其实也不是非常难。在这里我使用的是一步求法，而不是梯度下降那样迭代。首先是要生成数据：</span><br><span class="line">```py</span><br><span class="line">def make_data():</span><br><span class="line">    result = []</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        x1 = random.random()*2-1</span><br><span class="line">        x2 = random.random()*2-1</span><br><span class="line">        result.append([x1,x2,sign(pow(x1,2)+pow(x2,2)-0.6)])</span><br><span class="line">    return result</span><br></pre></td></tr></table></figure></p><p>为了检查做的数据是否正确，对生成的数据进行了可视化（因为输出长宽比例不同，所以这个圆看上去不是正圆）：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(data,W=[])</span>:</span></span><br><span class="line">    nx = []</span><br><span class="line">    ny = []</span><br><span class="line">    ox = []</span><br><span class="line">    oy = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> data[i][<span class="number">-1</span>] == <span class="number">-1</span>:</span><br><span class="line">            nx.append(data[i][<span class="number">1</span>])</span><br><span class="line">            ny.append(data[i][<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ox.append(data[i][<span class="number">1</span>])</span><br><span class="line">            oy.append(data[i][<span class="number">2</span>])</span><br><span class="line">    plt.scatter(nx,ny,marker=<span class="string">"x"</span>,c=<span class="string">"r"</span>)</span><br><span class="line">    plt.scatter(ox,oy,marker=<span class="string">"o"</span>,c=<span class="string">"g"</span>)</span><br><span class="line">    theta = np.linspace(<span class="number">0</span>, <span class="number">2</span> * np.pi, <span class="number">800</span>)</span><br><span class="line">    x, y = np.cos(theta) * <span class="number">0.77459666924148</span>, np.sin(theta) * <span class="number">0.77459666924148</span><span class="comment"># sqrt 0.6</span></span><br><span class="line">    plt.plot(x, y, color=<span class="string">'blue'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(W)!=<span class="number">0</span>:</span><br><span class="line">        print(W)</span><br><span class="line">        x = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">50</span>)</span><br><span class="line">        y = -W[<span class="number">1</span>] / W[<span class="number">2</span>] * x - W[<span class="number">0</span>] / W[<span class="number">2</span>]</span><br><span class="line">        plt.plot(x, y, color=<span class="string">"black"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/RE%40%60F%29JRPQT_KE%7EFIVEC17K.png" alt="生成数据"></p><p>然后通过线性回归得到$W = (X^TX)^{-1}X^TY$:<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_regression_one_step</span><span class="params">(data)</span>:</span></span><br><span class="line">    X_matrix = []</span><br><span class="line">    Y_matrix = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        temp = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data[i])<span class="number">-1</span>):</span><br><span class="line">            temp.append(data[i][j])</span><br><span class="line">        X_matrix.append(temp)</span><br><span class="line">        Y_matrix.append([data[i][<span class="number">-1</span>]])</span><br><span class="line">    X = np.mat(X_matrix)</span><br><span class="line">    Y = np.mat(Y_matrix)</span><br><span class="line"></span><br><span class="line">    W = (X.T*X).I*X.T*Y</span><br><span class="line">    <span class="keyword">return</span> W.T.tolist()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p><p>最后通过分类计算$E_{in}$：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Ein</span><span class="params">(data,W)</span>:</span></span><br><span class="line">    err_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(W)):</span><br><span class="line">            res += W[j]*data[i][j]</span><br><span class="line">        <span class="keyword">if</span> sign(res) != data[i][<span class="number">-1</span>]:</span><br><span class="line">            err_num+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> err_num</span><br></pre></td></tr></table></figure></p><p>运行1000次取输出为：<code>0.50614</code></p><p>因此答案选c.其实我们也可以想象得到这个错误率是接近0.5的，可视化的结果如下：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/_%7BA%60P%28N%255%7B4U8%25%25NQ%24H%408O9.png" alt=""></p><p>不管怎么画这条线，总会有接近一半的区域被分错.</p><p><strong>14. Now, transform the training data into the following nonlinear feature vector:$(1,x_1,x_2,x_1x_2,x_1^2,x_2^2)$.Find the vector $\tilde{\mathbf{w}}$ that corresponds to the solution of Linear Regression, and take it for classification. Which of the following hypotheses is closest to the one you find using Linear Regression on the transformed input? Closest here means agrees the most with your hypothesis (has the most probability of agreeing on a randomly selected point).</strong></p><p>a. $g(x_1,x_2) = sign(-1-1.5x_1+0.08x_2+0.13x_1x_2+0.05x_1^2+1.5x_2^2)$</p><p>b. $g(x_1,x_2) = sign(-1-1.5x_1+0.08x_2+0.13x_1x_2+0.05x_1^2+0.05x_2^2)$</p><p>c. $g(x_1,x_2) = sign(-1-0.05x_1+0.08x_2+0.13x_1x_2+1.5x_1^2+15x_2^2)$</p><p>d. $g(x_1,x_2) = sign(-1-0.05x_1+0.08x_2+0.13x_1x_2+1.5x_1^2+1.5x_2^2)$</p><p>e. $g(x_1,x_2) = sign(-1-0.05x_1+0.08x_2+0.13x_1x_2+15x_1^2+1.5x_2^2)$</p><p>经过特征转换后进行线性回归，找到最相似的W向量。实际上，每次输出的向量不容易看出来他们的相似性，最好的办法就是从z空间转回去看实际的分类效果。<br>为了完成这道题目，需要添加一些新的函数。首先是一个特征转换的函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform_data</span><span class="params">(data)</span>:</span></span><br><span class="line">    t_data = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        temp = [<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        temp.append(data[i][<span class="number">1</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">2</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">1</span>]*data[i][<span class="number">2</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">1</span>]*data[i][<span class="number">1</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">2</span>]*data[i][<span class="number">2</span>])</span><br><span class="line">        temp.append(data[i][<span class="number">-1</span>])</span><br><span class="line">        t_data.append(temp)</span><br><span class="line">    <span class="keyword">return</span> t_data</span><br></pre></td></tr></table></figure></p><p>另外，我重新写了一个可视化的函数，来画出学习后分类的结果，并且与原始的界限做对比。实际上，如果不通过可视化，单单从W向量我们不是很容易能看出来他们之间的相似度，如：</p><script type="math/tex; mode=display">W = [-1.233493970901365, 0.0289716107001069, -0.04249028735529122, -0.06563216707578017, 1.8906604891218894, 2.014485177474217]</script><p>得到的分类效果如下：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%24NF51V%5BFC0ELUWH8QXJ%7D%5BDE.png" alt=""></p><p>而其他几个选项按照a,b,c,d,e的顺序分别得到下面的分类效果：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/XZSCVFU97%28EH4V5%29X%5DDT%7E70.png" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/V%28%7D%7BZ%5BQ2L%402145%5D%7D%5D9FW%7E_B.png" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/R67TAG1%7BEXKD2%406Y_WS%28SZA.png" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%5BI13AGR586%24DR9%5BG3%5D038%40F.png" alt=""><br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/2HM1%5D84NO9J%29%7BUA%7DNI%7E2%5D90.png" alt=""></p><p>可以很明显的看出来，答案选择d.</p><p><strong>15. Following Question 14, what is the closest value to the classification out-of-sample error $E_{\rm out}$ of your hypothesis? Estimate it by generating a new set of 1000 points and adding noise as before. Average over 1000 runs to reduce the variation in your results.</strong></p><p>a. 0.1</p><p>b. 0.3</p><p>c. 0.5</p><p>d. 0.7</p><p>e. 0.9</p><p>这道题目需要来测量$E_{out}$，并且要加上噪声。其实还是很简单的，只需要做简单的改动，来计算$E_{out}$.</p><p>既然是$E_{out}$，那就需要每次都重新生成数据，这就是和$E_{in}$的区别，再加个转换，除此之外是一样的，因此可以复用$E_{in}$函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Eout</span><span class="params">(W)</span>:</span></span><br><span class="line">    data = make_data()</span><br><span class="line">    t_data = transform_data(data)</span><br><span class="line">    <span class="keyword">return</span> Ein(t_data,W)</span><br></pre></td></tr></table></figure></p><p>然后运行1000次就可以了，最后得到的错误率：<code>0.126856</code>,答案选a.</p><p>For Questions 16-17, you will derive an algorithm for the multinomial (multiclass) logistic regression model.<br><strong>16. For a $K$-class classification problem, we will denote the output space $\mathcal{Y} = \{1, 2, \ldots, K\}$. The hypotheses considered by the model are indexed by a list of weight vectors $(\mathbf{w}_1, \mathbf{w}_2, \ldots, \mathbf{w}_K)$, each weight vector of length $d+1$. Each list represents a hypothesis</strong></p><script type="math/tex; mode=display">h_y( X) = \frac {e^{W_y^TX}} {\sum _{k=1} ^{K} e^{W_k^TX}}</script><p>that can be used to approximate the target distribution $P(y|\mathbf{x})$P. The model then seeks for the maximum likelihood solution over all such hypotheses.(Note:$X$ = $\mathbf{x}$)</p><p>For general $K$, derive an $E_{\text{in}}(\mathbf{w}_1, \cdots, \mathbf{w}_K)$ like page 11 of Lecture 10 slides by minimizing the negative log likelihood. What is the resulting $E_{\text{in}}$?</p><p>a. \frac 1 N \sum _{n = 1}^N \left ( \sum _{k=1} ^K (W_k^TX_n - W_{y_n}^TX_n)\right)</p><p>b. \frac 1 N \sum _{n = 1}^N \left  (\sum _{k=1} ^K W_k^TX_n - W_{y_n}^TX_n\right)</p><p>c. \frac 1 N \sum _{n = 1}^N \left ( \ln (\sum _{k=1} ^K e^{W_k^TX_n}) - W_{y_n}^TX_n\right)</p><p>d. none of the other choices</p><p>e. \frac 1 N \sum _{n = 1}^N \left ( \ln (\sum _{k=1} ^K e^{W_k^TX_n} - e^{W_{y_n}^TX_n})\right)</p><p>这是一个很有意思的概率的定义，它保证了分到各个分类的概率和加起来为1，而之前的假设是不能保证这个问题的。</p><p>对于$E_{in}$的处理，也是一致的。按照之前的想法来一步一步做。首先，计算出在该$W$的情况下，出现当前分类的概率，可以知道的是互相连乘，最后为了让他变成加法，以及最小化（而非最大化），需要加一个负号，忽略P(X=X_i)。</p><p>可以得到下面的过程：</p><script type="math/tex; mode=display">\prod_{i=n}^{N} \frac {e^{W_{y_n}^TX_{n}}} {\sum _{k=1} ^{K} e^{W_k^TX_n}}</script><script type="math/tex; mode=display">=> -\sum_{n = 1}^N( \ln (e^{W_{y_n}^TX_n}) - \ln (\sum _{k = 1}^K e^{W_{k}^TX_n}))</script><script type="math/tex; mode=display">  =>\sum _{n = 1}^N \left ( \ln (\sum _{k=1} ^K e^{W_k^TX_n} - W_{y_n}^TX_n)\right)</script><p>最后除以N，得到选项c.</p><p><strong>17. For the $E_{\text{in}}$ derived above, its gradient $\nabla E_{\text{in}}$ can be represented by $\left(\frac{\partial E_{\text{in}}}{\partial\mathbf{w}_1}, \frac{\partial E_{\text{in}}}{\partial\mathbf{w}_2}, \cdots, \frac{\partial E_{\text{in}}}{\partial\mathbf{w}_K}\right)$, write down $\frac{\partial E_{\text{in}}}{\partial\mathbf{w}_i}$ .</strong></p><p>a. \frac 1 N \sum _{n=1}^N \left(\sum _{i = 1} ^K(e^{W_i^TX_n} - [[y_n=i]])X_n\right)</p><p>b. \frac 1 N \sum_{n=1}^N ((h_i(x_n)-1)x_n)</p><p>c. none of the other choices</p><p>d. \frac 1 N \sum _{n=1}^N \left((h_i(x_n) - [[y_n=i]])X_n\right)</p><p>e. \frac 1 N \sum _{n=1}^N \left( \sum _(i = 1)^K(e^{W_i^TX_n}-1)X_n\right)</p><p>这个题目就是对上面的题目的选择结果进行求导即可。虽然比较复杂，但是不算难。一步步算下来就成，正确答案是d.</p><p>For Questions 18-20, you will play with logistic regression. Please use the following set for training:</p><p><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw3_train.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw3_train.dat</a></p><p>and the following set for testing:</p><p><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw3_test.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_algo/hw3_test.dat</a></p><p><strong>18. Implement the fixed learning rate gradient descent algorithm for logistic regression. Run the algorithm with $\eta = 0.001$ and $T = 2000$. What is $E_{out}(g)$ from your algorithm, evaluated using the $0/1$ error on the test set?</strong></p><p>a. 0.475</p><p>b. 0.412</p><p>c. 0.322</p><p>d. 0.220</p><p>e. 0.103</p><p><strong>19. Implement the fixed learning rate gradient descent algorithm for logistic regression. Run the algorithm with $\eta = 0.01$ and $T = 2000$. What is $E_{out}(g)$ from your algorithm, evaluated using the $0/1$ error on the test set?</strong></p><p>a. 0.475</p><p>b. 0.412</p><p>c. 0.322</p><p>d. 0.220</p><p>e. 0.103</p><p><strong>20. Implement the fixed learning rate stochastic gradient descent algorithm for logistic regression. Instead of randomly choosing nn in each iteration, please simply pick the example with the cyclic order $n = 1, 2, \ldots, N, 1, 2, \ldots$,Run the algorithm with $\eta = 0.001$ and $T = 2000$. What is $E_{out}(g)$ from your algorithm, evaluated using the $0/1$ error on the test set?</strong></p><p>a. 0.475</p><p>b. 0.412</p><p>c. 0.322</p><p>d. 0.220</p><p>e. 0.103</p><p>这3道题目，可以用一套方法做出来，可以引用第7题的程序中的梯度下降算法与13题程序中的对于$E_{in}$的估计。当然，对于之前代码的还需要进行一丝修改。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gradient_decent_7 <span class="keyword">as</span> gd</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> _linear_regression_13 <span class="keyword">as</span> lr</span><br><span class="line">now = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+math.exp(-x))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_logistic_gradient</span><span class="params">(lastW,data)</span>:</span></span><br><span class="line">    W = np.mat([lastW]).T</span><br><span class="line">    X = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        temp = data[i][<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">        temp.append(<span class="number">1</span>)</span><br><span class="line">        X.append(np.mat([temp]).T)</span><br><span class="line">    gra = logistic(-data[<span class="number">0</span>][<span class="number">-1</span>]*(W.T*X[<span class="number">0</span>])[<span class="number">0</span>][<span class="number">0</span>])*(-data[<span class="number">0</span>][<span class="number">-1</span>]*X[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(data)):</span><br><span class="line">        gra = gra + logistic(-data[i][<span class="number">-1</span>]*(W.T*X[i])[<span class="number">0</span>][<span class="number">0</span>])*(-data[i][<span class="number">-1</span>]*X[i])</span><br><span class="line">    <span class="comment">#print(gra)</span></span><br><span class="line">    <span class="keyword">return</span> ((<span class="number">1</span>/len(data))*gra).T.tolist()[<span class="number">0</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stochastic_gradient_init</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span>  now</span><br><span class="line">    now = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stochastic_gradient</span><span class="params">(lastW,data)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> now</span><br><span class="line">    <span class="keyword">if</span> now == len(data):</span><br><span class="line">        now = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    W = np.mat([lastW]).T</span><br><span class="line">    temp = data[now][<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">    temp.append(<span class="number">1</span>)</span><br><span class="line">    X = np.mat([temp]).T</span><br><span class="line">    gra = logistic(-data[now][<span class="number">-1</span>]*(W.T*X)[<span class="number">0</span>][<span class="number">0</span>])*(-data[now][<span class="number">-1</span>]*X)</span><br><span class="line">    now += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> gra.T.tolist()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataFrom</span><span class="params">(filename)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    separator = re.compile(<span class="string">'\t|\b| |\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(filename,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline()[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">        <span class="comment">#print(line)</span></span><br><span class="line">        <span class="keyword">while</span> line:</span><br><span class="line">            temp = separator.split(line)</span><br><span class="line">            <span class="comment">#print(temp)</span></span><br><span class="line"></span><br><span class="line">            abc = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> temp]</span><br><span class="line">            <span class="comment">#print(abc)</span></span><br><span class="line">            result.append(abc)</span><br><span class="line">            <span class="comment">#print(result)</span></span><br><span class="line">            line = f.readline()[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p><p>上面展示了5个函数，第一个logistic函数就是为了计算logistic函数的值，然后分别有两个计算梯度的函数，为了可以复用之前的代码，采用了一样的形式，不过值得注意的是多增加了一个data参数，这是之前没有的。为了实现题目中要求的顺序采取一个样本来做修正，使用了一个全局变量来记录当前的样本索引，同时有一个初始化函数，可以让样本索引归零。</p><p>还有一个readDataFrom不用多说，根据资料的输入形式进行适当调整。</p><p>最后在主函数中整合输出结果：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    data = readDataFrom(<span class="string">"./hw3_train.dat"</span>)</span><br><span class="line">    start = [<span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,len(data[<span class="number">0</span>]))]</span><br><span class="line">    i_times = <span class="number">2000</span></span><br><span class="line">    stochastic_gradient_init()</span><br><span class="line">    W1 = gd.gradient_decent(start,get_logistic_gradient,<span class="number">0.001</span>,i_times,data)</span><br><span class="line">    W2 = gd.gradient_decent(start,get_logistic_gradient,<span class="number">0.01</span>,i_times,data)</span><br><span class="line">    W3 = gd.gradient_decent(start,stochastic_gradient,<span class="number">0.001</span>,i_times,data)</span><br><span class="line">    err1 = lr.Ein(data,W1)</span><br><span class="line">    err2 = lr.Ein(data,W2)</span><br><span class="line">    err3 = lr.Ein(data,W3)</span><br><span class="line">    out_data = readDataFrom(<span class="string">"./hw3_test.dat"</span>)</span><br><span class="line">    err_out1 = lr.Ein(out_data,W1)</span><br><span class="line">    err_out2 = lr.Ein(out_data,W2)</span><br><span class="line">    err_out3 = lr.Ein(out_data,W3)</span><br><span class="line">    print(<span class="string">"Ein:"</span>,err1,err1/len(data),err2,err2/len(data),err3,err3/len(data))</span><br><span class="line">    print(<span class="string">"Eout:"</span>,err_out1,err_out1/len(out_data),err_out2,err_out2/len(out_data),err_out3,err_out3/len(out_data))</span><br></pre></td></tr></table></figure></p><p>我将起始的W设定为0向量，不同的起始向量可能得到不同的性能。</p><p>最后的结果，分别是3道题目的${E_in}$与$E_{out}$.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ein: 430 0.43 204 0.204 427 0.427</span><br><span class="line">Eout: 1354 0.4513333333333333 678 0.226 1352 0.45066666666666666</span><br></pre></td></tr></table></figure><p>因此我认为答案是a,d,a. 可以看到学习率过低的话可能会使得下降速度过慢，而且随机梯度下降的性能有时候不见得比普通的梯度下降差，但是速度却大大提高。</p><p>将迭代次数更新为10000，3个学习方法都取得了不错的效果，而步长大的性能反而不如之前，说明因为步长过大，它只能再最低点徘徊很难取得更低的位置，而步长小的依然没有达到极限：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ein: 236 0.236 206 0.206 235 0.235</span><br><span class="line">Eout: 779 0.25966666666666666 695 0.23166666666666666 776 0.25866666666666666</span><br></pre></td></tr></table></figure></p><h2 id="p-s"><a href="#p-s" class="headerlink" title="p.s."></a>p.s.</h2><p>1.python中的全局变量，list为引用，而赋值一个常数则会重新声明，为了避免歧义。因此想要改变全局变量的常数，需要添加关键词global。</p><p>2.牛顿方向与海森矩阵。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Nonlinear Transformation</title>
      <link href="/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Nonlinear-Transformation/"/>
      <url>/2018/09/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Nonlinear-Transformation/</url>
      
        <content type="html"><![CDATA[<p>之前我们学习的所有模型，都是linear model。我们做的都是用一条直线（或者平面等）来分类，或者拟合，或者是通过该直线来预测概率。但是现实中很多时候线性不一定能做得很好。<a id="more"></a>如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/5%4014N%288G7K0JNSKXZF%29DU_7.png" alt=""></p><p>似乎用一个圆，能更好地对这些样本进行分类。实际上，上图的分类的依据是：</p><script type="math/tex; mode=display">h(X) = sign(0.6-x_1^2-x_2^2)</script><p>因此，这样我们就引入了二次假设（quadratic）。<br>在上式中，如果我们令$z_0 = x_0 = 1, z_1 = x_1^2 ,z_2 = x_2^2$，那么就发现，实际上上面中对于$x$的二次假设实际上转换为了对$Z$的线性假设。一个样本在x空间上是很难线性分割的，无论怎样都不能得到较好的$E_{in}$，但是展开到z空间上也许就是线性可分的了。</p><p>因此怎么做实际上很简单，之前的训练集是$D$，我们通过展开到z空间来得到训练集$D’$，用训练集来进行之前的用于线性模型的训练。</p><p>通过这个，我们仿佛进入了新世界：我们可以任意来构建多项式(特征转换)，达到非线性学习的结果。</p><p>但是世界上不会天上掉馅饼。我们知道不会有这么白白的好事发生。既然多项式这么强大，它必然会付出更多的代价，下面我们来简单说明下它的price。</p><p>假如原始特征有d个，我们构建的是最高次为Q的Q次多项式($Q \leq d$)。那么，构造的新的样本集会有多少个维度？</p><script type="math/tex; mode=display">\Phi _Q(X) = \left ( \begin{matrix}     1,\\    x_1,x_2,...,x_d,\\    x_1^2,x_1x_2,...,x_d^2,\\    ...,\\    x_1^Q,x_1^{Q-1}x_2,...,x_d^Q\\        \end{matrix}   \right )</script><p>假如我们乘转换后的维度是$\overline d$，则 $\overline d = C_{Q+d}^d-1 =&gt;O(Q^d)$(如何得到这个值需要排列组合知识，在此处知道即可).</p><p>这意味着$\overline W$是（$1+\overline d$）维的向量，而转换后的$vc dimension \leq \overline d+1$(之前的VC bound中证明过了二元分类维度为d的时候，vc dimension为d+1).vc dimension可能会增加很多，也就意味着我们需要非常多的资料可能才能得到较好的准确度，同时也会极大地增加存储空间，以及算法的学习速度。</p><p>我们列出次数为1-Q时候的维度如下：</p><script type="math/tex; mode=display">\Phi _0(x) = (1)</script><script type="math/tex; mode=display">\Phi _1(x) = (\Phi _0(x) , x_1,x_2,...,x_d)</script><script type="math/tex; mode=display">\Phi _2(x) = (\Phi _1(x) , x_1^2,x_1x_2,...,x_d^2)</script><p>…</p><script type="math/tex; mode=display">\Phi _Q(x) = (\Phi _{Q-1}(x),x_1^Q,x_1^{Q-1}x_2,...,x_d^Q)</script><p>因此：我们可以得到：</p><p>$H_0 \subset H_1 \subset H_2 \subset H_3 \subset … \subset H_Q$;</p><p>从而得到：</p><p>$ d_{vc}(H_0) \leq d_{vc}(H_1) \leq d_{vc}(H_2) \leq … \leq d_{vc}(H_Q)$;</p><p>而对于$E_in$来说，不错的消息是$E_{in}$是在不会变大的。因为它最多最好的线与之前一样：</p><p>$ E_{in} (g_0) \geq  E_{in} (g_1) \geq E_{in} (g_2) \geq … \geq E_{in}(g_Q)$;</p><p>更重要的一件事，不知道你是否还记得这个学习曲线：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/M%29P32DW%29EE9%7BWB%246A08T8%29X.png" alt=""></p><p>从上面可以看出来，维度个数增加，$E_{out}$并不是一直下降的，最好的维度个数是在中间某个地方。而$E_{in}$从来就不是我们关注的重点，我们尽可能减少他，是为了得到更好的$E_{out}$,而过分增加维度个数，可能会本末倒置。$E_{out}$才是我们想要的。</p><p>实际中，我们在学习时候应该先从低的维度开始，再慢慢向上增加，直到得到想要的$E_{in}$，往往线性的学习并不像人们想象中的那样效果很差，可能从较低的维度就可以得到较好的结果。如果一开始就用很多的维度，可能直接得到了很好的$E_{in}$，但是泛化能力却很差。</p><p>最后，要注意，有的人说，刚开始举得例子中，如果通过可视化，我们直接用 $s(X) = w_0 + W_1 x_1^2 + W_2x_2 ^2$，这样看起来，似乎维度只有3个，实际上类似的还有$s(x) = w_0 + W_1( x_1^2 + x_2 ^2)$,似乎维度只有两个，甚至是可以降到0个。但是这实际上是人脑学习的过程，我们已经替机器学习了不少，因此最后的泛化结果可能并不是我们想象的那么好，因为真实的代价还是存在的。而且，高纬度的可视化是很难做到的。</p><p>因此，使用多项式并不见得就是好的，我们要结合实际情况来进行学习。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> polynomial </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Multiclass（OVA and OVO）</title>
      <link href="/2018/09/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Multiclass/"/>
      <url>/2018/09/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Multiclass/</url>
      
        <content type="html"><![CDATA[<p>目前，我们对二元分类已经有了不少的了解，可以用多个线性模型去实现二元分类。但是生活中遇到的往往不是是非题，而是选择题，尤其是图像识别问题中，我们往往需要识别多个物体。如何通过之前实现的二元分类，来实现多元分类呢？<br><a id="more"></a><br>这里介绍两种思路，一个是OVA（One Vesus All），另一个是OVO（One Vesus One）。</p><h2 id="OVA-via-Logistic-Regression"><a href="#OVA-via-Logistic-Regression" class="headerlink" title="OVA(via Logistic Regression)"></a>OVA(via Logistic Regression)</h2><p>要想进行多元分类，我们首先想到的是对每一种类型进行是非判断。理想中，这样似乎不错，找个物体，哪一种类型的判断说是，就是该类型，但是现实往往不尽人意。</p><p>假如有下图所示的一个样本集：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/5%7ES9ZBTNV%25J%40NFF1X9ER%29%24Y.png" alt=""></p><p>可以看到一共有四类，分别对每个类型进行是非判断，可以得到下面的4条线来分类：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/K%240%7E%29%7E_4A%25I%60_5B%29B4KOG1X.png" alt=""></p><p>从左至右分别是正方体，菱形，三角形，五角星得到的线。</p><p>融合到原来的图形上：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/56XK%28P%242S%29VUE%7B47%24WLLDH3.png" alt=""></p><p>对于上图中，有几个部分区域的样本可以很明确的判断出来是什么类型，但是其他部分区域，要么是多个类型都说是，要么没有一个类型说是，这就让我们无法进行判断。</p><p>我们很容易想到既然用明确的是非无法进行判断，如果使用概率会不会好一点。因此要使用logistic regression。</p><p>使用logistic regression进行的还是上面的步骤，得到的是是各个类型的概率。选择概率最高的，就可进行分类。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/S%402ZQSW29UEE%7D3X%7B9I0P%60%7ET.png" alt=""></p><p>下面的分类图是利用上述方法进行分类得到的结果，可以看到对每个区域，都能为它制定一个类别。值得注意的是logistic function是单调增函数，因此比较概率的时候我们并不用真的求出来大小，而只用比较$s(X)$的大小即可。</p><p>具体步骤如下：</p><p>(1) for $k \in Y$, obtain W_{[k]} by running logistic regression on $D_{[k]} = \left \{ (X_n,y’_n = 2[y_n = k] - 1) \right\}_{n=1}^N$.<br>(2) return $g(X) = argmax_{k \in y}(W_{[k]}^TX) $</p><p><em>*</em>注：argmax是一种函数，函数y=f(x)，x0= argmax(f(x)) 的意思就是参数x0满足f(x0)为f(x)的最大值；换句话说就是 argmax(f(x))是使得 f(x)取得最大值所对应的变量x。arg即argument，此处意为“自变量”。在上式中为结果为某个k$(k \in y)$。</p><hr><p>上面的方法很简单的就可以实现了多元分类。但是上面的算法有个缺点，一对多，当种类k特别多时候，很容易造成不平衡的情况，一个不好的算法但是却得到了很好的$E_{in}$，影响最后的分类结果。因此希望可以找到一种方法来解决这个问题。</p><h2 id="OVO-via-Binary-Classification"><a href="#OVO-via-Binary-Classification" class="headerlink" title="OVO(via Binary Classification)"></a>OVO(via Binary Classification)</h2><p>OVO是一对一的算法，可以很好的解决上面最后留下来的问题。它的思想是这样的，从k个类别中挑出两种类别来进行学习，每次学习都可以得到一个用来区分的$W$，一共可以得到$C_k^2$种。</p><p>这里得到的$W_i$与上面的办法用途是不一样的，它直接用来做二元分类（+1 or -1），而不是得到一个概率。通过两两组合进行二元分类的学习，我们得到了$C_k^2$个分类器，每个分类器都会对放入的样本进行一个明确的分类。下图是上面的样本集得到的几个分类器：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/A%28PYVE%60M%404EFA73%25S531CMM.png" alt=""></p><p>从左到右，分别是对[菱形，方块]，[三角形，方块],[五角星，方块]，[菱形，三角形]，[菱形，五角星]，[三角形，五角星]进行二元分类。</p><p>进行预测时候，取一个样本，经过6个分类器来预测，6个分类器得到不同的结果，但是每个都会对该样本的类别进行明确的预测，类似于投票，最后我们选择得票最多的类别。</p><p>下图为用OVO分类得到的结果：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/7%28CYH%24KM%5BVTG%7EM%25UL3R%7D28F.png" alt=""></p><p>OVO算法的主要过程如下：</p><p>(1) for ($k,\zeta$) $\in Y \times Y$, obtain $W_{[k,\zeta]}$ by running linear binary classification on $D_{[k,\zeta]} = \left \{ (X_n,y’_n = 2[y_n = k] - 1):y_n = k or y_n = \zeta \right \}$ </p><p>(2) return $g(X) =$ $tournament$ $champion$ $\left \{W^T_{[k,\zeta]}\right \}$</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面就是两种用在多元分类上的算法，他们都是很简单并且非常常见的算法。两个算法运行速度都很快（OVO虽然增加了分类器的个数，但是用来学习的样本量会减少很多）。OVO的缺点是如果类别真的非常大，那么分类器个数可能过多，会占用较大的空间，一定程度上也会影响速度，但是它有较高的稳定性，减少出现不平衡的情况。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> classification </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——linear model for classification</title>
      <link href="/2018/09/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-model-for-classification/"/>
      <url>/2018/09/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-model-for-classification/</url>
      
        <content type="html"><![CDATA[<p>到目前为止，已经学习了3个线性模型了，他们都使用到了$score = W^TX$(后文中简写为$s$)，使用特征间线性组合来打分，通过分数来做后续的处理。<a id="more"></a></p><p>linear regression用于分类前面有一篇博客已经说明，现在我们想要知道，logistic regression 是否也可以用于分类？毕竟线性回归的错误对于二元分类来说是一个很大的上界，这意味着它的效果虽然不差，但可能错失更好的。而PLA找到一个最小的$E_{in}$是NP-hard问题，只能使用改进的POCKET算法。我们希望看到logistic regression用于二元分类可以有更好的表现。</p><p>与之前的步骤一样，逻辑回归中，$E_{in} = \sum_{n = 1}^{N} \ln{1 + e^{-y_nW^TX_n}}$，我们对比的是单个样本的错误，就写作$err_{name}$好了。</p><p>为了让这3种模型都有较为清晰的对比，我们对PLA以及线性回归的错误衡量也做处理，如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">method</th><th style="text-align:center">linear classification</th><th style="text-align:center">linear regression</th><th style="text-align:center">logistic regression</th></tr></thead><tbody><tr><td style="text-align:center"> err</td><td style="text-align:center">$[sign(ys \neq 1)]$</td><td style="text-align:center">$(sy-1)^2$</td><td style="text-align:center">$\ln{1+e^{-ys}}$</td></tr></tbody></table></div><p> 将它们的曲线绘制到一张图上，可以得到下面的结果：<br> <img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/87T%7EV%5DV75N992E1I%5B3M9%5DZK.png" alt=""><br> 其中蓝色是linear classification的错误，红色是linear regression的错误，绿色是logistic regression。坏了，绿色的线并不总是大于蓝色的线，这意味着我们无法像之前一样，简单地将$E_{in}(linear classification)$换成$E_{in}(logistic regression)$。</p><p> 实际上，之前我们选择用$ln$函数是因为这是最常见的，只是将乘法换成加法，理论上我们可以取任何对数，如，将对数函数换为$log_2^x$,就可以得到另外一副曲线图：<br> <img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/CCO%29%25RV4OG9Z8%7D60%40%404W6G0.png" alt=""></p><p> 这样就可以满足我们的需要，也方便下面的证明。<br>我们称使用$ln(x)$函数的错误为$err_{ce}$，使用$log_2(x)$的为$err_{sce}$，则由上图可以知道：</p><p>$err_{0/1}(s,y) \leq err_{sce}(s,y) = \frac 1 {\ln2} err_{ce}(s,y)$，<br>（由换底公式：$\frac {\ln x}{\ln2} = log_2x ）<br>也就可以知道：</p><script type="math/tex; mode=display">E_{in}^{0/1} \leq E_{in}^{sce} = \frac 1 {\ln2} E_{in}^{ce}</script><p>同样的道理：</p><script type="math/tex; mode=display">E_{out}^{0/1} \leq E_{out}^{sce} = \frac 1 {\ln2} E_{out}^{ce}</script><p>因此，我们可以像之前一样推导：</p><script type="math/tex; mode=display">E_{out}^{0/1} \leq E_{in}^{0/1}+ \Omega ^{0/1} \leq \frac 1 {\ln2} E_{in}^{ce}+\Omega ^{0/1}</script><p>同样，从另一个方向也可以推导：</p><script type="math/tex; mode=display">E_{out}^{0/1} \leq \frac 1 {\ln{2}} E_{out}^{ce} \leq \frac 1 {\ln2} E_{in}^{ce}+\Omega ^{ce}</script><p>无论哪个，都可以证明，logistic regression是可以用于二元分类的。而上面的图像也说明了，他的效果比线性回归更好，bound更紧一点。</p><p>在实际应用中，我们使用linear regression来初始化$W$，然后通过POCKET或者logistic regression来进行后面的步骤，而且logistic regression更为常用。</p><p><strong><em>注：上面推导中，判断都是以s=0为界定，对应到logistic regression也就是概率为0.5为界定。</em></strong></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> classification </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Gradient Decent</title>
      <link href="/2018/08/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Gradient-Decent/"/>
      <url>/2018/08/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Gradient-Decent/</url>
      
        <content type="html"><![CDATA[<p>Gradient Decent,即梯度下降。梯度下降是机器学习中非常重要的接近最优解的工具。<a id="more"></a>理论上只要得到梯度，就可以使用梯度下降。因此它同样可以用于linear regression，在数据量很大特征很多的情况下，因为矩阵求逆的时间复杂度很大，它往往比之前介绍的linear regression“一步登天”的做法性能更好。</p><p>首先，假设我们已经知道了$E_{in}$的梯度为$\nabla E_{in}$。首先，我们要知道一件事，梯度是所有方向上，“坡度”最陡的方向。梯度下降，使用了贪心的思想：每次都朝着坡度最陡的方向往下走。也许最后得到的不一定是全局最优解，但是一定是一个极小值点，通常也能取得不错的效果。</p><p>所以，有一个起始点为$W_0$，每次向下走一个单位的长度乘上一个未知的$\eta$，用来控制步长。在梯度方向上的单位向量等于$\frac {\nabla E_{in}}{|\nabla E_{in}|}$，当然，我们也可以很容易知道，我们要走的方向应该是梯度的反方向。因为求出来的梯度往往指向的是函数值增加最快的方向，而我们要的是尽可能减少$E_{in}$。所以就可以得到下面的式子：</p><script type="math/tex; mode=display">W_1 = W_0 - \eta \frac {\nabla E_{in}}{|\nabla E_{in}|}</script><p>每次朝着梯度方向走一步，理想中这个函数就会下降一点，因为当走动的距离很小时候，有以下近似式：</p><script type="math/tex; mode=display">E_{in}(W_0+\Delta) \approx E_{in} + \Delta \nabla E_{in} (W_0)</script><p>上式其实是多维函数泰勒展开式（一阶）。</p><p>接下来，就是对$\eta$的选择了。选择$\eta$时候，有下面几种情况：<br>1.$\eta$ 太小。 如果$\eta$很小，那么我们可以保证它最后一定可以走到一个很低的地方，不过速度太慢了。因为每一步步长太小。</p><p>2.$\eta$ 太大。如果$\eta$太大，那么之前的泰勒展开式就不适用，充满了不确定性。有可能一步太长走到对面，运气好的话函数值还在变小，运气不好函数值会增加，因此这样也是不可选的。</p><p>3.如下图，让$\eta$在变化。当梯度很大时候，步子迈的大一点，当梯度小了，意味着距离最低点很近了，步子小一点，谨慎一点走。上面三种情况如下图：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/eta_choice.png" alt=""></p><p>很明显，我们应当选择的是第三种策略。如何控制$\eta$可变？简单的做法就是让$\eta$与$|\nabla E_{in}|$成正比，如果$\eta = \alpha|\nabla E_{in}| $就会抵消了原来式子中的分母部分，最后得到下式：</p><script type="math/tex; mode=display">W_{i+1} = W_i - \eta  {\nabla E_{in}}</script><p>可以看到式子变得更加简洁了。</p><p>上式中的$\eta$成为fixed learning rate，尽管学习率是固定的，但是每一步步长却在改变。当然，对于上式中的$\eta$我们也应该选择合适的值，否则还是会出现上述的两种情况，但是它改进了很多，使得算法效率得到了提升。</p><p>最后，梯度下降什么时候停止？当$\nabla E_{in} \approx 0 $或者进行了足够多次数的迭代之后，我们就应该停止了。因为在计算机中数值上得到一个完全为0的值是很困难的，而约等于0时候，我们就可以取得满意的结果。或者进行了足够多的次数，依然得不到满意的结果，我们需要考虑的是改进算法，是不是学习率值取得不够好等等。</p><p>以上就是梯度下降。</p><p>在这里，另外提到一个叫随机梯度下降（Stochastic Gradient Desent）的算法。上面介绍的梯度下降算法虽然可以很好的找到我们想要的结果，但是在n很大的时候，每次更新都需要进行求和平均，这就导致了算法速度可能受到影响。实际上，它的时间复杂度与POCKET算法是一样的。我们希望可以将复杂度提升到PLA的级别。</p><p>$E_{in}$的定义是对所有点的$err$加起来求平均，在n很大时候，平均值的期望值与随机抽取一个样本的值的期望值是接近的，因此随机梯度下降实际上就是每次随机选取一个点（或者少量点求平均），然后用它的$err$来计算梯度，并进行更正。它类似于PLA算法的步骤:</p><script type="math/tex; mode=display">SGD logistic regression:  W_{t+1} = W_t + \eta  \theta (-y_nW_t^TXn)(y_nX_n)</script><script type="math/tex; mode=display">PLA:W_{t+1} =  W_{t}+[y \neq sign(W_t^TX_n)] (y_nX_n)</script><p>当SGD logistic regression的错误非常离谱，它的更新效果实际上接近于PLA算法。</p><p>这个算法运行什么时候终结？一般来说运行足够长的时间之后或者此时的$E_{in}$已经足够小，我们就认为已经取得了不错的效果。它的优点是速度快，缺点是最终的结果相比于梯度下降还是差了一点。因此它是梯度下降算法的一个改进。</p><p>适用场景：1.n特别大 2.如果本身样本是一个一个来的，而不是一批一批来的，也可以适用这个方法，也就是可以适用于在线学习（online learning）。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——logistic Regression</title>
      <link href="/2018/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94logistic-Regression/"/>
      <url>/2018/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94logistic-Regression/</url>
      
        <content type="html"><![CDATA[<p>通过线性分类，我们预测的是一个样本是positive，还是negative，不过有时候我们并不想要那样明确的结果。<a id="more"></a>有时候，这种情况在医学中更为常见，我们想知道一个样本是正的概率，比如医院中对肿瘤良性与恶性的预测，来决定后续的治疗方式。概率是从0到1的实数，因此对概率的预测依然属于回归而非分类。</p><p>理想中，我们希望样本的样子是这样的：$\{X_1,0.9\},\{x_2,0.2\},\{x_3,0.65\}…$，即对每个样本，都已知它是positive的概率。但是实际上我们往往无法得到这样的结果，我们无法确切知道某个样本是正的概率。我们得到的样本，往往与分类问题的样本一样，对每个样本，知道它是negative，还是positive。不过我们可以假想，得到的训练集是理想情况+噪声造成的：如果是negative，我们可以说它是positive的概率为0，如果是positive，我们称该概率为1。我们希望可以预测出概率。</p><p>首先，有之前的pla与linear regression的基础，很容易想到，使用$WX$去得到预测值。但是预测值虽然是实数，但是因为是概率，所以它的分布仅在于$[0,1]$，因此仅仅使用$WX$是不符合预期的。</p><p>这里，将介绍一种函数叫logistic函数：$f(x) = \frac {1} {1+e^{-x}}$（在数学上这个定义更加严格一点，而此处是logistic函数的一种）.这个函数的图像如下：<br><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png" alt=""></p><p>它满足下面的条件：$\lim_{x \to +\infty} f(x) = 1$ &amp; $\lim_{x \to -\infty} f(x) = 0 $，它的值域是（0，1），这个性质目前很符合我们的期望。</p><p>接下来，我们需要定义的就是$E_{in}$，因为有$E_{in}$我们才能从H种找到一个g，它的$E_{in}$最小。但是$E_{in}$是不能随便定义的。之前的$E_{in}$，都是在找与真正对应的$y$之间的距离，这里我们不知道真正的$y$（也就是概率值），因此我们要换种考虑方法。</p><p>假如有一个理想的函数$f$，能知道样本为positive的真实概率，表示为：$P(y_i=+1|X_i) = f(X_i)$，那么该样本是现在这个样子的概率为：$P(X_i \bigcap y_i = +1) = P(X_i) \times P(y_i=+1|X_i)$，而当$y_i = -1$时，$P(X_i \bigcap y_i = -1) = P(X_i) \times (1-P(y_i=+1|X_i))$，合并两种情况，得到：$P(X_i \bigcap y_i) =\frac {(y_i+1)} 2 P(X_i) \times P(y_i = +1|X_i) +\frac {(1 - y_i)} 2 P(X_i) \times (1 - P(y_i = +1|X_i)) $.各个样本之间是独立的话，那么出现这个样本集的概率等于：$\prod_{i=1}^{n}P(X_i \bigcap y_i)$。</p><p>目前，我们不知道$f$，但是假如我们用$H$中的某个$h$来代替，这就意味着在函数h的情况下，出现这个样本集的概率，当然我们想要做的是令这个概率越大越好。平时处理的$E_{in}$都是和，而这次我们依然希望用和来处理，而不是连乘，因此我们为上式加上一个$\ln$，而因为P(X_i)的概率都是一定的，所以我们无需关注。省掉$P(X_i)$,再进行上面的处理之后变为：<br>$\frac{1}{N} \sum _{i = 1}^{n} \ln {(\frac {(y_i+1)} 2 h(X_i) +\frac {(1 - y_i)} 2 (1 - h(X_i)))}$.</p><p>但是这不符合$E_{in}$，因为我们想要的是$E_{in}$越小越好，而上面的式子是越大越好，因此需要加上一个负号，同时，如果我们使用之前的logistic function作为h，我们可以发现它有一个性质：1 - h(x) = h(-x)，因此,可以得到下面的式子：</p><script type="math/tex; mode=display">E_{in} = -\frac{1}{n}  \sum _{i = 1}^{n} \ln {(\frac {(y_i+1)} 2 h(X_i) +\frac {(1 - y_i)} 2 (1 - h(X_i)))} = -\sum _{i = 1}^{n} \ln h(y_iX_i).</script><p>将logistic function 带入上式：</p><script type="math/tex; mode=display">E_{in} =\frac{1}{n}  \sum _{i = 1}^{n} \ln(1+e^{-y_iW^TX_i})</script><p>从上式可以看出来，如果$y_i = 1$，而预测它为1的概率小于0.5（$W^TX_i&lt;0$），那么$E_{in}$的值会大于$ln2$，而$E_{in}$是没有上界的。错的越离谱，惩罚就越大。</p><p>接下来的问题，就是如何让$E_{in}$取到最小了。</p><p>首先，可以证明的是，这个$E_{in}$也是一个凸函数（证明办法需要用到更深入的线性代数知识），因此我们可以找到一个最小值。和线性回归时候遇到的情况一样，要得到极值点，就要找到梯度为0的点。因此首先要得到的是$E_{in}$的梯度。从微积分里，我们知道梯度的求法，也就是对每个方向求偏导，由它们组成的向量。为了得到梯度，我们首先应该求出$E_{in}$对每个$w_i$的偏导数，对于偏导数的求法在微积分中课程中我们也学习过，可以得到下面的结果：</p><script type="math/tex; mode=display">\frac {dE_{in}} {d{w_i}} =\frac{1}{N}  \sum _{n = 1}^N \frac {e^{-y_nW^TX_n} \times ( -y_nx_{n,i})} {1+e^{-y_nW^TX_n}}</script><p>注意：上式中为了方便，我们用$N$替代了之前的$n$，用$n$替代了$i$，并且用$i$代表了$W$向量中维度序列。</p><p>如果对上式向量化，我们可以得到 $\nabla E_{in}(\mathbf{w}) = \frac{1}{N} \sum\limits_{n=1}^N {\theta\left({-y_n \mathbf{w}^T \mathbf{x}_n}\right)} {\bigl(-y_n \mathbf{x}_n\bigr)}$. </p><p>上式中，$\theta(x) = \frac {1} {1+e^{-x}}$.</p><p>由此，我们求到了$E_{in}$的梯度。为了让这个梯度为0，首先我们想到的是，所有的$\theta\left({-y_n \mathbf{w}^T \mathbf{x}_n}\right)$等于0，这要求所有的$y_nW^TX_n$都是远大于0，这意味着原来的数据是线性可分的。</p><p>如果不是这种情况，原来的数据则不是线性可分（大多数情况下我们的数据都不是这么理想），想使得最终结果为0，那么各个数据是加权加起来最后得0.那么我们希望可以像线性回归一样通过某种表达式直接求得一个解，不过遗憾的是这个函数不是线性函数，我们没有办法一下求得这个解。我们能做的只能是步步逼近，类似于之前的PLA算法。</p><p>这就要介绍一个方法，叫<strong>梯度下降</strong>（gradient decent）。</p><p>梯度下降具体内容查看：<a href="https://wlsdzyzl.top/2018/08/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Gradient-Decent/" target="_blank" rel="noopener">Gradient Decent</a>。</p><p>通过梯度下降，我们可以找到一个合适的$W$，从而得到较好的逻辑回归效果。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——linear regression与linear classification</title>
      <link href="/2018/08/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression%E4%B8%8Elinear-classification/"/>
      <url>/2018/08/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression%E4%B8%8Elinear-classification/</url>
      
        <content type="html"><![CDATA[<p>上一篇博客介绍了线性回归模型，但是不知道大家是否有这样的感觉：它与之前的PLA算法似乎有很多类似之处。<br><a id="more"></a><br>这两个算法都在使用线性的方法，也就是它们都是通过$y_n = W^TX_n$来计算出$y_n$，只不过PLA算法通过$y_n$来判断第n个样本的分类，而线性回归直接使用$y_n$来作为它的预测值。</p><p>线性回归中，$y$的值的范围是整个实数，从另一方面想，线性classification的$y$取值只有+1，-1两个取值，这两个值当然也是实数，我们是否能将线性回归算法用作于线性分类中呢？</p><p>要思考这个问题，首先要决定如何将线性回归用于线性分类：对样本集$\{X_n,Y_n\}$利用线性回归来进行学习，得到$W$，然后通过$sign(y’_n)$（其中$y’_n = W^TX_n$）来对该样本进行分类。与PLA的区别是PLA一直在尝试各种不同的$W$，而线性回归直接得到一个自己认为最好的$W$。但是实际上它们的Hypothesis都是一样的。</p><p>这个算法是否可行，需要来检查它的泛化能力，也就是它的$E_{out}$是否像PLA算法一样有个上界。首先，我们观察两个算法对于错误的衡量有什么区别（注：以下错误都是单个样本的错误）：</p><div class="table-container"><table><thead><tr><th>category</th><th>$E_{in}$</th></tr></thead><tbody><tr><td> linear classification(PLA)</td><td>$y \neq y’$</td></tr><tr><td> linear regression</td><td>$(y - y’)^2$</td></tr><tr><td> linear regression to classification</td><td>$y \neq sign(y’)$</td></tr></tbody></table></div><p>在上面的表格中，我加了一行，也就是利用线性回归算法来进行线性分类时候的$E_{in}$，这意味着它们的$y’$是一样的(实际上$y’$代表的应该是最终的预测值，这里正确的写法应该是$h(X)$,此处只为了方便区分PLA)。</p><p>如果画出y = -1 与 y = +1 时候的曲线图，我们可以清晰地观察到，线性回归得到的错误永远是大于利用线性回归进行分类的错误的：</p><p>y = +1时：<br> <img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/W%24%40%7B0SE%246CEJRR%6098Y255E0.png" alt=""></p><p>y = -1时：<br> <img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/V%5D%5D%24DG%28R6%5B6G%7E0%29%5D%2588KLDE.png" alt=""> </p><p>而通过之前vc bound那一节我们可以知道：</p><script type="math/tex; mode=display">E_{out} \leq E_{in}(classification)+\sqrt {...}</script><p>也就可以得到：</p><script type="math/tex; mode=display">E_{out} \leq E_{in}(regression) +\sqrt {...}</script><p>这意味着，只要linear regression的$E_{in}$做的足够好，那么使用线性回归来做线性分类，往往也能取到比较好的效果。</p><p>实际中，我们也可以使用线性回归与PLA算法结合，先通过线性回归得到W，然后因为给了PLA或者POCKET算法一个好的初始点，它能更快得到最后好的结果。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> classification </tag>
            
            <tag> regression </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——linear regression</title>
      <link href="/2018/08/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression/"/>
      <url>/2018/08/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94linear-regression/</url>
      
        <content type="html"><![CDATA[<p>终于完成了机器学习基石相对理论的部分，可以开始一些具体的算法的学习了。首先学习的第一个算法就是线性回归（linear regression）。<br><a id="more"></a><br>线性回归想做到的事情是，给出一堆点，使用一条直线（平面或者其他）来拟合这个dataset。而在之前的noise and error中提到了，它用来衡量错误的办法是$(y - y’)^2$。</p><p>和之前的机器学习算法也一致，因为VC bound在线性回归的例子中也一样适用，所以我们想做的是保证$E_{in}$越小越好。</p><p>对于线性回归的H集合是 $y’ = W^TX$，当然$X$，$W$都是列向量，向量的维度是d+1（d为特征量的个数）.为了minimize $E_{in}$，首先我们应该写出来$E_{in}$的表达式：</p><script type="math/tex; mode=display">E_{in} = \frac 1 n \sum _{i = 1} (h(X_n) - y)^2 =  \frac 1 n \sum _{i = 1} (W^TX_n - y_n)^2</script><p>这个表达式看着还比较复杂，有个求和符号在里面。首先，这后面有N个平方和，我们可以很轻松的想到向量的范数求法。因此，我们可以将原式写成对向量求范数的形式：</p><script type="math/tex; mode=display">E_{in} = \frac 1 n || XW - Y||^2</script><p>上式中</p><script type="math/tex; mode=display">X = \begin{bmatrix}...X_1^T... \\...X_2^T... \\..........\\...X_n ^T ...\end{bmatrix}</script><p>X是一个n*（d+1）的矩阵，n是样本个数，d是特征量个数。</p><p>因此$E_{in}$可以说是一个关于W的函数，而且可以证明的是，这个函数是连续的（continuous），可导的（differentiable）,并且是凸函数（convex）。因此我们一定可以求得最低点，也就是$E_{in}$的最小值。与实数的函数一样（实际上求的是W的各个方向的偏导数），在取最小值的那个点的时候，$E_{in}$关于$W$的导数是0，表明取得是极值，也就是梯度是0。</p><p>将上式展开可以得到：</p><script type="math/tex; mode=display">E_{in} = \frac 1 n (W^TX^TXW -2Y^TXW +Y^TY)，</script><p>将除了W之外的矩阵或者数字看成常量，则可以得到：</p><script type="math/tex; mode=display">E_{in} =  \frac 1 n (W^TAW-2BW+c)</script><p>为了求关于$W$的导数，我们首先想象一下如果是$W$一维的话的样子。</p><script type="math/tex; mode=display">E_{in} = aW^2-2bW+c ; \frac {dE_{in}} {dW} = 2aW-2b</script><p>对应到矩阵上来说:</p><script type="math/tex; mode=display">\frac {dE_{in}} {dW} = \frac 1 n 2AW-2B</script><p>可以看到的是梯度是一个向量。</p><p>为了使得$E_{in}$取得最小值，那么$X^TXW = X^TY$,如果$(X^TX)$的反矩阵存在，那么很简单:</p><script type="math/tex; mode=display">W = (X^TX)^{-1}X^TY</script><p>我们称$(X^TX)^{-1}X^T$为pseudo-inverse $X^{+}$。而且大多数时候我们遇到的都是可逆的，因为$n&gt;&gt;d+1$，这意味着首先对于X矩阵来说，它的秩很可能就是等于d+1的.这样它们相乘的秩很大可能也是d+1，也就是可逆。</p><p>但是如果遇到另外的情况，如不可逆，我们可以使用其他的方式来定义$X^{+}$，具体的数学原理需要更详细的线性代数知识，但是我们知道很多程序包里都实现了这些东西，用它一样可以得到比较好的结果。</p><p>综上，$W = X^{+}Y$,$Y’ = XW = XX^{+}Y$.</p><p>最后，这个算法之所以可以学习，我们可以使用VC bound来证明。但是还有另一种方法，也可以证明它泛化能力不错，可以取得良好的学习效果，当然，与VC bound一样，严格的证明需要更严密的数学推导，下面只是简要介绍。</p><p>首先，我们推导$\overline {E_{in}}$是很接近噪声的（噪声意味着我们无法通过学习进行改善的部分），而同样的步骤可以用在对$\overline {E_{out}}$的分析上，这样就说明了，平均来说我们的算法是可以取得很好的学习效果的。</p><p>首先，我们应该定义一下$\overline {E_{in}}$：</p><script type="math/tex; mode=display">\overline {E_{in}} = \epsilon _{D~P^N}\left\{\ E_{in}(W_{LIN} w.r.t. D)  \right\} = noise  level \cdot (1-\frac {d+1}{N})</script><p>具体的含义就是多个样本的$E_{in}$平均值，大概看起来会接近noise level，而当样本量越大，与noise level越接近。</p><p>首先，我们应该将线性回归得到的结果带入$E_{in}$的表达式中：</p><script type="math/tex; mode=display">E_{in} = \frac 1 N ||Y - \hat Y||^2 = \frac 1 N ||Y - XX^{+}Y ||^2 = \frac 1 N ||(I - X X^{+})Y||^2</script><p>我们称$XX^{+}$为hat matrix。</p><p>这里我们思考$\hat Y = XW$在做什么。Y是一个N维向量，而X可以看做是m个N维向量构成的矩阵，而实际上W的作用，是给每个矩阵中的N维向量分配一个参数，让他们做线性组合，最终得到一个新的N维向量。为了使得$\hat Y$尽量接近于$Y$，从另一个方面来说，就是让$Y - \hat Y \bot X’s span$，也就是让他们的差尽量垂直于X所展开的空间，当垂直时，$\hat Y$等于Y在X上的投影，这时候二者相差是最小的.</p><p>实际上，Y一般不可能被X完美表示，因为一般来讲$N&gt;&gt;d$.所以我们能做的就是上面说的。</p><p>所以，Hat的作用就是将Y投影到X上。而$(I-Hat)$就是将Y转换为$(Y-\hat Y)$的矩阵。<br>而且我们可以计算出来$trace (I - Hat) = n - (d+1)$，意味着$(I- Hat)$有$N - d- 1$个自由度。</p><p>如果$Y$来自与一些理想的$f(X)$与噪声的组合，那么如果只是理想的函数，则上述得到的差距实际上是由噪声造成的，因此：</p><script type="math/tex; mode=display">E_{in} = \frac 1 N ||Y - \hat Y||^2  = \frac 1 N ||(I - Hat)noise||^2 = \frac 1 N (N - d - 1)||noise||^2</script><p>而$\overline {E_{in}} = ( 1 - \frac{d+1}{N})noise level$<br>利用类似的办法，可以推断出来，$\overline {E_{out}} = ( 1 + \frac{d+1}{N})noise level$.</p><p>也就是平均来说，我们通过拟合样本，可以得到更小的错误率，但是泛化之后的错误率往往更大一点。</p><p>因此平均来说，我们可以将$E_{in}$与$E_{out}$画在一张图上：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/8P%292%25K%7DDKX0VSSRIW5WS%29JU.png" alt=""></p><p>如果对应到实际的机器学习，对于一些很少的样本量的机器学习过程，很容易拟合成功，得到很好的$E_{in}$，甚至是0，但是这时候泛化能力却很差。机器学习，不是一味地增加特征量减少$E_{in}$，而纠正过拟合的一种办法，就是增加样本量。</p><p>最后，我想说的是，上面的”证明”非常不严格，甚至有些地方让人费解。对于机器学习，理论部分严格的证明更多是数学和统计的事情，而学习计算机的人更多的是掌握各种算法，学习利用它来解决问题。即使这样，尽可能多地了解理论部分，对于实际的应用有很大的帮助。这个世界很复杂，永远保持一个好奇心吧。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）作业二</title>
      <link href="/2018/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A2/"/>
      <url>/2018/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A2/</url>
      
        <content type="html"><![CDATA[<p>总共20道题目。<br><a id="more"></a></p><p>Questions 1-2 are about noisy targets.</p><p><strong>1.Consider the bin model for a hypothesis $h$ that makes an error with probability $\mu$ in approximating a deterministic target function $f$ (both $h$ and $f$ outputs $\{-1, +1\}$).</strong><br> If we use the same $h$ to approximate a noisy version of $f$ given by</p><script type="math/tex; mode=display">P({\bf{x}},y) = P({\bf{x}})P(y|{\bf{x}})P(x,y)=P({\bf{x}})P(y∣ {\bf{x}})</script><script type="math/tex; mode=display">P(y|{\bf{x}}) = \left \{ \begin{matrix} \lambda & {y=f(x)} \\1-\lambda & \text{otherwise}\end{matrix} \right.​</script><p>What is the probability of error that $h$ makes in approximating the noisy target $y$?</p><p>a. $1-\lambda$</p><p>b. $\mu$</p><p>c. $\lambda(1-\mu)+(1-\lambda)\mu$</p><p>d. $\lambda\mu+(1-\lambda)(1-\mu)$</p><p>e. none of the other choices</p><p>这个题目半天看不懂，实际上意思是噪声的几率是($1-\lambda$)。算最后的错误率。所以，当预测错误时候，如果是非噪声，则最后还是错误；当预测正确时候，结果该样本是噪声，则会造成错误，将两种情况加起来，因此答案是 $\mu \lambda + (1-\lambda)(1-\mu)$，选d.</p><p><strong>2. Following Question 1, with what value of $\lambda$ will the performance of $h$ be independent of $\mu$?</strong></p><p>a. 0</p><p>b. 0 or 1</p><p>c. 1</p><p>d. 0.5</p><p>e. none of the other choices</p><p>这道题目很简单，意思是$\lambda$的值是多少的时候，h的性能与$\mu$无关。<br>很简单，将错误率展开：$\mu(2 \lambda - 1) + 1 - \lambda$，可以很容易看出来，$\lambda = 0.5$.</p><p>Questions 3-5 are about generalization error, and getting the feel of the bounds numerically.</p><p><strong>3. Please use the simple upper bound $N^{d_{\text{vc}}}$ on the growth function $m_{\mathcal{H}}(N)$,assuming that $N \geq 2$ and $d_{vc} \geq 2$.<br>For an $\mathcal{H}$ with $d_{\text{vc}} = 10$, if you want $95\%$ confidence that your generalization error is at most 0.05, what is the closest numerical approximation of the sample size that the VC generalization bound predicts?</strong></p><p>a. 420,000</p><p>b. 440,000</p><p>c. 460,000</p><p>d. 480,000</p><p>e. 500,000</p><p>这个题目考验的是VC bound.翻看直接我们推导出来的最终结果：</p><script type="math/tex; mode=display">\epsilon = \sqrt {\frac 8 N \ln {(\frac {4(2N)^{d_{vc}}} {\delta })}}</script><p>上式中，$\epsilon = 0.05(generalization error), \delta = 0.05 (confidence)$,带入上式中，可以计算出来以下结果：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\\ε^<span class="number">2</span> = (<span class="number">8</span>/N)*ln(((<span class="number">2</span>*N)^<span class="number">10</span>*<span class="number">4</span>)/<span class="number">0.05</span>) $\approx$ <span class="number">0.0025</span></span><br><span class="line">N = <span class="number">420</span>,<span class="number">000</span>  ε = <span class="number">0.0026817828255785</span></span><br><span class="line">N = <span class="number">440</span>,<span class="number">000</span>  ε = <span class="number">0.0025683417908949</span></span><br><span class="line">N = <span class="number">460</span>,<span class="number">000</span>  ε = <span class="number">0.0024644054978248</span></span><br><span class="line">N = <span class="number">480</span>,<span class="number">000</span>  ε = <span class="number">0.0023688152044852</span> </span><br><span class="line">N = <span class="number">500</span>,<span class="number">000</span>  ε = <span class="number">0.0022805941154291</span></span><br></pre></td></tr></table></figure></p><p>可以看到答案为 460，000.</p><p><strong>4. There are a number of bounds on the generalization error $\epsilon$, all holding with probability at least $1 - \delta$. Fix $d_{\text{vc}} = 50$d and $\delta = 0.05$ and plot these bounds as a function of N. Which bound is the tightest (smallest) for very large N, say N=10,000?<br>Note that Devroye and Parrondo &amp; Van den Broek are implicit bounds in $\epsilon$.</strong></p><p>a. Original VC bound: $ \epsilon \le \sqrt{\frac{8}{N}\ln\frac{4m_{\mathcal{H}}(2N)}{\delta}}$</p><p>b. Rademacher Penalty Bound: $ \epsilon \le \sqrt{\frac{2\ln(2Nm_{\mathcal{H}}(N))}{N}} + \sqrt{\frac{2}{N}\ln\frac{1}{\delta}} + \frac{1}{N}$</p><p>c. Parrondo and Van den Broek: $ \epsilon \le \sqrt{\frac{1}{N}(2\epsilon + \ln\frac{6m_{\mathcal{H}}(2N)}{\delta})}$</p><p>d. Devroye: $\epsilon \le \sqrt{\frac{1}{2N} (4\epsilon(1 + \epsilon) + \ln \frac{4m_{\mathcal{H}}(N^2)}{\delta})}$</p><p>e. Variant VC bound: $\epsilon \le \sqrt{\frac{16}{N}\ln\frac{2m_{\mathcal{H}}(N)}{\sqrt{\delta}}}$</p><p>代公式的问题：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a. (8/10000*ln((4*(2*10000)^50)/0.05))^(0.5) = 0.63217491520084</span><br><span class="line"></span><br><span class="line">b. ((2*ln(2*10000*10000^50))/10000)^0.5+(2/10000*ln(1/0.05))^0.5+1/10000 = 0.33130878596164</span><br><span class="line"></span><br><span class="line">c. (1/10000*(2*ε+ln(6*(20000)^50/0.05)))^0.5 当ε等于0.223左右的时候取等号,当ε大于0.223时候，上式已经不再成立，当小于0.223时候是成立的，所以bound在是0.223左右</span><br><span class="line"></span><br><span class="line">d. (1/20000*(4*ε*(1+ε)+ln(4*1000000^(50)/0.05)))^0.5 同上，bound在0.186左右</span><br><span class="line"></span><br><span class="line">e. (16/10000*ln(2*10000^50/0.5))^0.5 = 0.85967743993657</span><br></pre></td></tr></table></figure></p><p>答案为Devroye,选d.</p><p><strong>5. Continuing from Question 4, for small N, say N=5, which bound is the tightest (smallest)?</strong></p><p>答案与上面解答过程类似。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a. (8/5*ln((4*(2*5)^50)/0.05))^0.5 = 13.828161484991</span><br><span class="line"></span><br><span class="line">b. ((2*ln(2*5*5^50))/5)^0.5+(2/5*ln(1/0.05))^0.5+1/5 = 7.0487765641837</span><br><span class="line"></span><br><span class="line">c. 答案为5.0左右</span><br><span class="line"></span><br><span class="line">d. 答案为5.5左右</span><br><span class="line"></span><br><span class="line">e. (16/5*ln(2*5^50/0.5))^0.5 = 16.184752328814</span><br></pre></td></tr></table></figure></p><p>显然答案选Parrondo and Van den Broek.</p><p>In Questions 6­-11, you are asked to play with the growth function or VC-dimension of some hypothesis sets.</p><p><strong>6. What is the growth function $m_{\mathcal{H}}(N)$ of “positive-and-negative intervals on $\mathbb{R}$”? The hypothesis set $\mathcal{H}$ of “positive-and-negative intervals” contains the functions which are $+1$ within an interval $[\ell,r]$ and −1 elsewhere, as well as the functions which are −1 within an interval $[\ell,r]$ and +1 elsewhere.<br>For instance, the hypothesis $h_1(x)=sign(x(x−4))$ is a negative interval with -1 within $[0, 4]$ and +1 elsewhere, and hence belongs to $\mathcal{H}$. The hypothesis $h_2(x)=sign((x+1)(x)(x−1))$ contains two positive intervals in $[-1, 0]$ and $[1, \infty)$ and hence does not belong to $\mathcal{H}$.</strong></p><p>a. $N^2-N+2$</p><p>b. $N^2$</p><p>c. $N^2+1$</p><p>d. $N^2+N+2$</p><p>e. none of the other choices.</p><p>这个题目题意描述很长，但是看懂了并不难。实际上就是positive intervals的拓展，只不过原来是中间是正的，两边是负的,这时候情况与之前就不一样了。<br>之前，N个样本将这个直线划分成了N+1个区域，从中取两个，中间是正，外面是负，同时还包含一种全是负的情况，比如选的两个点在一个区域内，就会有全负的情况，因此结果是$C_{N+1}^2+1 =  frac{1}{2} N^2+ \frac{1}{2}N+1$;<br>而本题就要注意一些问题了，很直觉的想法是对上面的做法翻倍，但是实际上仔细想想，如果我们取到最边上的两个点，那么实际上就包含了全是正和全是负的结果，另一方面，只要我们取到了最边上的区域某个点，就会有重复的结果（与取另一端的端点是一样的），因此取到最边上的点应当只算一次。<br>所以我们要换个思路，一是两个点都不是端点区域的：$C_{N-1}^2$,<br>第二个是两个点有一个是端点区域的：$C_{N-1}^1 \times C_2^1 $,<br>最后一种情况是两个端点区域的，有两种情况，全正或者全负：2.<br>至于取相同区域的情况得到的结果是与最后一种情况一致的。<br>所以最后结果：$m_H(N) = N^2-N+2 $.</p><p>另一种讨巧的做法：当N = 3的时候，其他的答案都大于8，这是不可能发生的。</p><p><strong>7. Continuing from the previous problem, what is the VC-dimension of the hypothesis set of “positive-and-negative intervals on $\mathbb{R}$”?</strong></p><p>既然上面都得到成长函数了，很轻易可以得到结果，答案是3，当为N = 4时候，$N^2-N+2 = 14&lt;16$.</p><p><strong>8. What is the growth function $m_{\mathcal{H}}(N)$ of “positive donuts in $\mathbb{R}^2$”?</strong></p><p>The hypothesis set $\mathcal{H}$ of “positive donuts” contains hypotheses formed by two concentric circles centered at the origin. In particular, each hypothesis is +1 within a “donut” region of $a^2 \leq x_1^2+x_2^2 \leq b^2$ and −1 elsewhere. Without loss of generality, we assume $0 \lt a \lt b \lt \infty$.</p><p>a. $N+1$</p><p>b. $C_{N+1}^2+1$</p><p>c. $C_{N+1}^3+1$</p><p>d. none of the other choices.</p><p>e. $C_N^2+1$</p><p>这道题目是要在以原点为中心画两个圆，分布在环上的点为正，其余为负。看上去维度似乎变成了二维，实际上还是一维的：这个维度就是与原点的距离。如果与原点距离一致，它们的分类也是一样的。因此，我们简化一下这个问题，将与原点的距离画到一条线上，立马这个问题就成为一般的positive intervals问题了，答案也是一样的：$C_{N+2}^2+1$。</p><p><strong>9. Consider the “polynomial discriminant” hypothesis set of degree $D$ on $\mathbb{R}$, which is given by</strong></p><script type="math/tex; mode=display">\begin{eqnarray}\mathcal{H} = \left\{ h_{\bf{c}} \; \middle| \; h_{\bf{c}}(x) = {\rm{sign}}\left(\sum_{i=0}^D c_ix^i\right) \right\}\end{eqnarray}</script><p>What is the VC-dimension of such an $\mathcal{H}$?</p><p>这个不就是perceptron吗？答案是$D+1$.</p><p><strong>10.Consider the “simplified decision trees” hypothesis set on $\mathbb{R}^d$, which is given by</strong></p><script type="math/tex; mode=display">\begin{eqnarray}\mathcal{H}= \{h_{\mathbf{t},\mathbf{S}} \; | & \; h_{\mathbf{t},\mathbf{S}}(\mathbf{x}) = 2 [[\mathbf{v}\in S]] - 1,\text{ where} \; v_i = [[x_i>t_i]], & \\& \mathbf{S} \text{ a collection of vectors in } \{0,1\}^d,\mathbf{t} \in \mathbb{R}^d &\}\end{eqnarray}</script><p>That is, each hypothesis makes a prediction by first using the $d$ thresholds $t_i$ to locate $\mathbf{x}$ to be within one of the $2^d$ hyper-rectangular regions, and looking up $\mathbf{S}$ to decide whether the region should be +1 or −1.</p><p>What is the VC-dimension of the “simplified decision trees” hypothesis set?</p><p>a. $2^d$</p><p>b. $2^{d+1}-3$</p><p>c. $\infty$</p><p>d. none of the other choices.</p><p>e. $2^{d+1}$</p><p>这个题目看不大懂…</p><p><strong>11. Consider the “triangle waves’’ hypothesis set on $\mathbb{R}$, which is given by</strong></p><script type="math/tex; mode=display">\begin{eqnarray}\mathcal{H} = \{h_{\alpha} \; | & \; h_{\alpha}(x) = \text{sign}(| (\alpha x) \mbox{ mod } 4 - 2| - 1), \alpha \in \mathbb{R} \}\end{eqnarray}</script><p>Here $(z mod 4)$ is a number $z - 4k$ for some integer $k$ such that $z - 4k \in [0, 4)$. For instance, $(11.26 mod 4)$ is 3.26, and $(−11.26 mod 4)$ is 0.74. What is the VC-dimension of such an $\mathcal{H}$?</p><p>a. 1</p><p>b. 2</p><p>c. ∞</p><p>d. none of the other choices</p><p>e. 3</p><p>这个问题看上去很复杂，所以一步一步拆开来解决。<br>第一，这个点是分布在实数轴上的，所以我们要首先弄清楚轴上的那部分的点是+1，哪部分的点是-1.<br>如果是-1，则$|(\alpha x) mod 4 - 2| &lt; 1 $,可以推出来$(\alpha x) mod 4 \in (1,3)$,同理可以退出来如果是+1，则 $(\alpha x) mod 4 \in (0,1) \bigcup (3,4)$ ,根据题中负数取余数的定义，总结一下如下：</p><script type="math/tex; mode=display"> h_{\alpha}(x) = \left \{\begin{matrix}+1& \alpha x \in (-1+4k,1+4k) \\-1 & \alpha x \in (1+4k,3+4k)\end{matrix} \right.</script><p>对于N = 1和N = 2的时候，很容易可以知道各种情况都是可以shatter的。</p><p>（举个N=2的例子，如</p><p>$[0.6,0.7]—[+1,+1]; [0.6 \times \frac 9 6, 0.7 \times \frac 9 6 ]—[+1,-1];[0.6 \times \frac 29 6,0.7 \times \frac 29 6]—[-1,+1];[0.6 \times \frac 29 7,0.7 \times \frac 29 7]—[-1,-1]$）. </p><p>当N等于3的时候，也是可以被shatter。</p><p>实际上，取余的过程中有这么一个性质：$\alpha x mod 4 = [\alpha (x mod 4)] mod 4$，这意味着(假设有3个样本)，对于任何大小的$x_n$,我们都可以将它缩放到$[0,4)$的范围来进行处理。这个题目的答案是∞。但是如何证明我还不是很清楚。</p><p>In Questions 12-15, you are asked to verify some properties or bounds on the growth function and VC-dimension.</p><p><strong>12. Which of the following is an upper bounds of the growth function $m_\mathcal{H}(N)$ for $N \ge d_ \ge 2$?</strong></p><p>a. $m_H(⌊N/2⌋)$</p><p>b. $2^{d_{vc}}$</p><p>c. $ \min _{1 \leq i \leq N-1} 2^im_H(N-i)$</p><p>d. $\sqrt {N^{d_{vc}}}$</p><p>e. none of the other choices.</p><p>这个题目问的是成长函数。对于成长函数的界限，之前的博客已经有了以下的说明：</p><script type="math/tex; mode=display">B(N,k) \leq \sum _{i=0} ^{k-1} C_N^i</script><p>而上式中，$k = d+1$。<br>根据上式，我们可以很轻易的排除a,b两项。同时，如果举例计算，亦可以排除选项d。如，$B(6,3) = 22 ＞ \sqrt {6^2}$.</p><p>因此答案是c.至于对c的证明，我们可以从之前vc bound的表格里发现， </p><p>$B(N,d) = B(N-1,d-1)+B(N-1,d) \leq 2 \times B(N-1,d) \leq 4 \times B(N-2,d) \leq 2^i \times B(N-i,d)$，因此，任何 $2^im_H(N-i)$都是大于等于$m_H(N)$的，选择一个最小的即可。</p><p><strong>13. Which of the following is not a possible growth functions $m_{\mathcal{H}}(N)$for some hypothesis set?</strong></p><p>a. $2^N$</p><p>b. $2^{⌊ \sqrt {N} ⌋}$</p><p>c. 1</p><p>d. $N^2 -N +2$</p><p>e. none of the other choices.</p><p>答案是b. 首先，a,d的情况我们都遇到过，而c的情况也是很简单的，比如这个H对所有的样本都取正。至于b为什么错了，当N = 1的时候，$2^1 = 2$，而当N = 2的时候，$m_H(2) = 2$，<br>$m_H(3) =2$, $m_H(4) = 4$. 实际上是不可能出现成长函数呈现出这样的规律增长的，因为N个点中随意取N-1个出来，必然要满足之前的N-1个时候的所有要求（出现的情况与之前的N-1的各种情况一致，可以有重复，但是不能多也不能少），这保证了成长函数要么是严格单调增的，要么是不变的（我的理解）。</p><p><strong>14. For hypothesis sets $\mathcal{H}_1, \mathcal{H}_2, …, \mathcal{H}_K$ with finite, positive VC-dimensions d_(\mathcal{H}_k), some of the following bounds are correct and some are not.</strong></p><p>Which among the correct ones is the tightest bound on $d_(\bigcap_{k=1}^{K}!\mathcal{H}_k)$, the VC-dimension of the $\bf{intersection}$ of the sets?</p><p>(The VC-dimension of an empty set or a singleton set is taken as zero.)</p><p>这个题目是有K个H集合，每个集合都对应一个vc dimension，问题是这些集合的交集构成的集合的vc dimension的范围。</p><p>a. $ 0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k)$</p><p>b. $0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \min\{d_{vc}(H_k) \}_{k=1}^K $</p><p>c. $0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \max\{d_{vc}(H_k) \}_{k=1}^K $</p><p>d. $ \min\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \max\{d_{vc}(H_k) \}_{k=1}^K $</p><p>e. $ \min\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k) $</p><p>如果交集为空，那么vc dimension为0。同时，不管怎么说，H的大小不可能是比之前任何一个<br>$H_n$大，而且一定是之前任何一个集合的一部分。因此它的vc dimension也不会超过之前任何一个集合，所有答案很明显，是b.</p><p><strong>15. For hypothesis sets $\mathcal{H}_1, \mathcal{H}_2, …, \mathcal{H}_K$ with finite, positive VC-dimensions d_(\mathcal{H}_k), some of the following bounds are correct and some are not.</strong></p><p>Which among the correct ones is the tightest bound on $d_(\bigcup_{k=1}^{K}!\mathcal{H}_k)$, the VC-dimension of the $\bf{union}$ of the sets?</p><p>a.  $ 0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq K-1+\sum _{k=1} ^K d_{vc}(H_k)$</p><p>b. $ \min\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k) $</p><p>c. $ \max\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k) $</p><p>d. $ \max\{d_{vc}(H_k) \}_{k=1}^K  \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq K-1+\sum _{k=1} ^K d_{vc}(H_k) $</p><p>e. $0 \leq d_{vc}({\bigcap _{k=1}}^K H_k) \leq \sum _{k=1} ^K d_{vc}(H_k) $</p><p>这道题目与上一道刚好相反。首先，并集是包含所有的，因此它的vc dimension一定是大于最大的。所以就排除了a，b，d。然后，再c与d之间做选择.想象一个情况，$H_1$是将所有的点划分为正，$H_2$是将所有的点划分为负，$H_1+H_2$的vc dimension是1，但是各自的vc dimension为0.这样足以选出这个答案是d。如何证明？观察之前的那个表,可以举出更多的例子。但是如何得到这个具体的界限，需要更严格的数学证明。</p><p>For Questions 16-20, you will play with the decision stump algorithm.</p><p>16-20题目依然是编程问题。</p><p><strong>16. In class, we taught about the learning model of “positive and negative rays” (which is simply one-dimensional perceptron) for one-dimensional data. The model contains hypotheses of the form:</strong></p><script type="math/tex; mode=display">h_{s, \theta}(x) = s \cdot \mbox{sign}(x - \theta).</script><p>The model is frequently named the “decision stump’’ model and is one of the simplest learning models. As shown in class, for one-dimensional data, the VC dimension of the decision stump model is 2.</p><p>In fact, the decision stump model is one of the few models that we could easily minimize $E_{in}$ efficiently by enumerating all possible thresholds. In particular, for $N$ examples, there are at most $2N$ dichotomies (see page 22 of lecture 5 slides), and thus at most $2N$ different $E_{in}$ values. We can then easily choose the dichotomy that leads to the lowest $E_{in}$, where ties an be broken by randomly choosing among the lowest $E_{in}$ ones. The chosen dichotomy stands for a combination of some “spot” (range of $\theta$) and $s$, and commonly the median of the range is chosen as the $\theta$ that realizes the dichotomy.</p><p>In this problem, you are asked to implement such and algorithm and run your program on an artificial data set. First of all, start by generating a one-dimensional data by the procedure below:</p><p>(a) Generate $x$ by a uniform distribution in $[-1, 1]$.</p><p>(b) Generate $y$ by $f(x) = \tilde{s}(x)$+$noise$ where $ \tilde{s}(x) = sign(x)$ and the noise flips the result with $20%$ probability.</p><p>For any decision stump $h_{s, \theta}$ with $\theta \in [-1, 1]$, express $E_{out}(h_{s, \theta})$ as a function of $\theta$ and $s$.</p><p>a. $0.3+0.5s(|\theta| - 1)$</p><p>b. $0.3+0.5s(1 - |\theta|)$</p><p>c. $0.5+0.3s(|\theta| - 1)$</p><p>d. $0.5+0.3s(1 - |\theta|)$</p><p>e. none of the other choices.</p><p>虽然是编程题目，但是本道题目还没有涉及到代码编写，而是从理论分析这个问题。本题中数据生成是利用$sign(x)+noise$，其中noise出现的概率是20%。<br>我们可以知道，当$h_{s,\theta}(x)$在没有噪声的情况下，错误率是$\frac \theta 2$.</p><p>由第一题的分析可以知道，$E_{out} =  \frac {|\theta|} 2 \times (1 - 0.2) + (1 - \frac {|\theta|} 2) \times 0.2 = 0.3 |\theta| + 0.2$, 看了下似乎没有这个答案，这是因为我们没有考虑到符号的问题。如果考虑到符号，s是负的，那么原先的正确率反而变成错误率了, 即 $0.8 - 0.3 |\theta|$可以看到，答案选c。</p><p><strong>17. Generate a data set of size 20 by the procedure above and run the one-dimensional decision stump algorithm on the data set. Record $E_{in}$ and compute $E_{out}$ with the formula above. Repeat the experiment (including data generation, running the decision stump algorithm, and computing $E_{in}$ and $E_{out}$) 5,000 times. What is the average $E_{in}$? Please choose the closest option.</strong></p><p>a. 0.05</p><p>b. 0.15</p><p>c. 0.25</p><p>d. 0.35</p><p>e. 0.45</p><p>这道题目需要编程实现。首先，我们需要生成数据和噪音：<br>下面的代码生成20个数据，并用0.2的概率抽出来作为噪音。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sign</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">else</span> : <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateXY</span><span class="params">()</span>:</span></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span>  range(<span class="number">0</span>,<span class="number">20</span>):</span><br><span class="line">        x.append([random.random()*<span class="number">2</span><span class="number">-1</span>])</span><br><span class="line">    noise = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">20</span>):</span><br><span class="line">        ran = random.random()</span><br><span class="line">        <span class="comment">#print(ran)</span></span><br><span class="line">        <span class="keyword">if</span> ran &lt;= <span class="number">0.2</span>:</span><br><span class="line">            noise+=<span class="number">1</span></span><br><span class="line">            x[i].append(-sign(x[i][<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">else</span> :x[i].append(sign(x[i][<span class="number">0</span>]))</span><br><span class="line">    <span class="comment">#print("noise:",noise)</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>然后就是实现算法了。这个算法很简单，我们可以很轻易得枚举出来各种过程。同时为了简化算法，我没有实现s为负的场景，因为为负的场景最后大概率是选不到的。</p><p>首先，将随机数据排序，然后每次选择一个间隔，统计其之前与之后错误的分类个数。选择间隔的时候，首先选取d[i]，意味着现在选择的区域是(d[i-1],d[i])，将d[i]之前的作为-1，d[i]之后包括d[i]的作为+1，这样可以简化算法。值得注意的是i将会等于len(d)，因为间隔有len(d)+1个。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decision_stump</span><span class="params">(dataset)</span>:</span></span><br><span class="line"></span><br><span class="line">    sort_d = sorted(dataset)</span><br><span class="line">    min_pos = []</span><br><span class="line"></span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    min_err = len(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(dataset)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,i):</span><br><span class="line">            <span class="keyword">if</span> sort_d[k][<span class="number">1</span>]&gt;<span class="number">0</span>:</span><br><span class="line">                err+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(i,len(dataset)):</span><br><span class="line">            <span class="keyword">if</span> sort_d[k][<span class="number">1</span>]&lt;<span class="number">0</span>:</span><br><span class="line">                err+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> err &lt; min_err:</span><br><span class="line">            min_pos = []</span><br><span class="line">            min_pos.append(i)</span><br><span class="line">            min_err = err</span><br><span class="line">        <span class="keyword">elif</span> err == min_err:</span><br><span class="line">            min_pos.append(i)</span><br><span class="line">        err = <span class="number">0</span></span><br><span class="line"><span class="comment"># choose the lowest Ein randomly</span></span><br><span class="line">    choosen = int(len(min_pos)*random.random())</span><br><span class="line">    <span class="keyword">if</span> min_pos[choosen] &lt; len(sort_d):</span><br><span class="line">        <span class="keyword">return</span> [sort_d[min_pos[choosen]][<span class="number">0</span>],min_err]</span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> [(sort_d[min_pos[choosen]<span class="number">-1</span>][<span class="number">0</span>]+<span class="number">1</span>)/<span class="number">2</span>,min_err]</span><br></pre></td></tr></table></figure><p>结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">average Ein: 0.1713600000000006</span><br></pre></td></tr></table></figure></p><p>因此答案选b。</p><p><strong>18. Continuing from the previous question, what is the average E_{out}? Please choose the closest option.</strong></p><p>a. 0.05</p><p>b. 0.15</p><p>c. 0.25</p><p>d. 0.35</p><p>e. 0.45</p><p>对于Eout的计算，可以直接使用16中的公式带入。结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">average Eout: 0.25962811866336116</span><br></pre></td></tr></table></figure></p><p>因此答案选C.</p><p><strong>19. Decision stumps can also work for multi-dimensional data. In particular, each decision stump now deals with a specific dimension $i$, as shown below.</strong></p><script type="math/tex; mode=display">h_{s, i, \theta}(\mathbf{x}) = s \cdot \mbox{sign}(x_i - \theta).</script><p>Implement the following decision stump algorithm for multi-dimensional data:</p><p>a) for each dimension $i = 1, 2, \cdots, d$, find the best decision stump $h_{s, i, \theta}$ using the one-dimensional decision stump algorithm that you have just implemented.</p><p>b) return the “best of best” decision stump in terms of $E_{in}$. If there is a tie , please randomly choose among the lowest-$E_{in}$ ones.</p><p>The training data $\mathcal{D}_{train}$ is available at:</p><p><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw2_train.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw2_train.dat</a></p><p>The testing data $\mathcal{D}_{test}$ is available at:</p><p><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw2_test.dat" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw2_test.dat</a></p><p>Run the algorithm on the $\mathcal{D}_{train}$. Report the $E_{\text{in}}$​ of the optimal decision stump returned by your program. Choose the closest option.</p><p>在本例中，是将之前的算法用到多维度的数据上，分两步：1.对每个维度的数据运用上面的算法选出最佳的$E_in$;2.在所有的维度中选择一个最好的出来。</p><p>这个对应到实际中可能会出现，比如某个维度是真正起作用的，而其余的特征的作用不大。</p><p>实际上用到的算法与之前的一致。但是需要注意的是，因为这次我们对真实的$\theta,s$值一无所知，因为不能忽略s为负的情况。改进算法的步骤很简单，因为s为负的情况出错的个数就是所有样本个数减去s为正的情况出错的个数。</p><p>改正后的算法：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decision_stump</span><span class="params">(dataset)</span>:</span></span><br><span class="line"></span><br><span class="line">    sort_d = sorted(dataset)</span><br><span class="line">    min_pos = []</span><br><span class="line"></span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line">    isNeg = <span class="keyword">False</span></span><br><span class="line">    min_err = len(dataset)</span><br><span class="line">    size = len(dataset)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(dataset)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,i):</span><br><span class="line">            <span class="keyword">if</span> sort_d[k][<span class="number">1</span>]&gt;<span class="number">0</span>:</span><br><span class="line">                err+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(i,len(dataset)):</span><br><span class="line">            <span class="keyword">if</span> sort_d[k][<span class="number">1</span>]&lt;<span class="number">0</span>:</span><br><span class="line">                err+=<span class="number">1</span></span><br><span class="line">        isNeg = <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">if</span> err &lt; min_err:</span><br><span class="line">            min_pos = []</span><br><span class="line">            min_pos.append([i,isNeg])</span><br><span class="line">            min_err = err</span><br><span class="line">        <span class="keyword">elif</span> err == min_err:</span><br><span class="line">            min_pos.append([i,isNeg])</span><br><span class="line">        isNeg = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">if</span> (size - err) &lt; min_err:</span><br><span class="line">            min_pos = []</span><br><span class="line">            min_pos.append([i,isNeg])</span><br><span class="line">            min_err = size - err</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> (size - err) == min_err:</span><br><span class="line">            min_pos.append([i,isNeg])</span><br><span class="line">        err = <span class="number">0</span></span><br><span class="line"><span class="comment"># choose the lowest Ein randomly</span></span><br><span class="line">    <span class="comment">#print(min_pos)</span></span><br><span class="line">    choosen = int(len(min_pos)*random.random())</span><br><span class="line">    <span class="keyword">if</span> min_pos[choosen][<span class="number">0</span>] &lt; len(sort_d):</span><br><span class="line">        <span class="keyword">return</span> [sort_d[min_pos[choosen][<span class="number">0</span>]][<span class="number">0</span>],min_err,min_pos[choosen][<span class="number">1</span>]]</span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> [(sort_d[min_pos[choosen][<span class="number">0</span>]<span class="number">-1</span>][<span class="number">0</span>]+<span class="number">1</span>)/<span class="number">2</span>,min_err,min_pos[choosen][<span class="number">1</span>]]</span><br></pre></td></tr></table></figure></p><p>我们增添了一个isNeg的变量，来代表s是否是-1.</p><p>最后multi算法就是在不同维度上运行该算法，挑出错误最小的维度与$\theta$。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiDDecision_stump</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    min_err_d = []</span><br><span class="line">    min_err = <span class="number">0x7fffffff</span></span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)):<span class="comment">#</span></span><br><span class="line">        temp = decision_stump(dataset[i])</span><br><span class="line">        err = temp[<span class="number">1</span>]</span><br><span class="line">        <span class="comment">#print(err)</span></span><br><span class="line">        <span class="keyword">if</span> err &lt; min_err:</span><br><span class="line">            min_err = err</span><br><span class="line">            min_err_d = []</span><br><span class="line">            min_err_d.append([temp[<span class="number">0</span>],i,min_err,temp[<span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> err == min_err:</span><br><span class="line">            min_err_d.append([temp[<span class="number">0</span>],i,min_err,temp[<span class="number">2</span>]])</span><br><span class="line">    choosen = int(random.random()*len(min_err_d))</span><br><span class="line">    <span class="keyword">return</span> min_err_d[choosen]</span><br></pre></td></tr></table></figure></p><p>这道题目用到的数据是课程提供的，因此写入读取数据的过程：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataFrom</span><span class="params">(filename)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">with</span> open (filename) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline()[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">while</span> line:</span><br><span class="line">            temp = line.split(<span class="string">' '</span>)</span><br><span class="line">            <span class="comment">#print(temp)</span></span><br><span class="line">            <span class="keyword">if</span> len(result) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">for</span> x_i <span class="keyword">in</span> range(len(temp)<span class="number">-1</span>):</span><br><span class="line">                    result.append([[float(temp[x_i]),float(temp[<span class="number">-1</span>])]])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> x_i <span class="keyword">in</span> range(len(temp) - <span class="number">1</span>):</span><br><span class="line">                    result[x_i].append([float(temp[x_i]),float(temp[<span class="number">-1</span>])])</span><br><span class="line">            line = f.readline()[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>最后得到结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dimension: 3</span><br><span class="line">theta: 1.774</span><br><span class="line">Ein: 0.25</span><br></pre></td></tr></table></figure></p><p><strong>20. Use the returned decision stump to predict the label of each example within $\mathcal{D}_{test}$. Report an estimate of $E_{\text{out}}$ by $E_{\text{test}}$. Please choose the closest option.</strong></p><p>使用题目给的数据来做测试，估计$E_{out}$，需要一个检测错误的函数：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkout</span><span class="params">(min_err_d,dataset)</span>:</span></span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> dataset[min_err_d[<span class="number">1</span>]]:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> sign(i[<span class="number">0</span>] - min_err_d[<span class="number">0</span>]) != sign(i[<span class="number">1</span>]):</span><br><span class="line">            err += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> min_err_d[<span class="number">3</span>] == <span class="keyword">True</span>:</span><br><span class="line">        err =  len(dataset[<span class="number">0</span>]) - err</span><br><span class="line">    <span class="keyword">return</span> err</span><br></pre></td></tr></table></figure></p><p>最后结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eout: 0.36</span><br></pre></td></tr></table></figure></p><p>p.s. 10，11，15题目留有疑问。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Noise and Error</title>
      <link href="/2018/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Noise-and-Error/"/>
      <url>/2018/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Noise-and-Error/</url>
      
        <content type="html"><![CDATA[<p>上次的博客介绍了VC bound，用的是二元分类来证明。实际上推广到其他的线性回归等问题，我们只需要修改一些VC bound里相关的定义，最终一样可以得到类似的结果。<br><a id="more"></a><br>在有noise的情况下，VC bound也是成立的，学习一样是可行的。</p><p>本篇博客少了对上面这些论点的证明，因为我也不会。</p><p>这里主要介绍的是以些error measure的方法。一方面，我们想找到一个实际上$E_{in}$最小的解是一个NP-hard问题，因此只能尽可能去找到较好的解;另一方面，对不同的应用情景，可以定义不同的$E_{in}(h)$。用不同的定义来衡量错误。</p><p>我们之前的衡量g表现时候有3个特征：</p><ol><li>out of sample（通过对未见过的数据的预测进行衡量）</li><li>point wise（逐点衡量）</li><li>classification（二元分类问题）</li></ol><p>接着上面，我们已经知道二元分类有一个衡量方法，如下:</p><p>$E_{out}(g) = \epsilon _{x~P}[g(x) \neq f(x)]$</p><p>实际上也就是统计预测错误的个数。</p><p>在以后的学习中我们还是会使用point wise这个策略，每个点每个点的来进行计算。我们将衡量每个点的错误的办法记为$err(y’,y)$，那么上述衡量办法就是$err(y’,y) = [y’ \neq y]$<br>另外一种衡量错误的方法：</p><p>$err(y’,y) = (y - y’)^2$</p><p>这个衡量错误的办法适用于线性回归，因为它得到的y’是实数，因此可以定义与真实值的距离来衡量错误。</p><p>还有很多别的定义，如$err(y’,y) = |y - y’|$.</p><p>对于不同的衡量错误的方法，得到的最佳的学习算法很可能是不一致的。</p><p>在实际情况中，即使是二元分类问题，我们也可能有不同的衡量错误算法，下面介绍加权分类。因为错误的情况有两种，假正和假负，它们对于实际应用造成的代价可能是不一致的。比如一间超市搞促销，对于预测为正的顾客认为是回头客，会给予打折活动。这时候假负例的代价是很大的，因为可能会损失回头客，再如果是CIA情报局的门禁系统，对于预测为工作人员的准许进入，假正的代价会非常大，因此我们可以写出下面样子的两个表格，代表不同错误的权重：</p><div class="table-container"><table><thead><tr><th style="text-align:center">R\P</th><th style="text-align:center">+1</th><th style="text-align:center">-1</th><th style="text-align:center"></th><th style="text-align:center">R\P</th><th style="text-align:center">+1</th><th style="text-align:center">-1</th></tr></thead><tbody><tr><td style="text-align:center">+1</td><td style="text-align:center">0</td><td style="text-align:center">1000</td><td style="text-align:center"></td><td style="text-align:center">+1</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">-1</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center"></td><td style="text-align:center">-1</td><td style="text-align:center">10000</td><td style="text-align:center">0</td></tr></tbody></table></div><p>因此，对于加权分类的错误衡量办法，可以写成：</p><script type="math/tex; mode=display">err(y',y) = \frac {(y + 1)(y - y')} 4 a_1 + \frac {(1-y)( y' - y)} 4 a_2</script><p>上式中，$a_1$是预测为假正的权重，$a_2$是预测为假负的权重.</p><p>我们需要将错误衡量方法加入学习算法，才能使得最终的结果让$E_{in}$尽量小.</p><p>举个例子，对于pocket，假如采用上面回头客的例子中的权重来进行约束，那么pocket算法中，假负的代价很高，当遇到假负的情况时候，等价于复制了1000个相同的点，每个点权重一致。这要求我们在实际写算法时候，不光对于该点的惩罚翻了1000倍，同时还要让这个点下次被选中的概率变大。其他算法中也是一样的，如果一个情况的错误代价很大，我们不光要对代价增加，也要尽可能地改正这个错误。</p><p>最后，要说明除此之外的一种情况。有一种数据是unbalanced data，这样的数据加上了权重，依然可能会给一个很烂的学习算法很低的错误评价，比如cia的例子中，我们有999 990个员工的样本，只有10个入侵者的样本，那么即使假正的权重提升到10000，对于一个总是预测正确的算法，错误衡量依然只有0.1，似乎还不错的评价，而这个算法甚至算不上一个学习算法。这说明评价算法还有别的方面需要考虑，如以后可能提到的查准率与查全率。</p><p>以上。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——VC bound</title>
      <link href="/2018/08/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94VC-bound/"/>
      <url>/2018/08/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94VC-bound/</url>
      
        <content type="html"><![CDATA[<p>上次的Hoeffding不等式那篇，证明了一个hypothesis集合是有限集合，那么学习是可行的。<br><a id="more"></a><br>如果定义$E_{in}$是资料上的错误率，$E_{out}$是整体的错误率，我们证明的结果，如果N足够大，那么很大概率上，$E_{in} \approx E_{out}$.我们只需要在有限的集合利用里学习算法选出一个$E_{in}$最低的，就可以实现学习，因为很大概率上它对整体分类后的错误率也是与$E_{in}$差不太多的。</p><p>先思考一个问题，H的大小影响的了什么？学习需要做的有两个：1. 保证$E_{in} \approx E_{out}$ 2.找到一个h使得$E_{in}很小$。<br>如果H集合过大，那么我们不容易保证第一个条件，但是如果集合过小，我们不一定能找到一个h使得它甚至在测试数据上有很好的表现。</p><p>上次博客留下来了一个问题：如果这个$H$集合是无限集合呢？例如之前实现的PLA算法。那我们怎么保证在无限的集合上，学习是可行的呢？</p><p>首先，我们来观察上次得到的hoeffding不等式：$P_{baddata} \leq 2te^{-2\epsilon ^2N}.如果其中t-&gt;$\lnfty$，那么这个不等式实际上是没有意义的，因为右边的值将会远大于1，但是说一个概率小于等于1那是废话。</p><p>仔细想想，那是因为我们的union bound太宽松了。它们实际上会有很多重叠的部分，比如对于某个hypothesis是bad data，对于另一个它可能也是。这就要求我们将这个union bound继续压缩。</p><p>利用2D的perceptron learning algorithm来举例，如果N = 1，也就是我们只有一个样本，那么它要么是正要么是负，虽然平面上有无数条线，但是似乎只有这么两个效果，也就是只有这么两类线，在这两类线上，它们的$E_{in}$是一致的。</p><p>同样的道理，如果平面上有两个点，我们利用平面上的直线最多也就只能分成4种情况,我们将每一种情况称为一个dichotomy。</p><p>当N为3的时候，在纸上我们可以画出，平面上可以有8种dichotomy，但是也会有意外，例如如果3个点拍成一条直线，那么“× ○ ×”的情况，我们似乎无法用一条直线分开了。</p><p>当N为4的时候，即使4个点是每一个点都是凸四边形的顶点，我们依然无法将所有的情况都表示出来，如下面这种情况：</p><p>× ○</p><p>○ ×</p><p>实际上，当N为4的时候，我们可以分出来的dichotomy共有14种。而所有的情况有$2^4=16$种，很明显可以看出dichotomy的数量是少于$2^N$。</p><p>我们将某个大小为N的dataset所有情况都可以用这个H做出来(dichotomy的数量为$2^N$)，成为被H shatter。</p><p>当N&gt;4的时候，这个dichotomy又有多少？现在我们很难找到2d perceptron其中这个规律。幸运的是最后我们也不需要关注它具体是多少。</p><p>在这里我们考虑几种不同的简单的H，来更加熟悉这个概念：</p><ol><li>Positive Ray</li></ol><p>样本为1维的点，这个hypothesis set是在直线上所有的非样本点，选取一个点，该点坐标之前的为positive，之后的为negative。容易看出来，当样本个数为N时候，最多可以有N+1个dichotomy（N个点将该轴分为N+1个部分，每个部分的点是一类）。</p><ol><li>Positive Intervals</li></ol><p>样本依然是1维的点，这个hypothesis set是选取一个范围，范围内的为positive，范围之外的为negative。当样本个数为N的时候，最多可以有$\frac {(N+1)N} {2}+1$个dichotomy（N个点将该轴分为N+1个部分，从N+1个部分中任两个取一个点即可，但是这样还缺一种，就是全是positive的情况，我们依然可以做到将这个情况，只需要将两次的点选在同一个部分即可）。</p><ol><li>Convex Sets</li></ol><p>样本是二维的点，并且是凸N边形的顶点。选取一个凸多边形的范围，使得多边形内部为positive，外部为negative。可以看到任何时候这个dataset都可以被H shatter，所以它的dichotomy个数是$2^N$.</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/SEKLYM%60EURGS%40%5D4F%247%5B347X.png" alt="1"></p><ol><li>1D perceptron（positive/negative ray）</li></ol><p>与1类似，除了最端点的两个部分，其他的分割之后都有个与之对立的dichotomy，而端点的部分得到的是全p或者全n，所有是$2(N+1-2)+2 = 2N$.</p><p>而这个2N，N+1等等，我们乘其为成长函数。假设我们希望用$m_H$来代替乘进去的那个集合的大小，用$m_H(N)$来表示成长函数，例如：对于positive ray来说，$m_H(N) = N+1$。</p><h2 id="Break-Point"><a href="#Break-Point" class="headerlink" title="Break Point"></a>Break Point</h2><p>我们引入一个新的定义，叫做Break Point，它表示第一个所有情况下都不能被shatter的样本个数。我们将break point简写为k，举个例子，positive ray的k = 2，因为$2+1!=2^2$，同样的道理，positive intervals的k = 3，1D perceptron的k = 3，convex sets的k不存在。</p><p>如果用2D perceptron为例，他的k = 4，但是我们很难得到它的成长函数。我们希望它的成长函数可以是一个多项式，这样随着N的增加，$E_{in}$与$E_{out}$还是会很大可能相差不多的。</p><p>找不到成长函数，另一个希望是可以找到成长函数的上限。比如，在k = 4的情况下，N个样本最多能产生几个dichotomy？我们将这个简写为B(N,k).<br>k = 4，意味着任意3个样本都不能被shatter。我们试图去填写下面这样的一个表格：</p><div class="table-container"><table><thead><tr><th>B(N,k)</th><th style="text-align:center">1</th><th style="text-align:center">2</th><th style="text-align:center">3</th><th style="text-align:center">4</th><th style="text-align:center">5</th><th style="text-align:center">…</th><th>N</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">…</td><td>2</td></tr><tr><td>2</td><td style="text-align:center">1</td><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">4</td><td style="text-align:center">4</td><td style="text-align:center">…</td><td>4</td></tr><tr><td>3</td><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center">7</td><td style="text-align:center">8</td><td style="text-align:center">8</td><td style="text-align:center">…</td><td>8</td></tr><tr><td>4</td><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">15</td><td style="text-align:center">16</td><td style="text-align:center">…</td><td>16</td></tr><tr><td>5</td><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">31</td><td style="text-align:center">…</td><td>32</td></tr></tbody></table></div><p>表格中的已经填写的部分我们很容易就知道了，如果N &lt; k，那么可以shatter，答案就是$2^N$，如果N = k，那么恰好不能shatter，所以最多就是$2^N-1$,接下来我们尝试一个简单的,N = 3,k = 2的情况。我们一个个列举所看到的情况，很容易发现最多最多，可以写出4个dichotomy，任意两个都没有被shatter,如下：</p><p>o o o</p><p>o o x</p><p>o x x</p><p>x o o </p><p>我们再添加任何一种，都会导致有两个样本被shatter。</p><p>将 4 填入表中后，我们发现了一个有趣的规律，在已经填好的数据里，任何一个$B(N,k) = B(N-1,k)+B(N-1,k-1)$，不知道这是否是个巧合？</p><p>利用程序$^{见p.s1.}$将B(4,3)的情况跑出来，发现B(4,3)=11:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">11</span><br><span class="line">[0, 0, 0, 0]</span><br><span class="line">[1, 0, 0, 0]</span><br><span class="line">[0, 1, 0, 0]</span><br><span class="line">[1, 1, 0, 0]</span><br><span class="line">[0, 0, 1, 0]</span><br><span class="line">[1, 0, 1, 0]</span><br><span class="line">[0, 1, 1, 0]</span><br><span class="line">[0, 0, 0, 1]</span><br><span class="line">[1, 0, 0, 1]</span><br><span class="line">[0, 1, 0, 1]</span><br><span class="line">[0, 0, 1, 1]</span><br></pre></td></tr></table></figure></p><p>我们将0标为negative，1标为positive，经过整理可以得到下面的样子：</p><p>2α</p><script type="math/tex; mode=display">\begin{Bmatrix}X & X & X & X \\X & X & X & O \\X & X & O & X \\X & X & O & O \\X & O & X & X \\X & O & X & O \\O & X & X & X \\O & X & X & O\end{Bmatrix}</script><p>β</p><script type="math/tex; mode=display">\begin{Bmatrix}O & O & X & X \\O & X & O & X \\X & O & O & X \end{Bmatrix}</script><p>首先，前2α中每一组种每个dichotomy前3个是一致的，因此只看前3列，$\alpha + \beta \leq B(3,3)$，再看前α组的第一行的前3个，它们每两个必然不能shatter，否则加上第四列的就会出现3个样本被shatter的情况，因此$\alpha \leq B(3,2)$.</p><p>总的来说共有$2\alpha + \beta$种，它是小于等于B(3,3)+B(3,2)的。推广到更大的N，这个也依然是成立的，我简单说明一下其中的道理：</p><p>B(N-1,k-1)的dichotomy每个后面都增加一个O或者X，那么个数会翻倍，而且可以shatter的样本个数加一，这就是B(N,k)的一部分，其余部分的前N-1个元素不会出现相同的情况，如果相同，则前N-1个元素与之前的2*B(N-1,k-1)个必然会有k-1个被shatter，加上最后的一列会有k个被shatter，这与前提是矛盾的，而且剩余的个数是小于$B(N-1,k) - B(N-1,k-1)$的，不然依然会与条件矛盾。</p><p>因此，我们可以填满这张表格了：</p><div class="table-container"><table><thead><tr><th>B(N,k)</th><th style="text-align:center">1</th><th style="text-align:center">2</th><th style="text-align:center">3</th><th style="text-align:center">4</th><th style="text-align:center">5</th><th style="text-align:center">…</th><th>N</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">…</td><td>2</td></tr><tr><td>2</td><td style="text-align:center">1</td><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">4</td><td style="text-align:center">4</td><td style="text-align:center">…</td><td>4</td></tr><tr><td>3</td><td style="text-align:center">1</td><td style="text-align:center">4</td><td style="text-align:center">7</td><td style="text-align:center">8</td><td style="text-align:center">8</td><td style="text-align:center">…</td><td>8</td></tr><tr><td>4</td><td style="text-align:center">1</td><td style="text-align:center">5</td><td style="text-align:center">11</td><td style="text-align:center">15</td><td style="text-align:center">16</td><td style="text-align:center">…</td><td>16</td></tr><tr><td>5</td><td style="text-align:center">1</td><td style="text-align:center">6</td><td style="text-align:center">16</td><td style="text-align:center">26</td><td style="text-align:center">31</td><td style="text-align:center">…</td><td>32</td></tr></tbody></table></div><p>那么B(N,k) = B(N-1,k-1) +B(N-1,k) ,利用上面的表格一路上去，我们可以使用数学归纳法证明下式成立：</p><script type="math/tex; mode=display">B(N,k) \leq \sum _{i=0} ^{k-1} C_N^i</script><p>实际上等号也是成立的，但是证明需要更加复杂的数学理论。</p><p>而$C_N^i$的上限是$N^i$，那么$B(N,k)$首项最高项就是$N^{k-1}$，这是一个好消息，因为它的增长速度不够快。所以$m_H(N)$我们可以使用$N^{k-1}$来代替了（当$N \leq 2,k \leq 3$时）。</p><p>但是它能否直接带入原来的不等式呢？还是有点问题，实际上，我们无法保证</p><script type="math/tex; mode=display">P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|>\epsilon] \leq 2 m_H(N) e^{-2\epsilon ^2N}</script><p>我们最终得到的是下面的样子：</p><script type="math/tex; mode=display">P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|>\epsilon] \leq 2 \cdot 2 m_H(2N) \cdot e^{-2 \cdot \frac 1 {16} \epsilon ^2 N}</script><p>严格的证明需要很高的数学技巧以及数学理论，但是可以从以下3个方向简单解释下原因：</p><h4 id="1-finite-E-in-and-infinite-E-out"><a href="#1-finite-E-in-and-infinite-E-out" class="headerlink" title="1. finite $E_{in}$ and infinite $E_{out}$"></a>1. finite $E_{in}$ and infinite $E_{out}$</h4><p>我们的这些证明都是在只考虑了$E_{in}$的基础上，在泛化的过程中是有问题的。首先，对于dataset，$E_{in}$的个数是有限的，因为只要有break point，我们一定可以根据N与k找到h种类的上限，但是$E_{out}$的个数是无限的。虽然同一类h它们的$E_{in}$可能一致，但是它们的$E_{out}$并不一致。</p><p>如何对付这个无限的$E_{out}$？我们可以再从总体种抽出一个数目为N的dataset，它用H得到的错误率记为$E’_{in}$，然后我们用$E_{in}$与$E’_{in}$来解决这个问题，因为同样，$E’_{in}的个数是有限的$。</p><p>从下图中可以看出来，当$|E_{in}-E_{out}| \geq \epsilon$时候，$|E_{in}-E’_{in}| \geq \epsilon$的概率大概为1/2，当然可能会更大。</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/XU%5DTY%7DQ%24SSE4X%40B%24_A1ZORN.png" alt=""></p><p>不过实际上的其他情况下，$|E_{in}-E’_{in}| \geq \epsilon$也是有可能会发生的，因此</p><script type="math/tex; mode=display">\frac 1 2 P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)| > \epsilon] \leq P[∃h \ln H s.t. |E_{in}(h) - E'_{in}(h)| > \frac {\epsilon} 2]</script><p>为什么要对${\epsilon}$除以2，我也不清楚。$E_{out}$是无限的，如果$E_{out}$与$E_{in}$是一一对应的关系，那么不除以二上式也是成立的。也许因为是更严格的数学限制，但是不管怎么说经过复杂的数学证明（超出我的能力界限，交给统计学家与数学家吧），上式一定是成立的。</p><p>因此我们将无限的换成了有限的，这样离终点就进了一步。我们可以携程下面的样子：</p><p>$P[Baddata] \leq 2P[∃h \ln H s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$</p><h4 id="2-decompose-H-by-kind"><a href="#2-decompose-H-by-kind" class="headerlink" title="2. decompose H by kind"></a>2. decompose H by kind</h4><p>这一步，需要使用$m_H(N)$来处理上式的$∃h \ln H$，但是值得注意的是，因为我们后来又取了N个样本来做$E’_{in}$，因此所有的样本量是2N，需要替换为$m_H(2N)$,得到下面的结果：</p><p>$P[Baddata] \leq 2 m_H(2N) P[fixed h s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$</p><h4 id="3-hoeffding-without-replacement"><a href="#3-hoeffding-without-replacement" class="headerlink" title="3. hoeffding without replacement"></a>3. hoeffding without replacement</h4><p>第三个，就要用来处理$P[fixed h s.t. |E_{in}(h) - E’_{in}(h)| &gt; \frac {\epsilon} 2]$了。实际上，我们可以将上式写成下面的样子：</p><script type="math/tex; mode=display">P[fixed h s.t. |E_{in}(h) - \frac {E'_{in}(h)+E_{in}(h)} 2 | > \frac {\epsilon} 4 ]</script><p>仔细观察，上面其实就是hoeffding不等式的一种，只不过这时候的bin不是无限大了，但是最后结果是一样的。（从2N个抽出N个，算出错误的比率，与实际上2N的错误的比率的差）（<font color="red">实际上我对这个解释是存有疑虑的，这个随机抽出2N个应该是从整体出发的，而不是从2N个中抽出来N个，算这个期望差，也许可以从数学上证明二者概率是一致的吧</font>）。</p><p>代入hoeffding不等式可以得到最终的结果：</p><script type="math/tex; mode=display">P[∃h \ln H s.t. |E_{in}(h) - E_{out}(h)|>\epsilon] \leq 2 \cdot 2 m_H(2N) \cdot e^{-2 \cdot \frac 1 {16} \epsilon ^2 N}</script><p>这就是对怎么得到最终结果的简单的说明。严格的证明是非常复杂的。不过我们好歹似乎明白了那么一点点其中的道理。</p><h2 id="VC-bound"><a href="#VC-bound" class="headerlink" title="VC bound"></a>VC bound</h2><p>上面的简单证明得到的结果，叫做Vapnik Chervonenkis Bound，简称为VC bound。</p><p>引入一个新的定义，叫做VC dimension，它的定义与break point非常类似，VC dimension = k - 1，也就是最后一个可以在某种dataset下被shatter的dataset的大小。</p><p>现在我们尝试推算一下 perceptrons 的 VC dimension.</p><p>对于1维的来说很简单， 它的VC dimension 是 2.</p><p>对于2维的来说，由之前的也可以得到是 3.</p><p>那么对于d维的perceptron，我们可以猜测，它的vc dimension 难道是 d+1吗？</p><p>为了证明V(d) = d+1,我们需要证明两点：1. $V(d) \geq d+1$ 2. $ V(d) \leq d+1$.</p><p><strong>证明$V(d) \geq d+1$：</strong></p><p>首先，构造下面一个d+1*d+1的矩阵：</p><script type="math/tex; mode=display">\begin{bmatrix}1&0&0&0&0&...&0 \\1&1&0&0&0&...&0 \\1&0&1&0&0&...&0 \\...\\1&0&0&0&0&...&1\end{bmatrix}</script><p>上述矩阵每一行都是一个样本的，是d维的，不过会加上额外的$x_0$维度。<br>共有d+1个样本。</p><p>回想perceptron，$XW = Y$(在本例中),而上述矩阵是可逆的，则$W = YX_{-1}$，因此不管Y怎么变，都有W可以使得它成立，因此至少上面的这个dataset可以被H shatter，所有$V(d) \geq d+1$.</p><p><strong>证明$V(d) \leq d+1$：</strong></p><p>为了证明上式，我们要再加入一个样本，证明无论如何d+2个样本是不能被shatter的。</p><p>我们再上面的矩阵里再加一个非零的行向量$X_{d+2}$，那么由线性代数可以知道:</p><script type="math/tex; mode=display">X_{d+2} = \sum _{i = 1}^{d+1} a_iX_i</script><p>因此 $X_{d+2}W = \sum _{i = 1}^{d+1} a_iX_iW$.</p><p>则 y = $\{sign(a_1),sign(a_2),…sign(a_{d+1}) ,-1 \}$这种情况就一定是不能生成的($a_iX_iW$后每一项都是大于等于0的)。<br>所以d+2个样本是无法被shatter的.</p><p>如果前d+1个样本都不能被shatter，就更不用说d+2个可以被shatter了。</p><p>所以我们可以得到，V(d) = d+1.</p><p>VC dimension 实际上是自由度，一般来说，它是互不依赖的可以变动的参数个数（并不一定总是这样）。</p><h2 id="Interpreting-of-VC-dimension"><a href="#Interpreting-of-VC-dimension" class="headerlink" title="Interpreting of VC dimension"></a>Interpreting of VC dimension</h2><p>Hoeffding 告诉我们坏事情发生的概率，我们现在反推，好事情发生的概率，很简单如下：</p><p>$P[|E_{in}(g) - E_{out}(g)|&lt; \epsilon ] \geq 1 -  4(2N)^{d_{vc}}e^{- \frac 1 8 \epsilon ^2 N} $</p><p>如果将大于等于后复杂的那一部分（VC bound）列为$\delta$，那么经过推算可以得到：</p><script type="math/tex; mode=display">\epsilon = \sqrt {\frac 8 N \ln  {(\frac {4(2N)^{d_{vc}}} {\delta })}}</script><p>那么我们可以在$1 - \delta$的概率下获得保证$E_{out}$在这个范围内：</p><script type="math/tex; mode=display">\left [ E_{in}(g) - \sqrt {\frac 8 N \ln {(\frac {4(2N)^{d_{vc}}} {\delta })}}, E_{in}(g) + \sqrt {\frac 8 N \ln {(\frac {4(2N)^{d_{vc}}} {\delta })}} \right ]</script><p>我们比较重视右边的部分，也就是$E_{out}$最坏是多少。我们称$\sqrt {…}$为penalty for model complexity，记为${\Omega (N,H,\delta)}$.</p><p>一般来说，有个以下的关系图：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/M%29P32DW%29EE9%7BWB%246A08T8%29X.png" alt=""></p><p>从上面可以看出来，如果样本个数一定而且保证很高的probability，一味增加维度（增加新的特征）可能会出现过拟合的情况，因为它增加了模型复杂度。这启发了我们在机器学习时候不一定非要增加过多的特征量，或者一味地去降低$E_{in}$，从而导致泛化能力不强。</p><p>此外，我们还需要注意一点，如果我们利用VC bound去求所需要的数据量，往往得到一个很大的值，但是实际上一般来说只要10$d_{vc}$就差不多足够了，这说明VC bound是很宽松的。因为我们一直取的都是上限，但是我们也很难在包容这么多分布的情况下找到一个更好的界限。</p><p>到这里，就说的差不多了，我们证明了如果有VC dimension，那么在N足够大的情况，可以取得不错的学习效果。同时也启发了以后我们在机器学习上的一些做法。</p><h2 id="p-s"><a href="#p-s" class="headerlink" title="p.s."></a>p.s.</h2><ol><li><p>用程序生成B(4,3)，我使用的是很简单的程序，但是应该可以证明这样生成的dichotomy个数就是最大的个数。程序如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">(result,l)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> in_a <span class="keyword">in</span> [[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]:</span><br><span class="line">        exist = [<span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">8</span>)]</span><br><span class="line">        size = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            temp = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> bit <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                temp+=(i[in_a[bit]]&lt;&lt;bit)</span><br><span class="line">            <span class="keyword">if</span> exist[temp] == <span class="number">0</span>:</span><br><span class="line">                exist[temp] = <span class="number">1</span></span><br><span class="line">                size+=<span class="number">1</span></span><br><span class="line">        temp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> bit <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            temp += (l[in_a[bit]] &lt;&lt; bit)</span><br><span class="line">        <span class="keyword">if</span> exist[temp] == <span class="number">0</span>:</span><br><span class="line">            exist[temp] = <span class="number">1</span></span><br><span class="line">            size += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> size == <span class="number">8</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">four_three</span><span class="params">()</span>:</span></span><br><span class="line">    l = []</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">16</span>):</span><br><span class="line">        temp = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">            temp.append((i&gt;&gt;j)&amp;<span class="number">1</span>)</span><br><span class="line">        l.append(temp)</span><br><span class="line"></span><br><span class="line">    result.append(l[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">16</span>):</span><br><span class="line">        <span class="keyword">if</span> check(result,l[i]):</span><br><span class="line">            result.append(l[i])</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    result = four_three()</span><br><span class="line">    print(len(result))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">        print(i)</span><br></pre></td></tr></table></figure></li><li><p>hoeffding不等式是无需知道数据分布情况的，也就是对于任何分布它都适用，这也是为何VC bound很宽松的一个原因。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——（基石）作业1</title>
      <link href="/2018/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A1/"/>
      <url>/2018/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%EF%BC%88%E5%9F%BA%E7%9F%B3%EF%BC%89%E4%BD%9C%E4%B8%9A1/</url>
      
        <content type="html"><![CDATA[<p>总共20道题目。<a id="more"></a></p><p><strong>1. Which of the following problems are best suited for machine learning?</strong></p><p>(i) Classifying numbers into primes and non-primes</p><p>(ii) Detecting potential fraud in credit card charges</p><p>(iii) Determining the time it would take a falling object to hit the ground</p><p>(iv) Determining the optimal cycle for traffic lights in a busy intersection</p><p>(v) Determining the age at which a particular medical test is recommended</p><p>这个题目比较简单，其中1和3很明显不是机器学习问题，我们清楚质数与非质数的规则，也知道物体下落公式，不需要机器去学习，其他正确，答案是2，4，5.</p><p>For Questions 2­-5, identify the best type of learning that can be used to solve each task below.</p><p><strong>2. Play chess better by practicing different strategies and receive outcome as feedback.</strong></p><p>reinforcement learning———加强学习，因为需要不断加强，学习过程是连续的。</p><p><strong>3. Categorize books into groups without pre-defined topics.</strong></p><p>unsupervised learning————很明显是无监督学习。</p><p><strong>4. Recognize whether there is a face in the picture by a thousand face pictures and ten thousand non­face pictures.</strong></p><p>supervised learning————数据已经标好标签。</p><p><strong>5. Selectively schedule experiments on mice to quickly evaluate the potential of cancer medicines.</strong></p><p>active learning————实验的次数是有限的，可能无法做出海量次数的实验，因此需要根据少数实验结果（即部分样本有标签），这实际上是半监督学习的一种，当遇到机器无法决断的时候再去人工标签，也就是主动学习。</p><p>Question 6-8 are about Off-Training-Set error.</p><p>6.<img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/B%247SX%5BIV_SSX4LWNA%5BO7%7EM6.png" alt="6"></p><p>这个题目中样本$x_1,…x_n$为训练集，而其余L个为测试集。正确的分类是所有的都是+1，而我们得到的$g(x)$是样本中下标为奇数的是+1，也就是大概会错一半。具体错多少？<br>总体样本错的也就是⌊$\frac {N+L} 2​​$⌋，而除去训练集中会错的⌊$\frac {N} 2​​$⌋答案是第五个。</p><p><strong>7. We say that a target function $f$ can “generate” $\mathcal{D}$ in a noiseless setting if $f(x_n)=y_n$​ for all ($x_n$, $y_n$) $\in \mathcal{D}$.<br>For all possible f$ \colon \mathcal{X} \rightarrow \mathcal{Y}$, how many of them can generate $\mathcal{D}$ in a noiseless setting?</strong></p><p>这个题目意思容易让人曲解，实际上问的是外面测试集大小为L，那么有多少种可能的f，f满足D中的样本，但是对于测试集中是无所谓的，因此可能的f有$2^L$个。</p><p>8.<img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/22%24ZSJYPDBCLC0U%7EC7%7DP87Q.png" alt="8"><br>这个题目主要在考察的是NFL定理。如果所有可以generateD的f是等概率的，也就是对于测试集中样本的+1，-1是完全随机的，那么所有学习算法得到的误差期望都是一致的。所以选2.</p><p>For Questions 9-12, consider the bin model introduced in class. </p><p><strong>9. Consider a bin with infinitely many marbles, and let μ be the fraction of orange marbles in the bin, and ν is the fraction of orange marbles in a sample of 10 marbles. If μ=0.5, what is the probability of ν=μ?</strong></p><p>这是一道比较简单的概率题。u = 0.5，求选出10个出来有5个是橘色的概率。因为这个仓库箱子里弹珠的个数是无穷的，所以即使不放回，每次取出来依然近似于独立重复实验。则<br>$p = C_{10}^5 {\frac 1 2}^{10} \approx 0.246$.</p><p><strong>10. If μ=0.9, what is the probability of ν=μ?</strong></p><p>与上面类似：$p = C_{10}^9 {0.9}^9 \times 0.1 \approx 0.387$.</p><p><strong>11. If μ=0.9, what is the actual probability of ν≤0.1?</strong></p><p>这个问题就上面来说稍微复杂了一点，但是也不难。v≤0.1也就是10个中抽到了1个或者0个。<br>$p = C_{10}^9 {0.9}^1 \times 0.1^9 + C_{10}^{10} {0.1}^{10} = 9.1 \times 10^{-9}$.</p><p><strong>12. If μ=0.9, what is the bound given by Hoeffding’s Inequality for the probability of ν≤0.1?</strong></p><p>由题目可以知道$\epsilon$ = 0.8,带入公式可以得到概率上界为$2e^{-12.8} \approx 5.52 \times 10^{-6}$</p><p>Questions 13­-14 illustrate what happens with multiple bins using dice to indicate 6 bins. Please note that the dice is not meant to be thrown for random experiments in this problem. They are just used to bind the six faces together. The probability below only refers to drawing from the bag.</p><p><strong>13. Consider four kinds of dice in a bag, with the same (super large) quantity for each kind.</strong></p><p>A: all even numbers are colored orange, all odd numbers are colored green</p><p>B: all even numbers are colored green, all odd numbers are colored orange</p><p>C: all small (1~­3) are colored orange, all large numbers (4­~6) are colored green</p><p>D: all small (1­~3) are colored green, all large numbers (4~­6) are colored orange</p><p>If we pick 5 dice from the bag, what is the probability that we get 5 orange 1’s?</p><p>简单翻译下题目：袋子里有4种骰子，第一种2，4，6面为橘色，第二种1，3，5面为橘色，第三种1，2，3面为橘色，第四种4，5，6面为橘色。4种筛子比例相同，骰子数目很多。第一道题目问到，拿5个骰子出来，5个骰子第一面都是橘色的概率？</p><p>1面是橘色，我们可以将上面4类分成2类了，其中第二与第三合并，每次取出来1面为橘色的概率是0.5，所以5个都是的概率是$\frac 1 {32}$。</p><p><strong>14. If we pick 5 dice from the bag, what is the probability that we get “some number” that is purely orange?</strong></p><p>我们拿出5个骰子，至少有一面全部都是橘色的概率。</p><p>这个就是稍微复杂的一个问题。首先观察骰子种类，我们发现，只要第一种与第二种碰面，或者第三种与第四种碰面，那么就不可能有一面全都是橘色。所以我们要求的就是上面两种情况不发生的概率。</p><p>如果抽出的5个骰子，占了4种骰子种的3种或者4种，那么上面的情况至少会有一种会发生。<br>而取5次取出3种的情况有2 2 1与 3 1 1两种可能。</p><p>首先，从4种里选3种出来$C_4^3$,其次，考虑2 2 1的情况$C_5^2C_3^2$,而2 2 1又会有3种分布，因此2 2 1的所有可能情况是$3C_4^3C_5^2C_3^2 = 360$.</p><p>3 1 1与上述类似$3C_4^3C_5^3C_2^1 = 240$.</p><p>然后考虑从4种取4种的情况，只会有一种分布：1 1 1 2，可以得到$4C_5^2C_3^1C_2^1 = 240$.</p><p>最后我们就要考虑到从4种中取出来两种，而且恰好是第一种与第二种，或者第三种与第四种的概率。骰子有两种的次数分布有2种情况：1 4，2 3.</p><p>1 4: 2$C_5^4 = 10$</p><p>2 3: $2C_5^3 = 20$</p><p>考虑到第一种与第二种，第三种与第四种，因此结果还应乘2，最后结果是：60.</p><p>所以，所有不符合的情况共有240+240+60+360 = 900，因此这道题目最后结果是$1 - \frac {900} {4^5} = \frac {31} {256}$.</p><p>For Questions 15-20, you will play with PLA and pocket algorithm. </p><p>15-20为编程题目，需要自己写代码验证，然后得到结果。</p><p><strong>15.  First, we use an artificial data set to study PLA. The data set is in<br><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_15_train.dat" target="_blank" rel="noopener">data</a>.Each line of the data set contains one ($\mathbf{x}_n, y_n$) with $\mathbf{x}_n \in \mathbb{R}^4$. The first 4 numbers of the line contains the components of $\mathbf{x}_n$ orderly, the last number is $y_n$.<br>Please initialize your algorithm with $\mathbf{w} = 0$ and take $sign(0)$ as -1. Please always remember to add $x_0 = 1$ to each $\mathbf{x}_n​$.Implement a version of PLA by visiting examples in the naive cycle using the order of examples in the data set. Run the algorithm on the data set. What is the number of updates before the algorithm halts?</strong></p><p>a.&lt;10 updates</p><p>b.11 - 30 updates</p><p>c.31 - 50 updates</p><p>d.$\geq$ 201 updates</p><p>e.51 - 200 updates</p><p>这道题目只需要应用上次实现的PLA算法，需要额外做的是数据的读取。在数据读取时候我运用了正则表达式来进行分割，整个过程整合在一个叫做readDataFrom函数中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataFrom</span><span class="params">(filename)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    separator = re.compile(<span class="string">'\t|\b| |\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(filename,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline()</span><br><span class="line">        <span class="keyword">while</span> line:</span><br><span class="line">            temp = separator.split(line)[<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">            abc = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> temp]</span><br><span class="line">            result.append(abc)</span><br><span class="line">            line = f.readline()</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p><p>最后得到结果是修正了61次。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修正次数： 61</span><br></pre></td></tr></table></figure></p><p><strong>16. Implement a version of PLA by visiting examples in fixed, pre-determined random cycles throughout the algorithm. Run the algorithm on the data set. Please repeat your experiment for 2000 times, each with a different random seed. What is the average number of updates before the algorithm halts?</strong></p><p>a.&lt;10 updates</p><p>b.11 - 30 updates</p><p> c.31 - 50 updates</p><p>d.$\geq$ 201 updates</p><p>e.51 - 200 updates</p><p>这个版本需要对原来的pla算法进行简单的修改，每次寻找预测错误的样本时候采用随机的顺序去寻找。对于序列进行随机的办法实现方法很简单，也就是打乱序列，做法是与随机的坐标进行交换：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomIndex</span><span class="params">(n)</span>:</span></span><br><span class="line">    index = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,n)]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">swap</span><span class="params">(l,x,y)</span>:</span></span><br><span class="line">        l[x] = l[x]+l[y]</span><br><span class="line">        l[y] = l[x] - l[y]</span><br><span class="line">        l[x] = l[x] - l[y]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,n):</span><br><span class="line">        swap(index,i,int(random.random()*n))</span><br><span class="line">    <span class="keyword">return</span> index</span><br></pre></td></tr></table></figure></p><p>应用上面的函数生成随机打乱的序列，然后代替顺序查找，运行2000次平均修正次数如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修正次数： 61.3933</span><br></pre></td></tr></table></figure></p><p>**17. Implement a version of PLA by visiting examples in fixed, pre-determined random cycles throughout the algorithm, while changing the update rule to be </p><script type="math/tex; mode=display">\mathbf{w}_{t+1} \leftarrow \mathbf{w}_t +\eta y_{n(t)}\mathbf{x}_{n(t)}</script><p>with η=0.5. Note that your PLA in the previous Question corresponds to η=1. Please repeat your experiment for 2000 times, each with a different random seed. What is the average number of updates before the algorithm halts?**<br>a.&lt;10 updates</p><p>b.11 - 30 updates</p><p>c.31 - 50 updates</p><p>d.$\geq$ 201 updates</p><p>e.51 - 200 updates</p><p>只需要对上述算法进行简单改动即可.运行2000次后平均修正次数如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修正次数： 63.532</span><br></pre></td></tr></table></figure></p><p><strong>18. Next, we play with the pocket algorithm. Modify your PLA in Question 16 to visit examples purely randomly, and then add the “pocket” steps to the algorithm. We will use <a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_18_train.dat" target="_blank" rel="noopener">train</a> as the training data set $\mathcal{D}$, and <a href="https://www.csie.ntu.edu.tw/~htlin/mooc/datasets/mlfound_math/hw1_18_test.dat" target="_blank" rel="noopener">test</a> as the test set for “verifying’’ the gg returned by your algorithm (see lecture 4 about verifying). The sets are of the same format as the previous one. Run the pocket algorithm with a total of 50 updates on $\mathcal{D}$ , and verify the performance of $\mathbf{w}_{POCKET}$ using the test set. Please repeat your experiment for 2000 times, each with a different random seed. What is the average error rate on the test set?</strong></p><p>a. &lt;0.2</p><p>b. 0.2 - 0.4</p><p>c. 0.4 - 0.6</p><p>d. $\geq$ 0.8</p><p>e. 0.6 - 0.8</p><p>这个题目需要实现pocket算法。pocket算法之前没有介绍，因为它和pla很像，只是pla算法的一个变形。因为我们无法保证数据一定是线性可分的，为此我们每次遇到错误更新后，与之前的w进行对比，如果错误率更低，再更新这个参数，同时pla算法选择错误的样本时候是随机顺序选择的，从之前的代码验证中我们也发现了随机对于减小修正次数来说是有好处的（但是生成随机序列同样也会带来额外开销）。</p><p>实现pocket算法只需要多加几行代码以及做少量改动，这里就不列出来了。值得注意的是需要添加一个新的函数，进行错误评估：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeER</span><span class="params">(para,datas)</span>:</span></span><br><span class="line">    size = len(datas)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> size &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    dms = len(datas[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> dms == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, size):</span><br><span class="line">        p = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, dms - <span class="number">1</span>):</span><br><span class="line">            p += para[x] * datas[i][x]</span><br><span class="line">        p += para[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> p &lt;= <span class="number">0</span> <span class="keyword">and</span> datas[i][<span class="number">-1</span>] &gt; <span class="number">0</span> <span class="keyword">or</span> p &gt; <span class="number">0</span> <span class="keyword">and</span> datas[i][<span class="number">-1</span>] &lt; <span class="number">0</span>:<span class="comment">#ignore </span></span><br><span class="line">            count=count+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count/size</span><br></pre></td></tr></table></figure></p><p>下面是运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">平均错误率： 0.12437000000000001</span><br></pre></td></tr></table></figure></p><p><strong>19. Modify your algorithm in Question 18 to return $\mathbf{w}_{50}$ (the PLA vector after 5050 updates) instead of $\hat{\mathbf{w}}$ (the pocket vector) after 50 updates.Run the modified algorithm on $\mathcal{D}$, and verify the performance using the test set.Please repeat your experiment for 2000 times, each with a different random seed. What is the average error rate on the test set?</strong></p><p>a. &lt;0.2</p><p>b. 0.2 - 0.4</p><p>c. 0.4 - 0.6</p><p>d. $\geq$ 0.8</p><p>e. 0.6 - 0.8</p><p>这个算法返回pla向量。运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">平均错误率： 0.3666599999999999</span><br></pre></td></tr></table></figure></p><p><strong>20. Modify your algorithm in Question 18 to run for 100 updates instead of 50, and verify the performance of \$mathbf{w}_{POCKET}$ ​using the test set. Please repeat your experiment for 2000 times, each with a different random seed. What is the average error rate on the test set?</strong></p><p>a. &lt;0.2</p><p>b. 0.2 - 0.4</p><p>c. 0.4 - 0.6</p><p>d. $\geq$ 0.8</p><p>e. 0.6 - 0.8</p><p>很简单的改动，运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">平均错误率： 0.10796000000000007</span><br></pre></td></tr></table></figure></p><h2 id="Note："><a href="#Note：" class="headerlink" title="Note："></a>Note：</h2><ol><li><p><em>刚开始对pocket算法的理解有误，以为wt的更新是每次都对pocket中的w为基准的，实际上它就是正常的pla算法运行的过程，仔细思考这样确实比原来的算法更快。第二，pocket算法中随机选取错误意味着每次都要随机打乱样本，这样可以获得更低的错误率。</em></p></li><li><p><em>python不支持i++,++i这种操作，但是，为何不报错…</em></p></li><li><p><em>list直接赋值只是对源对象进行了引用，同时有浅拷贝与深拷贝之分。这个狠狠地坑了我一把。</em></p></li><li><p>15，16，17题目前运行依然是60多次.答案是31到50。———<br>更新于8.8。 我忽略了cycle这个词，也就是找错误的过程应该从上次断掉的地方继续开始，更新后得到正确的结果。<br>受到影响的代码重新跑了一遍：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">15. 修正次数： 46</span><br><span class="line">16. 修正次数： 40.867</span><br><span class="line">17. 修正次数： 41.5105</span><br></pre></td></tr></table></figure></li></ol><p>代码上传至<a href="https://github.com/MyEvolution/PLA" target="_blank" rel="noopener">github</a>，修改了上次可视化的内容，不过只是修改了接口内容。</p><p>代码几乎没怎么写注释，这是需要改进的地方。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> homework </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——Hoeffding不等式</title>
      <link href="/2018/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Hoeffding%E4%B8%8D%E7%AD%89%E5%BC%8F/"/>
      <url>/2018/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Hoeffding%E4%B8%8D%E7%AD%89%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>这次用霍夫丁不等式来证明学习的可行性。首先要说明一个定理，叫做“No Free Lunch”定理。如果真是需要预测的值是完全随机的情况下，我们无论最后建立一个什么样的模型，误差期望都是一致的。这样学习似乎是不可行的。<a id="more"></a>但是实际上，事物都有自己的规律。我们可以套用霍夫丁不等式来说明，在某个验证集上这个模型的准确率是p，那么在总体上它预测的实际准确率很大可能与p是相差不大的（Probably Approximately Correct）。</p><p>Hoeffding不等式：$P[\nu  - \upsilon|&gt; \epsilon ] \leq 2 e^{-2\epsilon ^2N}$</p><p>其中$\nu$是我们测的期望，而$\upsilon$是真实期望，这是未知的，N是测试抽取的样本数量，而$\epsilon$是我们可以容忍的误差值，因此实际上也就是$\upsilon ∈ [\nu - \epsilon , \nu + \epsilon]$的概率是大于等于$2 e^{-2\epsilon ^2N}$的，也就是置信区间与置信度的关系。</p><p>因此霍夫丁不等式对独立随机变量的和与其期望值偏差的概率上限。</p><p>从另一个简单的例子来说：假如我们有一个罐子里装了红球和绿球，我们想要测的是红球的占比。每次取出N个球，则这N个球中红球占比为$\nu$，而总体红球占比为$\upsilon$，我们假设可以接受的误差范围为$\epsilon$，那么这几个量满足霍夫丁不等式。总体球中取出N个有m中不同的组合，而这些组合中红球占比误差很大的组合占了所有组合的比重是小于$2 e^{-2\epsilon ^2N}$的。而这些误差很大的样本组合就是所谓的Bad Data。因为从它测出来的值与实际值偏差很大。</p><p>从另一方面来讲，如果我们测试的数目足够多，依然很有可能选到错误样本。就像你我是天才的概率很小，但这个世界总会出现天才。用霍夫丁不等式来说，假如我们测试了t次，那么出现一次bad data 的概率是小于$2te^{-2\epsilon ^2N}$，为什么可以简单相加？如下：</p><p>假如一件事发生的概率是p，那么n次它至少发生一次的概率是$1-(1-p)^n$。</p><p> 令 $g(p) = 1- (1-p)^n - np, g’(p) = n(1-p)^{n-1} - n = n[(1-p)^{n-1} - 1];$<br> 令$g’(p) = 0$,则$p = 0;$<br> 当p$∈[0,1]$时候， $g’(p) \leq 0, g(0) = 0$,所以$g(p)\leq 0$;<br> 因此 $1- (1-p)^n \leq np$</p><p>上述是一个简单的证明，而实际上独立随机变量至少发生一件的概率是小于它们各自发生的概率之和的。在概率论中这相当于是个常识。</p><p>应用到机器学习当中，如果H是有限的，也就是我们可选假说个数是有限的，只要选取足够大的测试样本量（Hoeffding不等式中的N足够大），出现错误估计的概率依然是非常小的，该test dataset有很大的概率对每个假说都能正确评估它在总体样本上的性能，因此我们可以选择一个表现最好的来当做g，它对大多数样本都会使用，相比之下也就更接近f。</p><p>这就说明学习是可行的。</p><p>这里还有个问题：如果H的个数是无限的呢？</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Fibonacci数列——快速矩阵幂</title>
      <link href="/2018/08/01/Fibonacci%E6%95%B0%E5%88%97%E2%80%94%E2%80%94%E5%BF%AB%E9%80%9F%E7%9F%A9%E9%98%B5%E5%B9%82/"/>
      <url>/2018/08/01/Fibonacci%E6%95%B0%E5%88%97%E2%80%94%E2%80%94%E5%BF%AB%E9%80%9F%E7%9F%A9%E9%98%B5%E5%B9%82/</url>
      
        <content type="html"><![CDATA[<p>今天想起来之前一个oj题目，是求类似与斐波那契数列一个数列的第N位。那时候接触到一个算法叫快速矩阵幂。</p><p>在这里我就用斐波那契数列的列子来简单说明一下如何用快速矩阵幂来解决这个题目。<br><a id="more"></a></p><p>Fibonacci数列定义：$F(0) = 1, F(1) = 1, F(2) = 1, F(3) = 2, …… F(n) = F(n-1)+F(n-2)$</p><p>首先说明一下，因为斐波那契数列增长速度非常迅速，得到的数字可能过大，因此我们将结果对10000007（$10^7+7$）取余来进行对比。</p><h2 id="最天真的做法是用递归来解决："><a href="#最天真的做法是用递归来解决：" class="headerlink" title="最天真的做法是用递归来解决："></a>最天真的做法是用递归来解决：</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">fibNaive</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> (fibNaive(n<span class="number">-1</span>)%d+fibNaive(n<span class="number">-2</span>)%d)%d;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不用说了，算法第一步就会介绍这个反例，来说明递归效率不一定会高(他的算法的运行时间随n的增长类似与Fibonacci数列的增长)。实际上这个做法到n = 40的时候就已经可以让人等的有点急了。</p><h2 id="然后正常的做法是用简单的循环"><a href="#然后正常的做法是用简单的循环" class="headerlink" title="然后正常的做法是用简单的循环"></a>然后正常的做法是用简单的循环</h2><p>用两个数来代表之前的两个值，求出新值后继续依次更新前两个值，直到得到正确的结果：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">fibNormal</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>; </span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> last1 = <span class="number">0</span>,last2 = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> now;</span><br><span class="line">    n--;</span><br><span class="line">    <span class="keyword">while</span>(n--)</span><br><span class="line">    &#123;</span><br><span class="line">        now = (last1%d+last2%d)%d;</span><br><span class="line">        last1 = last2;</span><br><span class="line">        last2 = now;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> now;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个算法时间复杂度是$O(n)$。$O(n)$已经是一个很好的复杂度了，那还有没有办法继续加快这个过程？？</p><h2 id="快速矩阵幂"><a href="#快速矩阵幂" class="headerlink" title="快速矩阵幂"></a>快速矩阵幂</h2><p>观察斐波那契数列的生成过程，我们可以发现它们可以被写成下面的样子：</p><script type="math/tex; mode=display">F(N) = F(N-1) + F(N-2)F(N-1) = F(N-1)+0*F(N-2)</script><p>上面的式子可以写成矩阵形式：</p><script type="math/tex; mode=display">\left [\begin{matrix}F(N)\\F(N-1)\end{matrix}\right ] =\begin{bmatrix}1&1\\1&0\end{bmatrix}\begin{bmatrix}F(N-1)\\F(N-2)\end{bmatrix}</script><p>不断重复上面过程，往后继续展开，我们可以得到：</p><script type="math/tex; mode=display">\left [\begin{matrix}F(N)\\F(N-1)\end{matrix}\right ] ={\begin{bmatrix}1&1\\1&0\end{bmatrix}}^{n-1}\begin{bmatrix}F(1)\\F(0)\end{bmatrix}</script><p>因此我们可以把重点放到怎么来求中间这个矩阵的幂。而快速矩阵幂的思想也很简单，就类似与对于数字的幂的求法一致。比如：$X^9 = X^8 \cdot X$,而$X^8 = (X^4)^2 = ((X^2)^2)^2$，因此需要3+1次乘法就可以算出来8次幂，容易看出来快速矩阵幂的时间复杂度是$O(\log (n))$。<br>因此利用快速矩阵幂，可以将斐波那契数列的求法进一步加速。</p><p>至于如何实现就是细节问题了，需要注意的时候是乘法取余数的时候，两方都小于10000007,乘积依然可能会超过int的范围（10000007*10000007），导致出错，因此我在这里选择long long类型，这样可以保证结果的正确性。</p><p>实现分为几步1：定义矩阵乘法：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;&gt; Matrix;</span><br><span class="line"><span class="keyword">long</span> <span class="keyword">long</span> d = <span class="number">10000007</span>;</span><br><span class="line"><span class="function">Matrix <span class="title">m_mul</span><span class="params">(<span class="keyword">const</span> Matrix &amp;m,<span class="keyword">const</span> Matrix &amp;n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//check(m,n);</span></span><br><span class="line">    Matrix result = <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;&gt;(m.size(),<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;(n[<span class="number">0</span>].size()));</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">long</span> <span class="keyword">long</span> i = <span class="number">0</span>;i!=m.size();++i)</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">long</span> <span class="keyword">long</span> j = <span class="number">0</span>;j!=n[<span class="number">0</span>].size();++j)</span><br><span class="line">    &#123;</span><br><span class="line">         <span class="keyword">long</span> <span class="keyword">long</span> temp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">long</span> <span class="keyword">long</span> k = <span class="number">0</span>;k!=n.size();++k )</span><br><span class="line">         temp = ((m[i][k]*n[k][j])%d + temp%d)%d;</span><br><span class="line">         result[i][j] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p><p>第二，定义help函数，专门对矩阵的幂为2的整数次幂来计算：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function">Matrix <span class="title">help</span><span class="params">(<span class="keyword">const</span> Matrix &amp; m,<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix result;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> m;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(n == <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> m_mul(m,m);</span><br><span class="line">    result = help(m,n/<span class="number">2</span>);</span><br><span class="line">     <span class="keyword">return</span> m_mul(result,result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>第三步，实际的quickMartrixPower函数，它实际上会将n次幂拆散为2的整数次幂之和，实际实现将n用二进制表示，如9 = (1001)$_b$。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Matrix <span class="title">quickMatrixPower</span><span class="params">(<span class="keyword">const</span> Matrix &amp;m,<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//check(m);</span></span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> np = <span class="number">1</span>;</span><br><span class="line">    Matrix result = <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;&gt; (m.size(),<span class="built_in">vector</span>&lt;<span class="keyword">long</span> <span class="keyword">long</span>&gt;(m.size()));</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">long</span> <span class="keyword">long</span> i = <span class="number">0</span>;i!=m.size();++i)</span><br><span class="line">    result[i][i] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(n!=<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(n&amp;<span class="number">1</span>)</span><br><span class="line">        result = m_mul(result,help(m,np));</span><br><span class="line">        n = n &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        np = np&lt;&lt;<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后用fib函数封装起来：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">fib</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">       &#123;</span><br><span class="line">           Matrix start = &#123;&#123;<span class="number">1</span>,<span class="number">1</span>&#125;,&#123;<span class="number">1</span>,<span class="number">0</span>&#125;&#125;;</span><br><span class="line">           Matrix m = quickMatrixPower(start,n<span class="number">-1</span>);</span><br><span class="line">           <span class="keyword">return</span> m[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后用main函数利用clock函数进行时间测试<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> n,result;</span><br><span class="line">    <span class="keyword">double</span> start,end;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;n)</span><br><span class="line">    &#123;</span><br><span class="line">    start = clock();</span><br><span class="line">    result = fib(n);</span><br><span class="line">    end = clock();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;result&lt;&lt;<span class="string">" "</span>&lt;&lt;end-start&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    start = clock();</span><br><span class="line">    result = fibNormal(n);</span><br><span class="line">    end = clock();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;result&lt;&lt;<span class="string">" "</span>&lt;&lt;end-start&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    start = clock();</span><br><span class="line">    <span class="keyword">if</span>(n&lt;<span class="number">45</span>)</span><br><span class="line">    &#123;</span><br><span class="line">    result = fibNaive(n);</span><br><span class="line">    end = clock();</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;result&lt;&lt;<span class="string">" "</span>&lt;&lt;end-start&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>输出第一个为结果，第二个是运行的clock差值，结果如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入：<span class="number">40</span></span><br><span class="line"><span class="number">2334085</span> <span class="number">0</span></span><br><span class="line"><span class="number">2334085</span> <span class="number">0</span></span><br><span class="line"><span class="number">2334085</span> <span class="number">6956</span></span><br><span class="line">输入：<span class="number">1000000</span><span class="comment">//此时naive的算法已经无法求出来</span></span><br><span class="line"><span class="number">9640841</span> <span class="number">0</span></span><br><span class="line"><span class="number">9640841</span> <span class="number">19</span></span><br><span class="line">输入：<span class="number">100000000</span></span><br><span class="line"><span class="number">129680</span> <span class="number">0</span></span><br><span class="line"><span class="number">129680</span> <span class="number">3295</span></span><br></pre></td></tr></table></figure></p><p>可以看到快速矩阵幂算法在数据量很大的时候很牛逼。<br>不过，斐波那契数列还有个公式：</p><script type="math/tex; mode=display">F(n) = \frac{1}{\sqrt 5}{\left [ {\left ( \frac {1+\sqrt 5}{2} \right )}^n - {\left ( \frac {1-\sqrt 5}{2} \right )}^n  \right ]}</script><p>所以学计算机不如学数学啊！</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
            <tag> Matrix </tag>
            
            <tag> code </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——PLA算法实现与可视化</title>
      <link href="/2018/07/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94PLA%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
      <url>/2018/07/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94PLA%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>上次主要是证明了PLA算法的可行性，这次用来实现PLA算法，并且实现可视化。<br>这个算法的实现是比较简单的，比较难的部分在于要考虑可视化。<br><a id="more"></a><br>我选择python来实现这个算法，同时利用了matplotlib来进行图形的绘制。<br>为了可视化数据，我们需要的就不能是仅仅实现那么简单吗，而且还要考虑到可视化之后的清晰与美观。因此这部分的代码主要分成3个部分：</p><h2 id="随机生成数据"><a href="#随机生成数据" class="headerlink" title="随机生成数据"></a>随机生成数据</h2><p>数据的生成一定是要局限在某个范围内，为了简便我选择的数据特征量范围在0，20之间。而一维数据较为简单，高维数据画不出来，因此生成数据应该是二维或者三维的，以便于可视化。为了简便，我选择生成二维数据。<br>同时还要生成一组参数，作为$W_f$，也就是最初的规则，这里需要注意，随机生成的参数确定的分割线可能不会经过上述范围的数据，这样导致所有的样本都归为一类，这就失去了可视化的意义，因为生成参数时，我选择了在范围内随机生成两个点，用这两个点来确定分割线，再计算出对应的参数出来。</p><h2 id="PLA算法"><a href="#PLA算法" class="headerlink" title="PLA算法"></a>PLA算法</h2><p>pla算法没什么好说的，参数初始设为0，然后每次遇到一个坏点，就开始更正，直到没有坏点。我们需要保证传入的数据是线性可分的。</p><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>可视化使用matplotlib来实现，使用两种不同的标志（尽量区分颜色，如红x与绿o）来区分正负样本，在坐标轴上标出，并且用实线来绘制实际的规则，用虚线来绘制我们算法得到的规则。最后可以得到很明显的可视化效果。</p><h3 id="可视化结果"><a href="#可视化结果" class="headerlink" title="可视化结果"></a>可视化结果</h3><p>随机样本为20个：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/%5BNJ07J%7E9%29%286ZV0%2846%28S%40%29LN.png" alt="20"><br>修正次数： 3209</p><p>随机样本为50个：<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/NLYU%7EZSV%609S%29557%602RBG8%409.png" alt="50"></p><p>修正次数： 2268</p><p>随机样本为100个：</p><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/71K%251Y%7B%7D3K1HMRY%5DR%60K%29%25E8.png" alt="100"></p><p>修正次数： 4540</p><p>从图中可以看到虽然红线不一定与蓝线重合，但是依然很好的分割了样本。实际上相重合是很困难的，样本越是多越更有可能相似，如下图，样本次数提高到1000，我们可以说推断的规则与原先的规则已经基本一致了。<br><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/EQPB1J%7B5LY%7B%5B4V%24%7BK0N6%29CU.png" alt="1000"></p><p>我们从这里看不到修正次数与样本个数之间的关系，因为本来他们关系就不够大，甚至一定程度上可以说是”运气”，但是算法终究会停止，由上一篇博客的证明也可知道，如果R与P的比值很小，那么就算数据再大，也可以很快的得到想要的规则。</p><p>下面是PLA实现的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pla</span><span class="params">(datas)</span>:</span></span><br><span class="line">    size = len(datas)</span><br><span class="line">    <span class="keyword">if</span> size&lt;=<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    err_i = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    dms = len(datas[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> dms == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    para = [<span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,dms)]</span><br><span class="line">    run_times = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line"></span><br><span class="line">        run_times+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, size):</span><br><span class="line">            p = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, dms - <span class="number">1</span>):</span><br><span class="line">                p += para[x] * datas[i][x]</span><br><span class="line">            p += para[<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">if</span> p &lt;= <span class="number">0</span> <span class="keyword">and</span> datas[i][<span class="number">-1</span>] &gt; <span class="number">0</span> <span class="keyword">or</span> p &gt;= <span class="number">0</span> <span class="keyword">and</span> datas[i][<span class="number">-1</span>] &lt; <span class="number">0</span>:<span class="comment">#ignore datas[i][-1] == 0</span></span><br><span class="line">                err_i = i;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">if</span> err_i != <span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, dms - <span class="number">1</span>):</span><br><span class="line">                para[x] += datas[err_i][<span class="number">-1</span>] * datas[err_i][x]  <span class="comment"># update the parameters</span></span><br><span class="line">            para[<span class="number">-1</span>] += datas[err_i][<span class="number">-1</span>]</span><br><span class="line">            err_i = <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">else</span>:<span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [para,run_times]</span><br></pre></td></tr></table></figure></p><p>全部python代码可以在<a href="https://github.com/MyEvolution/PLA" target="_blank" rel="noopener">PLA</a>找到。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> code </tag>
            
            <tag> machine learning </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>markdown+mathjax显示公式，苦逼的找bug过程 </title>
      <link href="/2018/07/29/markdown-mathjax%E6%98%BE%E7%A4%BA%E5%85%AC%E5%BC%8F%EF%BC%8C%E8%8B%A6%E9%80%BC%E7%9A%84%E6%89%BEbug%E8%BF%87%E7%A8%8B/"/>
      <url>/2018/07/29/markdown-mathjax%E6%98%BE%E7%A4%BA%E5%85%AC%E5%BC%8F%EF%BC%8C%E8%8B%A6%E9%80%BC%E7%9A%84%E6%89%BEbug%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>在记录自己学习过程中，难免会遇到公式，截图的办法不是长久之计。于是我给它加上了渲染公式的过程。</p><p>整个过程非常崎岖。<br><a id="more"></a></p><p>其实很简单，在普通的页面上引入一个js文件，就可以将latex代码渲染成公式。为了方便编写，我直接在文章中引入了这个js，在vs code上渲染是非常成功的。但是在博客上怎么弄也没法成功。百度的话有很多相关的博客来介绍怎么去做，主要是因为hexo的渲染器与mathjax中部分语法有冲突。我也天真的相信我的问题就是这些构成的，后来我发现即使是最简单的公式（没有下标）也无法渲染成功，此时我的blog里已经加了很多别的没用包了，也删除了很多可能有用的包，怎么设置也没办法。</p><p>昨晚就纠结了很久，今天没办法了重新装了下blog，先解决最简单公式显示的问题（直接打开next主题中的mathjax开关），成功了，然后我遇到的问题，才是别人遇到的那些问题。慢慢解决，后来发现还是有部分错误，有两处问题：</p><p>1.这次是latex与markdown的冲突：markdown中的*是斜体，因此尽量乘法不要使用它，可以使用{a \times b}（$a \times b$）来代替来代替 a*b,或者就是对*进行转义，或者直接省略。</p><p>2.在使用范式时||a||，似乎直接使用‘|’这个符号也会出错，总之有范式的地方的公式显示是很混乱的，可能也有冲突（在latex是可以直接使用这个符号的），因此使用{\Vert a \Vert}（${\Vert a \Vert}$）来代替。</p><p>最后，浏览器响应github page的速度不快，可能已经deploy了但是依然没有体现出更新的结果。</p><p>哎，折腾了一天，感觉收获远远不够花费的时间，不过我经常遇到这样的问题，找bug的能力还有待提高。</p><h2 id="P-S-Markdown与latex常用语法"><a href="#P-S-Markdown与latex常用语法" class="headerlink" title="P.S. Markdown与latex常用语法"></a>P.S. Markdown与latex常用语法</h2><h3 id="markdown语法"><a href="#markdown语法" class="headerlink" title="markdown语法"></a>markdown语法</h3><ul><li>标题：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 一号字体 #</span><br><span class="line">## 二号字体 ## </span><br><span class="line">### 三号字体 ###</span><br></pre></td></tr></table></figure><h1 id="一号字体"><a href="#一号字体" class="headerlink" title="一号字体"></a>一号字体</h1><h2 id="二号字体"><a href="#二号字体" class="headerlink" title="二号字体"></a>二号字体</h2><h3 id="三号字体"><a href="#三号字体" class="headerlink" title="三号字体"></a>三号字体</h3><ul><li>加粗：</li></ul><p>要加粗的文字左右分别用两个*号包起来</p><ul><li>斜体：</li></ul><p>要倾斜的文字左右分别用一个*号包起来</p><ul><li>斜体加粗：</li></ul><p>要倾斜和加粗的文字左右分别用三个*号包起来</p><ul><li>删除线：</li></ul><p>要加删除线的文字左右分别用两个~~号包起来</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">**这是加粗的文字**</span><br><span class="line">*这是倾斜的文字*`</span><br><span class="line">***这是斜体加粗的文字***</span><br><span class="line">~~这是加删除线的文字~~</span><br></pre></td></tr></table></figure><p><strong>这是加粗的文字</strong></p><p><em>这是倾斜的文字</em></p><p><strong><em>这是斜体加粗的文字</em></strong></p><p><del>这是加删除线的文字</del></p><ul><li>引用：</li></ul><p>在引用的文字前加&gt;即可</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; 引用的内容</span><br></pre></td></tr></table></figure><blockquote><p>引用的内容</p></blockquote><ul><li>分割线：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">***</span><br></pre></td></tr></table></figure></li></ul><hr><hr><ul><li>超链接：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[name](url)</span><br></pre></td></tr></table></figure><p><a href="https://www.google.com" target="_blank" rel="noopener">Google</a></p><ul><li>图片：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![name](imgurl)</span><br></pre></td></tr></table></figure><p><img src="https://evolution-video.oss-cn-beijing.aliyuncs.com/images/IMG_8234.PNG" alt="name"></p><ul><li>列表：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 列表内容</span><br><span class="line">+ 列表内容</span><br><span class="line">* 列表内容</span><br></pre></td></tr></table></figure><pre><code>注意：- + * 跟内容之间都要有一个空格</code></pre><ul><li>列表内容</li></ul><ul><li>列表内容</li></ul><ul><li><p>列表内容</p></li><li><p>表格：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">表头|表头|表头</span><br><span class="line">---|:--:|---:</span><br><span class="line">内容|内容2|内容</span><br><span class="line">内容|内容100|内容</span><br></pre></td></tr></table></figure><p>第二行分割表头和内容。<br>文字默认居左<br>-两边加：表示文字居中<br>-右边加：表示文字居右<br>注：原生的语法两边都要用 | 包起来。此处省略</p><div class="table-container"><table><thead><tr><th>表头</th><th style="text-align:center">表头</th><th style="text-align:right">表头</th></tr></thead><tbody><tr><td>内容</td><td style="text-align:center">内容2</td><td style="text-align:right">内容</td></tr><tr><td>内容</td><td style="text-align:center">内容100</td><td style="text-align:right">内容</td></tr></tbody></table></div><ul><li>代码：</li></ul><p><code>单行代码</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">多行代码</span><br></pre></td></tr></table></figure></p><p>vscode中前面加制表符自动为代码格式。<br>可以在标记后标记出代码语言，用来高亮：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"hello,world"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="Latex语法"><a href="#Latex语法" class="headerlink" title="Latex语法"></a>Latex语法</h3><ul><li>希腊字母：</li></ul><div class="table-container"><table><thead><tr><th>显示</th><th>命令</th><th>显示</th><th>命令</th></tr></thead><tbody><tr><td>α</td><td>\alpha</td><td>β</td><td>\beta</td></tr><tr><td>γ</td><td>\gamma</td><td>δ</td><td>\delta</td></tr><tr><td>ε</td><td>\epsilon</td><td>ζ</td><td>\zeta</td></tr><tr><td>η</td><td>\eta</td><td>θ</td><td>\theta</td></tr><tr><td>ι</td><td>\iota</td><td>κ</td><td>\kappa</td></tr><tr><td>λ</td><td>\lambda</td><td>μ</td><td>\mu</td></tr><tr><td>ν</td><td>\nu</td><td>ξ</td><td>\xi</td></tr><tr><td>π</td><td>\pi</td><td>ρ</td><td>\rho</td></tr><tr><td>σ</td><td>\sigma</td><td>τ</td><td>\tau</td></tr><tr><td>υ</td><td>\upsilon</td><td>φ</td><td>\phi</td></tr><tr><td>χ</td><td>\chi</td><td>ψ</td><td>\psi</td></tr><tr><td>ω</td><td>\omega</td><td></td></tr></tbody></table></div><p>命令首字母大写则为显示为大写。</p><ul><li>字母修饰：</li></ul><p>上标：^</p><p>下标：_</p><p>举例：C_n^2 呈现为 $C_n^2$</p><p>矢量：</p><p>\vec a呈现为 $\vec a$</p><p>\overrightarrow{xy}呈现为$\overrightarrow{xy}$</p><ul><li>分组:</li></ul><p>使用{}将具有相同等级的内容扩入其中，成组处理</p><p> 举例：10^{10}呈现为$10^{10}$，而10^10呈现为$10^10$</p><ul><li>括号：<br>小括号：()呈现为()<br>中括号：[]呈现为[]<br>尖括号：\langle,\rangle呈现为$\langle,\rangle$</li></ul><p>大括号为与分组符号{}相区别，使用转义字符\</p><p>使用\left(或\right)使符号大小与邻近的公式相适应；该语句适用于所有括号类型</p><p>(\frac{x}{y})呈现为$(\frac{x}{y})$</p><p>而\left(\frac{x}{y}\right)呈现为$\left(\frac{x}{y}\right)$</p><ul><li>求和：</li></ul><p>求和符号\sum显示为$∑$</p><p>举例:\sum_{i=0}^n 显示为 $\sum_{i=0}^n$</p><ul><li>极限：</li></ul><p>极限符号\lim显示为$lim$</p><p>举例:\lim_{x\to\infty} </p><p>$<br>\lim_{x\to\infty}<br>$</p><ul><li>积分：</li></ul><div class="table-container"><table><thead><tr><th>命令</th><th>显示</th></tr></thead><tbody><tr><td>\int</td><td>∫</td></tr><tr><td>\iint</td><td>∬</td></tr><tr><td>\iiint</td><td>∭</td></tr><tr><td>\iiiint</td><td>∬∬</td></tr><tr><td>\oint</td><td>∮</td></tr></tbody></table></div><p>举例：\int_0^\infty{fxdx} 显示为<script type="math/tex">\int_0^\infty{f(x)dx}</script></p><ul><li>分式：</li></ul><p>\frac{公式1}{公式2}显示为$\frac{公式1}{公式2}$</p><p>举例:\frac a b $\frac a b$</p><ul><li><p>根号：<br>\sqrt[x]{y}显示为$\sqrt[x]{y}$</p></li><li><p>常见函数：</p></li></ul><p>\函数名</p><p>举例:\sin x,\ln x,\log_n^2 5,\max(A,B,C)显示为</p><script type="math/tex; mode=display">\sin x,\ln x,\log_n^2,\max(A,B,C)</script><p>暂时写这么些，还有很多其他用法，需要平时的积累。</p>]]></content>
      
      
      <categories>
          
          <category> 博客建设 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> markdown </tag>
            
            <tag> LaTex </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习——PLA</title>
      <link href="/2018/07/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94PLA/"/>
      <url>/2018/07/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94PLA/</url>
      
        <content type="html"><![CDATA[<p>对研究生要跟的导师还不确定，暑假打算学习点专业课与英语，也迟迟没有做好。我想不管哪个实验室应该都不会离开机器学习吧。因此开始看这方面的东西。</p><a id="more"></a><p>今天接触了一个算法叫<strong>PLA</strong>（Percetron Learning Algorithm）,用来做线性分类的算法。它应用的前提是样本集是线性可分的。用二维特征值的样本来举例子：</p><p><img src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=793659404,4189322929&amp;fm=27&amp;gp=0.jpg" alt="linear separable"></p><p>我们要的就是通过算法来找到这条线。对于二维的样本（特征分别为$x_1$,$x_2$）,则分类结果为-1，+1，分别表示为negative，positive（这与另一种常用的分类算法不一致）。思想就是每个特征对应一个参数，乘积之后如果大于某个阈值，则设定为分类结果为+1，小于则为-1。若为特征添加一个特征$ x_0 $恒等于一，则用向量化可以将分类过程写成如下形式：</p><script type="math/tex; mode=display">result(X) = sign(W{X^T})</script><p>其中W为特征的参数向量，我们使用$y$来表示样本真实类别。</p><p>整个算法的思想其实很简单，刚开始画出一条线，如果分错了，则往正确的方向旋转这条线。但是如何旋转这条线，旋转多少角度，还是很有意思的。一般的想法都是从图直观上来看，利用代价函数（cost function）来解决，不过对于这个简单的线性分类，用代价函数进行梯度下降还是相对来说计算量还是比较大的。这个算法让我觉得厉害的地方在于它向量化不光是为了提高计算效率，而是从向量的角度来考虑一步步向结果逼近的：遇到的分类错误有两种情况，如果$y$应该是正，但是$W{X^T}$得到的是负的，从向量角度来说，$W$与$X$的夹角太大，因此内积为负，我们要减小两个向量的角度，可以令$W=W+X$,相反，$y$应该是负，结果却为正，那么$W$与$X$的夹角太小，可以令$W=W-X$，这样就增大了夹角，从下图可以很直观的看出来这个道理：</p><p><img src="https://gss3.bdstatic.com/7Po3dSag_xI4khGkpoWK1HF6hhy/baike/c0%3Dbaike72%2C5%2C5%2C72%2C24/sign=71339aceab773912d02b8d339970ed7d/b3b7d0a20cf431ad4cdf9f4a4936acaf2edd98b0.jpg" alt="向量加减"></p><p>合并两种情况，则每次遇到被错误分类的样本$X_n$，我们对参数向量$W_t$进行如下更新（其中$t$表示修正的次数）：<script type="math/tex">W_{t+1} = W_t + y_nX_n</script><br>下面主要来证明一下，对于线性可分的样本来说，这个算法一定会停止，找到那条符合的参数向量$W_f$。我们可以知道：</p><script type="math/tex; mode=display">y_n{W_f}^TX_n >= _{min}[ y_nX_nW_f^T]>0</script><p>而</p><script type="math/tex; mode=display">W_{t+1}W_f^T = W_tW_f^t + y_nX_nW_f^T >= W_tW_f^T + _{min}[ y_nX_nW_f^T]</script><p>因此我们可以得到：</p><script type="math/tex; mode=display">W_{t+1}W_f^T >= W_tW_f^T >= W_0W_f^T +(t+1) *_{min}[ y_nX_nW_f^T]</script><p>因为我们每次找到一个出错点才进行修正，出错点为（$X_n,y_n$），可以知道$ y_nW_tX_n^T&lt;0 $，则：</p><script type="math/tex; mode=display">\Vert W_{t+1} \Vert ^2 = \Vert W_t \Vert ^2 + \Vert y_nX_n \Vert ^2+2y_nW_tX_n^T>= \Vert W_t \Vert ^2+_{max}[ \Vert X_n \Vert ^2]</script><p>因此我们可以得到：</p><script type="math/tex; mode=display"> \Vert W_{t+1} \Vert ^2 = \Vert W_t \Vert ^2 +  \Vert y_nX_n \Vert ^2+2 \times y_nW_tX_n^T>= \Vert W_0 \Vert ^2+ (t+1) \times _{max}[ \Vert X_n \Vert ^2]</script><p>最后，假设最开始$W_0=0$，通过正规化，我们可以算出$W_t$与$W_f$之间的角度是不断逼近的（角度重合时候也就得到了正确的参数，实际上角度相同后我们不在乎向量的模的大小，因为它不会影响$W_t^TX_n$的符号）：</p><script type="math/tex; mode=display">\frac{W_tW_f^T}{ \Vert W_t \Vert  \Vert W_f \Vert } >= \frac{t \times _{min}[y_nW_fX_n]}{\sqrt{t} \times _{max} \Vert X_n \Vert  \Vert W_f \Vert } = \sqrt{t} \frac q R</script><p>其中：$q = _{min}[y_nW_fX_n],R^2 = ( _{max} \Vert X_n \Vert  )^2$，而正规化后内积是小于等于1的（此时方向一致），可以得到$ t&lt;=\frac {R^2} {q^2} $，可以得到，最多经过$\frac {R^2} {q^2} $次修正即可得到正确结果。</p><p>到这里就证明结束了,以后会上传相关的代码。</p><p>可以看到虽然算法实现很简单，但其中的推理还是不容易的。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> classification </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
